{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7e8113-fc6b-42be-9a3c-685830458daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 1:  cuda:2\n",
      "Device 2:  cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "# from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import loadmat,savemat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device1 = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "device2 = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Device 1: \",device1)\n",
    "print(\"Device 2: \",device2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e12c536f-3169-48e3-82a1-915d437b21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "R0 = 5.36 #mm 5.36\n",
    "Rs = 19 #mm\n",
    "mu_vis = 0.3 \n",
    "mu = 0.3 #Friction Coefficient (not viscosity)\n",
    "delta = 0.5\n",
    "A = 6.41 #For slip factor\n",
    "pi = np.pi\n",
    "Omega = 600 #rpm\n",
    "V = 1 #mm/s\n",
    "F = 0.67 #mm\n",
    "rho = 2700 * 1e-6 #g/mm3\n",
    "k_B = 1.380649*1e-23 #J/K\n",
    "R = 8.314 #J/(K.mol)\n",
    "E_a = 205000 #J/mol #Q\n",
    "alpha_sig = 52 #mm^2/(kN)\n",
    "# A = np.exp(27.78)\n",
    "log_A = 27.78\n",
    "n = 3.49\n",
    "\n",
    "k = 0.167 #Thermal Conductivity #W/(mmK)\n",
    "c_p = 0.897 #J/gK \n",
    "alpha_m = k/(rho*c_p)\n",
    "T_a = 298.0\n",
    "\n",
    "\n",
    "k_t = 0.0176 #W/(mmK)\n",
    "c_p_t = 0.46 #J/gk\n",
    "rho_t = 7750 * 1e-6 #g/mm3\n",
    "alpha_t = k_t/(rho_t*c_p_t)\n",
    "\n",
    "h_sides = 5*1e-6 #W/mm^2K\n",
    "C_bot = 0.15*1e-6 #W/mm^2K^3\n",
    "\n",
    "eeta = alpha_m/(alpha_m+alpha_t)\n",
    "\n",
    "lb_xyz_uvw = np.array([-50.0,-20.0,-3.0])\n",
    "ub_xyz_uvw = np.array([50.0,20.0,0.0])\n",
    "\n",
    "\n",
    "lb_xyz = np.array([-50.0,-20.0,-3.0])\n",
    "ub_xyz = np.array([50.0,20.0,0.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb877af0-8a4e-4628-b94d-de92a0d130bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat,uvw_true_top,r_fr_ph_out):\n",
    "    # def closure():\n",
    "    optimizer.zero_grad()\n",
    "    #model_PINN.zero_grad()\n",
    "    loss_uvw,loss_T = model_PINN.loss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat,uvw_true_top,r_fr_ph_out)\n",
    "    # loss_uvw.backward()\n",
    "    loss_T.backward()\n",
    "\n",
    "        # return loss\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5478b554-59b5-4825-95bb-acf6c27211d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep,n_batches):\n",
    "    print(rep)\n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot, uvw_true_top,r_fr_ph_out = trainingdata_uvw(N_B,N_f,lb_xyz,ub_xyz,rep*123)\n",
    "    xyz_coll = torch.from_numpy(xyz_coll).float()#.to(device)\n",
    "    xyz_1 = torch.from_numpy(xyz_1).float()#.to(device)\n",
    "    xyz_2 = torch.from_numpy(xyz_2).float()#.to(device)\n",
    "    xyz_3 = torch.from_numpy(xyz_3).float()#.to(device)\n",
    "    xyz_4 = torch.from_numpy(xyz_4).float()#.to(device)\n",
    "    r_fr_ph_out = torch.from_numpy(r_fr_ph_out).float()\n",
    "    \n",
    "    xyz_top = torch.from_numpy(xyz_top).float()#.to(device)\n",
    "    xyz_bot = torch.from_numpy(xyz_bot).float()#.to(device)\n",
    "   \n",
    "    uvw_true_top = torch.from_numpy(uvw_true_top).float().to(device1)\n",
    "    f_hat = torch.zeros(xyz_coll.shape[0],1)#.to(device1)\n",
    "    N_hat = torch.zeros(xyz_top.shape[0],1).to(device2)\n",
    "    \n",
    "\n",
    "    #pretrain\n",
    "    # for i in range(50):\n",
    "    #     optimizer.zero_grad()\n",
    "    #     loss_pretrain = model_PINN.pretrain_T_loss(xyz_coll)\n",
    "    #     loss_pretrain.backward()\n",
    "    #     optimizer.step()\n",
    "        \n",
    "    # print(\"Pretrained with T = 300.0\")\n",
    "    \n",
    "    #Batching only Collocation and f_hat for now\n",
    "    \n",
    "    # batch_size_coll = int(xyz_coll.shape[0]/n_batches)\n",
    "    # batch_size_top = int(xyz_top.shape[0]/n_batches)\n",
    "\n",
    "    # batch_size_sides = int(xyz_1.shape[0]/n_batches)\n",
    "    # batch_size_bot = int(xyz_bot.shape[0]/n_batches)\n",
    "\n",
    "    # xyz_coll_batches = torch.split(xyz_coll,batch_size_coll)\n",
    "    # f_hat_batches = torch.split(f_hat,batch_size_coll)\n",
    "    \n",
    "    # xyz_top_batches = torch.split(xyz_top,batch_size_top)\n",
    "    # N_hat_batches = torch.split(N_hat,batch_size_top)\n",
    "\n",
    "    # xyz_1_batches = torch.split(xyz_1,batch_size_sides)\n",
    "    # xyz_2_batches = torch.split(xyz_2,batch_size_sides)\n",
    "    # xyz_3_batches = torch.split(xyz_3,batch_size_sides)\n",
    "    # xyz_4_batches = torch.split(xyz_4,batch_size_sides)\n",
    "    \n",
    "    # xyz_bot_batches = torch.split(xyz_4,batch_size_bot)\n",
    "\n",
    "    # uvw_true_top_batches = torch.split(uvw_true_top,batch_size_top)\n",
    "    # r_fr_ph_out_batches = torch.split(r_fr_ph_out,batch_size_top)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "#         if(i>0 and i%50==0):\n",
    "#             _,_,_,_,_,xyz_top,xyz_bot = trainingdata(N_B,N_f,i*123)\n",
    "#             # xyz_coll = torch.from_numpy(xyz_coll).float().to(device)\n",
    "#             # xyz_1 = torch.from_numpy(xyz_1).float().to(device)\n",
    "#             # xyz_2 = torch.from_numpy(xyz_2).float().to(device)\n",
    "#             # xyz_3 = torch.from_numpy(xyz_3).float().to(device)\n",
    "#             # xyz_4 = torch.from_numpy(xyz_4).float().to(device)\n",
    "\n",
    "#             xyz_top = torch.from_numpy(xyz_top).float().to(device)\n",
    "#             xyz_bot = torch.from_numpy(xyz_bot).float().to(device)\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        # for b in range(n_batches):\n",
    "        #     loss_uvw,loss_T = model_PINN.loss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat,uvw_true_top,r_fr_ph_out)\n",
    "        #     loss_uvw.backward()\n",
    "        #     loss_T.backward()\n",
    "\n",
    "        # optimizer.step()\n",
    "        \n",
    "        # train_step(xyz_coll_batches[b],xyz_1_batches[b], xyz_2_batches[b], xyz_3_batches[b], xyz_4_batches[b],xyz_top_batches[b],xyz_bot_batches[b],f_hat_batches[b],N_hat_batches[b],uvw_true_top_batches[b],r_fr_ph_out_batches[b])\n",
    "            \n",
    "\n",
    "        train_step(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat,uvw_true_top,r_fr_ph_out)\n",
    "        # loss_np = PINN.loss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat).cpu().detach().numpy()\n",
    "        # print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "        loss_np1,loss_np2 = model_PINN.loss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat,uvw_true_top,r_fr_ph_out)\n",
    "        loss_np = loss_np1.cpu().detach().numpy() + loss_np2.cpu().detach().numpy()\n",
    "        print(i,\"Train Loss\",loss_np)\n",
    "\n",
    "        # if(i>0 and i%25 ==0):\n",
    "        #   pretrain(xyt_DBC,p_iters)\n",
    "\n",
    "        if(loss_np<10.0):\n",
    "            print(\"Loss Less than 7.5...\")\n",
    "            break\n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b5a6e4a-7ebc-437a-a707-0b7256025237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "Loss  2320.2893 C_bot  0.15 k_c 0.0\n",
      "Loss  40834.02 C_bot  0.15 k_c 0.0\n",
      "0 Train Loss 40890.676\n",
      "Loss  40834.02 C_bot  0.15 k_c 0.0\n",
      "Loss  4859.661 C_bot  0.15 k_c 0.0\n",
      "1 Train Loss 4885.377\n",
      "Loss  4859.661 C_bot  0.15 k_c 0.0\n",
      "Loss  7565.4375 C_bot  0.15 k_c 0.0\n",
      "2 Train Loss 7583.4062\n",
      "Loss  7565.4375 C_bot  0.15 k_c 0.0\n",
      "Loss  13565.044 C_bot  0.15 k_c 0.0\n",
      "3 Train Loss 13590.315\n",
      "Loss  13565.044 C_bot  0.15 k_c 0.0\n",
      "Loss  6206.05 C_bot  0.15 k_c 0.0\n",
      "4 Train Loss 6241.9844\n",
      "Loss  6206.05 C_bot  0.15 k_c 0.0\n",
      "Loss  960.20245 C_bot  0.15 k_c 0.0\n",
      "5 Train Loss 1016.60284\n",
      "Loss  960.20245 C_bot  0.15 k_c 0.0\n",
      "Loss  3618.3286 C_bot  0.15 k_c 0.0\n",
      "6 Train Loss 3706.9788\n",
      "Loss  3618.3286 C_bot  0.15 k_c 0.0\n",
      "Loss  7103.645 C_bot  0.15 k_c 0.0\n",
      "7 Train Loss 7219.0645\n",
      "Loss  7103.645 C_bot  0.15 k_c 0.0\n",
      "Loss  5927.2256 C_bot  0.15 k_c 0.0\n",
      "8 Train Loss 6044.6113\n",
      "Loss  5927.2256 C_bot  0.15 k_c 0.0\n",
      "Loss  2290.2266 C_bot  0.15 k_c 0.0\n",
      "9 Train Loss 2391.5034\n",
      "Loss  2290.2266 C_bot  0.15 k_c 0.0\n",
      "Loss  531.0538 C_bot  0.15 k_c 0.0\n",
      "10 Train Loss 612.99347\n",
      "Loss  531.0538 C_bot  0.15 k_c 0.0\n",
      "Loss  1817.5436 C_bot  0.15 k_c 0.0\n",
      "11 Train Loss 1886.7379\n",
      "Loss  1817.5436 C_bot  0.15 k_c 0.0\n",
      "Loss  3363.143 C_bot  0.15 k_c 0.0\n",
      "12 Train Loss 3428.5605\n",
      "Loss  3363.143 C_bot  0.15 k_c 0.0\n",
      "Loss  2795.768 C_bot  0.15 k_c 0.0\n",
      "13 Train Loss 2865.77\n",
      "Loss  2795.768 C_bot  0.15 k_c 0.0\n",
      "Loss  1070.8047 C_bot  0.15 k_c 0.0\n",
      "14 Train Loss 1153.7043\n",
      "Loss  1070.8047 C_bot  0.15 k_c 0.0\n",
      "Loss  362.17453 C_bot  0.15 k_c 0.0\n",
      "15 Train Loss 464.68756\n",
      "Loss  362.17453 C_bot  0.15 k_c 0.0\n",
      "Loss  1186.1229 C_bot  0.15 k_c 0.0\n",
      "16 Train Loss 1308.3933\n",
      "Loss  1186.1229 C_bot  0.15 k_c 0.0\n",
      "Loss  2153.4438 C_bot  0.15 k_c 0.0\n",
      "17 Train Loss 2286.1204\n",
      "Loss  2153.4438 C_bot  0.15 k_c 0.0\n",
      "Loss  1952.9679 C_bot  0.15 k_c 0.0\n",
      "18 Train Loss 2081.5234\n",
      "Loss  1952.9679 C_bot  0.15 k_c 0.0\n",
      "Loss  832.8349 C_bot  0.15 k_c 0.0\n",
      "19 Train Loss 945.7101\n",
      "Loss  832.8349 C_bot  0.15 k_c 0.0\n",
      "Loss  55.98624 C_bot  0.15 k_c 0.0\n",
      "20 Train Loss 149.48218\n",
      "Loss  55.98624 C_bot  0.15 k_c 0.0\n",
      "Loss  357.9579 C_bot  0.15 k_c 0.0\n",
      "21 Train Loss 435.61298\n",
      "Loss  357.9579 C_bot  0.15 k_c 0.0\n",
      "Loss  1115.3705 C_bot  0.15 k_c 0.0\n",
      "22 Train Loss 1183.903\n",
      "Loss  1115.3705 C_bot  0.15 k_c 0.0\n",
      "Loss  1248.1166 C_bot  0.15 k_c 0.0\n",
      "23 Train Loss 1314.0515\n",
      "Loss  1248.1166 C_bot  0.15 k_c 0.0\n",
      "Loss  678.25836 C_bot  0.15 k_c 0.0\n",
      "24 Train Loss 746.95874\n",
      "Loss  678.25836 C_bot  0.15 k_c 0.0\n",
      "Loss  228.73383 C_bot  0.15 k_c 0.0\n",
      "25 Train Loss 304.1095\n",
      "Loss  228.73383 C_bot  0.15 k_c 0.0\n",
      "Loss  359.95355 C_bot  0.15 k_c 0.0\n",
      "26 Train Loss 443.1928\n",
      "Loss  359.95355 C_bot  0.15 k_c 0.0\n",
      "Loss  667.9095 C_bot  0.15 k_c 0.0\n",
      "27 Train Loss 756.16943\n",
      "Loss  667.9095 C_bot  0.15 k_c 0.0\n",
      "Loss  618.2725 C_bot  0.15 k_c 0.0\n",
      "28 Train Loss 705.74927\n",
      "Loss  618.2725 C_bot  0.15 k_c 0.0\n",
      "Loss  273.3465 C_bot  0.15 k_c 0.0\n",
      "29 Train Loss 354.59647\n",
      "Loss  273.3465 C_bot  0.15 k_c 0.0\n",
      "Loss  95.98362 C_bot  0.15 k_c 0.0\n",
      "30 Train Loss 168.67088\n",
      "Loss  95.98362 C_bot  0.15 k_c 0.0\n",
      "Loss  279.6389 C_bot  0.15 k_c 0.0\n",
      "31 Train Loss 344.83234\n",
      "Loss  279.6389 C_bot  0.15 k_c 0.0\n",
      "Loss  513.59796 C_bot  0.15 k_c 0.0\n",
      "32 Train Loss 574.14404\n",
      "Loss  513.59796 C_bot  0.15 k_c 0.0\n",
      "Loss  448.3255 C_bot  0.15 k_c 0.0\n",
      "33 Train Loss 507.22647\n",
      "Loss  448.3255 C_bot  0.15 k_c 0.0\n",
      "Loss  171.51965 C_bot  0.15 k_c 0.0\n",
      "34 Train Loss 231.12154\n",
      "Loss  171.51965 C_bot  0.15 k_c 0.0\n",
      "Loss  31.90358 C_bot  0.15 k_c 0.0\n",
      "35 Train Loss 93.3732\n",
      "Loss  31.90358 C_bot  0.15 k_c 0.0\n",
      "Loss  139.73874 C_bot  0.15 k_c 0.0\n",
      "36 Train Loss 202.57614\n",
      "Loss  139.73874 C_bot  0.15 k_c 0.0\n",
      "Loss  268.42453 C_bot  0.15 k_c 0.0\n",
      "37 Train Loss 330.64758\n",
      "Loss  268.42453 C_bot  0.15 k_c 0.0\n",
      "Loss  221.5895 C_bot  0.15 k_c 0.0\n",
      "38 Train Loss 280.8806\n",
      "Loss  221.5895 C_bot  0.15 k_c 0.0\n",
      "Loss  90.38654 C_bot  0.15 k_c 0.0\n",
      "39 Train Loss 145.45879\n",
      "Loss  90.38654 C_bot  0.15 k_c 0.0\n",
      "Loss  68.04227 C_bot  0.15 k_c 0.0\n",
      "40 Train Loss 119.16276\n",
      "Loss  68.04227 C_bot  0.15 k_c 0.0\n",
      "Loss  150.27574 C_bot  0.15 k_c 0.0\n",
      "41 Train Loss 198.76028\n",
      "Loss  150.27574 C_bot  0.15 k_c 0.0\n",
      "Loss  172.061 C_bot  0.15 k_c 0.0\n",
      "42 Train Loss 219.42801\n",
      "Loss  172.061 C_bot  0.15 k_c 0.0\n",
      "Loss  85.44849 C_bot  0.15 k_c 0.0\n",
      "43 Train Loss 132.9409\n",
      "Loss  85.44849 C_bot  0.15 k_c 0.0\n",
      "Loss  19.932186 C_bot  0.15 k_c 0.0\n",
      "44 Train Loss 68.32852\n",
      "Loss  19.932186 C_bot  0.15 k_c 0.0\n",
      "Loss  61.297207 C_bot  0.15 k_c 0.0\n",
      "45 Train Loss 110.64701\n",
      "Loss  61.297207 C_bot  0.15 k_c 0.0\n",
      "Loss  127.65568 C_bot  0.15 k_c 0.0\n",
      "46 Train Loss 177.15265\n",
      "Loss  127.65568 C_bot  0.15 k_c 0.0\n",
      "Loss  112.43021 C_bot  0.15 k_c 0.0\n",
      "47 Train Loss 160.84898\n",
      "Loss  112.43021 C_bot  0.15 k_c 0.0\n",
      "Loss  42.298233 C_bot  0.15 k_c 0.0\n",
      "48 Train Loss 88.79023\n",
      "Loss  42.298233 C_bot  0.15 k_c 0.0\n",
      "Loss  17.913462 C_bot  0.15 k_c 0.0\n",
      "49 Train Loss 62.440105\n",
      "Loss  17.913462 C_bot  0.15 k_c 0.0\n",
      "Loss  55.296143 C_bot  0.15 k_c 0.0\n",
      "50 Train Loss 98.39825\n",
      "Loss  55.296143 C_bot  0.15 k_c 0.0\n",
      "Loss  77.23381 C_bot  0.15 k_c 0.0\n",
      "51 Train Loss 119.57132\n",
      "Loss  77.23381 C_bot  0.15 k_c 0.0\n",
      "Loss  48.07049 C_bot  0.15 k_c 0.0\n",
      "52 Train Loss 90.181305\n",
      "Loss  48.07049 C_bot  0.15 k_c 0.0\n",
      "Loss  20.389103 C_bot  0.15 k_c 0.0\n",
      "53 Train Loss 62.622906\n",
      "Loss  20.389103 C_bot  0.15 k_c 0.0\n",
      "Loss  33.439102 C_bot  0.15 k_c 0.0\n",
      "54 Train Loss 75.853806\n",
      "Loss  33.439102 C_bot  0.15 k_c 0.0\n",
      "Loss  51.872482 C_bot  0.15 k_c 0.0\n",
      "55 Train Loss 94.16013\n",
      "Loss  51.872482 C_bot  0.15 k_c 0.0\n",
      "Loss  36.510212 C_bot  0.15 k_c 0.0\n",
      "56 Train Loss 78.16899\n",
      "Loss  36.510212 C_bot  0.15 k_c 0.0\n",
      "Loss  10.438384 C_bot  0.15 k_c 0.0\n",
      "57 Train Loss 51.114777\n",
      "Loss  10.438384 C_bot  0.15 k_c 0.0\n",
      "Loss  13.576792 C_bot  0.15 k_c 0.0\n",
      "58 Train Loss 53.253136\n",
      "Loss  13.576792 C_bot  0.15 k_c 0.0\n",
      "Loss  34.793713 C_bot  0.15 k_c 0.0\n",
      "59 Train Loss 73.70347\n",
      "Loss  34.793713 C_bot  0.15 k_c 0.0\n",
      "Loss  35.828587 C_bot  0.15 k_c 0.0\n",
      "60 Train Loss 74.27955\n",
      "Loss  35.828587 C_bot  0.15 k_c 0.0\n",
      "Loss  16.509789 C_bot  0.15 k_c 0.0\n",
      "61 Train Loss 54.766296\n",
      "Loss  16.509789 C_bot  0.15 k_c 0.0\n",
      "Loss  8.235223 C_bot  0.15 k_c 0.0\n",
      "62 Train Loss 46.42905\n",
      "Loss  8.235223 C_bot  0.15 k_c 0.0\n",
      "Loss  17.78325 C_bot  0.15 k_c 0.0\n",
      "63 Train Loss 55.83515\n",
      "Loss  17.78325 C_bot  0.15 k_c 0.0\n",
      "Loss  22.234514 C_bot  0.15 k_c 0.0\n",
      "64 Train Loss 59.887184\n",
      "Loss  22.234514 C_bot  0.15 k_c 0.0\n",
      "Loss  13.510923 C_bot  0.15 k_c 0.0\n",
      "65 Train Loss 50.505524\n",
      "Loss  13.510923 C_bot  0.15 k_c 0.0\n",
      "Loss  8.84753 C_bot  0.15 k_c 0.0\n",
      "66 Train Loss 45.091427\n",
      "Loss  8.84753 C_bot  0.15 k_c 0.0\n",
      "Loss  15.424654 C_bot  0.15 k_c 0.0\n",
      "67 Train Loss 51.00741\n",
      "Loss  15.424654 C_bot  0.15 k_c 0.0\n",
      "Loss  18.355135 C_bot  0.15 k_c 0.0\n",
      "68 Train Loss 53.458645\n",
      "Loss  18.355135 C_bot  0.15 k_c 0.0\n",
      "Loss  10.53576 C_bot  0.15 k_c 0.0\n",
      "69 Train Loss 45.350853\n",
      "Loss  10.53576 C_bot  0.15 k_c 0.0\n",
      "Loss  5.0126886 C_bot  0.15 k_c 0.0\n",
      "70 Train Loss 39.673378\n",
      "Loss  5.0126886 C_bot  0.15 k_c 0.0\n",
      "Loss  9.442007 C_bot  0.15 k_c 0.0\n",
      "71 Train Loss 43.9543\n",
      "Loss  9.442007 C_bot  0.15 k_c 0.0\n",
      "Loss  13.469641 C_bot  0.15 k_c 0.0\n",
      "72 Train Loss 47.69471\n",
      "Loss  13.469641 C_bot  0.15 k_c 0.0\n",
      "Loss  9.53682 C_bot  0.15 k_c 0.0\n",
      "73 Train Loss 43.285908\n",
      "Loss  9.53682 C_bot  0.15 k_c 0.0\n",
      "Loss  5.2701917 C_bot  0.15 k_c 0.0\n",
      "74 Train Loss 38.439163\n",
      "Loss  5.2701917 C_bot  0.15 k_c 0.0\n",
      "Loss  7.2110047 C_bot  0.15 k_c 0.0\n",
      "75 Train Loss 39.833195\n",
      "Loss  7.2110047 C_bot  0.15 k_c 0.0\n",
      "Loss  9.5741205 C_bot  0.15 k_c 0.0\n",
      "76 Train Loss 41.77459\n",
      "Loss  9.5741205 C_bot  0.15 k_c 0.0\n",
      "Loss  7.2389817 C_bot  0.15 k_c 0.0\n",
      "77 Train Loss 39.159973\n",
      "Loss  7.2389817 C_bot  0.15 k_c 0.0\n",
      "Loss  5.0145273 C_bot  0.15 k_c 0.0\n",
      "78 Train Loss 36.753372\n",
      "Loss  5.0145273 C_bot  0.15 k_c 0.0\n",
      "Loss  6.675354 C_bot  0.15 k_c 0.0\n",
      "79 Train Loss 38.239468\n",
      "Loss  6.675354 C_bot  0.15 k_c 0.0\n",
      "Loss  7.829658 C_bot  0.15 k_c 0.0\n",
      "80 Train Loss 39.135056\n",
      "Loss  7.829658 C_bot  0.15 k_c 0.0\n",
      "Loss  5.582551 C_bot  0.15 k_c 0.0\n",
      "81 Train Loss 36.516434\n",
      "Loss  5.582551 C_bot  0.15 k_c 0.0\n",
      "Loss  4.0420337 C_bot  0.15 k_c 0.0\n",
      "82 Train Loss 34.545044\n",
      "Loss  4.0420337 C_bot  0.15 k_c 0.0\n",
      "Loss  5.6604166 C_bot  0.15 k_c 0.0\n",
      "83 Train Loss 35.760338\n",
      "Loss  5.6604166 C_bot  0.15 k_c 0.0\n",
      "Loss  6.784079 C_bot  0.15 k_c 0.0\n",
      "84 Train Loss 36.569206\n",
      "Loss  6.784079 C_bot  0.15 k_c 0.0\n",
      "Loss  5.2964096 C_bot  0.15 k_c 0.0\n",
      "85 Train Loss 34.86377\n",
      "Loss  5.2964096 C_bot  0.15 k_c 0.0\n",
      "Loss  4.132465 C_bot  0.15 k_c 0.0\n",
      "86 Train Loss 33.538795\n",
      "Loss  4.132465 C_bot  0.15 k_c 0.0\n",
      "Loss  4.8236303 C_bot  0.15 k_c 0.0\n",
      "87 Train Loss 34.056545\n",
      "Loss  4.8236303 C_bot  0.15 k_c 0.0\n",
      "Loss  5.091457 C_bot  0.15 k_c 0.0\n",
      "88 Train Loss 34.08238\n",
      "Loss  5.091457 C_bot  0.15 k_c 0.0\n",
      "Loss  4.1772885 C_bot  0.15 k_c 0.0\n",
      "89 Train Loss 32.85456\n",
      "Loss  4.1772885 C_bot  0.15 k_c 0.0\n",
      "Loss  4.0494304 C_bot  0.15 k_c 0.0\n",
      "90 Train Loss 32.39018\n",
      "Loss  4.0494304 C_bot  0.15 k_c 0.0\n",
      "Loss  4.845616 C_bot  0.15 k_c 0.0\n",
      "91 Train Loss 32.88707\n",
      "Loss  4.845616 C_bot  0.15 k_c 0.0\n",
      "Loss  4.6915493 C_bot  0.15 k_c 0.0\n",
      "92 Train Loss 32.50447\n",
      "Loss  4.6915493 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7372267 C_bot  0.15 k_c 0.0\n",
      "93 Train Loss 31.386013\n",
      "Loss  3.7372267 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6559067 C_bot  0.15 k_c 0.0\n",
      "94 Train Loss 31.16481\n",
      "Loss  3.6559067 C_bot  0.15 k_c 0.0\n",
      "Loss  4.189803 C_bot  0.15 k_c 0.0\n",
      "95 Train Loss 31.531967\n",
      "Loss  4.189803 C_bot  0.15 k_c 0.0\n",
      "Loss  4.0385375 C_bot  0.15 k_c 0.0\n",
      "96 Train Loss 31.159155\n",
      "Loss  4.0385375 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5834599 C_bot  0.15 k_c 0.0\n",
      "97 Train Loss 30.44238\n",
      "Loss  3.5834599 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7370412 C_bot  0.15 k_c 0.0\n",
      "98 Train Loss 30.336515\n",
      "Loss  3.7370412 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9707677 C_bot  0.15 k_c 0.0\n",
      "99 Train Loss 30.35037\n",
      "Loss  3.9707677 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6716223 C_bot  0.15 k_c 0.0\n",
      "100 Train Loss 29.881296\n",
      "Loss  3.6716223 C_bot  0.15 k_c 0.0\n",
      "Loss  3.437454 C_bot  0.15 k_c 0.0\n",
      "101 Train Loss 29.508495\n",
      "Loss  3.437454 C_bot  0.15 k_c 0.0\n",
      "Loss  3.622594 C_bot  0.15 k_c 0.0\n",
      "102 Train Loss 29.55209\n",
      "Loss  3.622594 C_bot  0.15 k_c 0.0\n",
      "Loss  3.635283 C_bot  0.15 k_c 0.0\n",
      "103 Train Loss 29.393433\n",
      "Loss  3.635283 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3531485 C_bot  0.15 k_c 0.0\n",
      "104 Train Loss 28.909122\n",
      "Loss  3.3531485 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3335998 C_bot  0.15 k_c 0.0\n",
      "105 Train Loss 28.679693\n",
      "Loss  3.3335998 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5372298 C_bot  0.15 k_c 0.0\n",
      "106 Train Loss 28.693476\n",
      "Loss  3.5372298 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4776688 C_bot  0.15 k_c 0.0\n",
      "107 Train Loss 28.477385\n",
      "Loss  3.4776688 C_bot  0.15 k_c 0.0\n",
      "Loss  3.274389 C_bot  0.15 k_c 0.0\n",
      "108 Train Loss 28.143183\n",
      "Loss  3.274389 C_bot  0.15 k_c 0.0\n",
      "Loss  3.275341 C_bot  0.15 k_c 0.0\n",
      "109 Train Loss 28.016836\n",
      "Loss  3.275341 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3143814 C_bot  0.15 k_c 0.0\n",
      "110 Train Loss 27.91142\n",
      "Loss  3.3143814 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2157557 C_bot  0.15 k_c 0.0\n",
      "111 Train Loss 27.646406\n",
      "Loss  3.2157557 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1948252 C_bot  0.15 k_c 0.0\n",
      "112 Train Loss 27.450567\n",
      "Loss  3.1948252 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2928166 C_bot  0.15 k_c 0.0\n",
      "113 Train Loss 27.38509\n",
      "Loss  3.2928166 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2639277 C_bot  0.15 k_c 0.0\n",
      "114 Train Loss 27.216097\n",
      "Loss  3.2639277 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1353576 C_bot  0.15 k_c 0.0\n",
      "115 Train Loss 26.96795\n",
      "Loss  3.1353576 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1175175 C_bot  0.15 k_c 0.0\n",
      "116 Train Loss 26.836702\n",
      "Loss  3.1175175 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1500568 C_bot  0.15 k_c 0.0\n",
      "117 Train Loss 26.746517\n",
      "Loss  3.1500568 C_bot  0.15 k_c 0.0\n",
      "Loss  3.105239 C_bot  0.15 k_c 0.0\n",
      "118 Train Loss 26.564186\n",
      "Loss  3.105239 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0758326 C_bot  0.15 k_c 0.0\n",
      "119 Train Loss 26.390148\n",
      "Loss  3.0758326 C_bot  0.15 k_c 0.0\n",
      "Loss  3.108607 C_bot  0.15 k_c 0.0\n",
      "120 Train Loss 26.284792\n",
      "Loss  3.108607 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0916677 C_bot  0.15 k_c 0.0\n",
      "121 Train Loss 26.145199\n",
      "Loss  3.0916677 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0293305 C_bot  0.15 k_c 0.0\n",
      "122 Train Loss 25.974432\n",
      "Loss  3.0293305 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0188384 C_bot  0.15 k_c 0.0\n",
      "123 Train Loss 25.860247\n",
      "Loss  3.0188384 C_bot  0.15 k_c 0.0\n",
      "Loss  3.024945 C_bot  0.15 k_c 0.0\n",
      "124 Train Loss 25.75718\n",
      "Loss  3.024945 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9899845 C_bot  0.15 k_c 0.0\n",
      "125 Train Loss 25.604233\n",
      "Loss  2.9899845 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9719787 C_bot  0.15 k_c 0.0\n",
      "126 Train Loss 25.46481\n",
      "Loss  2.9719787 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9893122 C_bot  0.15 k_c 0.0\n",
      "127 Train Loss 25.366297\n",
      "Loss  2.9893122 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9764967 C_bot  0.15 k_c 0.0\n",
      "128 Train Loss 25.248575\n",
      "Loss  2.9764967 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9387803 C_bot  0.15 k_c 0.0\n",
      "129 Train Loss 25.115099\n",
      "Loss  2.9387803 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9256024 C_bot  0.15 k_c 0.0\n",
      "130 Train Loss 25.008286\n",
      "Loss  2.9256024 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9183753 C_bot  0.15 k_c 0.0\n",
      "131 Train Loss 24.902946\n",
      "Loss  2.9183753 C_bot  0.15 k_c 0.0\n",
      "Loss  2.898554 C_bot  0.15 k_c 0.0\n",
      "132 Train Loss 24.77936\n",
      "Loss  2.898554 C_bot  0.15 k_c 0.0\n",
      "Loss  2.894955 C_bot  0.15 k_c 0.0\n",
      "133 Train Loss 24.67103\n",
      "Loss  2.894955 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9007478 C_bot  0.15 k_c 0.0\n",
      "134 Train Loss 24.577415\n",
      "Loss  2.9007478 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8823314 C_bot  0.15 k_c 0.0\n",
      "135 Train Loss 24.467907\n",
      "Loss  2.8823314 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8564813 C_bot  0.15 k_c 0.0\n",
      "136 Train Loss 24.357098\n",
      "Loss  2.8564813 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8468113 C_bot  0.15 k_c 0.0\n",
      "137 Train Loss 24.263367\n",
      "Loss  2.8468113 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8380513 C_bot  0.15 k_c 0.0\n",
      "138 Train Loss 24.167334\n",
      "Loss  2.8380513 C_bot  0.15 k_c 0.0\n",
      "Loss  2.825646 C_bot  0.15 k_c 0.0\n",
      "139 Train Loss 24.064482\n",
      "Loss  2.825646 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8226511 C_bot  0.15 k_c 0.0\n",
      "140 Train Loss 23.97151\n",
      "Loss  2.8226511 C_bot  0.15 k_c 0.0\n",
      "Loss  2.818078 C_bot  0.15 k_c 0.0\n",
      "141 Train Loss 23.88135\n",
      "Loss  2.818078 C_bot  0.15 k_c 0.0\n",
      "Loss  2.801417 C_bot  0.15 k_c 0.0\n",
      "142 Train Loss 23.784592\n",
      "Loss  2.801417 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7874527 C_bot  0.15 k_c 0.0\n",
      "143 Train Loss 23.69376\n",
      "Loss  2.7874527 C_bot  0.15 k_c 0.0\n",
      "Loss  2.780388 C_bot  0.15 k_c 0.0\n",
      "144 Train Loss 23.609554\n",
      "Loss  2.780388 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7704287 C_bot  0.15 k_c 0.0\n",
      "145 Train Loss 23.520313\n",
      "Loss  2.7704287 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7615738 C_bot  0.15 k_c 0.0\n",
      "146 Train Loss 23.431147\n",
      "Loss  2.7615738 C_bot  0.15 k_c 0.0\n",
      "Loss  2.757694 C_bot  0.15 k_c 0.0\n",
      "147 Train Loss 23.348791\n",
      "Loss  2.757694 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7493768 C_bot  0.15 k_c 0.0\n",
      "148 Train Loss 23.265858\n",
      "Loss  2.7493768 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7362504 C_bot  0.15 k_c 0.0\n",
      "149 Train Loss 23.181627\n",
      "Loss  2.7362504 C_bot  0.15 k_c 0.0\n",
      "Loss  2.726289 C_bot  0.15 k_c 0.0\n",
      "150 Train Loss 23.101767\n",
      "Loss  2.726289 C_bot  0.15 k_c 0.0\n",
      "Loss  2.718197 C_bot  0.15 k_c 0.0\n",
      "151 Train Loss 23.022743\n",
      "Loss  2.718197 C_bot  0.15 k_c 0.0\n",
      "Loss  2.709939 C_bot  0.15 k_c 0.0\n",
      "152 Train Loss 22.942175\n",
      "Loss  2.709939 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7047534 C_bot  0.15 k_c 0.0\n",
      "153 Train Loss 22.864944\n",
      "Loss  2.7047534 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6995003 C_bot  0.15 k_c 0.0\n",
      "154 Train Loss 22.789984\n",
      "Loss  2.6995003 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6897058 C_bot  0.15 k_c 0.0\n",
      "155 Train Loss 22.713596\n",
      "Loss  2.6897058 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6792014 C_bot  0.15 k_c 0.0\n",
      "156 Train Loss 22.638565\n",
      "Loss  2.6792014 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6711874 C_bot  0.15 k_c 0.0\n",
      "157 Train Loss 22.56624\n",
      "Loss  2.6711874 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6636856 C_bot  0.15 k_c 0.0\n",
      "158 Train Loss 22.493557\n",
      "Loss  2.6636856 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6573417 C_bot  0.15 k_c 0.0\n",
      "159 Train Loss 22.421656\n",
      "Loss  2.6573417 C_bot  0.15 k_c 0.0\n",
      "Loss  2.652014 C_bot  0.15 k_c 0.0\n",
      "160 Train Loss 22.35183\n",
      "Loss  2.652014 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6447525 C_bot  0.15 k_c 0.0\n",
      "161 Train Loss 22.28218\n",
      "Loss  2.6447525 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6356955 C_bot  0.15 k_c 0.0\n",
      "162 Train Loss 22.212664\n",
      "Loss  2.6356955 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6282034 C_bot  0.15 k_c 0.0\n",
      "163 Train Loss 22.145481\n",
      "Loss  2.6282034 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6214278 C_bot  0.15 k_c 0.0\n",
      "164 Train Loss 22.078772\n",
      "Loss  2.6214278 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6149933 C_bot  0.15 k_c 0.0\n",
      "165 Train Loss 22.01213\n",
      "Loss  2.6149933 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6094518 C_bot  0.15 k_c 0.0\n",
      "166 Train Loss 21.947016\n",
      "Loss  2.6094518 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6033194 C_bot  0.15 k_c 0.0\n",
      "167 Train Loss 21.882864\n",
      "Loss  2.6033194 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5957668 C_bot  0.15 k_c 0.0\n",
      "168 Train Loss 21.818977\n",
      "Loss  2.5957668 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5883613 C_bot  0.15 k_c 0.0\n",
      "169 Train Loss 21.756212\n",
      "Loss  2.5883613 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5817769 C_bot  0.15 k_c 0.0\n",
      "170 Train Loss 21.694344\n",
      "Loss  2.5817769 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5757365 C_bot  0.15 k_c 0.0\n",
      "171 Train Loss 21.63282\n",
      "Loss  2.5757365 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5704558 C_bot  0.15 k_c 0.0\n",
      "172 Train Loss 21.572367\n",
      "Loss  2.5704558 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5650086 C_bot  0.15 k_c 0.0\n",
      "173 Train Loss 21.512846\n",
      "Loss  2.5650086 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5584915 C_bot  0.15 k_c 0.0\n",
      "174 Train Loss 21.453667\n",
      "Loss  2.5584915 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5516994 C_bot  0.15 k_c 0.0\n",
      "175 Train Loss 21.395267\n",
      "Loss  2.5516994 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5455256 C_bot  0.15 k_c 0.0\n",
      "176 Train Loss 21.337864\n",
      "Loss  2.5455256 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5398173 C_bot  0.15 k_c 0.0\n",
      "177 Train Loss 21.28094\n",
      "Loss  2.5398173 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5345926 C_bot  0.15 k_c 0.0\n",
      "178 Train Loss 21.224724\n",
      "Loss  2.5345926 C_bot  0.15 k_c 0.0\n",
      "Loss  2.529358 C_bot  0.15 k_c 0.0\n",
      "179 Train Loss 21.16925\n",
      "Loss  2.529358 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5236323 C_bot  0.15 k_c 0.0\n",
      "180 Train Loss 21.114357\n",
      "Loss  2.5236323 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5177202 C_bot  0.15 k_c 0.0\n",
      "181 Train Loss 21.060175\n",
      "Loss  2.5177202 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5119548 C_bot  0.15 k_c 0.0\n",
      "182 Train Loss 21.006573\n",
      "Loss  2.5119548 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5067933 C_bot  0.15 k_c 0.0\n",
      "183 Train Loss 20.953716\n",
      "Loss  2.5067933 C_bot  0.15 k_c 0.0\n",
      "Loss  2.501691 C_bot  0.15 k_c 0.0\n",
      "184 Train Loss 20.901175\n",
      "Loss  2.501691 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4969685 C_bot  0.15 k_c 0.0\n",
      "185 Train Loss 20.849636\n",
      "Loss  2.4969685 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4918272 C_bot  0.15 k_c 0.0\n",
      "186 Train Loss 20.798565\n",
      "Loss  2.4918272 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4862995 C_bot  0.15 k_c 0.0\n",
      "187 Train Loss 20.74788\n",
      "Loss  2.4862995 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4812722 C_bot  0.15 k_c 0.0\n",
      "188 Train Loss 20.698124\n",
      "Loss  2.4812722 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4762585 C_bot  0.15 k_c 0.0\n",
      "189 Train Loss 20.648546\n",
      "Loss  2.4762585 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4715927 C_bot  0.15 k_c 0.0\n",
      "190 Train Loss 20.599531\n",
      "Loss  2.4715927 C_bot  0.15 k_c 0.0\n",
      "Loss  2.467278 C_bot  0.15 k_c 0.0\n",
      "191 Train Loss 20.551357\n",
      "Loss  2.467278 C_bot  0.15 k_c 0.0\n",
      "Loss  2.462566 C_bot  0.15 k_c 0.0\n",
      "192 Train Loss 20.503475\n",
      "Loss  2.462566 C_bot  0.15 k_c 0.0\n",
      "Loss  2.457748 C_bot  0.15 k_c 0.0\n",
      "193 Train Loss 20.45615\n",
      "Loss  2.457748 C_bot  0.15 k_c 0.0\n",
      "Loss  2.452967 C_bot  0.15 k_c 0.0\n",
      "194 Train Loss 20.409267\n",
      "Loss  2.452967 C_bot  0.15 k_c 0.0\n",
      "Loss  2.448557 C_bot  0.15 k_c 0.0\n",
      "195 Train Loss 20.362972\n",
      "Loss  2.448557 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4442852 C_bot  0.15 k_c 0.0\n",
      "196 Train Loss 20.317057\n",
      "Loss  2.4442852 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4400847 C_bot  0.15 k_c 0.0\n",
      "197 Train Loss 20.271624\n",
      "Loss  2.4400847 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4357367 C_bot  0.15 k_c 0.0\n",
      "198 Train Loss 20.226608\n",
      "Loss  2.4357367 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4314907 C_bot  0.15 k_c 0.0\n",
      "199 Train Loss 20.18222\n",
      "Loss  2.4314907 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4271777 C_bot  0.15 k_c 0.0\n",
      "200 Train Loss 20.138126\n",
      "Loss  2.4271777 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4232185 C_bot  0.15 k_c 0.0\n",
      "201 Train Loss 20.094608\n",
      "Loss  2.4232185 C_bot  0.15 k_c 0.0\n",
      "Loss  2.41907 C_bot  0.15 k_c 0.0\n",
      "202 Train Loss 20.051151\n",
      "Loss  2.41907 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4153605 C_bot  0.15 k_c 0.0\n",
      "203 Train Loss 20.008528\n",
      "Loss  2.4153605 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4112787 C_bot  0.15 k_c 0.0\n",
      "204 Train Loss 19.966028\n",
      "Loss  2.4112787 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4073782 C_bot  0.15 k_c 0.0\n",
      "205 Train Loss 19.92416\n",
      "Loss  2.4073782 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4034975 C_bot  0.15 k_c 0.0\n",
      "206 Train Loss 19.882633\n",
      "Loss  2.4034975 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3997045 C_bot  0.15 k_c 0.0\n",
      "207 Train Loss 19.841415\n",
      "Loss  2.3997045 C_bot  0.15 k_c 0.0\n",
      "Loss  2.39613 C_bot  0.15 k_c 0.0\n",
      "208 Train Loss 19.800665\n",
      "Loss  2.39613 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3926249 C_bot  0.15 k_c 0.0\n",
      "209 Train Loss 19.76033\n",
      "Loss  2.3926249 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3889265 C_bot  0.15 k_c 0.0\n",
      "210 Train Loss 19.720226\n",
      "Loss  2.3889265 C_bot  0.15 k_c 0.0\n",
      "Loss  2.385416 C_bot  0.15 k_c 0.0\n",
      "211 Train Loss 19.68069\n",
      "Loss  2.385416 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3818574 C_bot  0.15 k_c 0.0\n",
      "212 Train Loss 19.641394\n",
      "Loss  2.3818574 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3783453 C_bot  0.15 k_c 0.0\n",
      "213 Train Loss 19.602365\n",
      "Loss  2.3783453 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3750465 C_bot  0.15 k_c 0.0\n",
      "214 Train Loss 19.563795\n",
      "Loss  2.3750465 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3716416 C_bot  0.15 k_c 0.0\n",
      "215 Train Loss 19.525444\n",
      "Loss  2.3716416 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3683965 C_bot  0.15 k_c 0.0\n",
      "216 Train Loss 19.487604\n",
      "Loss  2.3683965 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3651366 C_bot  0.15 k_c 0.0\n",
      "217 Train Loss 19.450058\n",
      "Loss  2.3651366 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3618224 C_bot  0.15 k_c 0.0\n",
      "218 Train Loss 19.41269\n",
      "Loss  2.3618224 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3586879 C_bot  0.15 k_c 0.0\n",
      "219 Train Loss 19.37571\n",
      "Loss  2.3586879 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3556492 C_bot  0.15 k_c 0.0\n",
      "220 Train Loss 19.339045\n",
      "Loss  2.3556492 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3525772 C_bot  0.15 k_c 0.0\n",
      "221 Train Loss 19.302626\n",
      "Loss  2.3525772 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3496 C_bot  0.15 k_c 0.0\n",
      "222 Train Loss 19.266586\n",
      "Loss  2.3496 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3464718 C_bot  0.15 k_c 0.0\n",
      "223 Train Loss 19.230648\n",
      "Loss  2.3464718 C_bot  0.15 k_c 0.0\n",
      "Loss  2.343487 C_bot  0.15 k_c 0.0\n",
      "224 Train Loss 19.195034\n",
      "Loss  2.343487 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3405986 C_bot  0.15 k_c 0.0\n",
      "225 Train Loss 19.159681\n",
      "Loss  2.3405986 C_bot  0.15 k_c 0.0\n",
      "Loss  2.337778 C_bot  0.15 k_c 0.0\n",
      "226 Train Loss 19.124584\n",
      "Loss  2.337778 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3349779 C_bot  0.15 k_c 0.0\n",
      "227 Train Loss 19.089733\n",
      "Loss  2.3349779 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3321397 C_bot  0.15 k_c 0.0\n",
      "228 Train Loss 19.055073\n",
      "Loss  2.3321397 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3293488 C_bot  0.15 k_c 0.0\n",
      "229 Train Loss 19.02064\n",
      "Loss  2.3293488 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3266163 C_bot  0.15 k_c 0.0\n",
      "230 Train Loss 18.98641\n",
      "Loss  2.3266163 C_bot  0.15 k_c 0.0\n",
      "Loss  2.32401 C_bot  0.15 k_c 0.0\n",
      "231 Train Loss 18.952452\n",
      "Loss  2.32401 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3214364 C_bot  0.15 k_c 0.0\n",
      "232 Train Loss 18.9187\n",
      "Loss  2.3214364 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3188858 C_bot  0.15 k_c 0.0\n",
      "233 Train Loss 18.885166\n",
      "Loss  2.3188858 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3161662 C_bot  0.15 k_c 0.0\n",
      "234 Train Loss 18.85165\n",
      "Loss  2.3161662 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3137805 C_bot  0.15 k_c 0.0\n",
      "235 Train Loss 18.818632\n",
      "Loss  2.3137805 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3111992 C_bot  0.15 k_c 0.0\n",
      "236 Train Loss 18.785559\n",
      "Loss  2.3111992 C_bot  0.15 k_c 0.0\n",
      "Loss  2.308755 C_bot  0.15 k_c 0.0\n",
      "237 Train Loss 18.752787\n",
      "Loss  2.308755 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3063304 C_bot  0.15 k_c 0.0\n",
      "238 Train Loss 18.720226\n",
      "Loss  2.3063304 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3038483 C_bot  0.15 k_c 0.0\n",
      "239 Train Loss 18.687832\n",
      "Loss  2.3038483 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3014307 C_bot  0.15 k_c 0.0\n",
      "240 Train Loss 18.655708\n",
      "Loss  2.3014307 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2991087 C_bot  0.15 k_c 0.0\n",
      "241 Train Loss 18.623875\n",
      "Loss  2.2991087 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2967496 C_bot  0.15 k_c 0.0\n",
      "242 Train Loss 18.592213\n",
      "Loss  2.2967496 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2945163 C_bot  0.15 k_c 0.0\n",
      "243 Train Loss 18.56091\n",
      "Loss  2.2945163 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2921135 C_bot  0.15 k_c 0.0\n",
      "244 Train Loss 18.529707\n",
      "Loss  2.2921135 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2898564 C_bot  0.15 k_c 0.0\n",
      "245 Train Loss 18.498926\n",
      "Loss  2.2898564 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2877064 C_bot  0.15 k_c 0.0\n",
      "246 Train Loss 18.468533\n",
      "Loss  2.2877064 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2853441 C_bot  0.15 k_c 0.0\n",
      "247 Train Loss 18.438192\n",
      "Loss  2.2853441 C_bot  0.15 k_c 0.0\n",
      "Loss  2.283071 C_bot  0.15 k_c 0.0\n",
      "248 Train Loss 18.40824\n",
      "Loss  2.283071 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2807972 C_bot  0.15 k_c 0.0\n",
      "249 Train Loss 18.378595\n",
      "Loss  2.2807972 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2786093 C_bot  0.15 k_c 0.0\n",
      "250 Train Loss 18.349373\n",
      "Loss  2.2786093 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2763765 C_bot  0.15 k_c 0.0\n",
      "251 Train Loss 18.320435\n",
      "Loss  2.2763765 C_bot  0.15 k_c 0.0\n",
      "Loss  2.274069 C_bot  0.15 k_c 0.0\n",
      "252 Train Loss 18.291735\n",
      "Loss  2.274069 C_bot  0.15 k_c 0.0\n",
      "Loss  2.271865 C_bot  0.15 k_c 0.0\n",
      "253 Train Loss 18.263458\n",
      "Loss  2.271865 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2696893 C_bot  0.15 k_c 0.0\n",
      "254 Train Loss 18.235535\n",
      "Loss  2.2696893 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2675145 C_bot  0.15 k_c 0.0\n",
      "255 Train Loss 18.207949\n",
      "Loss  2.2675145 C_bot  0.15 k_c 0.0\n",
      "Loss  2.265239 C_bot  0.15 k_c 0.0\n",
      "256 Train Loss 18.180593\n",
      "Loss  2.265239 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2631133 C_bot  0.15 k_c 0.0\n",
      "257 Train Loss 18.153706\n",
      "Loss  2.2631133 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2609186 C_bot  0.15 k_c 0.0\n",
      "258 Train Loss 18.127056\n",
      "Loss  2.2609186 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2586625 C_bot  0.15 k_c 0.0\n",
      "259 Train Loss 18.100634\n",
      "Loss  2.2586625 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2563617 C_bot  0.15 k_c 0.0\n",
      "260 Train Loss 18.074467\n",
      "Loss  2.2563617 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2541506 C_bot  0.15 k_c 0.0\n",
      "261 Train Loss 18.048687\n",
      "Loss  2.2541506 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2518723 C_bot  0.15 k_c 0.0\n",
      "262 Train Loss 18.023125\n",
      "Loss  2.2518723 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2497218 C_bot  0.15 k_c 0.0\n",
      "263 Train Loss 17.997953\n",
      "Loss  2.2497218 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2474997 C_bot  0.15 k_c 0.0\n",
      "264 Train Loss 17.972963\n",
      "Loss  2.2474997 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2451293 C_bot  0.15 k_c 0.0\n",
      "265 Train Loss 17.948072\n",
      "Loss  2.2451293 C_bot  0.15 k_c 0.0\n",
      "Loss  2.242949 C_bot  0.15 k_c 0.0\n",
      "266 Train Loss 17.92362\n",
      "Loss  2.242949 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2407527 C_bot  0.15 k_c 0.0\n",
      "267 Train Loss 17.899391\n",
      "Loss  2.2407527 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2383993 C_bot  0.15 k_c 0.0\n",
      "268 Train Loss 17.875229\n",
      "Loss  2.2383993 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2361484 C_bot  0.15 k_c 0.0\n",
      "269 Train Loss 17.851374\n",
      "Loss  2.2361484 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2339435 C_bot  0.15 k_c 0.0\n",
      "270 Train Loss 17.82777\n",
      "Loss  2.2339435 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2316918 C_bot  0.15 k_c 0.0\n",
      "271 Train Loss 17.804329\n",
      "Loss  2.2316918 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2293394 C_bot  0.15 k_c 0.0\n",
      "272 Train Loss 17.780983\n",
      "Loss  2.2293394 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2270696 C_bot  0.15 k_c 0.0\n",
      "273 Train Loss 17.757912\n",
      "Loss  2.2270696 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2249513 C_bot  0.15 k_c 0.0\n",
      "274 Train Loss 17.73517\n",
      "Loss  2.2249513 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2226346 C_bot  0.15 k_c 0.0\n",
      "275 Train Loss 17.712404\n",
      "Loss  2.2226346 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2203064 C_bot  0.15 k_c 0.0\n",
      "276 Train Loss 17.689798\n",
      "Loss  2.2203064 C_bot  0.15 k_c 0.0\n",
      "Loss  2.218073 C_bot  0.15 k_c 0.0\n",
      "277 Train Loss 17.667454\n",
      "Loss  2.218073 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2157762 C_bot  0.15 k_c 0.0\n",
      "278 Train Loss 17.645212\n",
      "Loss  2.2157762 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2134097 C_bot  0.15 k_c 0.0\n",
      "279 Train Loss 17.623058\n",
      "Loss  2.2134097 C_bot  0.15 k_c 0.0\n",
      "Loss  2.211251 C_bot  0.15 k_c 0.0\n",
      "280 Train Loss 17.601265\n",
      "Loss  2.211251 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2088473 C_bot  0.15 k_c 0.0\n",
      "281 Train Loss 17.579372\n",
      "Loss  2.2088473 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2066004 C_bot  0.15 k_c 0.0\n",
      "282 Train Loss 17.557783\n",
      "Loss  2.2066004 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2044456 C_bot  0.15 k_c 0.0\n",
      "283 Train Loss 17.536434\n",
      "Loss  2.2044456 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2021925 C_bot  0.15 k_c 0.0\n",
      "284 Train Loss 17.515121\n",
      "Loss  2.2021925 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1998785 C_bot  0.15 k_c 0.0\n",
      "285 Train Loss 17.493885\n",
      "Loss  2.1998785 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1976209 C_bot  0.15 k_c 0.0\n",
      "286 Train Loss 17.472834\n",
      "Loss  2.1976209 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1953971 C_bot  0.15 k_c 0.0\n",
      "287 Train Loss 17.451948\n",
      "Loss  2.1953971 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1930985 C_bot  0.15 k_c 0.0\n",
      "288 Train Loss 17.431118\n",
      "Loss  2.1930985 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1909404 C_bot  0.15 k_c 0.0\n",
      "289 Train Loss 17.410551\n",
      "Loss  2.1909404 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1887085 C_bot  0.15 k_c 0.0\n",
      "290 Train Loss 17.390036\n",
      "Loss  2.1887085 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1864374 C_bot  0.15 k_c 0.0\n",
      "291 Train Loss 17.369598\n",
      "Loss  2.1864374 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1842225 C_bot  0.15 k_c 0.0\n",
      "292 Train Loss 17.349337\n",
      "Loss  2.1842225 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1820865 C_bot  0.15 k_c 0.0\n",
      "293 Train Loss 17.329258\n",
      "Loss  2.1820865 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1798155 C_bot  0.15 k_c 0.0\n",
      "294 Train Loss 17.309172\n",
      "Loss  2.1798155 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1775656 C_bot  0.15 k_c 0.0\n",
      "295 Train Loss 17.289213\n",
      "Loss  2.1775656 C_bot  0.15 k_c 0.0\n",
      "Loss  2.175451 C_bot  0.15 k_c 0.0\n",
      "296 Train Loss 17.269499\n",
      "Loss  2.175451 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1731806 C_bot  0.15 k_c 0.0\n",
      "297 Train Loss 17.249737\n",
      "Loss  2.1731806 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1709862 C_bot  0.15 k_c 0.0\n",
      "298 Train Loss 17.230145\n",
      "Loss  2.1709862 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1688623 C_bot  0.15 k_c 0.0\n",
      "299 Train Loss 17.21074\n",
      "Loss  2.1688623 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1667252 C_bot  0.15 k_c 0.0\n",
      "300 Train Loss 17.191425\n",
      "Loss  2.1667252 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1645327 C_bot  0.15 k_c 0.0\n",
      "301 Train Loss 17.172152\n",
      "Loss  2.1645327 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1624665 C_bot  0.15 k_c 0.0\n",
      "302 Train Loss 17.153103\n",
      "Loss  2.1624665 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1603024 C_bot  0.15 k_c 0.0\n",
      "303 Train Loss 17.134048\n",
      "Loss  2.1603024 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1581645 C_bot  0.15 k_c 0.0\n",
      "304 Train Loss 17.115128\n",
      "Loss  2.1581645 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1559885 C_bot  0.15 k_c 0.0\n",
      "305 Train Loss 17.096262\n",
      "Loss  2.1559885 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1539192 C_bot  0.15 k_c 0.0\n",
      "306 Train Loss 17.077597\n",
      "Loss  2.1539192 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1518326 C_bot  0.15 k_c 0.0\n",
      "307 Train Loss 17.058996\n",
      "Loss  2.1518326 C_bot  0.15 k_c 0.0\n",
      "Loss  2.149877 C_bot  0.15 k_c 0.0\n",
      "308 Train Loss 17.040625\n",
      "Loss  2.149877 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1477349 C_bot  0.15 k_c 0.0\n",
      "309 Train Loss 17.02216\n",
      "Loss  2.1477349 C_bot  0.15 k_c 0.0\n",
      "Loss  2.145679 C_bot  0.15 k_c 0.0\n",
      "310 Train Loss 17.003876\n",
      "Loss  2.145679 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1435518 C_bot  0.15 k_c 0.0\n",
      "311 Train Loss 16.9856\n",
      "Loss  2.1435518 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1415017 C_bot  0.15 k_c 0.0\n",
      "312 Train Loss 16.96749\n",
      "Loss  2.1415017 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1395812 C_bot  0.15 k_c 0.0\n",
      "313 Train Loss 16.949593\n",
      "Loss  2.1395812 C_bot  0.15 k_c 0.0\n",
      "Loss  2.137488 C_bot  0.15 k_c 0.0\n",
      "314 Train Loss 16.931612\n",
      "Loss  2.137488 C_bot  0.15 k_c 0.0\n",
      "Loss  2.135438 C_bot  0.15 k_c 0.0\n",
      "315 Train Loss 16.913765\n",
      "Loss  2.135438 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1335113 C_bot  0.15 k_c 0.0\n",
      "316 Train Loss 16.896118\n",
      "Loss  2.1335113 C_bot  0.15 k_c 0.0\n",
      "Loss  2.131407 C_bot  0.15 k_c 0.0\n",
      "317 Train Loss 16.878374\n",
      "Loss  2.131407 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1295512 C_bot  0.15 k_c 0.0\n",
      "318 Train Loss 16.860964\n",
      "Loss  2.1295512 C_bot  0.15 k_c 0.0\n",
      "Loss  2.127471 C_bot  0.15 k_c 0.0\n",
      "319 Train Loss 16.84341\n",
      "Loss  2.127471 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1255748 C_bot  0.15 k_c 0.0\n",
      "320 Train Loss 16.826122\n",
      "Loss  2.1255748 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1235595 C_bot  0.15 k_c 0.0\n",
      "321 Train Loss 16.808796\n",
      "Loss  2.1235595 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1215913 C_bot  0.15 k_c 0.0\n",
      "322 Train Loss 16.791592\n",
      "Loss  2.1215913 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1197119 C_bot  0.15 k_c 0.0\n",
      "323 Train Loss 16.774551\n",
      "Loss  2.1197119 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1177764 C_bot  0.15 k_c 0.0\n",
      "324 Train Loss 16.757534\n",
      "Loss  2.1177764 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1158316 C_bot  0.15 k_c 0.0\n",
      "325 Train Loss 16.74059\n",
      "Loss  2.1158316 C_bot  0.15 k_c 0.0\n",
      "Loss  2.113742 C_bot  0.15 k_c 0.0\n",
      "326 Train Loss 16.723576\n",
      "Loss  2.113742 C_bot  0.15 k_c 0.0\n",
      "Loss  2.111994 C_bot  0.15 k_c 0.0\n",
      "327 Train Loss 16.70697\n",
      "Loss  2.111994 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1101048 C_bot  0.15 k_c 0.0\n",
      "328 Train Loss 16.690298\n",
      "Loss  2.1101048 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1081998 C_bot  0.15 k_c 0.0\n",
      "329 Train Loss 16.673687\n",
      "Loss  2.1081998 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1062129 C_bot  0.15 k_c 0.0\n",
      "330 Train Loss 16.65707\n",
      "Loss  2.1062129 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1043777 C_bot  0.15 k_c 0.0\n",
      "331 Train Loss 16.640675\n",
      "Loss  2.1043777 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1026096 C_bot  0.15 k_c 0.0\n",
      "332 Train Loss 16.624414\n",
      "Loss  2.1026096 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1007297 C_bot  0.15 k_c 0.0\n",
      "333 Train Loss 16.608112\n",
      "Loss  2.1007297 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0988762 C_bot  0.15 k_c 0.0\n",
      "334 Train Loss 16.591911\n",
      "Loss  2.0988762 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0969794 C_bot  0.15 k_c 0.0\n",
      "335 Train Loss 16.575733\n",
      "Loss  2.0969794 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0951376 C_bot  0.15 k_c 0.0\n",
      "336 Train Loss 16.559677\n",
      "Loss  2.0951376 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0932364 C_bot  0.15 k_c 0.0\n",
      "337 Train Loss 16.543623\n",
      "Loss  2.0932364 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0914307 C_bot  0.15 k_c 0.0\n",
      "338 Train Loss 16.52774\n",
      "Loss  2.0914307 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0897267 C_bot  0.15 k_c 0.0\n",
      "339 Train Loss 16.512026\n",
      "Loss  2.0897267 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0877943 C_bot  0.15 k_c 0.0\n",
      "340 Train Loss 16.496147\n",
      "Loss  2.0877943 C_bot  0.15 k_c 0.0\n",
      "Loss  2.086066 C_bot  0.15 k_c 0.0\n",
      "341 Train Loss 16.480534\n",
      "Loss  2.086066 C_bot  0.15 k_c 0.0\n",
      "Loss  2.084171 C_bot  0.15 k_c 0.0\n",
      "342 Train Loss 16.464815\n",
      "Loss  2.084171 C_bot  0.15 k_c 0.0\n",
      "Loss  2.082369 C_bot  0.15 k_c 0.0\n",
      "343 Train Loss 16.449257\n",
      "Loss  2.082369 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0806384 C_bot  0.15 k_c 0.0\n",
      "344 Train Loss 16.43383\n",
      "Loss  2.0806384 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0787506 C_bot  0.15 k_c 0.0\n",
      "345 Train Loss 16.418312\n",
      "Loss  2.0787506 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0769374 C_bot  0.15 k_c 0.0\n",
      "346 Train Loss 16.402924\n",
      "Loss  2.0769374 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0752761 C_bot  0.15 k_c 0.0\n",
      "347 Train Loss 16.387753\n",
      "Loss  2.0752761 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0734096 C_bot  0.15 k_c 0.0\n",
      "348 Train Loss 16.372429\n",
      "Loss  2.0734096 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0717738 C_bot  0.15 k_c 0.0\n",
      "349 Train Loss 16.3574\n",
      "Loss  2.0717738 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0698898 C_bot  0.15 k_c 0.0\n",
      "350 Train Loss 16.342182\n",
      "Loss  2.0698898 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0681748 C_bot  0.15 k_c 0.0\n",
      "351 Train Loss 16.327188\n",
      "Loss  2.0681748 C_bot  0.15 k_c 0.0\n",
      "Loss  2.06651 C_bot  0.15 k_c 0.0\n",
      "352 Train Loss 16.3123\n",
      "Loss  2.06651 C_bot  0.15 k_c 0.0\n",
      "Loss  2.064772 C_bot  0.15 k_c 0.0\n",
      "353 Train Loss 16.297398\n",
      "Loss  2.064772 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0629182 C_bot  0.15 k_c 0.0\n",
      "354 Train Loss 16.282433\n",
      "Loss  2.0629182 C_bot  0.15 k_c 0.0\n",
      "Loss  2.061259 C_bot  0.15 k_c 0.0\n",
      "355 Train Loss 16.267717\n",
      "Loss  2.061259 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0594404 C_bot  0.15 k_c 0.0\n",
      "356 Train Loss 16.2529\n",
      "Loss  2.0594404 C_bot  0.15 k_c 0.0\n",
      "Loss  2.057744 C_bot  0.15 k_c 0.0\n",
      "357 Train Loss 16.238255\n",
      "Loss  2.057744 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0561624 C_bot  0.15 k_c 0.0\n",
      "358 Train Loss 16.223782\n",
      "Loss  2.0561624 C_bot  0.15 k_c 0.0\n",
      "Loss  2.054271 C_bot  0.15 k_c 0.0\n",
      "359 Train Loss 16.20905\n",
      "Loss  2.054271 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0525942 C_bot  0.15 k_c 0.0\n",
      "360 Train Loss 16.194584\n",
      "Loss  2.0525942 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0509021 C_bot  0.15 k_c 0.0\n",
      "361 Train Loss 16.180151\n",
      "Loss  2.0509021 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0492427 C_bot  0.15 k_c 0.0\n",
      "362 Train Loss 16.165808\n",
      "Loss  2.0492427 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0475698 C_bot  0.15 k_c 0.0\n",
      "363 Train Loss 16.151497\n",
      "Loss  2.0475698 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0458891 C_bot  0.15 k_c 0.0\n",
      "364 Train Loss 16.137232\n",
      "Loss  2.0458891 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0441964 C_bot  0.15 k_c 0.0\n",
      "365 Train Loss 16.123\n",
      "Loss  2.0441964 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0424864 C_bot  0.15 k_c 0.0\n",
      "366 Train Loss 16.108805\n",
      "Loss  2.0424864 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0407906 C_bot  0.15 k_c 0.0\n",
      "367 Train Loss 16.094667\n",
      "Loss  2.0407906 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0390613 C_bot  0.15 k_c 0.0\n",
      "368 Train Loss 16.080547\n",
      "Loss  2.0390613 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0374832 C_bot  0.15 k_c 0.0\n",
      "369 Train Loss 16.066622\n",
      "Loss  2.0374832 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0359175 C_bot  0.15 k_c 0.0\n",
      "370 Train Loss 16.05276\n",
      "Loss  2.0359175 C_bot  0.15 k_c 0.0\n",
      "Loss  2.034229 C_bot  0.15 k_c 0.0\n",
      "371 Train Loss 16.038818\n",
      "Loss  2.034229 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0324895 C_bot  0.15 k_c 0.0\n",
      "372 Train Loss 16.024878\n",
      "Loss  2.0324895 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0308387 C_bot  0.15 k_c 0.0\n",
      "373 Train Loss 16.011066\n",
      "Loss  2.0308387 C_bot  0.15 k_c 0.0\n",
      "Loss  2.029244 C_bot  0.15 k_c 0.0\n",
      "374 Train Loss 15.997356\n",
      "Loss  2.029244 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0275798 C_bot  0.15 k_c 0.0\n",
      "375 Train Loss 15.983621\n",
      "Loss  2.0275798 C_bot  0.15 k_c 0.0\n",
      "Loss  2.026015 C_bot  0.15 k_c 0.0\n",
      "376 Train Loss 15.970028\n",
      "Loss  2.026015 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0244105 C_bot  0.15 k_c 0.0\n",
      "377 Train Loss 15.956443\n",
      "Loss  2.0244105 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0227764 C_bot  0.15 k_c 0.0\n",
      "378 Train Loss 15.942871\n",
      "Loss  2.0227764 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0210996 C_bot  0.15 k_c 0.0\n",
      "379 Train Loss 15.929296\n",
      "Loss  2.0210996 C_bot  0.15 k_c 0.0\n",
      "Loss  2.019563 C_bot  0.15 k_c 0.0\n",
      "380 Train Loss 15.915903\n",
      "Loss  2.019563 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0179996 C_bot  0.15 k_c 0.0\n",
      "381 Train Loss 15.902529\n",
      "Loss  2.0179996 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0164328 C_bot  0.15 k_c 0.0\n",
      "382 Train Loss 15.889193\n",
      "Loss  2.0164328 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0147185 C_bot  0.15 k_c 0.0\n",
      "383 Train Loss 15.87575\n",
      "Loss  2.0147185 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0132415 C_bot  0.15 k_c 0.0\n",
      "384 Train Loss 15.862583\n",
      "Loss  2.0132415 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0116248 C_bot  0.15 k_c 0.0\n",
      "385 Train Loss 15.849325\n",
      "Loss  2.0116248 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0099878 C_bot  0.15 k_c 0.0\n",
      "386 Train Loss 15.836082\n",
      "Loss  2.0099878 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0084395 C_bot  0.15 k_c 0.0\n",
      "387 Train Loss 15.822966\n",
      "Loss  2.0084395 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0069208 C_bot  0.15 k_c 0.0\n",
      "388 Train Loss 15.809919\n",
      "Loss  2.0069208 C_bot  0.15 k_c 0.0\n",
      "Loss  2.005319 C_bot  0.15 k_c 0.0\n",
      "389 Train Loss 15.796833\n",
      "Loss  2.005319 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0038304 C_bot  0.15 k_c 0.0\n",
      "390 Train Loss 15.7838955\n",
      "Loss  2.0038304 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0022202 C_bot  0.15 k_c 0.0\n",
      "391 Train Loss 15.770872\n",
      "Loss  2.0022202 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0005915 C_bot  0.15 k_c 0.0\n",
      "392 Train Loss 15.757873\n",
      "Loss  2.0005915 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9991448 C_bot  0.15 k_c 0.0\n",
      "393 Train Loss 15.745092\n",
      "Loss  1.9991448 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9976071 C_bot  0.15 k_c 0.0\n",
      "394 Train Loss 15.73226\n",
      "Loss  1.9976071 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9961101 C_bot  0.15 k_c 0.0\n",
      "395 Train Loss 15.7195015\n",
      "Loss  1.9961101 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9943888 C_bot  0.15 k_c 0.0\n",
      "396 Train Loss 15.706558\n",
      "Loss  1.9943888 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9929644 C_bot  0.15 k_c 0.0\n",
      "397 Train Loss 15.693945\n",
      "Loss  1.9929644 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9915255 C_bot  0.15 k_c 0.0\n",
      "398 Train Loss 15.681356\n",
      "Loss  1.9915255 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9899874 C_bot  0.15 k_c 0.0\n",
      "399 Train Loss 15.668707\n",
      "Loss  1.9899874 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9884799 C_bot  0.15 k_c 0.0\n",
      "400 Train Loss 15.656126\n",
      "Loss  1.9884799 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9868957 C_bot  0.15 k_c 0.0\n",
      "401 Train Loss 15.643496\n",
      "Loss  1.9868957 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9854364 C_bot  0.15 k_c 0.0\n",
      "402 Train Loss 15.631029\n",
      "Loss  1.9854364 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9838867 C_bot  0.15 k_c 0.0\n",
      "403 Train Loss 15.618504\n",
      "Loss  1.9838867 C_bot  0.15 k_c 0.0\n",
      "Loss  1.982441 C_bot  0.15 k_c 0.0\n",
      "404 Train Loss 15.606125\n",
      "Loss  1.982441 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9809631 C_bot  0.15 k_c 0.0\n",
      "405 Train Loss 15.593745\n",
      "Loss  1.9809631 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9794965 C_bot  0.15 k_c 0.0\n",
      "406 Train Loss 15.581406\n",
      "Loss  1.9794965 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9780505 C_bot  0.15 k_c 0.0\n",
      "407 Train Loss 15.569124\n",
      "Loss  1.9780505 C_bot  0.15 k_c 0.0\n",
      "Loss  1.976516 C_bot  0.15 k_c 0.0\n",
      "408 Train Loss 15.556788\n",
      "Loss  1.976516 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9750526 C_bot  0.15 k_c 0.0\n",
      "409 Train Loss 15.544558\n",
      "Loss  1.9750526 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9736323 C_bot  0.15 k_c 0.0\n",
      "410 Train Loss 15.532402\n",
      "Loss  1.9736323 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9721034 C_bot  0.15 k_c 0.0\n",
      "411 Train Loss 15.52017\n",
      "Loss  1.9721034 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9707067 C_bot  0.15 k_c 0.0\n",
      "412 Train Loss 15.508108\n",
      "Loss  1.9707067 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9692854 C_bot  0.15 k_c 0.0\n",
      "413 Train Loss 15.496051\n",
      "Loss  1.9692854 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9677167 C_bot  0.15 k_c 0.0\n",
      "414 Train Loss 15.483879\n",
      "Loss  1.9677167 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9663272 C_bot  0.15 k_c 0.0\n",
      "415 Train Loss 15.471922\n",
      "Loss  1.9663272 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9648011 C_bot  0.15 k_c 0.0\n",
      "416 Train Loss 15.459858\n",
      "Loss  1.9648011 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9634523 C_bot  0.15 k_c 0.0\n",
      "417 Train Loss 15.448002\n",
      "Loss  1.9634523 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9620045 C_bot  0.15 k_c 0.0\n",
      "418 Train Loss 15.436085\n",
      "Loss  1.9620045 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9605265 C_bot  0.15 k_c 0.0\n",
      "419 Train Loss 15.424167\n",
      "Loss  1.9605265 C_bot  0.15 k_c 0.0\n",
      "Loss  1.959066 C_bot  0.15 k_c 0.0\n",
      "420 Train Loss 15.412302\n",
      "Loss  1.959066 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9576948 C_bot  0.15 k_c 0.0\n",
      "421 Train Loss 15.400553\n",
      "Loss  1.9576948 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9563136 C_bot  0.15 k_c 0.0\n",
      "422 Train Loss 15.38883\n",
      "Loss  1.9563136 C_bot  0.15 k_c 0.0\n",
      "Loss  1.954856 C_bot  0.15 k_c 0.0\n",
      "423 Train Loss 15.377064\n",
      "Loss  1.954856 C_bot  0.15 k_c 0.0\n",
      "Loss  1.953423 C_bot  0.15 k_c 0.0\n",
      "424 Train Loss 15.365356\n",
      "Loss  1.953423 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9519831 C_bot  0.15 k_c 0.0\n",
      "425 Train Loss 15.35367\n",
      "Loss  1.9519831 C_bot  0.15 k_c 0.0\n",
      "Loss  1.950652 C_bot  0.15 k_c 0.0\n",
      "426 Train Loss 15.342124\n",
      "Loss  1.950652 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9492103 C_bot  0.15 k_c 0.0\n",
      "427 Train Loss 15.330506\n",
      "Loss  1.9492103 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9478109 C_bot  0.15 k_c 0.0\n",
      "428 Train Loss 15.318962\n",
      "Loss  1.9478109 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9464165 C_bot  0.15 k_c 0.0\n",
      "429 Train Loss 15.307455\n",
      "Loss  1.9464165 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9450538 C_bot  0.15 k_c 0.0\n",
      "430 Train Loss 15.29601\n",
      "Loss  1.9450538 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9436394 C_bot  0.15 k_c 0.0\n",
      "431 Train Loss 15.284552\n",
      "Loss  1.9436394 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9422541 C_bot  0.15 k_c 0.0\n",
      "432 Train Loss 15.273153\n",
      "Loss  1.9422541 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9409381 C_bot  0.15 k_c 0.0\n",
      "433 Train Loss 15.261855\n",
      "Loss  1.9409381 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9395757 C_bot  0.15 k_c 0.0\n",
      "434 Train Loss 15.2505455\n",
      "Loss  1.9395757 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9381952 C_bot  0.15 k_c 0.0\n",
      "435 Train Loss 15.239258\n",
      "Loss  1.9381952 C_bot  0.15 k_c 0.0\n",
      "Loss  1.936709 C_bot  0.15 k_c 0.0\n",
      "436 Train Loss 15.22789\n",
      "Loss  1.936709 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9353936 C_bot  0.15 k_c 0.0\n",
      "437 Train Loss 15.216731\n",
      "Loss  1.9353936 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9339945 C_bot  0.15 k_c 0.0\n",
      "438 Train Loss 15.205523\n",
      "Loss  1.9339945 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9327346 C_bot  0.15 k_c 0.0\n",
      "439 Train Loss 15.194487\n",
      "Loss  1.9327346 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9313296 C_bot  0.15 k_c 0.0\n",
      "440 Train Loss 15.183342\n",
      "Loss  1.9313296 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9299088 C_bot  0.15 k_c 0.0\n",
      "441 Train Loss 15.17222\n",
      "Loss  1.9299088 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9285853 C_bot  0.15 k_c 0.0\n",
      "442 Train Loss 15.161226\n",
      "Loss  1.9285853 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9273336 C_bot  0.15 k_c 0.0\n",
      "443 Train Loss 15.150339\n",
      "Loss  1.9273336 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9259704 C_bot  0.15 k_c 0.0\n",
      "444 Train Loss 15.139378\n",
      "Loss  1.9259704 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9246229 C_bot  0.15 k_c 0.0\n",
      "445 Train Loss 15.128471\n",
      "Loss  1.9246229 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9232912 C_bot  0.15 k_c 0.0\n",
      "446 Train Loss 15.117615\n",
      "Loss  1.9232912 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9219755 C_bot  0.15 k_c 0.0\n",
      "447 Train Loss 15.106809\n",
      "Loss  1.9219755 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9205462 C_bot  0.15 k_c 0.0\n",
      "448 Train Loss 15.095924\n",
      "Loss  1.9205462 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9192691 C_bot  0.15 k_c 0.0\n",
      "449 Train Loss 15.085232\n",
      "Loss  1.9192691 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9179243 C_bot  0.15 k_c 0.0\n",
      "450 Train Loss 15.074509\n",
      "Loss  1.9179243 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9166338 C_bot  0.15 k_c 0.0\n",
      "451 Train Loss 15.063877\n",
      "Loss  1.9166338 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9152839 C_bot  0.15 k_c 0.0\n",
      "452 Train Loss 15.053219\n",
      "Loss  1.9152839 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9140136 C_bot  0.15 k_c 0.0\n",
      "453 Train Loss 15.042679\n",
      "Loss  1.9140136 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9125981 C_bot  0.15 k_c 0.0\n",
      "454 Train Loss 15.032032\n",
      "Loss  1.9125981 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9112502 C_bot  0.15 k_c 0.0\n",
      "455 Train Loss 15.02149\n",
      "Loss  1.9112502 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9100449 C_bot  0.15 k_c 0.0\n",
      "456 Train Loss 15.011127\n",
      "Loss  1.9100449 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9087359 C_bot  0.15 k_c 0.0\n",
      "457 Train Loss 15.000697\n",
      "Loss  1.9087359 C_bot  0.15 k_c 0.0\n",
      "Loss  1.907427 C_bot  0.15 k_c 0.0\n",
      "458 Train Loss 14.990309\n",
      "Loss  1.907427 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9060692 C_bot  0.15 k_c 0.0\n",
      "459 Train Loss 14.979902\n",
      "Loss  1.9060692 C_bot  0.15 k_c 0.0\n",
      "Loss  1.904747 C_bot  0.15 k_c 0.0\n",
      "460 Train Loss 14.969569\n",
      "Loss  1.904747 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9034292 C_bot  0.15 k_c 0.0\n",
      "461 Train Loss 14.95928\n",
      "Loss  1.9034292 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9022596 C_bot  0.15 k_c 0.0\n",
      "462 Train Loss 14.949181\n",
      "Loss  1.9022596 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9007876 C_bot  0.15 k_c 0.0\n",
      "463 Train Loss 14.938808\n",
      "Loss  1.9007876 C_bot  0.15 k_c 0.0\n",
      "Loss  1.899603 C_bot  0.15 k_c 0.0\n",
      "464 Train Loss 14.928764\n",
      "Loss  1.899603 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8983177 C_bot  0.15 k_c 0.0\n",
      "465 Train Loss 14.918652\n",
      "Loss  1.8983177 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8969444 C_bot  0.15 k_c 0.0\n",
      "466 Train Loss 14.908493\n",
      "Loss  1.8969444 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8957087 C_bot  0.15 k_c 0.0\n",
      "467 Train Loss 14.898508\n",
      "Loss  1.8957087 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8944451 C_bot  0.15 k_c 0.0\n",
      "468 Train Loss 14.888525\n",
      "Loss  1.8944451 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8931681 C_bot  0.15 k_c 0.0\n",
      "469 Train Loss 14.878567\n",
      "Loss  1.8931681 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8918277 C_bot  0.15 k_c 0.0\n",
      "470 Train Loss 14.868586\n",
      "Loss  1.8918277 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8905687 C_bot  0.15 k_c 0.0\n",
      "471 Train Loss 14.858723\n",
      "Loss  1.8905687 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8893204 C_bot  0.15 k_c 0.0\n",
      "472 Train Loss 14.848897\n",
      "Loss  1.8893204 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8880602 C_bot  0.15 k_c 0.0\n",
      "473 Train Loss 14.839094\n",
      "Loss  1.8880602 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8867526 C_bot  0.15 k_c 0.0\n",
      "474 Train Loss 14.829285\n",
      "Loss  1.8867526 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8853976 C_bot  0.15 k_c 0.0\n",
      "475 Train Loss 14.819462\n",
      "Loss  1.8853976 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8842214 C_bot  0.15 k_c 0.0\n",
      "476 Train Loss 14.809847\n",
      "Loss  1.8842214 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8829613 C_bot  0.15 k_c 0.0\n",
      "477 Train Loss 14.800184\n",
      "Loss  1.8829613 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8816963 C_bot  0.15 k_c 0.0\n",
      "478 Train Loss 14.790548\n",
      "Loss  1.8816963 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8805054 C_bot  0.15 k_c 0.0\n",
      "479 Train Loss 14.78103\n",
      "Loss  1.8805054 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8791554 C_bot  0.15 k_c 0.0\n",
      "480 Train Loss 14.771376\n",
      "Loss  1.8791554 C_bot  0.15 k_c 0.0\n",
      "Loss  1.877842 C_bot  0.15 k_c 0.0\n",
      "481 Train Loss 14.7617855\n",
      "Loss  1.877842 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8766423 C_bot  0.15 k_c 0.0\n",
      "482 Train Loss 14.752348\n",
      "Loss  1.8766423 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8753684 C_bot  0.15 k_c 0.0\n",
      "483 Train Loss 14.742868\n",
      "Loss  1.8753684 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8740445 C_bot  0.15 k_c 0.0\n",
      "484 Train Loss 14.733373\n",
      "Loss  1.8740445 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8727585 C_bot  0.15 k_c 0.0\n",
      "485 Train Loss 14.723936\n",
      "Loss  1.8727585 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8716028 C_bot  0.15 k_c 0.0\n",
      "486 Train Loss 14.714664\n",
      "Loss  1.8716028 C_bot  0.15 k_c 0.0\n",
      "Loss  1.870391 C_bot  0.15 k_c 0.0\n",
      "487 Train Loss 14.70537\n",
      "Loss  1.870391 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8691698 C_bot  0.15 k_c 0.0\n",
      "488 Train Loss 14.6960945\n",
      "Loss  1.8691698 C_bot  0.15 k_c 0.0\n",
      "Loss  1.867828 C_bot  0.15 k_c 0.0\n",
      "489 Train Loss 14.686726\n",
      "Loss  1.867828 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8665807 C_bot  0.15 k_c 0.0\n",
      "490 Train Loss 14.677479\n",
      "Loss  1.8665807 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8654498 C_bot  0.15 k_c 0.0\n",
      "491 Train Loss 14.668379\n",
      "Loss  1.8654498 C_bot  0.15 k_c 0.0\n",
      "Loss  1.86414 C_bot  0.15 k_c 0.0\n",
      "492 Train Loss 14.65913\n",
      "Loss  1.86414 C_bot  0.15 k_c 0.0\n",
      "Loss  1.862866 C_bot  0.15 k_c 0.0\n",
      "493 Train Loss 14.649939\n",
      "Loss  1.862866 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8616611 C_bot  0.15 k_c 0.0\n",
      "494 Train Loss 14.640848\n",
      "Loss  1.8616611 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8605024 C_bot  0.15 k_c 0.0\n",
      "495 Train Loss 14.631828\n",
      "Loss  1.8605024 C_bot  0.15 k_c 0.0\n",
      "Loss  1.859242 C_bot  0.15 k_c 0.0\n",
      "496 Train Loss 14.622736\n",
      "Loss  1.859242 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8579669 C_bot  0.15 k_c 0.0\n",
      "497 Train Loss 14.613653\n",
      "Loss  1.8579669 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8567567 C_bot  0.15 k_c 0.0\n",
      "498 Train Loss 14.604653\n",
      "Loss  1.8567567 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8554864 C_bot  0.15 k_c 0.0\n",
      "499 Train Loss 14.595623\n",
      "Loss  1.8554864 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8542972 C_bot  0.15 k_c 0.0\n",
      "500 Train Loss 14.586702\n",
      "Loss  1.8542972 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8530967 C_bot  0.15 k_c 0.0\n",
      "501 Train Loss 14.577793\n",
      "Loss  1.8530967 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8519092 C_bot  0.15 k_c 0.0\n",
      "502 Train Loss 14.568914\n",
      "Loss  1.8519092 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8507031 C_bot  0.15 k_c 0.0\n",
      "503 Train Loss 14.560043\n",
      "Loss  1.8507031 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8494791 C_bot  0.15 k_c 0.0\n",
      "504 Train Loss 14.551178\n",
      "Loss  1.8494791 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8483584 C_bot  0.15 k_c 0.0\n",
      "505 Train Loss 14.5424385\n",
      "Loss  1.8483584 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8470637 C_bot  0.15 k_c 0.0\n",
      "506 Train Loss 14.533543\n",
      "Loss  1.8470637 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8459312 C_bot  0.15 k_c 0.0\n",
      "507 Train Loss 14.524826\n",
      "Loss  1.8459312 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8446703 C_bot  0.15 k_c 0.0\n",
      "508 Train Loss 14.516007\n",
      "Loss  1.8446703 C_bot  0.15 k_c 0.0\n",
      "Loss  1.843489 C_bot  0.15 k_c 0.0\n",
      "509 Train Loss 14.507288\n",
      "Loss  1.843489 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8423035 C_bot  0.15 k_c 0.0\n",
      "510 Train Loss 14.498585\n",
      "Loss  1.8423035 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8410789 C_bot  0.15 k_c 0.0\n",
      "511 Train Loss 14.489856\n",
      "Loss  1.8410789 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8399867 C_bot  0.15 k_c 0.0\n",
      "512 Train Loss 14.481277\n",
      "Loss  1.8399867 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8386334 C_bot  0.15 k_c 0.0\n",
      "513 Train Loss 14.472461\n",
      "Loss  1.8386334 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8376322 C_bot  0.15 k_c 0.0\n",
      "514 Train Loss 14.46401\n",
      "Loss  1.8376322 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8364273 C_bot  0.15 k_c 0.0\n",
      "515 Train Loss 14.455368\n",
      "Loss  1.8364273 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8352206 C_bot  0.15 k_c 0.0\n",
      "516 Train Loss 14.446742\n",
      "Loss  1.8352206 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8341162 C_bot  0.15 k_c 0.0\n",
      "517 Train Loss 14.438234\n",
      "Loss  1.8341162 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8329116 C_bot  0.15 k_c 0.0\n",
      "518 Train Loss 14.429644\n",
      "Loss  1.8329116 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8317759 C_bot  0.15 k_c 0.0\n",
      "519 Train Loss 14.421131\n",
      "Loss  1.8317759 C_bot  0.15 k_c 0.0\n",
      "Loss  1.830584 C_bot  0.15 k_c 0.0\n",
      "520 Train Loss 14.412578\n",
      "Loss  1.830584 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8293673 C_bot  0.15 k_c 0.0\n",
      "521 Train Loss 14.404011\n",
      "Loss  1.8293673 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8282573 C_bot  0.15 k_c 0.0\n",
      "522 Train Loss 14.395567\n",
      "Loss  1.8282573 C_bot  0.15 k_c 0.0\n",
      "Loss  1.827091 C_bot  0.15 k_c 0.0\n",
      "523 Train Loss 14.387076\n",
      "Loss  1.827091 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8259261 C_bot  0.15 k_c 0.0\n",
      "524 Train Loss 14.378595\n",
      "Loss  1.8259261 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8247879 C_bot  0.15 k_c 0.0\n",
      "525 Train Loss 14.370157\n",
      "Loss  1.8247879 C_bot  0.15 k_c 0.0\n",
      "Loss  1.823577 C_bot  0.15 k_c 0.0\n",
      "526 Train Loss 14.361652\n",
      "Loss  1.823577 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8225499 C_bot  0.15 k_c 0.0\n",
      "527 Train Loss 14.353348\n",
      "Loss  1.8225499 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8213984 C_bot  0.15 k_c 0.0\n",
      "528 Train Loss 14.344919\n",
      "Loss  1.8213984 C_bot  0.15 k_c 0.0\n",
      "Loss  1.820315 C_bot  0.15 k_c 0.0\n",
      "529 Train Loss 14.336573\n",
      "Loss  1.820315 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8190747 C_bot  0.15 k_c 0.0\n",
      "530 Train Loss 14.328079\n",
      "Loss  1.8190747 C_bot  0.15 k_c 0.0\n",
      "Loss  1.817999 C_bot  0.15 k_c 0.0\n",
      "531 Train Loss 14.319763\n",
      "Loss  1.817999 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8168583 C_bot  0.15 k_c 0.0\n",
      "532 Train Loss 14.311385\n",
      "Loss  1.8168583 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8157917 C_bot  0.15 k_c 0.0\n",
      "533 Train Loss 14.303086\n",
      "Loss  1.8157917 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8146112 C_bot  0.15 k_c 0.0\n",
      "534 Train Loss 14.294691\n",
      "Loss  1.8146112 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8135058 C_bot  0.15 k_c 0.0\n",
      "535 Train Loss 14.28638\n",
      "Loss  1.8135058 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8123392 C_bot  0.15 k_c 0.0\n",
      "536 Train Loss 14.278013\n",
      "Loss  1.8123392 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8112129 C_bot  0.15 k_c 0.0\n",
      "537 Train Loss 14.269697\n",
      "Loss  1.8112129 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8101054 C_bot  0.15 k_c 0.0\n",
      "538 Train Loss 14.261412\n",
      "Loss  1.8101054 C_bot  0.15 k_c 0.0\n",
      "Loss  1.809066 C_bot  0.15 k_c 0.0\n",
      "539 Train Loss 14.253207\n",
      "Loss  1.809066 C_bot  0.15 k_c 0.0\n",
      "Loss  1.807933 C_bot  0.15 k_c 0.0\n",
      "540 Train Loss 14.244915\n",
      "Loss  1.807933 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8068261 C_bot  0.15 k_c 0.0\n",
      "541 Train Loss 14.236666\n",
      "Loss  1.8068261 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8057058 C_bot  0.15 k_c 0.0\n",
      "542 Train Loss 14.228415\n",
      "Loss  1.8057058 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8046564 C_bot  0.15 k_c 0.0\n",
      "543 Train Loss 14.220251\n",
      "Loss  1.8046564 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8035764 C_bot  0.15 k_c 0.0\n",
      "544 Train Loss 14.21207\n",
      "Loss  1.8035764 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8024863 C_bot  0.15 k_c 0.0\n",
      "545 Train Loss 14.203896\n",
      "Loss  1.8024863 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8013554 C_bot  0.15 k_c 0.0\n",
      "546 Train Loss 14.195695\n",
      "Loss  1.8013554 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8002723 C_bot  0.15 k_c 0.0\n",
      "547 Train Loss 14.187563\n",
      "Loss  1.8002723 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7992011 C_bot  0.15 k_c 0.0\n",
      "548 Train Loss 14.179466\n",
      "Loss  1.7992011 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7981578 C_bot  0.15 k_c 0.0\n",
      "549 Train Loss 14.171417\n",
      "Loss  1.7981578 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7970985 C_bot  0.15 k_c 0.0\n",
      "550 Train Loss 14.163377\n",
      "Loss  1.7970985 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7960465 C_bot  0.15 k_c 0.0\n",
      "551 Train Loss 14.155361\n",
      "Loss  1.7960465 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7949206 C_bot  0.15 k_c 0.0\n",
      "552 Train Loss 14.147298\n",
      "Loss  1.7949206 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7938509 C_bot  0.15 k_c 0.0\n",
      "553 Train Loss 14.139324\n",
      "Loss  1.7938509 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7927886 C_bot  0.15 k_c 0.0\n",
      "554 Train Loss 14.131378\n",
      "Loss  1.7927886 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7917663 C_bot  0.15 k_c 0.0\n",
      "555 Train Loss 14.123504\n",
      "Loss  1.7917663 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7908219 C_bot  0.15 k_c 0.0\n",
      "556 Train Loss 14.115734\n",
      "Loss  1.7908219 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7897272 C_bot  0.15 k_c 0.0\n",
      "557 Train Loss 14.107845\n",
      "Loss  1.7897272 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7886401 C_bot  0.15 k_c 0.0\n",
      "558 Train Loss 14.0999975\n",
      "Loss  1.7886401 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7875822 C_bot  0.15 k_c 0.0\n",
      "559 Train Loss 14.092209\n",
      "Loss  1.7875822 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7866092 C_bot  0.15 k_c 0.0\n",
      "560 Train Loss 14.084536\n",
      "Loss  1.7866092 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7855082 C_bot  0.15 k_c 0.0\n",
      "561 Train Loss 14.076769\n",
      "Loss  1.7855082 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7845026 C_bot  0.15 k_c 0.0\n",
      "562 Train Loss 14.069132\n",
      "Loss  1.7845026 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7834244 C_bot  0.15 k_c 0.0\n",
      "563 Train Loss 14.061454\n",
      "Loss  1.7834244 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7824552 C_bot  0.15 k_c 0.0\n",
      "564 Train Loss 14.053921\n",
      "Loss  1.7824552 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7813298 C_bot  0.15 k_c 0.0\n",
      "565 Train Loss 14.046259\n",
      "Loss  1.7813298 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7802976 C_bot  0.15 k_c 0.0\n",
      "566 Train Loss 14.038732\n",
      "Loss  1.7802976 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7793901 C_bot  0.15 k_c 0.0\n",
      "567 Train Loss 14.031361\n",
      "Loss  1.7793901 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7783684 C_bot  0.15 k_c 0.0\n",
      "568 Train Loss 14.023909\n",
      "Loss  1.7783684 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7773175 C_bot  0.15 k_c 0.0\n",
      "569 Train Loss 14.016457\n",
      "Loss  1.7773175 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7763125 C_bot  0.15 k_c 0.0\n",
      "570 Train Loss 14.0090885\n",
      "Loss  1.7763125 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7753717 C_bot  0.15 k_c 0.0\n",
      "571 Train Loss 14.001818\n",
      "Loss  1.7753717 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7743601 C_bot  0.15 k_c 0.0\n",
      "572 Train Loss 13.994505\n",
      "Loss  1.7743601 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7733451 C_bot  0.15 k_c 0.0\n",
      "573 Train Loss 13.987222\n",
      "Loss  1.7733451 C_bot  0.15 k_c 0.0\n",
      "Loss  1.772315 C_bot  0.15 k_c 0.0\n",
      "574 Train Loss 13.979956\n",
      "Loss  1.772315 C_bot  0.15 k_c 0.0\n",
      "Loss  1.77125 C_bot  0.15 k_c 0.0\n",
      "575 Train Loss 13.972691\n",
      "Loss  1.77125 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7703246 C_bot  0.15 k_c 0.0\n",
      "576 Train Loss 13.965592\n",
      "Loss  1.7703246 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7692579 C_bot  0.15 k_c 0.0\n",
      "577 Train Loss 13.958382\n",
      "Loss  1.7692579 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7681986 C_bot  0.15 k_c 0.0\n",
      "578 Train Loss 13.95121\n",
      "Loss  1.7681986 C_bot  0.15 k_c 0.0\n",
      "Loss  1.767353 C_bot  0.15 k_c 0.0\n",
      "579 Train Loss 13.944283\n",
      "Loss  1.767353 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7663424 C_bot  0.15 k_c 0.0\n",
      "580 Train Loss 13.937222\n",
      "Loss  1.7663424 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7653075 C_bot  0.15 k_c 0.0\n",
      "581 Train Loss 13.9301605\n",
      "Loss  1.7653075 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7643627 C_bot  0.15 k_c 0.0\n",
      "582 Train Loss 13.9232235\n",
      "Loss  1.7643627 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7633277 C_bot  0.15 k_c 0.0\n",
      "583 Train Loss 13.916222\n",
      "Loss  1.7633277 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7624137 C_bot  0.15 k_c 0.0\n",
      "584 Train Loss 13.9093685\n",
      "Loss  1.7624137 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7614367 C_bot  0.15 k_c 0.0\n",
      "585 Train Loss 13.902483\n",
      "Loss  1.7614367 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7604253 C_bot  0.15 k_c 0.0\n",
      "586 Train Loss 13.895584\n",
      "Loss  1.7604253 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7595156 C_bot  0.15 k_c 0.0\n",
      "587 Train Loss 13.888817\n",
      "Loss  1.7595156 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7584646 C_bot  0.15 k_c 0.0\n",
      "588 Train Loss 13.881937\n",
      "Loss  1.7584646 C_bot  0.15 k_c 0.0\n",
      "Loss  1.757518 C_bot  0.15 k_c 0.0\n",
      "589 Train Loss 13.875181\n",
      "Loss  1.757518 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7564842 C_bot  0.15 k_c 0.0\n",
      "590 Train Loss 13.868364\n",
      "Loss  1.7564842 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7555039 C_bot  0.15 k_c 0.0\n",
      "591 Train Loss 13.861628\n",
      "Loss  1.7555039 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7545898 C_bot  0.15 k_c 0.0\n",
      "592 Train Loss 13.85498\n",
      "Loss  1.7545898 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7535621 C_bot  0.15 k_c 0.0\n",
      "593 Train Loss 13.848242\n",
      "Loss  1.7535621 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7526457 C_bot  0.15 k_c 0.0\n",
      "594 Train Loss 13.841642\n",
      "Loss  1.7526457 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7517322 C_bot  0.15 k_c 0.0\n",
      "595 Train Loss 13.835066\n",
      "Loss  1.7517322 C_bot  0.15 k_c 0.0\n",
      "Loss  1.75069 C_bot  0.15 k_c 0.0\n",
      "596 Train Loss 13.8283825\n",
      "Loss  1.75069 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7497798 C_bot  0.15 k_c 0.0\n",
      "597 Train Loss 13.821854\n",
      "Loss  1.7497798 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7487986 C_bot  0.15 k_c 0.0\n",
      "598 Train Loss 13.815275\n",
      "Loss  1.7487986 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7478029 C_bot  0.15 k_c 0.0\n",
      "599 Train Loss 13.808702\n",
      "Loss  1.7478029 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7469233 C_bot  0.15 k_c 0.0\n",
      "600 Train Loss 13.802263\n",
      "Loss  1.7469233 C_bot  0.15 k_c 0.0\n",
      "Loss  1.745959 C_bot  0.15 k_c 0.0\n",
      "601 Train Loss 13.795766\n",
      "Loss  1.745959 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7449051 C_bot  0.15 k_c 0.0\n",
      "602 Train Loss 13.789196\n",
      "Loss  1.7449051 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7440138 C_bot  0.15 k_c 0.0\n",
      "603 Train Loss 13.782806\n",
      "Loss  1.7440138 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7430278 C_bot  0.15 k_c 0.0\n",
      "604 Train Loss 13.776339\n",
      "Loss  1.7430278 C_bot  0.15 k_c 0.0\n",
      "Loss  1.742193 C_bot  0.15 k_c 0.0\n",
      "605 Train Loss 13.770046\n",
      "Loss  1.742193 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7411635 C_bot  0.15 k_c 0.0\n",
      "606 Train Loss 13.7635765\n",
      "Loss  1.7411635 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7401626 C_bot  0.15 k_c 0.0\n",
      "607 Train Loss 13.757148\n",
      "Loss  1.7401626 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7392186 C_bot  0.15 k_c 0.0\n",
      "608 Train Loss 13.7508\n",
      "Loss  1.7392186 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7383014 C_bot  0.15 k_c 0.0\n",
      "609 Train Loss 13.744492\n",
      "Loss  1.7383014 C_bot  0.15 k_c 0.0\n",
      "Loss  1.737229 C_bot  0.15 k_c 0.0\n",
      "610 Train Loss 13.738044\n",
      "Loss  1.737229 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7364147 C_bot  0.15 k_c 0.0\n",
      "611 Train Loss 13.731865\n",
      "Loss  1.7364147 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7354265 C_bot  0.15 k_c 0.0\n",
      "612 Train Loss 13.725536\n",
      "Loss  1.7354265 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7344997 C_bot  0.15 k_c 0.0\n",
      "613 Train Loss 13.719284\n",
      "Loss  1.7344997 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7335894 C_bot  0.15 k_c 0.0\n",
      "614 Train Loss 13.713055\n",
      "Loss  1.7335894 C_bot  0.15 k_c 0.0\n",
      "Loss  1.732711 C_bot  0.15 k_c 0.0\n",
      "615 Train Loss 13.706873\n",
      "Loss  1.732711 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7317426 C_bot  0.15 k_c 0.0\n",
      "616 Train Loss 13.700623\n",
      "Loss  1.7317426 C_bot  0.15 k_c 0.0\n",
      "Loss  1.730795 C_bot  0.15 k_c 0.0\n",
      "617 Train Loss 13.694401\n",
      "Loss  1.730795 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7298154 C_bot  0.15 k_c 0.0\n",
      "618 Train Loss 13.688154\n",
      "Loss  1.7298154 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7288802 C_bot  0.15 k_c 0.0\n",
      "619 Train Loss 13.681969\n",
      "Loss  1.7288802 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7279197 C_bot  0.15 k_c 0.0\n",
      "620 Train Loss 13.6757765\n",
      "Loss  1.7279197 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7270887 C_bot  0.15 k_c 0.0\n",
      "621 Train Loss 13.669718\n",
      "Loss  1.7270887 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7261393 C_bot  0.15 k_c 0.0\n",
      "622 Train Loss 13.663546\n",
      "Loss  1.7261393 C_bot  0.15 k_c 0.0\n",
      "Loss  1.725216 C_bot  0.15 k_c 0.0\n",
      "623 Train Loss 13.657415\n",
      "Loss  1.725216 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7243686 C_bot  0.15 k_c 0.0\n",
      "624 Train Loss 13.651375\n",
      "Loss  1.7243686 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7233711 C_bot  0.15 k_c 0.0\n",
      "625 Train Loss 13.645187\n",
      "Loss  1.7233711 C_bot  0.15 k_c 0.0\n",
      "Loss  1.722378 C_bot  0.15 k_c 0.0\n",
      "626 Train Loss 13.639008\n",
      "Loss  1.722378 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7214993 C_bot  0.15 k_c 0.0\n",
      "627 Train Loss 13.632956\n",
      "Loss  1.7214993 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7205898 C_bot  0.15 k_c 0.0\n",
      "628 Train Loss 13.626884\n",
      "Loss  1.7205898 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7197019 C_bot  0.15 k_c 0.0\n",
      "629 Train Loss 13.620832\n",
      "Loss  1.7197019 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7188393 C_bot  0.15 k_c 0.0\n",
      "630 Train Loss 13.614809\n",
      "Loss  1.7188393 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7178596 C_bot  0.15 k_c 0.0\n",
      "631 Train Loss 13.608679\n",
      "Loss  1.7178596 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7168936 C_bot  0.15 k_c 0.0\n",
      "632 Train Loss 13.602566\n",
      "Loss  1.7168936 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7160321 C_bot  0.15 k_c 0.0\n",
      "633 Train Loss 13.596556\n",
      "Loss  1.7160321 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7151271 C_bot  0.15 k_c 0.0\n",
      "634 Train Loss 13.590502\n",
      "Loss  1.7151271 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7141553 C_bot  0.15 k_c 0.0\n",
      "635 Train Loss 13.584388\n",
      "Loss  1.7141553 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7133441 C_bot  0.15 k_c 0.0\n",
      "636 Train Loss 13.578436\n",
      "Loss  1.7133441 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7124723 C_bot  0.15 k_c 0.0\n",
      "637 Train Loss 13.572411\n",
      "Loss  1.7124723 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7115064 C_bot  0.15 k_c 0.0\n",
      "638 Train Loss 13.566296\n",
      "Loss  1.7115064 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7106516 C_bot  0.15 k_c 0.0\n",
      "639 Train Loss 13.560287\n",
      "Loss  1.7106516 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7096734 C_bot  0.15 k_c 0.0\n",
      "640 Train Loss 13.554152\n",
      "Loss  1.7096734 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7088354 C_bot  0.15 k_c 0.0\n",
      "641 Train Loss 13.548143\n",
      "Loss  1.7088354 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7079768 C_bot  0.15 k_c 0.0\n",
      "642 Train Loss 13.542107\n",
      "Loss  1.7079768 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7070073 C_bot  0.15 k_c 0.0\n",
      "643 Train Loss 13.535953\n",
      "Loss  1.7070073 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7061626 C_bot  0.15 k_c 0.0\n",
      "644 Train Loss 13.529907\n",
      "Loss  1.7061626 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7053047 C_bot  0.15 k_c 0.0\n",
      "645 Train Loss 13.5238285\n",
      "Loss  1.7053047 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7043501 C_bot  0.15 k_c 0.0\n",
      "646 Train Loss 13.517645\n",
      "Loss  1.7043501 C_bot  0.15 k_c 0.0\n",
      "Loss  1.703574 C_bot  0.15 k_c 0.0\n",
      "647 Train Loss 13.5116205\n",
      "Loss  1.703574 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7026887 C_bot  0.15 k_c 0.0\n",
      "648 Train Loss 13.505459\n",
      "Loss  1.7026887 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7017899 C_bot  0.15 k_c 0.0\n",
      "649 Train Loss 13.499258\n",
      "Loss  1.7017899 C_bot  0.15 k_c 0.0\n",
      "Loss  1.70093 C_bot  0.15 k_c 0.0\n",
      "650 Train Loss 13.493078\n",
      "Loss  1.70093 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7000426 C_bot  0.15 k_c 0.0\n",
      "651 Train Loss 13.4868355\n",
      "Loss  1.7000426 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6991893 C_bot  0.15 k_c 0.0\n",
      "652 Train Loss 13.480587\n",
      "Loss  1.6991893 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6983676 C_bot  0.15 k_c 0.0\n",
      "653 Train Loss 13.47434\n",
      "Loss  1.6983676 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6974455 C_bot  0.15 k_c 0.0\n",
      "654 Train Loss 13.467954\n",
      "Loss  1.6974455 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6965848 C_bot  0.15 k_c 0.0\n",
      "655 Train Loss 13.46158\n",
      "Loss  1.6965848 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6957319 C_bot  0.15 k_c 0.0\n",
      "656 Train Loss 13.455162\n",
      "Loss  1.6957319 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6948358 C_bot  0.15 k_c 0.0\n",
      "657 Train Loss 13.448656\n",
      "Loss  1.6948358 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6939632 C_bot  0.15 k_c 0.0\n",
      "658 Train Loss 13.442116\n",
      "Loss  1.6939632 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6932625 C_bot  0.15 k_c 0.0\n",
      "659 Train Loss 13.4356785\n",
      "Loss  1.6932625 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6924024 C_bot  0.15 k_c 0.0\n",
      "660 Train Loss 13.429023\n",
      "Loss  1.6924024 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6915357 C_bot  0.15 k_c 0.0\n",
      "661 Train Loss 13.422295\n",
      "Loss  1.6915357 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6906992 C_bot  0.15 k_c 0.0\n",
      "662 Train Loss 13.415526\n",
      "Loss  1.6906992 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6898024 C_bot  0.15 k_c 0.0\n",
      "663 Train Loss 13.408613\n",
      "Loss  1.6898024 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6889938 C_bot  0.15 k_c 0.0\n",
      "664 Train Loss 13.401717\n",
      "Loss  1.6889938 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6880927 C_bot  0.15 k_c 0.0\n",
      "665 Train Loss 13.394653\n",
      "Loss  1.6880927 C_bot  0.15 k_c 0.0\n",
      "Loss  1.687277 C_bot  0.15 k_c 0.0\n",
      "666 Train Loss 13.387596\n",
      "Loss  1.687277 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6864265 C_bot  0.15 k_c 0.0\n",
      "667 Train Loss 13.380421\n",
      "Loss  1.6864265 C_bot  0.15 k_c 0.0\n",
      "Loss  1.685585 C_bot  0.15 k_c 0.0\n",
      "668 Train Loss 13.373194\n",
      "Loss  1.685585 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6847583 C_bot  0.15 k_c 0.0\n",
      "669 Train Loss 13.365916\n",
      "Loss  1.6847583 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6839607 C_bot  0.15 k_c 0.0\n",
      "670 Train Loss 13.358607\n",
      "Loss  1.6839607 C_bot  0.15 k_c 0.0\n",
      "Loss  1.683122 C_bot  0.15 k_c 0.0\n",
      "671 Train Loss 13.351213\n",
      "Loss  1.683122 C_bot  0.15 k_c 0.0\n",
      "Loss  1.68229 C_bot  0.15 k_c 0.0\n",
      "672 Train Loss 13.343805\n",
      "Loss  1.68229 C_bot  0.15 k_c 0.0\n",
      "Loss  1.681563 C_bot  0.15 k_c 0.0\n",
      "673 Train Loss 13.336487\n",
      "Loss  1.681563 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6805989 C_bot  0.15 k_c 0.0\n",
      "674 Train Loss 13.328933\n",
      "Loss  1.6805989 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6797825 C_bot  0.15 k_c 0.0\n",
      "675 Train Loss 13.321566\n",
      "Loss  1.6797825 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6789784 C_bot  0.15 k_c 0.0\n",
      "676 Train Loss 13.314273\n",
      "Loss  1.6789784 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6780981 C_bot  0.15 k_c 0.0\n",
      "677 Train Loss 13.306976\n",
      "Loss  1.6780981 C_bot  0.15 k_c 0.0\n",
      "Loss  1.677336 C_bot  0.15 k_c 0.0\n",
      "678 Train Loss 13.299898\n",
      "Loss  1.677336 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6764783 C_bot  0.15 k_c 0.0\n",
      "679 Train Loss 13.29286\n",
      "Loss  1.6764783 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6756511 C_bot  0.15 k_c 0.0\n",
      "680 Train Loss 13.285994\n",
      "Loss  1.6756511 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6747582 C_bot  0.15 k_c 0.0\n",
      "681 Train Loss 13.279215\n",
      "Loss  1.6747582 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6739872 C_bot  0.15 k_c 0.0\n",
      "682 Train Loss 13.27273\n",
      "Loss  1.6739872 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6731685 C_bot  0.15 k_c 0.0\n",
      "683 Train Loss 13.266382\n",
      "Loss  1.6731685 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6722736 C_bot  0.15 k_c 0.0\n",
      "684 Train Loss 13.26013\n",
      "Loss  1.6722736 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6714889 C_bot  0.15 k_c 0.0\n",
      "685 Train Loss 13.254152\n",
      "Loss  1.6714889 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6707262 C_bot  0.15 k_c 0.0\n",
      "686 Train Loss 13.248367\n",
      "Loss  1.6707262 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6699028 C_bot  0.15 k_c 0.0\n",
      "687 Train Loss 13.242678\n",
      "Loss  1.6699028 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6691154 C_bot  0.15 k_c 0.0\n",
      "688 Train Loss 13.237153\n",
      "Loss  1.6691154 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6683197 C_bot  0.15 k_c 0.0\n",
      "689 Train Loss 13.231737\n",
      "Loss  1.6683197 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6674892 C_bot  0.15 k_c 0.0\n",
      "690 Train Loss 13.226395\n",
      "Loss  1.6674892 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6667341 C_bot  0.15 k_c 0.0\n",
      "691 Train Loss 13.221214\n",
      "Loss  1.6667341 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6659259 C_bot  0.15 k_c 0.0\n",
      "692 Train Loss 13.2160425\n",
      "Loss  1.6659259 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6651497 C_bot  0.15 k_c 0.0\n",
      "693 Train Loss 13.21096\n",
      "Loss  1.6651497 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6644497 C_bot  0.15 k_c 0.0\n",
      "694 Train Loss 13.206001\n",
      "Loss  1.6644497 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6636591 C_bot  0.15 k_c 0.0\n",
      "695 Train Loss 13.200981\n",
      "Loss  1.6636591 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6628963 C_bot  0.15 k_c 0.0\n",
      "696 Train Loss 13.196011\n",
      "Loss  1.6628963 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6621461 C_bot  0.15 k_c 0.0\n",
      "697 Train Loss 13.19107\n",
      "Loss  1.6621461 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6614405 C_bot  0.15 k_c 0.0\n",
      "698 Train Loss 13.186188\n",
      "Loss  1.6614405 C_bot  0.15 k_c 0.0\n",
      "Loss  1.660619 C_bot  0.15 k_c 0.0\n",
      "699 Train Loss 13.181194\n",
      "Loss  1.660619 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6599468 C_bot  0.15 k_c 0.0\n",
      "700 Train Loss 13.176359\n",
      "Loss  1.6599468 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6590487 C_bot  0.15 k_c 0.0\n",
      "701 Train Loss 13.171305\n",
      "Loss  1.6590487 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6583498 C_bot  0.15 k_c 0.0\n",
      "702 Train Loss 13.166458\n",
      "Loss  1.6583498 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6575992 C_bot  0.15 k_c 0.0\n",
      "703 Train Loss 13.161566\n",
      "Loss  1.6575992 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6567999 C_bot  0.15 k_c 0.0\n",
      "704 Train Loss 13.156634\n",
      "Loss  1.6567999 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6560516 C_bot  0.15 k_c 0.0\n",
      "705 Train Loss 13.151771\n",
      "Loss  1.6560516 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6553047 C_bot  0.15 k_c 0.0\n",
      "706 Train Loss 13.146922\n",
      "Loss  1.6553047 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6545562 C_bot  0.15 k_c 0.0\n",
      "707 Train Loss 13.142084\n",
      "Loss  1.6545562 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6537806 C_bot  0.15 k_c 0.0\n",
      "708 Train Loss 13.137238\n",
      "Loss  1.6537806 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6529939 C_bot  0.15 k_c 0.0\n",
      "709 Train Loss 13.132408\n",
      "Loss  1.6529939 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6521596 C_bot  0.15 k_c 0.0\n",
      "710 Train Loss 13.127549\n",
      "Loss  1.6521596 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6514459 C_bot  0.15 k_c 0.0\n",
      "711 Train Loss 13.122828\n",
      "Loss  1.6514459 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6506114 C_bot  0.15 k_c 0.0\n",
      "712 Train Loss 13.118021\n",
      "Loss  1.6506114 C_bot  0.15 k_c 0.0\n",
      "Loss  1.649894 C_bot  0.15 k_c 0.0\n",
      "713 Train Loss 13.113355\n",
      "Loss  1.649894 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6490308 C_bot  0.15 k_c 0.0\n",
      "714 Train Loss 13.108564\n",
      "Loss  1.6490308 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6482859 C_bot  0.15 k_c 0.0\n",
      "715 Train Loss 13.103918\n",
      "Loss  1.6482859 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6474601 C_bot  0.15 k_c 0.0\n",
      "716 Train Loss 13.099225\n",
      "Loss  1.6474601 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6466576 C_bot  0.15 k_c 0.0\n",
      "717 Train Loss 13.094582\n",
      "Loss  1.6466576 C_bot  0.15 k_c 0.0\n",
      "Loss  1.645874 C_bot  0.15 k_c 0.0\n",
      "718 Train Loss 13.089975\n",
      "Loss  1.645874 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6450609 C_bot  0.15 k_c 0.0\n",
      "719 Train Loss 13.085367\n",
      "Loss  1.6450609 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6442866 C_bot  0.15 k_c 0.0\n",
      "720 Train Loss 13.080828\n",
      "Loss  1.6442866 C_bot  0.15 k_c 0.0\n",
      "Loss  1.643401 C_bot  0.15 k_c 0.0\n",
      "721 Train Loss 13.076197\n",
      "Loss  1.643401 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6426405 C_bot  0.15 k_c 0.0\n",
      "722 Train Loss 13.071711\n",
      "Loss  1.6426405 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6417824 C_bot  0.15 k_c 0.0\n",
      "723 Train Loss 13.067154\n",
      "Loss  1.6417824 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6409566 C_bot  0.15 k_c 0.0\n",
      "724 Train Loss 13.062653\n",
      "Loss  1.6409566 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6400006 C_bot  0.15 k_c 0.0\n",
      "725 Train Loss 13.058036\n",
      "Loss  1.6400006 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6392367 C_bot  0.15 k_c 0.0\n",
      "726 Train Loss 13.053629\n",
      "Loss  1.6392367 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6384294 C_bot  0.15 k_c 0.0\n",
      "727 Train Loss 13.049206\n",
      "Loss  1.6384294 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6375822 C_bot  0.15 k_c 0.0\n",
      "728 Train Loss 13.044756\n",
      "Loss  1.6375822 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6367122 C_bot  0.15 k_c 0.0\n",
      "729 Train Loss 13.0402975\n",
      "Loss  1.6367122 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6359609 C_bot  0.15 k_c 0.0\n",
      "730 Train Loss 13.035978\n",
      "Loss  1.6359609 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6349889 C_bot  0.15 k_c 0.0\n",
      "731 Train Loss 13.031453\n",
      "Loss  1.6349889 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6342287 C_bot  0.15 k_c 0.0\n",
      "732 Train Loss 13.027155\n",
      "Loss  1.6342287 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6334288 C_bot  0.15 k_c 0.0\n",
      "733 Train Loss 13.022829\n",
      "Loss  1.6334288 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6325762 C_bot  0.15 k_c 0.0\n",
      "734 Train Loss 13.018471\n",
      "Loss  1.6325762 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6316999 C_bot  0.15 k_c 0.0\n",
      "735 Train Loss 13.014102\n",
      "Loss  1.6316999 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6308843 C_bot  0.15 k_c 0.0\n",
      "736 Train Loss 13.009806\n",
      "Loss  1.6308843 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6300703 C_bot  0.15 k_c 0.0\n",
      "737 Train Loss 13.005526\n",
      "Loss  1.6300703 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6292405 C_bot  0.15 k_c 0.0\n",
      "738 Train Loss 13.001246\n",
      "Loss  1.6292405 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6283625 C_bot  0.15 k_c 0.0\n",
      "739 Train Loss 12.996927\n",
      "Loss  1.6283625 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6274942 C_bot  0.15 k_c 0.0\n",
      "740 Train Loss 12.992632\n",
      "Loss  1.6274942 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6267059 C_bot  0.15 k_c 0.0\n",
      "741 Train Loss 12.988432\n",
      "Loss  1.6267059 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6258761 C_bot  0.15 k_c 0.0\n",
      "742 Train Loss 12.984205\n",
      "Loss  1.6258761 C_bot  0.15 k_c 0.0\n",
      "Loss  1.624996 C_bot  0.15 k_c 0.0\n",
      "743 Train Loss 12.979933\n",
      "Loss  1.624996 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6241745 C_bot  0.15 k_c 0.0\n",
      "744 Train Loss 12.975739\n",
      "Loss  1.6241745 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6233121 C_bot  0.15 k_c 0.0\n",
      "745 Train Loss 12.971516\n",
      "Loss  1.6233121 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6224808 C_bot  0.15 k_c 0.0\n",
      "746 Train Loss 12.967335\n",
      "Loss  1.6224808 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6217245 C_bot  0.15 k_c 0.0\n",
      "747 Train Loss 12.963238\n",
      "Loss  1.6217245 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6209028 C_bot  0.15 k_c 0.0\n",
      "748 Train Loss 12.959089\n",
      "Loss  1.6209028 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6200879 C_bot  0.15 k_c 0.0\n",
      "749 Train Loss 12.954962\n",
      "Loss  1.6200879 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6191492 C_bot  0.15 k_c 0.0\n",
      "750 Train Loss 12.950717\n",
      "Loss  1.6191492 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6184074 C_bot  0.15 k_c 0.0\n",
      "751 Train Loss 12.946683\n",
      "Loss  1.6184074 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6175739 C_bot  0.15 k_c 0.0\n",
      "752 Train Loss 12.942572\n",
      "Loss  1.6175739 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6167399 C_bot  0.15 k_c 0.0\n",
      "753 Train Loss 12.938465\n",
      "Loss  1.6167399 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6159352 C_bot  0.15 k_c 0.0\n",
      "754 Train Loss 12.934403\n",
      "Loss  1.6159352 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6152003 C_bot  0.15 k_c 0.0\n",
      "755 Train Loss 12.930423\n",
      "Loss  1.6152003 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6144358 C_bot  0.15 k_c 0.0\n",
      "756 Train Loss 12.926425\n",
      "Loss  1.6144358 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6135696 C_bot  0.15 k_c 0.0\n",
      "757 Train Loss 12.922332\n",
      "Loss  1.6135696 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6128144 C_bot  0.15 k_c 0.0\n",
      "758 Train Loss 12.918367\n",
      "Loss  1.6128144 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6119066 C_bot  0.15 k_c 0.0\n",
      "759 Train Loss 12.914258\n",
      "Loss  1.6119066 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6111726 C_bot  0.15 k_c 0.0\n",
      "760 Train Loss 12.910332\n",
      "Loss  1.6111726 C_bot  0.15 k_c 0.0\n",
      "Loss  1.610344 C_bot  0.15 k_c 0.0\n",
      "761 Train Loss 12.9063225\n",
      "Loss  1.610344 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6095457 C_bot  0.15 k_c 0.0\n",
      "762 Train Loss 12.90236\n",
      "Loss  1.6095457 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6087067 C_bot  0.15 k_c 0.0\n",
      "763 Train Loss 12.898361\n",
      "Loss  1.6087067 C_bot  0.15 k_c 0.0\n",
      "Loss  1.607947 C_bot  0.15 k_c 0.0\n",
      "764 Train Loss 12.894456\n",
      "Loss  1.607947 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6071159 C_bot  0.15 k_c 0.0\n",
      "765 Train Loss 12.8904915\n",
      "Loss  1.6071159 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6063416 C_bot  0.15 k_c 0.0\n",
      "766 Train Loss 12.886596\n",
      "Loss  1.6063416 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6055659 C_bot  0.15 k_c 0.0\n",
      "767 Train Loss 12.882708\n",
      "Loss  1.6055659 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6047875 C_bot  0.15 k_c 0.0\n",
      "768 Train Loss 12.878824\n",
      "Loss  1.6047875 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6039653 C_bot  0.15 k_c 0.0\n",
      "769 Train Loss 12.874916\n",
      "Loss  1.6039653 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6031774 C_bot  0.15 k_c 0.0\n",
      "770 Train Loss 12.871049\n",
      "Loss  1.6031774 C_bot  0.15 k_c 0.0\n",
      "Loss  1.602349 C_bot  0.15 k_c 0.0\n",
      "771 Train Loss 12.867149\n",
      "Loss  1.602349 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6015165 C_bot  0.15 k_c 0.0\n",
      "772 Train Loss 12.863261\n",
      "Loss  1.6015165 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6008561 C_bot  0.15 k_c 0.0\n",
      "773 Train Loss 12.859556\n",
      "Loss  1.6008561 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6000239 C_bot  0.15 k_c 0.0\n",
      "774 Train Loss 12.855686\n",
      "Loss  1.6000239 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5992599 C_bot  0.15 k_c 0.0\n",
      "775 Train Loss 12.851895\n",
      "Loss  1.5992599 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5984966 C_bot  0.15 k_c 0.0\n",
      "776 Train Loss 12.848124\n",
      "Loss  1.5984966 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5976944 C_bot  0.15 k_c 0.0\n",
      "777 Train Loss 12.8443165\n",
      "Loss  1.5976944 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5968773 C_bot  0.15 k_c 0.0\n",
      "778 Train Loss 12.840502\n",
      "Loss  1.5968773 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5959953 C_bot  0.15 k_c 0.0\n",
      "779 Train Loss 12.836643\n",
      "Loss  1.5959953 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5952848 C_bot  0.15 k_c 0.0\n",
      "780 Train Loss 12.83296\n",
      "Loss  1.5952848 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5945523 C_bot  0.15 k_c 0.0\n",
      "781 Train Loss 12.829266\n",
      "Loss  1.5945523 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5937408 C_bot  0.15 k_c 0.0\n",
      "782 Train Loss 12.825502\n",
      "Loss  1.5937408 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5929976 C_bot  0.15 k_c 0.0\n",
      "783 Train Loss 12.821825\n",
      "Loss  1.5929976 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5920902 C_bot  0.15 k_c 0.0\n",
      "784 Train Loss 12.817983\n",
      "Loss  1.5920902 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5914308 C_bot  0.15 k_c 0.0\n",
      "785 Train Loss 12.814404\n",
      "Loss  1.5914308 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5906535 C_bot  0.15 k_c 0.0\n",
      "786 Train Loss 12.810722\n",
      "Loss  1.5906535 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5898669 C_bot  0.15 k_c 0.0\n",
      "787 Train Loss 12.807034\n",
      "Loss  1.5898669 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5891157 C_bot  0.15 k_c 0.0\n",
      "788 Train Loss 12.803391\n",
      "Loss  1.5891157 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5883522 C_bot  0.15 k_c 0.0\n",
      "789 Train Loss 12.799752\n",
      "Loss  1.5883522 C_bot  0.15 k_c 0.0\n",
      "Loss  1.587517 C_bot  0.15 k_c 0.0\n",
      "790 Train Loss 12.796047\n",
      "Loss  1.587517 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5867469 C_bot  0.15 k_c 0.0\n",
      "791 Train Loss 12.792414\n",
      "Loss  1.5867469 C_bot  0.15 k_c 0.0\n",
      "Loss  1.586101 C_bot  0.15 k_c 0.0\n",
      "792 Train Loss 12.788923\n",
      "Loss  1.586101 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5852041 C_bot  0.15 k_c 0.0\n",
      "793 Train Loss 12.785189\n",
      "Loss  1.5852041 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5844262 C_bot  0.15 k_c 0.0\n",
      "794 Train Loss 12.781576\n",
      "Loss  1.5844262 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5837326 C_bot  0.15 k_c 0.0\n",
      "795 Train Loss 12.778063\n",
      "Loss  1.5837326 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5829262 C_bot  0.15 k_c 0.0\n",
      "796 Train Loss 12.774449\n",
      "Loss  1.5829262 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5821282 C_bot  0.15 k_c 0.0\n",
      "797 Train Loss 12.770848\n",
      "Loss  1.5821282 C_bot  0.15 k_c 0.0\n",
      "Loss  1.581321 C_bot  0.15 k_c 0.0\n",
      "798 Train Loss 12.767248\n",
      "Loss  1.581321 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5806178 C_bot  0.15 k_c 0.0\n",
      "799 Train Loss 12.763765\n",
      "Loss  1.5806178 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5798686 C_bot  0.15 k_c 0.0\n",
      "800 Train Loss 12.760242\n",
      "Loss  1.5798686 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5790637 C_bot  0.15 k_c 0.0\n",
      "801 Train Loss 12.756672\n",
      "Loss  1.5790637 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5783181 C_bot  0.15 k_c 0.0\n",
      "802 Train Loss 12.753172\n",
      "Loss  1.5783181 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5775634 C_bot  0.15 k_c 0.0\n",
      "803 Train Loss 12.749676\n",
      "Loss  1.5775634 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5768574 C_bot  0.15 k_c 0.0\n",
      "804 Train Loss 12.746235\n",
      "Loss  1.5768574 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5761055 C_bot  0.15 k_c 0.0\n",
      "805 Train Loss 12.742752\n",
      "Loss  1.5761055 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5752301 C_bot  0.15 k_c 0.0\n",
      "806 Train Loss 12.73916\n",
      "Loss  1.5752301 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5745171 C_bot  0.15 k_c 0.0\n",
      "807 Train Loss 12.735741\n",
      "Loss  1.5745171 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5736994 C_bot  0.15 k_c 0.0\n",
      "808 Train Loss 12.732222\n",
      "Loss  1.5736994 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5729723 C_bot  0.15 k_c 0.0\n",
      "809 Train Loss 12.728805\n",
      "Loss  1.5729723 C_bot  0.15 k_c 0.0\n",
      "Loss  1.572181 C_bot  0.15 k_c 0.0\n",
      "810 Train Loss 12.725334\n",
      "Loss  1.572181 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5714942 C_bot  0.15 k_c 0.0\n",
      "811 Train Loss 12.72197\n",
      "Loss  1.5714942 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5707293 C_bot  0.15 k_c 0.0\n",
      "812 Train Loss 12.71854\n",
      "Loss  1.5707293 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5699288 C_bot  0.15 k_c 0.0\n",
      "813 Train Loss 12.715086\n",
      "Loss  1.5699288 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5692106 C_bot  0.15 k_c 0.0\n",
      "814 Train Loss 12.7117195\n",
      "Loss  1.5692106 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5684854 C_bot  0.15 k_c 0.0\n",
      "815 Train Loss 12.708352\n",
      "Loss  1.5684854 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5677379 C_bot  0.15 k_c 0.0\n",
      "816 Train Loss 12.704977\n",
      "Loss  1.5677379 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5670588 C_bot  0.15 k_c 0.0\n",
      "817 Train Loss 12.701679\n",
      "Loss  1.5670588 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5661407 C_bot  0.15 k_c 0.0\n",
      "818 Train Loss 12.698145\n",
      "Loss  1.5661407 C_bot  0.15 k_c 0.0\n",
      "Loss  1.565474 C_bot  0.15 k_c 0.0\n",
      "819 Train Loss 12.694872\n",
      "Loss  1.565474 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5647249 C_bot  0.15 k_c 0.0\n",
      "820 Train Loss 12.691529\n",
      "Loss  1.5647249 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5639011 C_bot  0.15 k_c 0.0\n",
      "821 Train Loss 12.688118\n",
      "Loss  1.5639011 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5631865 C_bot  0.15 k_c 0.0\n",
      "822 Train Loss 12.684822\n",
      "Loss  1.5631865 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5624954 C_bot  0.15 k_c 0.0\n",
      "823 Train Loss 12.681559\n",
      "Loss  1.5624954 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5616862 C_bot  0.15 k_c 0.0\n",
      "824 Train Loss 12.678187\n",
      "Loss  1.5616862 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5609758 C_bot  0.15 k_c 0.0\n",
      "825 Train Loss 12.674919\n",
      "Loss  1.5609758 C_bot  0.15 k_c 0.0\n",
      "Loss  1.560246 C_bot  0.15 k_c 0.0\n",
      "826 Train Loss 12.671645\n",
      "Loss  1.560246 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5594757 C_bot  0.15 k_c 0.0\n",
      "827 Train Loss 12.668335\n",
      "Loss  1.5594757 C_bot  0.15 k_c 0.0\n",
      "Loss  1.558744 C_bot  0.15 k_c 0.0\n",
      "828 Train Loss 12.665073\n",
      "Loss  1.558744 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5580572 C_bot  0.15 k_c 0.0\n",
      "829 Train Loss 12.661861\n",
      "Loss  1.5580572 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5572202 C_bot  0.15 k_c 0.0\n",
      "830 Train Loss 12.658508\n",
      "Loss  1.5572202 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5565183 C_bot  0.15 k_c 0.0\n",
      "831 Train Loss 12.655301\n",
      "Loss  1.5565183 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5557855 C_bot  0.15 k_c 0.0\n",
      "832 Train Loss 12.652069\n",
      "Loss  1.5557855 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5550138 C_bot  0.15 k_c 0.0\n",
      "833 Train Loss 12.648804\n",
      "Loss  1.5550138 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5543559 C_bot  0.15 k_c 0.0\n",
      "834 Train Loss 12.645662\n",
      "Loss  1.5543559 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5536398 C_bot  0.15 k_c 0.0\n",
      "835 Train Loss 12.64247\n",
      "Loss  1.5536398 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5528183 C_bot  0.15 k_c 0.0\n",
      "836 Train Loss 12.639181\n",
      "Loss  1.5528183 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5521022 C_bot  0.15 k_c 0.0\n",
      "837 Train Loss 12.636005\n",
      "Loss  1.5521022 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5514442 C_bot  0.15 k_c 0.0\n",
      "838 Train Loss 12.6328945\n",
      "Loss  1.5514442 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5505847 C_bot  0.15 k_c 0.0\n",
      "839 Train Loss 12.629588\n",
      "Loss  1.5505847 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5498534 C_bot  0.15 k_c 0.0\n",
      "840 Train Loss 12.626423\n",
      "Loss  1.5498534 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5491775 C_bot  0.15 k_c 0.0\n",
      "841 Train Loss 12.623315\n",
      "Loss  1.5491775 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5483922 C_bot  0.15 k_c 0.0\n",
      "842 Train Loss 12.620106\n",
      "Loss  1.5483922 C_bot  0.15 k_c 0.0\n",
      "Loss  1.547655 C_bot  0.15 k_c 0.0\n",
      "843 Train Loss 12.616955\n",
      "Loss  1.547655 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5469551 C_bot  0.15 k_c 0.0\n",
      "844 Train Loss 12.613848\n",
      "Loss  1.5469551 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5462481 C_bot  0.15 k_c 0.0\n",
      "845 Train Loss 12.61074\n",
      "Loss  1.5462481 C_bot  0.15 k_c 0.0\n",
      "Loss  1.545399 C_bot  0.15 k_c 0.0\n",
      "846 Train Loss 12.607497\n",
      "Loss  1.545399 C_bot  0.15 k_c 0.0\n",
      "Loss  1.544728 C_bot  0.15 k_c 0.0\n",
      "847 Train Loss 12.604441\n",
      "Loss  1.544728 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5440662 C_bot  0.15 k_c 0.0\n",
      "848 Train Loss 12.601402\n",
      "Loss  1.5440662 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5433208 C_bot  0.15 k_c 0.0\n",
      "849 Train Loss 12.598282\n",
      "Loss  1.5433208 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5425532 C_bot  0.15 k_c 0.0\n",
      "850 Train Loss 12.595152\n",
      "Loss  1.5425532 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5418744 C_bot  0.15 k_c 0.0\n",
      "851 Train Loss 12.592115\n",
      "Loss  1.5418744 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5410944 C_bot  0.15 k_c 0.0\n",
      "852 Train Loss 12.588982\n",
      "Loss  1.5410944 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5404086 C_bot  0.15 k_c 0.0\n",
      "853 Train Loss 12.5859585\n",
      "Loss  1.5404086 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5397102 C_bot  0.15 k_c 0.0\n",
      "854 Train Loss 12.582925\n",
      "Loss  1.5397102 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5388956 C_bot  0.15 k_c 0.0\n",
      "855 Train Loss 12.579777\n",
      "Loss  1.5388956 C_bot  0.15 k_c 0.0\n",
      "Loss  1.538254 C_bot  0.15 k_c 0.0\n",
      "856 Train Loss 12.576817\n",
      "Loss  1.538254 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5375136 C_bot  0.15 k_c 0.0\n",
      "857 Train Loss 12.573765\n",
      "Loss  1.5375136 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5366532 C_bot  0.15 k_c 0.0\n",
      "858 Train Loss 12.570591\n",
      "Loss  1.5366532 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5360911 C_bot  0.15 k_c 0.0\n",
      "859 Train Loss 12.567728\n",
      "Loss  1.5360911 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5352626 C_bot  0.15 k_c 0.0\n",
      "860 Train Loss 12.564611\n",
      "Loss  1.5352626 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5345781 C_bot  0.15 k_c 0.0\n",
      "861 Train Loss 12.561638\n",
      "Loss  1.5345781 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5338682 C_bot  0.15 k_c 0.0\n",
      "862 Train Loss 12.558644\n",
      "Loss  1.5338682 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5332128 C_bot  0.15 k_c 0.0\n",
      "863 Train Loss 12.555717\n",
      "Loss  1.5332128 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5323887 C_bot  0.15 k_c 0.0\n",
      "864 Train Loss 12.552628\n",
      "Loss  1.5323887 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5317609 C_bot  0.15 k_c 0.0\n",
      "865 Train Loss 12.549734\n",
      "Loss  1.5317609 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5309879 C_bot  0.15 k_c 0.0\n",
      "866 Train Loss 12.546711\n",
      "Loss  1.5309879 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5302424 C_bot  0.15 k_c 0.0\n",
      "867 Train Loss 12.543722\n",
      "Loss  1.5302424 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5295404 C_bot  0.15 k_c 0.0\n",
      "868 Train Loss 12.540776\n",
      "Loss  1.5295404 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5287353 C_bot  0.15 k_c 0.0\n",
      "869 Train Loss 12.537737\n",
      "Loss  1.5287353 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5280454 C_bot  0.15 k_c 0.0\n",
      "870 Train Loss 12.534822\n",
      "Loss  1.5280454 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5273678 C_bot  0.15 k_c 0.0\n",
      "871 Train Loss 12.531921\n",
      "Loss  1.5273678 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5266101 C_bot  0.15 k_c 0.0\n",
      "872 Train Loss 12.528946\n",
      "Loss  1.5266101 C_bot  0.15 k_c 0.0\n",
      "Loss  1.525972 C_bot  0.15 k_c 0.0\n",
      "873 Train Loss 12.526103\n",
      "Loss  1.525972 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5252681 C_bot  0.15 k_c 0.0\n",
      "874 Train Loss 12.523199\n",
      "Loss  1.5252681 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5245076 C_bot  0.15 k_c 0.0\n",
      "875 Train Loss 12.520239\n",
      "Loss  1.5245076 C_bot  0.15 k_c 0.0\n",
      "Loss  1.523777 C_bot  0.15 k_c 0.0\n",
      "876 Train Loss 12.517319\n",
      "Loss  1.523777 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5230235 C_bot  0.15 k_c 0.0\n",
      "877 Train Loss 12.514387\n",
      "Loss  1.5230235 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5223666 C_bot  0.15 k_c 0.0\n",
      "878 Train Loss 12.511549\n",
      "Loss  1.5223666 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5216148 C_bot  0.15 k_c 0.0\n",
      "879 Train Loss 12.508627\n",
      "Loss  1.5216148 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5209994 C_bot  0.15 k_c 0.0\n",
      "880 Train Loss 12.50585\n",
      "Loss  1.5209994 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5202746 C_bot  0.15 k_c 0.0\n",
      "881 Train Loss 12.502965\n",
      "Loss  1.5202746 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5195093 C_bot  0.15 k_c 0.0\n",
      "882 Train Loss 12.500046\n",
      "Loss  1.5195093 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5187957 C_bot  0.15 k_c 0.0\n",
      "883 Train Loss 12.497192\n",
      "Loss  1.5187957 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5180036 C_bot  0.15 k_c 0.0\n",
      "884 Train Loss 12.494255\n",
      "Loss  1.5180036 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5174184 C_bot  0.15 k_c 0.0\n",
      "885 Train Loss 12.491534\n",
      "Loss  1.5174184 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5167159 C_bot  0.15 k_c 0.0\n",
      "886 Train Loss 12.488707\n",
      "Loss  1.5167159 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5158803 C_bot  0.15 k_c 0.0\n",
      "887 Train Loss 12.48575\n",
      "Loss  1.5158803 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5152074 C_bot  0.15 k_c 0.0\n",
      "888 Train Loss 12.482958\n",
      "Loss  1.5152074 C_bot  0.15 k_c 0.0\n",
      "Loss  1.514507 C_bot  0.15 k_c 0.0\n",
      "889 Train Loss 12.480148\n",
      "Loss  1.514507 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5137196 C_bot  0.15 k_c 0.0\n",
      "890 Train Loss 12.477259\n",
      "Loss  1.5137196 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5130961 C_bot  0.15 k_c 0.0\n",
      "891 Train Loss 12.474537\n",
      "Loss  1.5130961 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5123959 C_bot  0.15 k_c 0.0\n",
      "892 Train Loss 12.471741\n",
      "Loss  1.5123959 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5116285 C_bot  0.15 k_c 0.0\n",
      "893 Train Loss 12.468889\n",
      "Loss  1.5116285 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5109245 C_bot  0.15 k_c 0.0\n",
      "894 Train Loss 12.4661045\n",
      "Loss  1.5109245 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5101867 C_bot  0.15 k_c 0.0\n",
      "895 Train Loss 12.463287\n",
      "Loss  1.5101867 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5094805 C_bot  0.15 k_c 0.0\n",
      "896 Train Loss 12.46051\n",
      "Loss  1.5094805 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5087731 C_bot  0.15 k_c 0.0\n",
      "897 Train Loss 12.457743\n",
      "Loss  1.5087731 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5081096 C_bot  0.15 k_c 0.0\n",
      "898 Train Loss 12.455017\n",
      "Loss  1.5081096 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5073732 C_bot  0.15 k_c 0.0\n",
      "899 Train Loss 12.45223\n",
      "Loss  1.5073732 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5067242 C_bot  0.15 k_c 0.0\n",
      "900 Train Loss 12.449533\n",
      "Loss  1.5067242 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5059161 C_bot  0.15 k_c 0.0\n",
      "901 Train Loss 12.446682\n",
      "Loss  1.5059161 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5052266 C_bot  0.15 k_c 0.0\n",
      "902 Train Loss 12.443954\n",
      "Loss  1.5052266 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5044764 C_bot  0.15 k_c 0.0\n",
      "903 Train Loss 12.441176\n",
      "Loss  1.5044764 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5038215 C_bot  0.15 k_c 0.0\n",
      "904 Train Loss 12.438494\n",
      "Loss  1.5038215 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5031062 C_bot  0.15 k_c 0.0\n",
      "905 Train Loss 12.435759\n",
      "Loss  1.5031062 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5024495 C_bot  0.15 k_c 0.0\n",
      "906 Train Loss 12.433086\n",
      "Loss  1.5024495 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5017178 C_bot  0.15 k_c 0.0\n",
      "907 Train Loss 12.430344\n",
      "Loss  1.5017178 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5009533 C_bot  0.15 k_c 0.0\n",
      "908 Train Loss 12.427578\n",
      "Loss  1.5009533 C_bot  0.15 k_c 0.0\n",
      "Loss  1.500235 C_bot  0.15 k_c 0.0\n",
      "909 Train Loss 12.424858\n",
      "Loss  1.500235 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4995457 C_bot  0.15 k_c 0.0\n",
      "910 Train Loss 12.422176\n",
      "Loss  1.4995457 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4988585 C_bot  0.15 k_c 0.0\n",
      "911 Train Loss 12.4195\n",
      "Loss  1.4988585 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4981565 C_bot  0.15 k_c 0.0\n",
      "912 Train Loss 12.416815\n",
      "Loss  1.4981565 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4973811 C_bot  0.15 k_c 0.0\n",
      "913 Train Loss 12.414061\n",
      "Loss  1.4973811 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4967295 C_bot  0.15 k_c 0.0\n",
      "914 Train Loss 12.41144\n",
      "Loss  1.4967295 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4960046 C_bot  0.15 k_c 0.0\n",
      "915 Train Loss 12.408745\n",
      "Loss  1.4960046 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4952934 C_bot  0.15 k_c 0.0\n",
      "916 Train Loss 12.406069\n",
      "Loss  1.4952934 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4945152 C_bot  0.15 k_c 0.0\n",
      "917 Train Loss 12.4033375\n",
      "Loss  1.4945152 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4938563 C_bot  0.15 k_c 0.0\n",
      "918 Train Loss 12.400726\n",
      "Loss  1.4938563 C_bot  0.15 k_c 0.0\n",
      "Loss  1.49318 C_bot  0.15 k_c 0.0\n",
      "919 Train Loss 12.398098\n",
      "Loss  1.49318 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4924517 C_bot  0.15 k_c 0.0\n",
      "920 Train Loss 12.395431\n",
      "Loss  1.4924517 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4917403 C_bot  0.15 k_c 0.0\n",
      "921 Train Loss 12.39278\n",
      "Loss  1.4917403 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4909976 C_bot  0.15 k_c 0.0\n",
      "922 Train Loss 12.390102\n",
      "Loss  1.4909976 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4903237 C_bot  0.15 k_c 0.0\n",
      "923 Train Loss 12.387503\n",
      "Loss  1.4903237 C_bot  0.15 k_c 0.0\n",
      "Loss  1.489579 C_bot  0.15 k_c 0.0\n",
      "924 Train Loss 12.384838\n",
      "Loss  1.489579 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4888465 C_bot  0.15 k_c 0.0\n",
      "925 Train Loss 12.382184\n",
      "Loss  1.4888465 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4881136 C_bot  0.15 k_c 0.0\n",
      "926 Train Loss 12.3795395\n",
      "Loss  1.4881136 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4874557 C_bot  0.15 k_c 0.0\n",
      "927 Train Loss 12.376974\n",
      "Loss  1.4874557 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4867743 C_bot  0.15 k_c 0.0\n",
      "928 Train Loss 12.374388\n",
      "Loss  1.4867743 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4860193 C_bot  0.15 k_c 0.0\n",
      "929 Train Loss 12.371736\n",
      "Loss  1.4860193 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4853518 C_bot  0.15 k_c 0.0\n",
      "930 Train Loss 12.369175\n",
      "Loss  1.4853518 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4846303 C_bot  0.15 k_c 0.0\n",
      "931 Train Loss 12.366564\n",
      "Loss  1.4846303 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4838626 C_bot  0.15 k_c 0.0\n",
      "932 Train Loss 12.363911\n",
      "Loss  1.4838626 C_bot  0.15 k_c 0.0\n",
      "Loss  1.483239 C_bot  0.15 k_c 0.0\n",
      "933 Train Loss 12.361408\n",
      "Loss  1.483239 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4824666 C_bot  0.15 k_c 0.0\n",
      "934 Train Loss 12.358757\n",
      "Loss  1.4824666 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4817965 C_bot  0.15 k_c 0.0\n",
      "935 Train Loss 12.356218\n",
      "Loss  1.4817965 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4810349 C_bot  0.15 k_c 0.0\n",
      "936 Train Loss 12.353592\n",
      "Loss  1.4810349 C_bot  0.15 k_c 0.0\n",
      "Loss  1.480379 C_bot  0.15 k_c 0.0\n",
      "937 Train Loss 12.351071\n",
      "Loss  1.480379 C_bot  0.15 k_c 0.0\n",
      "Loss  1.479617 C_bot  0.15 k_c 0.0\n",
      "938 Train Loss 12.3484535\n",
      "Loss  1.479617 C_bot  0.15 k_c 0.0\n",
      "Loss  1.478848 C_bot  0.15 k_c 0.0\n",
      "939 Train Loss 12.345835\n",
      "Loss  1.478848 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4781234 C_bot  0.15 k_c 0.0\n",
      "940 Train Loss 12.34326\n",
      "Loss  1.4781234 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4775254 C_bot  0.15 k_c 0.0\n",
      "941 Train Loss 12.340818\n",
      "Loss  1.4775254 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4767911 C_bot  0.15 k_c 0.0\n",
      "942 Train Loss 12.338247\n",
      "Loss  1.4767911 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4760338 C_bot  0.15 k_c 0.0\n",
      "943 Train Loss 12.335653\n",
      "Loss  1.4760338 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4753317 C_bot  0.15 k_c 0.0\n",
      "944 Train Loss 12.33312\n",
      "Loss  1.4753317 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4746486 C_bot  0.15 k_c 0.0\n",
      "945 Train Loss 12.330613\n",
      "Loss  1.4746486 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4738559 C_bot  0.15 k_c 0.0\n",
      "946 Train Loss 12.327996\n",
      "Loss  1.4738559 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4731809 C_bot  0.15 k_c 0.0\n",
      "947 Train Loss 12.325505\n",
      "Loss  1.4731809 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4724691 C_bot  0.15 k_c 0.0\n",
      "948 Train Loss 12.322983\n",
      "Loss  1.4724691 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4718038 C_bot  0.15 k_c 0.0\n",
      "949 Train Loss 12.320507\n",
      "Loss  1.4718038 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4710575 C_bot  0.15 k_c 0.0\n",
      "950 Train Loss 12.317957\n",
      "Loss  1.4710575 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4703501 C_bot  0.15 k_c 0.0\n",
      "951 Train Loss 12.315451\n",
      "Loss  1.4703501 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4696214 C_bot  0.15 k_c 0.0\n",
      "952 Train Loss 12.312923\n",
      "Loss  1.4696214 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4688598 C_bot  0.15 k_c 0.0\n",
      "953 Train Loss 12.310373\n",
      "Loss  1.4688598 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4681389 C_bot  0.15 k_c 0.0\n",
      "954 Train Loss 12.307865\n",
      "Loss  1.4681389 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4674543 C_bot  0.15 k_c 0.0\n",
      "955 Train Loss 12.305395\n",
      "Loss  1.4674543 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4667361 C_bot  0.15 k_c 0.0\n",
      "956 Train Loss 12.302902\n",
      "Loss  1.4667361 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4660728 C_bot  0.15 k_c 0.0\n",
      "957 Train Loss 12.300459\n",
      "Loss  1.4660728 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4653056 C_bot  0.15 k_c 0.0\n",
      "958 Train Loss 12.297924\n",
      "Loss  1.4653056 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4644928 C_bot  0.15 k_c 0.0\n",
      "959 Train Loss 12.295347\n",
      "Loss  1.4644928 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4638722 C_bot  0.15 k_c 0.0\n",
      "960 Train Loss 12.292959\n",
      "Loss  1.4638722 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4631782 C_bot  0.15 k_c 0.0\n",
      "961 Train Loss 12.290506\n",
      "Loss  1.4631782 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4624257 C_bot  0.15 k_c 0.0\n",
      "962 Train Loss 12.288006\n",
      "Loss  1.4624257 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4616711 C_bot  0.15 k_c 0.0\n",
      "963 Train Loss 12.285494\n",
      "Loss  1.4616711 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4610324 C_bot  0.15 k_c 0.0\n",
      "964 Train Loss 12.28311\n",
      "Loss  1.4610324 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4602594 C_bot  0.15 k_c 0.0\n",
      "965 Train Loss 12.280602\n",
      "Loss  1.4602594 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4594812 C_bot  0.15 k_c 0.0\n",
      "966 Train Loss 12.278078\n",
      "Loss  1.4594812 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4588094 C_bot  0.15 k_c 0.0\n",
      "967 Train Loss 12.275673\n",
      "Loss  1.4588094 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4580818 C_bot  0.15 k_c 0.0\n",
      "968 Train Loss 12.273222\n",
      "Loss  1.4580818 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4573336 C_bot  0.15 k_c 0.0\n",
      "969 Train Loss 12.2707405\n",
      "Loss  1.4573336 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4565991 C_bot  0.15 k_c 0.0\n",
      "970 Train Loss 12.268278\n",
      "Loss  1.4565991 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4559189 C_bot  0.15 k_c 0.0\n",
      "971 Train Loss 12.265888\n",
      "Loss  1.4559189 C_bot  0.15 k_c 0.0\n",
      "Loss  1.455162 C_bot  0.15 k_c 0.0\n",
      "972 Train Loss 12.263412\n",
      "Loss  1.455162 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4544348 C_bot  0.15 k_c 0.0\n",
      "973 Train Loss 12.260971\n",
      "Loss  1.4544348 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4536939 C_bot  0.15 k_c 0.0\n",
      "974 Train Loss 12.25853\n",
      "Loss  1.4536939 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4530233 C_bot  0.15 k_c 0.0\n",
      "975 Train Loss 12.25615\n",
      "Loss  1.4530233 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4523331 C_bot  0.15 k_c 0.0\n",
      "976 Train Loss 12.253757\n",
      "Loss  1.4523331 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4516175 C_bot  0.15 k_c 0.0\n",
      "977 Train Loss 12.251352\n",
      "Loss  1.4516175 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4508156 C_bot  0.15 k_c 0.0\n",
      "978 Train Loss 12.24885\n",
      "Loss  1.4508156 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4501137 C_bot  0.15 k_c 0.0\n",
      "979 Train Loss 12.246463\n",
      "Loss  1.4501137 C_bot  0.15 k_c 0.0\n",
      "Loss  1.44935 C_bot  0.15 k_c 0.0\n",
      "980 Train Loss 12.244017\n",
      "Loss  1.44935 C_bot  0.15 k_c 0.0\n",
      "Loss  1.448728 C_bot  0.15 k_c 0.0\n",
      "981 Train Loss 12.241707\n",
      "Loss  1.448728 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4478834 C_bot  0.15 k_c 0.0\n",
      "982 Train Loss 12.239186\n",
      "Loss  1.4478834 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4472079 C_bot  0.15 k_c 0.0\n",
      "983 Train Loss 12.236841\n",
      "Loss  1.4472079 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4464738 C_bot  0.15 k_c 0.0\n",
      "984 Train Loss 12.23443\n",
      "Loss  1.4464738 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4457629 C_bot  0.15 k_c 0.0\n",
      "985 Train Loss 12.232054\n",
      "Loss  1.4457629 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4449903 C_bot  0.15 k_c 0.0\n",
      "986 Train Loss 12.229619\n",
      "Loss  1.4449903 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4442531 C_bot  0.15 k_c 0.0\n",
      "987 Train Loss 12.227217\n",
      "Loss  1.4442531 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4434528 C_bot  0.15 k_c 0.0\n",
      "988 Train Loss 12.224764\n",
      "Loss  1.4434528 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4428225 C_bot  0.15 k_c 0.0\n",
      "989 Train Loss 12.222482\n",
      "Loss  1.4428225 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4420446 C_bot  0.15 k_c 0.0\n",
      "990 Train Loss 12.220047\n",
      "Loss  1.4420446 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4413635 C_bot  0.15 k_c 0.0\n",
      "991 Train Loss 12.217725\n",
      "Loss  1.4413635 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4406275 C_bot  0.15 k_c 0.0\n",
      "992 Train Loss 12.215345\n",
      "Loss  1.4406275 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4397838 C_bot  0.15 k_c 0.0\n",
      "993 Train Loss 12.21286\n",
      "Loss  1.4397838 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4391339 C_bot  0.15 k_c 0.0\n",
      "994 Train Loss 12.210577\n",
      "Loss  1.4391339 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4383655 C_bot  0.15 k_c 0.0\n",
      "995 Train Loss 12.208174\n",
      "Loss  1.4383655 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4375863 C_bot  0.15 k_c 0.0\n",
      "996 Train Loss 12.205765\n",
      "Loss  1.4375863 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4368984 C_bot  0.15 k_c 0.0\n",
      "997 Train Loss 12.203454\n",
      "Loss  1.4368984 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4361336 C_bot  0.15 k_c 0.0\n",
      "998 Train Loss 12.201061\n",
      "Loss  1.4361336 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4354056 C_bot  0.15 k_c 0.0\n",
      "999 Train Loss 12.198713\n",
      "Loss  1.4354056 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4346406 C_bot  0.15 k_c 0.0\n",
      "1000 Train Loss 12.196337\n",
      "Loss  1.4346406 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4339169 C_bot  0.15 k_c 0.0\n",
      "1001 Train Loss 12.1939945\n",
      "Loss  1.4339169 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4331995 C_bot  0.15 k_c 0.0\n",
      "1002 Train Loss 12.191668\n",
      "Loss  1.4331995 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4324127 C_bot  0.15 k_c 0.0\n",
      "1003 Train Loss 12.189276\n",
      "Loss  1.4324127 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4316854 C_bot  0.15 k_c 0.0\n",
      "1004 Train Loss 12.186944\n",
      "Loss  1.4316854 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4309425 C_bot  0.15 k_c 0.0\n",
      "1005 Train Loss 12.184602\n",
      "Loss  1.4309425 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4302064 C_bot  0.15 k_c 0.0\n",
      "1006 Train Loss 12.182272\n",
      "Loss  1.4302064 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4294807 C_bot  0.15 k_c 0.0\n",
      "1007 Train Loss 12.179946\n",
      "Loss  1.4294807 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4286883 C_bot  0.15 k_c 0.0\n",
      "1008 Train Loss 12.177567\n",
      "Loss  1.4286883 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4279336 C_bot  0.15 k_c 0.0\n",
      "1009 Train Loss 12.175222\n",
      "Loss  1.4279336 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4271878 C_bot  0.15 k_c 0.0\n",
      "1010 Train Loss 12.17289\n",
      "Loss  1.4271878 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4264138 C_bot  0.15 k_c 0.0\n",
      "1011 Train Loss 12.170536\n",
      "Loss  1.4264138 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4256823 C_bot  0.15 k_c 0.0\n",
      "1012 Train Loss 12.168222\n",
      "Loss  1.4256823 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4249984 C_bot  0.15 k_c 0.0\n",
      "1013 Train Loss 12.165962\n",
      "Loss  1.4249984 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4241806 C_bot  0.15 k_c 0.0\n",
      "1014 Train Loss 12.163575\n",
      "Loss  1.4241806 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4234171 C_bot  0.15 k_c 0.0\n",
      "1015 Train Loss 12.161238\n",
      "Loss  1.4234171 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4226336 C_bot  0.15 k_c 0.0\n",
      "1016 Train Loss 12.158886\n",
      "Loss  1.4226336 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4219084 C_bot  0.15 k_c 0.0\n",
      "1017 Train Loss 12.156601\n",
      "Loss  1.4219084 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4211318 C_bot  0.15 k_c 0.0\n",
      "1018 Train Loss 12.154257\n",
      "Loss  1.4211318 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4203886 C_bot  0.15 k_c 0.0\n",
      "1019 Train Loss 12.151955\n",
      "Loss  1.4203886 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4196974 C_bot  0.15 k_c 0.0\n",
      "1020 Train Loss 12.1497135\n",
      "Loss  1.4196974 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4187797 C_bot  0.15 k_c 0.0\n",
      "1021 Train Loss 12.147235\n",
      "Loss  1.4187797 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4181849 C_bot  0.15 k_c 0.0\n",
      "1022 Train Loss 12.14509\n",
      "Loss  1.4181849 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4173324 C_bot  0.15 k_c 0.0\n",
      "1023 Train Loss 12.142693\n",
      "Loss  1.4173324 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4165274 C_bot  0.15 k_c 0.0\n",
      "1024 Train Loss 12.140339\n",
      "Loss  1.4165274 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4157754 C_bot  0.15 k_c 0.0\n",
      "1025 Train Loss 12.138044\n",
      "Loss  1.4157754 C_bot  0.15 k_c 0.0\n",
      "Loss  1.415105 C_bot  0.15 k_c 0.0\n",
      "1026 Train Loss 12.135835\n",
      "Loss  1.415105 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4143921 C_bot  0.15 k_c 0.0\n",
      "1027 Train Loss 12.133583\n",
      "Loss  1.4143921 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4135826 C_bot  0.15 k_c 0.0\n",
      "1028 Train Loss 12.131241\n",
      "Loss  1.4135826 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4127932 C_bot  0.15 k_c 0.0\n",
      "1029 Train Loss 12.128917\n",
      "Loss  1.4127932 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4120746 C_bot  0.15 k_c 0.0\n",
      "1030 Train Loss 12.126669\n",
      "Loss  1.4120746 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4112529 C_bot  0.15 k_c 0.0\n",
      "1031 Train Loss 12.124321\n",
      "Loss  1.4112529 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4105386 C_bot  0.15 k_c 0.0\n",
      "1032 Train Loss 12.12208\n",
      "Loss  1.4105386 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4096544 C_bot  0.15 k_c 0.0\n",
      "1033 Train Loss 12.119672\n",
      "Loss  1.4096544 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4089459 C_bot  0.15 k_c 0.0\n",
      "1034 Train Loss 12.117446\n",
      "Loss  1.4089459 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4081286 C_bot  0.15 k_c 0.0\n",
      "1035 Train Loss 12.1151085\n",
      "Loss  1.4081286 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4074072 C_bot  0.15 k_c 0.0\n",
      "1036 Train Loss 12.112872\n",
      "Loss  1.4074072 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4067004 C_bot  0.15 k_c 0.0\n",
      "1037 Train Loss 12.110653\n",
      "Loss  1.4067004 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4059116 C_bot  0.15 k_c 0.0\n",
      "1038 Train Loss 12.108349\n",
      "Loss  1.4059116 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4051204 C_bot  0.15 k_c 0.0\n",
      "1039 Train Loss 12.106053\n",
      "Loss  1.4051204 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4043453 C_bot  0.15 k_c 0.0\n",
      "1040 Train Loss 12.103767\n",
      "Loss  1.4043453 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4035068 C_bot  0.15 k_c 0.0\n",
      "1041 Train Loss 12.101425\n",
      "Loss  1.4035068 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4027034 C_bot  0.15 k_c 0.0\n",
      "1042 Train Loss 12.099121\n",
      "Loss  1.4027034 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4019996 C_bot  0.15 k_c 0.0\n",
      "1043 Train Loss 12.096911\n",
      "Loss  1.4019996 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4011832 C_bot  0.15 k_c 0.0\n",
      "1044 Train Loss 12.094603\n",
      "Loss  1.4011832 C_bot  0.15 k_c 0.0\n",
      "Loss  1.400421 C_bot  0.15 k_c 0.0\n",
      "1045 Train Loss 12.09234\n",
      "Loss  1.400421 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3996184 C_bot  0.15 k_c 0.0\n",
      "1046 Train Loss 12.090042\n",
      "Loss  1.3996184 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3989141 C_bot  0.15 k_c 0.0\n",
      "1047 Train Loss 12.087849\n",
      "Loss  1.3989141 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3980777 C_bot  0.15 k_c 0.0\n",
      "1048 Train Loss 12.085516\n",
      "Loss  1.3980777 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3973259 C_bot  0.15 k_c 0.0\n",
      "1049 Train Loss 12.083281\n",
      "Loss  1.3973259 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3965261 C_bot  0.15 k_c 0.0\n",
      "1050 Train Loss 12.080994\n",
      "Loss  1.3965261 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3957403 C_bot  0.15 k_c 0.0\n",
      "1051 Train Loss 12.078718\n",
      "Loss  1.3957403 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3949542 C_bot  0.15 k_c 0.0\n",
      "1052 Train Loss 12.076454\n",
      "Loss  1.3949542 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3941536 C_bot  0.15 k_c 0.0\n",
      "1053 Train Loss 12.074167\n",
      "Loss  1.3941536 C_bot  0.15 k_c 0.0\n",
      "Loss  1.393364 C_bot  0.15 k_c 0.0\n",
      "1054 Train Loss 12.071897\n",
      "Loss  1.393364 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3925316 C_bot  0.15 k_c 0.0\n",
      "1055 Train Loss 12.06959\n",
      "Loss  1.3925316 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3917981 C_bot  0.15 k_c 0.0\n",
      "1056 Train Loss 12.067371\n",
      "Loss  1.3917981 C_bot  0.15 k_c 0.0\n",
      "Loss  1.390965 C_bot  0.15 k_c 0.0\n",
      "1057 Train Loss 12.065067\n",
      "Loss  1.390965 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3902192 C_bot  0.15 k_c 0.0\n",
      "1058 Train Loss 12.062848\n",
      "Loss  1.3902192 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3893911 C_bot  0.15 k_c 0.0\n",
      "1059 Train Loss 12.060541\n",
      "Loss  1.3893911 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3886331 C_bot  0.15 k_c 0.0\n",
      "1060 Train Loss 12.058319\n",
      "Loss  1.3886331 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3878375 C_bot  0.15 k_c 0.0\n",
      "1061 Train Loss 12.056047\n",
      "Loss  1.3878375 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3870354 C_bot  0.15 k_c 0.0\n",
      "1062 Train Loss 12.053774\n",
      "Loss  1.3870354 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3862251 C_bot  0.15 k_c 0.0\n",
      "1063 Train Loss 12.0515\n",
      "Loss  1.3862251 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3854905 C_bot  0.15 k_c 0.0\n",
      "1064 Train Loss 12.0492935\n",
      "Loss  1.3854905 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3846532 C_bot  0.15 k_c 0.0\n",
      "1065 Train Loss 12.046989\n",
      "Loss  1.3846532 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3838702 C_bot  0.15 k_c 0.0\n",
      "1066 Train Loss 12.044747\n",
      "Loss  1.3838702 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3830514 C_bot  0.15 k_c 0.0\n",
      "1067 Train Loss 12.042457\n",
      "Loss  1.3830514 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3822604 C_bot  0.15 k_c 0.0\n",
      "1068 Train Loss 12.040209\n",
      "Loss  1.3822604 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3814168 C_bot  0.15 k_c 0.0\n",
      "1069 Train Loss 12.037901\n",
      "Loss  1.3814168 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3806655 C_bot  0.15 k_c 0.0\n",
      "1070 Train Loss 12.035682\n",
      "Loss  1.3806655 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3798351 C_bot  0.15 k_c 0.0\n",
      "1071 Train Loss 12.033398\n",
      "Loss  1.3798351 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3789731 C_bot  0.15 k_c 0.0\n",
      "1072 Train Loss 12.031072\n",
      "Loss  1.3789731 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3782288 C_bot  0.15 k_c 0.0\n",
      "1073 Train Loss 12.028864\n",
      "Loss  1.3782288 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3774122 C_bot  0.15 k_c 0.0\n",
      "1074 Train Loss 12.026596\n",
      "Loss  1.3774122 C_bot  0.15 k_c 0.0\n",
      "Loss  1.376681 C_bot  0.15 k_c 0.0\n",
      "1075 Train Loss 12.0244\n",
      "Loss  1.376681 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3758643 C_bot  0.15 k_c 0.0\n",
      "1076 Train Loss 12.022125\n",
      "Loss  1.3758643 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3750175 C_bot  0.15 k_c 0.0\n",
      "1077 Train Loss 12.019823\n",
      "Loss  1.3750175 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3741868 C_bot  0.15 k_c 0.0\n",
      "1078 Train Loss 12.017531\n",
      "Loss  1.3741868 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3733633 C_bot  0.15 k_c 0.0\n",
      "1079 Train Loss 12.015251\n",
      "Loss  1.3733633 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3725959 C_bot  0.15 k_c 0.0\n",
      "1080 Train Loss 12.013026\n",
      "Loss  1.3725959 C_bot  0.15 k_c 0.0\n",
      "Loss  1.371773 C_bot  0.15 k_c 0.0\n",
      "1081 Train Loss 12.01074\n",
      "Loss  1.371773 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3709129 C_bot  0.15 k_c 0.0\n",
      "1082 Train Loss 12.008429\n",
      "Loss  1.3709129 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3701876 C_bot  0.15 k_c 0.0\n",
      "1083 Train Loss 12.006243\n",
      "Loss  1.3701876 C_bot  0.15 k_c 0.0\n",
      "Loss  1.369329 C_bot  0.15 k_c 0.0\n",
      "1084 Train Loss 12.003922\n",
      "Loss  1.369329 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3685449 C_bot  0.15 k_c 0.0\n",
      "1085 Train Loss 12.001684\n",
      "Loss  1.3685449 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3676482 C_bot  0.15 k_c 0.0\n",
      "1086 Train Loss 11.999327\n",
      "Loss  1.3676482 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3668439 C_bot  0.15 k_c 0.0\n",
      "1087 Train Loss 11.997061\n",
      "Loss  1.3668439 C_bot  0.15 k_c 0.0\n",
      "Loss  1.366031 C_bot  0.15 k_c 0.0\n",
      "1088 Train Loss 11.994793\n",
      "Loss  1.366031 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3652285 C_bot  0.15 k_c 0.0\n",
      "1089 Train Loss 11.992528\n",
      "Loss  1.3652285 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3644378 C_bot  0.15 k_c 0.0\n",
      "1090 Train Loss 11.9902725\n",
      "Loss  1.3644378 C_bot  0.15 k_c 0.0\n",
      "Loss  1.363629 C_bot  0.15 k_c 0.0\n",
      "1091 Train Loss 11.988008\n",
      "Loss  1.363629 C_bot  0.15 k_c 0.0\n",
      "Loss  1.36276 C_bot  0.15 k_c 0.0\n",
      "1092 Train Loss 11.985669\n",
      "Loss  1.36276 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3619943 C_bot  0.15 k_c 0.0\n",
      "1093 Train Loss 11.983445\n",
      "Loss  1.3619943 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3611187 C_bot  0.15 k_c 0.0\n",
      "1094 Train Loss 11.981104\n",
      "Loss  1.3611187 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3603323 C_bot  0.15 k_c 0.0\n",
      "1095 Train Loss 11.978849\n",
      "Loss  1.3603323 C_bot  0.15 k_c 0.0\n",
      "Loss  1.359499 C_bot  0.15 k_c 0.0\n",
      "1096 Train Loss 11.976555\n",
      "Loss  1.359499 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3586437 C_bot  0.15 k_c 0.0\n",
      "1097 Train Loss 11.97423\n",
      "Loss  1.3586437 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3577795 C_bot  0.15 k_c 0.0\n",
      "1098 Train Loss 11.971896\n",
      "Loss  1.3577795 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3570696 C_bot  0.15 k_c 0.0\n",
      "1099 Train Loss 11.96972\n",
      "Loss  1.3570696 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3561747 C_bot  0.15 k_c 0.0\n",
      "1100 Train Loss 11.96735\n",
      "Loss  1.3561747 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3553511 C_bot  0.15 k_c 0.0\n",
      "1101 Train Loss 11.965057\n",
      "Loss  1.3553511 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3545129 C_bot  0.15 k_c 0.0\n",
      "1102 Train Loss 11.962748\n",
      "Loss  1.3545129 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3536664 C_bot  0.15 k_c 0.0\n",
      "1103 Train Loss 11.960425\n",
      "Loss  1.3536664 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3528723 C_bot  0.15 k_c 0.0\n",
      "1104 Train Loss 11.958157\n",
      "Loss  1.3528723 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3520607 C_bot  0.15 k_c 0.0\n",
      "1105 Train Loss 11.95587\n",
      "Loss  1.3520607 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3512571 C_bot  0.15 k_c 0.0\n",
      "1106 Train Loss 11.953586\n",
      "Loss  1.3512571 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3503447 C_bot  0.15 k_c 0.0\n",
      "1107 Train Loss 11.951199\n",
      "Loss  1.3503447 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3495677 C_bot  0.15 k_c 0.0\n",
      "1108 Train Loss 11.948936\n",
      "Loss  1.3495677 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3487356 C_bot  0.15 k_c 0.0\n",
      "1109 Train Loss 11.946625\n",
      "Loss  1.3487356 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3478887 C_bot  0.15 k_c 0.0\n",
      "1110 Train Loss 11.944299\n",
      "Loss  1.3478887 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3470423 C_bot  0.15 k_c 0.0\n",
      "1111 Train Loss 11.941963\n",
      "Loss  1.3470423 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3462086 C_bot  0.15 k_c 0.0\n",
      "1112 Train Loss 11.9396515\n",
      "Loss  1.3462086 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3453614 C_bot  0.15 k_c 0.0\n",
      "1113 Train Loss 11.937311\n",
      "Loss  1.3453614 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3445437 C_bot  0.15 k_c 0.0\n",
      "1114 Train Loss 11.935008\n",
      "Loss  1.3445437 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3437173 C_bot  0.15 k_c 0.0\n",
      "1115 Train Loss 11.932697\n",
      "Loss  1.3437173 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3428777 C_bot  0.15 k_c 0.0\n",
      "1116 Train Loss 11.930362\n",
      "Loss  1.3428777 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3420845 C_bot  0.15 k_c 0.0\n",
      "1117 Train Loss 11.928087\n",
      "Loss  1.3420845 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3412029 C_bot  0.15 k_c 0.0\n",
      "1118 Train Loss 11.925711\n",
      "Loss  1.3412029 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3403226 C_bot  0.15 k_c 0.0\n",
      "1119 Train Loss 11.92334\n",
      "Loss  1.3403226 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3394332 C_bot  0.15 k_c 0.0\n",
      "1120 Train Loss 11.920962\n",
      "Loss  1.3394332 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3387406 C_bot  0.15 k_c 0.0\n",
      "1121 Train Loss 11.9187765\n",
      "Loss  1.3387406 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3378224 C_bot  0.15 k_c 0.0\n",
      "1122 Train Loss 11.916367\n",
      "Loss  1.3378224 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3369851 C_bot  0.15 k_c 0.0\n",
      "1123 Train Loss 11.91404\n",
      "Loss  1.3369851 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3362218 C_bot  0.15 k_c 0.0\n",
      "1124 Train Loss 11.911782\n",
      "Loss  1.3362218 C_bot  0.15 k_c 0.0\n",
      "Loss  1.335293 C_bot  0.15 k_c 0.0\n",
      "1125 Train Loss 11.909364\n",
      "Loss  1.335293 C_bot  0.15 k_c 0.0\n",
      "Loss  1.334421 C_bot  0.15 k_c 0.0\n",
      "1126 Train Loss 11.9070015\n",
      "Loss  1.334421 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3336426 C_bot  0.15 k_c 0.0\n",
      "1127 Train Loss 11.90473\n",
      "Loss  1.3336426 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3327528 C_bot  0.15 k_c 0.0\n",
      "1128 Train Loss 11.902355\n",
      "Loss  1.3327528 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3319515 C_bot  0.15 k_c 0.0\n",
      "1129 Train Loss 11.900063\n",
      "Loss  1.3319515 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3310661 C_bot  0.15 k_c 0.0\n",
      "1130 Train Loss 11.897693\n",
      "Loss  1.3310661 C_bot  0.15 k_c 0.0\n",
      "Loss  1.330204 C_bot  0.15 k_c 0.0\n",
      "1131 Train Loss 11.895344\n",
      "Loss  1.330204 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3293992 C_bot  0.15 k_c 0.0\n",
      "1132 Train Loss 11.893053\n",
      "Loss  1.3293992 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3284701 C_bot  0.15 k_c 0.0\n",
      "1133 Train Loss 11.890644\n",
      "Loss  1.3284701 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3276547 C_bot  0.15 k_c 0.0\n",
      "1134 Train Loss 11.888346\n",
      "Loss  1.3276547 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3267395 C_bot  0.15 k_c 0.0\n",
      "1135 Train Loss 11.885953\n",
      "Loss  1.3267395 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3258773 C_bot  0.15 k_c 0.0\n",
      "1136 Train Loss 11.8836155\n",
      "Loss  1.3258773 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3250161 C_bot  0.15 k_c 0.0\n",
      "1137 Train Loss 11.881278\n",
      "Loss  1.3250161 C_bot  0.15 k_c 0.0\n",
      "Loss  1.324243 C_bot  0.15 k_c 0.0\n",
      "1138 Train Loss 11.879036\n",
      "Loss  1.324243 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3232865 C_bot  0.15 k_c 0.0\n",
      "1139 Train Loss 11.87661\n",
      "Loss  1.3232865 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3225067 C_bot  0.15 k_c 0.0\n",
      "1140 Train Loss 11.874363\n",
      "Loss  1.3225067 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3216399 C_bot  0.15 k_c 0.0\n",
      "1141 Train Loss 11.872035\n",
      "Loss  1.3216399 C_bot  0.15 k_c 0.0\n",
      "Loss  1.32077 C_bot  0.15 k_c 0.0\n",
      "1142 Train Loss 11.869705\n",
      "Loss  1.32077 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3198875 C_bot  0.15 k_c 0.0\n",
      "1143 Train Loss 11.867367\n",
      "Loss  1.3198875 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3189639 C_bot  0.15 k_c 0.0\n",
      "1144 Train Loss 11.864991\n",
      "Loss  1.3189639 C_bot  0.15 k_c 0.0\n",
      "Loss  1.318138 C_bot  0.15 k_c 0.0\n",
      "1145 Train Loss 11.862717\n",
      "Loss  1.318138 C_bot  0.15 k_c 0.0\n",
      "Loss  1.317265 C_bot  0.15 k_c 0.0\n",
      "1146 Train Loss 11.860399\n",
      "Loss  1.317265 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3163555 C_bot  0.15 k_c 0.0\n",
      "1147 Train Loss 11.858047\n",
      "Loss  1.3163555 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3154674 C_bot  0.15 k_c 0.0\n",
      "1148 Train Loss 11.855723\n",
      "Loss  1.3154674 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3145205 C_bot  0.15 k_c 0.0\n",
      "1149 Train Loss 11.85334\n",
      "Loss  1.3145205 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3137485 C_bot  0.15 k_c 0.0\n",
      "1150 Train Loss 11.851141\n",
      "Loss  1.3137485 C_bot  0.15 k_c 0.0\n",
      "Loss  1.312841 C_bot  0.15 k_c 0.0\n",
      "1151 Train Loss 11.84881\n",
      "Loss  1.312841 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3119631 C_bot  0.15 k_c 0.0\n",
      "1152 Train Loss 11.846507\n",
      "Loss  1.3119631 C_bot  0.15 k_c 0.0\n",
      "Loss  1.311037 C_bot  0.15 k_c 0.0\n",
      "1153 Train Loss 11.844172\n",
      "Loss  1.311037 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3101436 C_bot  0.15 k_c 0.0\n",
      "1154 Train Loss 11.841861\n",
      "Loss  1.3101436 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3093036 C_bot  0.15 k_c 0.0\n",
      "1155 Train Loss 11.839615\n",
      "Loss  1.3093036 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3083972 C_bot  0.15 k_c 0.0\n",
      "1156 Train Loss 11.83731\n",
      "Loss  1.3083972 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3075032 C_bot  0.15 k_c 0.0\n",
      "1157 Train Loss 11.83501\n",
      "Loss  1.3075032 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3066435 C_bot  0.15 k_c 0.0\n",
      "1158 Train Loss 11.832761\n",
      "Loss  1.3066435 C_bot  0.15 k_c 0.0\n",
      "Loss  1.305656 C_bot  0.15 k_c 0.0\n",
      "1159 Train Loss 11.83038\n",
      "Loss  1.305656 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3048104 C_bot  0.15 k_c 0.0\n",
      "1160 Train Loss 11.828151\n",
      "Loss  1.3048104 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3038837 C_bot  0.15 k_c 0.0\n",
      "1161 Train Loss 11.825842\n",
      "Loss  1.3038837 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3030503 C_bot  0.15 k_c 0.0\n",
      "1162 Train Loss 11.823632\n",
      "Loss  1.3030503 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3020961 C_bot  0.15 k_c 0.0\n",
      "1163 Train Loss 11.821306\n",
      "Loss  1.3020961 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3011806 C_bot  0.15 k_c 0.0\n",
      "1164 Train Loss 11.819023\n",
      "Loss  1.3011806 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3003511 C_bot  0.15 k_c 0.0\n",
      "1165 Train Loss 11.816828\n",
      "Loss  1.3003511 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2992717 C_bot  0.15 k_c 0.0\n",
      "1166 Train Loss 11.814393\n",
      "Loss  1.2992717 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2985411 C_bot  0.15 k_c 0.0\n",
      "1167 Train Loss 11.812302\n",
      "Loss  1.2985411 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2975227 C_bot  0.15 k_c 0.0\n",
      "1168 Train Loss 11.809935\n",
      "Loss  1.2975227 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2966708 C_bot  0.15 k_c 0.0\n",
      "1169 Train Loss 11.8077345\n",
      "Loss  1.2966708 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2957692 C_bot  0.15 k_c 0.0\n",
      "1170 Train Loss 11.805486\n",
      "Loss  1.2957692 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2948695 C_bot  0.15 k_c 0.0\n",
      "1171 Train Loss 11.803254\n",
      "Loss  1.2948695 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2939234 C_bot  0.15 k_c 0.0\n",
      "1172 Train Loss 11.800964\n",
      "Loss  1.2939234 C_bot  0.15 k_c 0.0\n",
      "Loss  1.293056 C_bot  0.15 k_c 0.0\n",
      "1173 Train Loss 11.79877\n",
      "Loss  1.293056 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2921252 C_bot  0.15 k_c 0.0\n",
      "1174 Train Loss 11.796509\n",
      "Loss  1.2921252 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2911812 C_bot  0.15 k_c 0.0\n",
      "1175 Train Loss 11.794237\n",
      "Loss  1.2911812 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2902341 C_bot  0.15 k_c 0.0\n",
      "1176 Train Loss 11.791973\n",
      "Loss  1.2902341 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2892925 C_bot  0.15 k_c 0.0\n",
      "1177 Train Loss 11.789707\n",
      "Loss  1.2892925 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2884209 C_bot  0.15 k_c 0.0\n",
      "1178 Train Loss 11.787525\n",
      "Loss  1.2884209 C_bot  0.15 k_c 0.0\n",
      "Loss  1.287534 C_bot  0.15 k_c 0.0\n",
      "1179 Train Loss 11.785324\n",
      "Loss  1.287534 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2865542 C_bot  0.15 k_c 0.0\n",
      "1180 Train Loss 11.783036\n",
      "Loss  1.2865542 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2856618 C_bot  0.15 k_c 0.0\n",
      "1181 Train Loss 11.78084\n",
      "Loss  1.2856618 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2846793 C_bot  0.15 k_c 0.0\n",
      "1182 Train Loss 11.778555\n",
      "Loss  1.2846793 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2838311 C_bot  0.15 k_c 0.0\n",
      "1183 Train Loss 11.776403\n",
      "Loss  1.2838311 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2828649 C_bot  0.15 k_c 0.0\n",
      "1184 Train Loss 11.774145\n",
      "Loss  1.2828649 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2819667 C_bot  0.15 k_c 0.0\n",
      "1185 Train Loss 11.77195\n",
      "Loss  1.2819667 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2810615 C_bot  0.15 k_c 0.0\n",
      "1186 Train Loss 11.769757\n",
      "Loss  1.2810615 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2801048 C_bot  0.15 k_c 0.0\n",
      "1187 Train Loss 11.767506\n",
      "Loss  1.2801048 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2791715 C_bot  0.15 k_c 0.0\n",
      "1188 Train Loss 11.765291\n",
      "Loss  1.2791715 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2782573 C_bot  0.15 k_c 0.0\n",
      "1189 Train Loss 11.763094\n",
      "Loss  1.2782573 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2772869 C_bot  0.15 k_c 0.0\n",
      "1190 Train Loss 11.760839\n",
      "Loss  1.2772869 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2763329 C_bot  0.15 k_c 0.0\n",
      "1191 Train Loss 11.75861\n",
      "Loss  1.2763329 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2754605 C_bot  0.15 k_c 0.0\n",
      "1192 Train Loss 11.756454\n",
      "Loss  1.2754605 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2745811 C_bot  0.15 k_c 0.0\n",
      "1193 Train Loss 11.754307\n",
      "Loss  1.2745811 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2736166 C_bot  0.15 k_c 0.0\n",
      "1194 Train Loss 11.752067\n",
      "Loss  1.2736166 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2726883 C_bot  0.15 k_c 0.0\n",
      "1195 Train Loss 11.749868\n",
      "Loss  1.2726883 C_bot  0.15 k_c 0.0\n",
      "Loss  1.271742 C_bot  0.15 k_c 0.0\n",
      "1196 Train Loss 11.747655\n",
      "Loss  1.271742 C_bot  0.15 k_c 0.0\n",
      "Loss  1.270846 C_bot  0.15 k_c 0.0\n",
      "1197 Train Loss 11.745495\n",
      "Loss  1.270846 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2699399 C_bot  0.15 k_c 0.0\n",
      "1198 Train Loss 11.743322\n",
      "Loss  1.2699399 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2689859 C_bot  0.15 k_c 0.0\n",
      "1199 Train Loss 11.741108\n",
      "Loss  1.2689859 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2680808 C_bot  0.15 k_c 0.0\n",
      "1200 Train Loss 11.738941\n",
      "Loss  1.2680808 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2672019 C_bot  0.15 k_c 0.0\n",
      "1201 Train Loss 11.736804\n",
      "Loss  1.2672019 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2661561 C_bot  0.15 k_c 0.0\n",
      "1202 Train Loss 11.734504\n",
      "Loss  1.2661561 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2652446 C_bot  0.15 k_c 0.0\n",
      "1203 Train Loss 11.732334\n",
      "Loss  1.2652446 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2643906 C_bot  0.15 k_c 0.0\n",
      "1204 Train Loss 11.73023\n",
      "Loss  1.2643906 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2634156 C_bot  0.15 k_c 0.0\n",
      "1205 Train Loss 11.7280035\n",
      "Loss  1.2634156 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2624617 C_bot  0.15 k_c 0.0\n",
      "1206 Train Loss 11.725798\n",
      "Loss  1.2624617 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2615972 C_bot  0.15 k_c 0.0\n",
      "1207 Train Loss 11.723688\n",
      "Loss  1.2615972 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2606794 C_bot  0.15 k_c 0.0\n",
      "1208 Train Loss 11.721521\n",
      "Loss  1.2606794 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2597135 C_bot  0.15 k_c 0.0\n",
      "1209 Train Loss 11.719313\n",
      "Loss  1.2597135 C_bot  0.15 k_c 0.0\n",
      "Loss  1.258844 C_bot  0.15 k_c 0.0\n",
      "1210 Train Loss 11.717197\n",
      "Loss  1.258844 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2579272 C_bot  0.15 k_c 0.0\n",
      "1211 Train Loss 11.71504\n",
      "Loss  1.2579272 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2569652 C_bot  0.15 k_c 0.0\n",
      "1212 Train Loss 11.712839\n",
      "Loss  1.2569652 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2560732 C_bot  0.15 k_c 0.0\n",
      "1213 Train Loss 11.710706\n",
      "Loss  1.2560732 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2550946 C_bot  0.15 k_c 0.0\n",
      "1214 Train Loss 11.70849\n",
      "Loss  1.2550946 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2542621 C_bot  0.15 k_c 0.0\n",
      "1215 Train Loss 11.706423\n",
      "Loss  1.2542621 C_bot  0.15 k_c 0.0\n",
      "Loss  1.253265 C_bot  0.15 k_c 0.0\n",
      "1216 Train Loss 11.704189\n",
      "Loss  1.253265 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2523696 C_bot  0.15 k_c 0.0\n",
      "1217 Train Loss 11.702063\n",
      "Loss  1.2523696 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2514496 C_bot  0.15 k_c 0.0\n",
      "1218 Train Loss 11.699909\n",
      "Loss  1.2514496 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2504799 C_bot  0.15 k_c 0.0\n",
      "1219 Train Loss 11.697709\n",
      "Loss  1.2504799 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2496327 C_bot  0.15 k_c 0.0\n",
      "1220 Train Loss 11.695636\n",
      "Loss  1.2496327 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2487535 C_bot  0.15 k_c 0.0\n",
      "1221 Train Loss 11.693523\n",
      "Loss  1.2487535 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2478421 C_bot  0.15 k_c 0.0\n",
      "1222 Train Loss 11.691389\n",
      "Loss  1.2478421 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2468759 C_bot  0.15 k_c 0.0\n",
      "1223 Train Loss 11.689196\n",
      "Loss  1.2468759 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2459743 C_bot  0.15 k_c 0.0\n",
      "1224 Train Loss 11.687075\n",
      "Loss  1.2459743 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2450147 C_bot  0.15 k_c 0.0\n",
      "1225 Train Loss 11.684889\n",
      "Loss  1.2450147 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2441604 C_bot  0.15 k_c 0.0\n",
      "1226 Train Loss 11.682819\n",
      "Loss  1.2441604 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2432514 C_bot  0.15 k_c 0.0\n",
      "1227 Train Loss 11.680686\n",
      "Loss  1.2432514 C_bot  0.15 k_c 0.0\n",
      "Loss  1.242256 C_bot  0.15 k_c 0.0\n",
      "1228 Train Loss 11.678477\n",
      "Loss  1.242256 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2413406 C_bot  0.15 k_c 0.0\n",
      "1229 Train Loss 11.67634\n",
      "Loss  1.2413406 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2404581 C_bot  0.15 k_c 0.0\n",
      "1230 Train Loss 11.674246\n",
      "Loss  1.2404581 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2395456 C_bot  0.15 k_c 0.0\n",
      "1231 Train Loss 11.672117\n",
      "Loss  1.2395456 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2386668 C_bot  0.15 k_c 0.0\n",
      "1232 Train Loss 11.670027\n",
      "Loss  1.2386668 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2377367 C_bot  0.15 k_c 0.0\n",
      "1233 Train Loss 11.6678915\n",
      "Loss  1.2377367 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2368352 C_bot  0.15 k_c 0.0\n",
      "1234 Train Loss 11.6657715\n",
      "Loss  1.2368352 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2359954 C_bot  0.15 k_c 0.0\n",
      "1235 Train Loss 11.6637335\n",
      "Loss  1.2359954 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2350206 C_bot  0.15 k_c 0.0\n",
      "1236 Train Loss 11.661539\n",
      "Loss  1.2350206 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2341331 C_bot  0.15 k_c 0.0\n",
      "1237 Train Loss 11.659458\n",
      "Loss  1.2341331 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2331725 C_bot  0.15 k_c 0.0\n",
      "1238 Train Loss 11.657285\n",
      "Loss  1.2331725 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2323447 C_bot  0.15 k_c 0.0\n",
      "1239 Train Loss 11.655257\n",
      "Loss  1.2323447 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2314081 C_bot  0.15 k_c 0.0\n",
      "1240 Train Loss 11.653123\n",
      "Loss  1.2314081 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2305117 C_bot  0.15 k_c 0.0\n",
      "1241 Train Loss 11.65102\n",
      "Loss  1.2305117 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2295382 C_bot  0.15 k_c 0.0\n",
      "1242 Train Loss 11.648857\n",
      "Loss  1.2295382 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2287214 C_bot  0.15 k_c 0.0\n",
      "1243 Train Loss 11.646835\n",
      "Loss  1.2287214 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2278318 C_bot  0.15 k_c 0.0\n",
      "1244 Train Loss 11.644756\n",
      "Loss  1.2278318 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2268968 C_bot  0.15 k_c 0.0\n",
      "1245 Train Loss 11.642622\n",
      "Loss  1.2268968 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2260143 C_bot  0.15 k_c 0.0\n",
      "1246 Train Loss 11.640551\n",
      "Loss  1.2260143 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2251028 C_bot  0.15 k_c 0.0\n",
      "1247 Train Loss 11.638451\n",
      "Loss  1.2251028 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2242386 C_bot  0.15 k_c 0.0\n",
      "1248 Train Loss 11.636391\n",
      "Loss  1.2242386 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2233694 C_bot  0.15 k_c 0.0\n",
      "1249 Train Loss 11.634342\n",
      "Loss  1.2233694 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2224215 C_bot  0.15 k_c 0.0\n",
      "1250 Train Loss 11.6322\n",
      "Loss  1.2224215 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2215083 C_bot  0.15 k_c 0.0\n",
      "1251 Train Loss 11.63011\n",
      "Loss  1.2215083 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2206589 C_bot  0.15 k_c 0.0\n",
      "1252 Train Loss 11.62807\n",
      "Loss  1.2206589 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2198141 C_bot  0.15 k_c 0.0\n",
      "1253 Train Loss 11.626047\n",
      "Loss  1.2198141 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2188272 C_bot  0.15 k_c 0.0\n",
      "1254 Train Loss 11.623882\n",
      "Loss  1.2188272 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2179785 C_bot  0.15 k_c 0.0\n",
      "1255 Train Loss 11.621847\n",
      "Loss  1.2179785 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2170969 C_bot  0.15 k_c 0.0\n",
      "1256 Train Loss 11.619802\n",
      "Loss  1.2170969 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2161888 C_bot  0.15 k_c 0.0\n",
      "1257 Train Loss 11.617704\n",
      "Loss  1.2161888 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2153691 C_bot  0.15 k_c 0.0\n",
      "1258 Train Loss 11.615728\n",
      "Loss  1.2153691 C_bot  0.15 k_c 0.0\n",
      "Loss  1.214473 C_bot  0.15 k_c 0.0\n",
      "1259 Train Loss 11.613644\n",
      "Loss  1.214473 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2135774 C_bot  0.15 k_c 0.0\n",
      "1260 Train Loss 11.611594\n",
      "Loss  1.2135774 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2126907 C_bot  0.15 k_c 0.0\n",
      "1261 Train Loss 11.609526\n",
      "Loss  1.2126907 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2118409 C_bot  0.15 k_c 0.0\n",
      "1262 Train Loss 11.607517\n",
      "Loss  1.2118409 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2109267 C_bot  0.15 k_c 0.0\n",
      "1263 Train Loss 11.605438\n",
      "Loss  1.2109267 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2100741 C_bot  0.15 k_c 0.0\n",
      "1264 Train Loss 11.603416\n",
      "Loss  1.2100741 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2092086 C_bot  0.15 k_c 0.0\n",
      "1265 Train Loss 11.6014\n",
      "Loss  1.2092086 C_bot  0.15 k_c 0.0\n",
      "Loss  1.208316 C_bot  0.15 k_c 0.0\n",
      "1266 Train Loss 11.599335\n",
      "Loss  1.208316 C_bot  0.15 k_c 0.0\n",
      "Loss  1.207384 C_bot  0.15 k_c 0.0\n",
      "1267 Train Loss 11.597261\n",
      "Loss  1.207384 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2065799 C_bot  0.15 k_c 0.0\n",
      "1268 Train Loss 11.595285\n",
      "Loss  1.2065799 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2057152 C_bot  0.15 k_c 0.0\n",
      "1269 Train Loss 11.593281\n",
      "Loss  1.2057152 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2048393 C_bot  0.15 k_c 0.0\n",
      "1270 Train Loss 11.591238\n",
      "Loss  1.2048393 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2039214 C_bot  0.15 k_c 0.0\n",
      "1271 Train Loss 11.58918\n",
      "Loss  1.2039214 C_bot  0.15 k_c 0.0\n",
      "Loss  1.203122 C_bot  0.15 k_c 0.0\n",
      "1272 Train Loss 11.587227\n",
      "Loss  1.203122 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2022727 C_bot  0.15 k_c 0.0\n",
      "1273 Train Loss 11.58523\n",
      "Loss  1.2022727 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2013255 C_bot  0.15 k_c 0.0\n",
      "1274 Train Loss 11.583142\n",
      "Loss  1.2013255 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2004459 C_bot  0.15 k_c 0.0\n",
      "1275 Train Loss 11.581114\n",
      "Loss  1.2004459 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1996559 C_bot  0.15 k_c 0.0\n",
      "1276 Train Loss 11.579189\n",
      "Loss  1.1996559 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1987697 C_bot  0.15 k_c 0.0\n",
      "1277 Train Loss 11.577156\n",
      "Loss  1.1987697 C_bot  0.15 k_c 0.0\n",
      "Loss  1.197946 C_bot  0.15 k_c 0.0\n",
      "1278 Train Loss 11.575199\n",
      "Loss  1.197946 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1971363 C_bot  0.15 k_c 0.0\n",
      "1279 Train Loss 11.573249\n",
      "Loss  1.1971363 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1962303 C_bot  0.15 k_c 0.0\n",
      "1280 Train Loss 11.571212\n",
      "Loss  1.1962303 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1953611 C_bot  0.15 k_c 0.0\n",
      "1281 Train Loss 11.56921\n",
      "Loss  1.1953611 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1944795 C_bot  0.15 k_c 0.0\n",
      "1282 Train Loss 11.567196\n",
      "Loss  1.1944795 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1935815 C_bot  0.15 k_c 0.0\n",
      "1283 Train Loss 11.565172\n",
      "Loss  1.1935815 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1928185 C_bot  0.15 k_c 0.0\n",
      "1284 Train Loss 11.563281\n",
      "Loss  1.1928185 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1919237 C_bot  0.15 k_c 0.0\n",
      "1285 Train Loss 11.561264\n",
      "Loss  1.1919237 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1910881 C_bot  0.15 k_c 0.0\n",
      "1286 Train Loss 11.559299\n",
      "Loss  1.1910881 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1902186 C_bot  0.15 k_c 0.0\n",
      "1287 Train Loss 11.557317\n",
      "Loss  1.1902186 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1893691 C_bot  0.15 k_c 0.0\n",
      "1288 Train Loss 11.555338\n",
      "Loss  1.1893691 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1885533 C_bot  0.15 k_c 0.0\n",
      "1289 Train Loss 11.553413\n",
      "Loss  1.1885533 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1877294 C_bot  0.15 k_c 0.0\n",
      "1290 Train Loss 11.551466\n",
      "Loss  1.1877294 C_bot  0.15 k_c 0.0\n",
      "Loss  1.186845 C_bot  0.15 k_c 0.0\n",
      "1291 Train Loss 11.549475\n",
      "Loss  1.186845 C_bot  0.15 k_c 0.0\n",
      "Loss  1.185981 C_bot  0.15 k_c 0.0\n",
      "1292 Train Loss 11.547493\n",
      "Loss  1.185981 C_bot  0.15 k_c 0.0\n",
      "Loss  1.185206 C_bot  0.15 k_c 0.0\n",
      "1293 Train Loss 11.545612\n",
      "Loss  1.185206 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1843139 C_bot  0.15 k_c 0.0\n",
      "1294 Train Loss 11.54361\n",
      "Loss  1.1843139 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1834441 C_bot  0.15 k_c 0.0\n",
      "1295 Train Loss 11.54163\n",
      "Loss  1.1834441 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1826826 C_bot  0.15 k_c 0.0\n",
      "1296 Train Loss 11.539771\n",
      "Loss  1.1826826 C_bot  0.15 k_c 0.0\n",
      "Loss  1.181815 C_bot  0.15 k_c 0.0\n",
      "1297 Train Loss 11.5377865\n",
      "Loss  1.181815 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1810275 C_bot  0.15 k_c 0.0\n",
      "1298 Train Loss 11.535919\n",
      "Loss  1.1810275 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1802112 C_bot  0.15 k_c 0.0\n",
      "1299 Train Loss 11.533978\n",
      "Loss  1.1802112 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1793177 C_bot  0.15 k_c 0.0\n",
      "1300 Train Loss 11.532016\n",
      "Loss  1.1793177 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1785016 C_bot  0.15 k_c 0.0\n",
      "1301 Train Loss 11.530072\n",
      "Loss  1.1785016 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1777252 C_bot  0.15 k_c 0.0\n",
      "1302 Train Loss 11.528235\n",
      "Loss  1.1777252 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1768953 C_bot  0.15 k_c 0.0\n",
      "1303 Train Loss 11.526279\n",
      "Loss  1.1768953 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1760514 C_bot  0.15 k_c 0.0\n",
      "1304 Train Loss 11.524378\n",
      "Loss  1.1760514 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1752299 C_bot  0.15 k_c 0.0\n",
      "1305 Train Loss 11.522432\n",
      "Loss  1.1752299 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1743386 C_bot  0.15 k_c 0.0\n",
      "1306 Train Loss 11.520491\n",
      "Loss  1.1743386 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1736053 C_bot  0.15 k_c 0.0\n",
      "1307 Train Loss 11.518636\n",
      "Loss  1.1736053 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1727005 C_bot  0.15 k_c 0.0\n",
      "1308 Train Loss 11.516685\n",
      "Loss  1.1727005 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1720115 C_bot  0.15 k_c 0.0\n",
      "1309 Train Loss 11.514875\n",
      "Loss  1.1720115 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1710165 C_bot  0.15 k_c 0.0\n",
      "1310 Train Loss 11.512838\n",
      "Loss  1.1710165 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1703246 C_bot  0.15 k_c 0.0\n",
      "1311 Train Loss 11.511032\n",
      "Loss  1.1703246 C_bot  0.15 k_c 0.0\n",
      "Loss  1.169532 C_bot  0.15 k_c 0.0\n",
      "1312 Train Loss 11.509195\n",
      "Loss  1.169532 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1687074 C_bot  0.15 k_c 0.0\n",
      "1313 Train Loss 11.507267\n",
      "Loss  1.1687074 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1678119 C_bot  0.15 k_c 0.0\n",
      "1314 Train Loss 11.505327\n",
      "Loss  1.1678119 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1671333 C_bot  0.15 k_c 0.0\n",
      "1315 Train Loss 11.503548\n",
      "Loss  1.1671333 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1662229 C_bot  0.15 k_c 0.0\n",
      "1316 Train Loss 11.501598\n",
      "Loss  1.1662229 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1655027 C_bot  0.15 k_c 0.0\n",
      "1317 Train Loss 11.499776\n",
      "Loss  1.1655027 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1646487 C_bot  0.15 k_c 0.0\n",
      "1318 Train Loss 11.497892\n",
      "Loss  1.1646487 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1638235 C_bot  0.15 k_c 0.0\n",
      "1319 Train Loss 11.49596\n",
      "Loss  1.1638235 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1630323 C_bot  0.15 k_c 0.0\n",
      "1320 Train Loss 11.494156\n",
      "Loss  1.1630323 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1622272 C_bot  0.15 k_c 0.0\n",
      "1321 Train Loss 11.49223\n",
      "Loss  1.1622272 C_bot  0.15 k_c 0.0\n",
      "Loss  1.161462 C_bot  0.15 k_c 0.0\n",
      "1322 Train Loss 11.49047\n",
      "Loss  1.161462 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1607065 C_bot  0.15 k_c 0.0\n",
      "1323 Train Loss 11.488581\n",
      "Loss  1.1607065 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1597666 C_bot  0.15 k_c 0.0\n",
      "1324 Train Loss 11.486673\n",
      "Loss  1.1597666 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1591141 C_bot  0.15 k_c 0.0\n",
      "1325 Train Loss 11.484863\n",
      "Loss  1.1591141 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1581978 C_bot  0.15 k_c 0.0\n",
      "1326 Train Loss 11.483013\n",
      "Loss  1.1581978 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1575786 C_bot  0.15 k_c 0.0\n",
      "1327 Train Loss 11.481201\n",
      "Loss  1.1575786 C_bot  0.15 k_c 0.0\n",
      "Loss  1.156688 C_bot  0.15 k_c 0.0\n",
      "1328 Train Loss 11.479425\n",
      "Loss  1.156688 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1561127 C_bot  0.15 k_c 0.0\n",
      "1329 Train Loss 11.477605\n",
      "Loss  1.1561127 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1551436 C_bot  0.15 k_c 0.0\n",
      "1330 Train Loss 11.47583\n",
      "Loss  1.1551436 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1548148 C_bot  0.15 k_c 0.0\n",
      "1331 Train Loss 11.474155\n",
      "Loss  1.1548148 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1538249 C_bot  0.15 k_c 0.0\n",
      "1332 Train Loss 11.472494\n",
      "Loss  1.1538249 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1538109 C_bot  0.15 k_c 0.0\n",
      "1333 Train Loss 11.470974\n",
      "Loss  1.1538109 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1529237 C_bot  0.15 k_c 0.0\n",
      "1334 Train Loss 11.469629\n",
      "Loss  1.1529237 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1535218 C_bot  0.15 k_c 0.0\n",
      "1335 Train Loss 11.468454\n",
      "Loss  1.1535218 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1530647 C_bot  0.15 k_c 0.0\n",
      "1336 Train Loss 11.46789\n",
      "Loss  1.1530647 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1554322 C_bot  0.15 k_c 0.0\n",
      "1337 Train Loss 11.46804\n",
      "Loss  1.1554322 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1565597 C_bot  0.15 k_c 0.0\n",
      "1338 Train Loss 11.469651\n",
      "Loss  1.1565597 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1632484 C_bot  0.15 k_c 0.0\n",
      "1339 Train Loss 11.47337\n",
      "Loss  1.1632484 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1698104 C_bot  0.15 k_c 0.0\n",
      "1340 Train Loss 11.48143\n",
      "Loss  1.1698104 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1885631 C_bot  0.15 k_c 0.0\n",
      "1341 Train Loss 11.49591\n",
      "Loss  1.1885631 C_bot  0.15 k_c 0.0\n",
      "Loss  1.212616 C_bot  0.15 k_c 0.0\n",
      "1342 Train Loss 11.523241\n",
      "Loss  1.212616 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2672577 C_bot  0.15 k_c 0.0\n",
      "1343 Train Loss 11.571345\n",
      "Loss  1.2672577 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3485041 C_bot  0.15 k_c 0.0\n",
      "1344 Train Loss 11.659067\n",
      "Loss  1.3485041 C_bot  0.15 k_c 0.0\n",
      "Loss  1.514391 C_bot  0.15 k_c 0.0\n",
      "1345 Train Loss 11.814429\n",
      "Loss  1.514391 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7865998 C_bot  0.15 k_c 0.0\n",
      "1346 Train Loss 12.099018\n",
      "Loss  1.7865998 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3147988 C_bot  0.15 k_c 0.0\n",
      "1347 Train Loss 12.609673\n",
      "Loss  2.3147988 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2394662 C_bot  0.15 k_c 0.0\n",
      "1348 Train Loss 13.558072\n",
      "Loss  3.2394662 C_bot  0.15 k_c 0.0\n",
      "Loss  4.985978 C_bot  0.15 k_c 0.0\n",
      "1349 Train Loss 15.274794\n",
      "Loss  4.985978 C_bot  0.15 k_c 0.0\n",
      "Loss  8.185691 C_bot  0.15 k_c 0.0\n",
      "1350 Train Loss 18.5213\n",
      "Loss  8.185691 C_bot  0.15 k_c 0.0\n",
      "Loss  14.103374 C_bot  0.15 k_c 0.0\n",
      "1351 Train Loss 24.3885\n",
      "Loss  14.103374 C_bot  0.15 k_c 0.0\n",
      "Loss  25.299059 C_bot  0.15 k_c 0.0\n",
      "1352 Train Loss 35.681892\n",
      "Loss  25.299059 C_bot  0.15 k_c 0.0\n",
      "Loss  45.205692 C_bot  0.15 k_c 0.0\n",
      "1353 Train Loss 55.504166\n",
      "Loss  45.205692 C_bot  0.15 k_c 0.0\n",
      "Loss  83.1795 C_bot  0.15 k_c 0.0\n",
      "1354 Train Loss 93.70059\n",
      "Loss  83.1795 C_bot  0.15 k_c 0.0\n",
      "Loss  143.30061 C_bot  0.15 k_c 0.0\n",
      "1355 Train Loss 153.67044\n",
      "Loss  143.30061 C_bot  0.15 k_c 0.0\n",
      "Loss  249.81842 C_bot  0.15 k_c 0.0\n",
      "1356 Train Loss 260.72852\n",
      "Loss  249.81842 C_bot  0.15 k_c 0.0\n",
      "Loss  362.12253 C_bot  0.15 k_c 0.0\n",
      "1357 Train Loss 372.63104\n",
      "Loss  362.12253 C_bot  0.15 k_c 0.0\n",
      "Loss  490.25754 C_bot  0.15 k_c 0.0\n",
      "1358 Train Loss 501.87738\n",
      "Loss  490.25754 C_bot  0.15 k_c 0.0\n",
      "Loss  436.1774 C_bot  0.15 k_c 0.0\n",
      "1359 Train Loss 446.58136\n",
      "Loss  436.1774 C_bot  0.15 k_c 0.0\n",
      "Loss  258.6449 C_bot  0.15 k_c 0.0\n",
      "1360 Train Loss 270.25366\n",
      "Loss  258.6449 C_bot  0.15 k_c 0.0\n",
      "Loss  43.791096 C_bot  0.15 k_c 0.0\n",
      "1361 Train Loss 54.30309\n",
      "Loss  43.791096 C_bot  0.15 k_c 0.0\n",
      "Loss  22.855896 C_bot  0.15 k_c 0.0\n",
      "1362 Train Loss 33.568623\n",
      "Loss  22.855896 C_bot  0.15 k_c 0.0\n",
      "Loss  154.32565 C_bot  0.15 k_c 0.0\n",
      "1363 Train Loss 166.36606\n",
      "Loss  154.32565 C_bot  0.15 k_c 0.0\n",
      "Loss  186.24431 C_bot  0.15 k_c 0.0\n",
      "1364 Train Loss 196.86911\n",
      "Loss  186.24431 C_bot  0.15 k_c 0.0\n",
      "Loss  70.043106 C_bot  0.15 k_c 0.0\n",
      "1365 Train Loss 82.062225\n",
      "Loss  70.043106 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6140995 C_bot  0.15 k_c 0.0\n",
      "1366 Train Loss 14.159249\n",
      "Loss  2.6140995 C_bot  0.15 k_c 0.0\n",
      "Loss  75.989105 C_bot  0.15 k_c 0.0\n",
      "1367 Train Loss 87.06404\n",
      "Loss  75.989105 C_bot  0.15 k_c 0.0\n",
      "Loss  118.59709 C_bot  0.15 k_c 0.0\n",
      "1368 Train Loss 131.06017\n",
      "Loss  118.59709 C_bot  0.15 k_c 0.0\n",
      "Loss  43.13908 C_bot  0.15 k_c 0.0\n",
      "1369 Train Loss 54.42848\n",
      "Loss  43.13908 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8868103 C_bot  0.15 k_c 0.0\n",
      "1370 Train Loss 15.456743\n",
      "Loss  3.8868103 C_bot  0.15 k_c 0.0\n",
      "Loss  57.27737 C_bot  0.15 k_c 0.0\n",
      "1371 Train Loss 69.42712\n",
      "Loss  57.27737 C_bot  0.15 k_c 0.0\n",
      "Loss  70.619385 C_bot  0.15 k_c 0.0\n",
      "1372 Train Loss 81.96222\n",
      "Loss  70.619385 C_bot  0.15 k_c 0.0\n",
      "Loss  17.554098 C_bot  0.15 k_c 0.0\n",
      "1373 Train Loss 29.486189\n",
      "Loss  17.554098 C_bot  0.15 k_c 0.0\n",
      "Loss  7.4625 C_bot  0.15 k_c 0.0\n",
      "1374 Train Loss 19.310778\n",
      "Loss  7.4625 C_bot  0.15 k_c 0.0\n",
      "Loss  45.754616 C_bot  0.15 k_c 0.0\n",
      "1375 Train Loss 57.247562\n",
      "Loss  45.754616 C_bot  0.15 k_c 0.0\n",
      "Loss  40.673103 C_bot  0.15 k_c 0.0\n",
      "1376 Train Loss 52.71374\n",
      "Loss  40.673103 C_bot  0.15 k_c 0.0\n",
      "Loss  5.1310697 C_bot  0.15 k_c 0.0\n",
      "1377 Train Loss 16.781208\n",
      "Loss  5.1310697 C_bot  0.15 k_c 0.0\n",
      "Loss  13.061355 C_bot  0.15 k_c 0.0\n",
      "1378 Train Loss 24.649485\n",
      "Loss  13.061355 C_bot  0.15 k_c 0.0\n",
      "Loss  35.48375 C_bot  0.15 k_c 0.0\n",
      "1379 Train Loss 47.444427\n",
      "Loss  35.48375 C_bot  0.15 k_c 0.0\n",
      "Loss  19.412401 C_bot  0.15 k_c 0.0\n",
      "1380 Train Loss 30.94844\n",
      "Loss  19.412401 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5701909 C_bot  0.15 k_c 0.0\n",
      "1381 Train Loss 13.23404\n",
      "Loss  1.5701909 C_bot  0.15 k_c 0.0\n",
      "Loss  15.527089 C_bot  0.15 k_c 0.0\n",
      "1382 Train Loss 27.343071\n",
      "Loss  15.527089 C_bot  0.15 k_c 0.0\n",
      "Loss  23.379976 C_bot  0.15 k_c 0.0\n",
      "1383 Train Loss 34.879818\n",
      "Loss  23.379976 C_bot  0.15 k_c 0.0\n",
      "Loss  7.422543 C_bot  0.15 k_c 0.0\n",
      "1384 Train Loss 19.156376\n",
      "Loss  7.422543 C_bot  0.15 k_c 0.0\n",
      "Loss  2.738706 C_bot  0.15 k_c 0.0\n",
      "1385 Train Loss 14.40049\n",
      "Loss  2.738706 C_bot  0.15 k_c 0.0\n",
      "Loss  14.813332 C_bot  0.15 k_c 0.0\n",
      "1386 Train Loss 26.294052\n",
      "Loss  14.813332 C_bot  0.15 k_c 0.0\n",
      "Loss  13.763957 C_bot  0.15 k_c 0.0\n",
      "1387 Train Loss 25.473955\n",
      "Loss  13.763957 C_bot  0.15 k_c 0.0\n",
      "Loss  2.649401 C_bot  0.15 k_c 0.0\n",
      "1388 Train Loss 14.147202\n",
      "Loss  2.649401 C_bot  0.15 k_c 0.0\n",
      "Loss  4.788995 C_bot  0.15 k_c 0.0\n",
      "1389 Train Loss 16.230637\n",
      "Loss  4.788995 C_bot  0.15 k_c 0.0\n",
      "Loss  11.914333 C_bot  0.15 k_c 0.0\n",
      "1390 Train Loss 23.502947\n",
      "Loss  11.914333 C_bot  0.15 k_c 0.0\n",
      "Loss  7.2940464 C_bot  0.15 k_c 0.0\n",
      "1391 Train Loss 18.662407\n",
      "Loss  7.2940464 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3975253 C_bot  0.15 k_c 0.0\n",
      "1392 Train Loss 12.813084\n",
      "Loss  1.3975253 C_bot  0.15 k_c 0.0\n",
      "Loss  5.5020704 C_bot  0.15 k_c 0.0\n",
      "1393 Train Loss 16.955816\n",
      "Loss  5.5020704 C_bot  0.15 k_c 0.0\n",
      "Loss  8.469477 C_bot  0.15 k_c 0.0\n",
      "1394 Train Loss 19.75877\n",
      "Loss  8.469477 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5560384 C_bot  0.15 k_c 0.0\n",
      "1395 Train Loss 14.939487\n",
      "Loss  3.5560384 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5707557 C_bot  0.15 k_c 0.0\n",
      "1396 Train Loss 12.89909\n",
      "Loss  1.5707557 C_bot  0.15 k_c 0.0\n",
      "Loss  5.3039217 C_bot  0.15 k_c 0.0\n",
      "1397 Train Loss 16.542658\n",
      "Loss  5.3039217 C_bot  0.15 k_c 0.0\n",
      "Loss  5.4967775 C_bot  0.15 k_c 0.0\n",
      "1398 Train Loss 16.82587\n",
      "Loss  5.4967775 C_bot  0.15 k_c 0.0\n",
      "Loss  1.968669 C_bot  0.15 k_c 0.0\n",
      "1399 Train Loss 13.192471\n",
      "Loss  1.968669 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9750994 C_bot  0.15 k_c 0.0\n",
      "1400 Train Loss 13.180023\n",
      "Loss  1.9750994 C_bot  0.15 k_c 0.0\n",
      "Loss  4.386815 C_bot  0.15 k_c 0.0\n",
      "1401 Train Loss 15.647892\n",
      "Loss  4.386815 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5713937 C_bot  0.15 k_c 0.0\n",
      "1402 Train Loss 14.725512\n",
      "Loss  3.5713937 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3347427 C_bot  0.15 k_c 0.0\n",
      "1403 Train Loss 12.519063\n",
      "Loss  1.3347427 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0984137 C_bot  0.15 k_c 0.0\n",
      "1404 Train Loss 13.284964\n",
      "Loss  2.0984137 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5123022 C_bot  0.15 k_c 0.0\n",
      "1405 Train Loss 14.621289\n",
      "Loss  3.5123022 C_bot  0.15 k_c 0.0\n",
      "Loss  2.336922 C_bot  0.15 k_c 0.0\n",
      "1406 Train Loss 13.495472\n",
      "Loss  2.336922 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2076007 C_bot  0.15 k_c 0.0\n",
      "1407 Train Loss 12.319317\n",
      "Loss  1.2076007 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1077447 C_bot  0.15 k_c 0.0\n",
      "1408 Train Loss 13.180727\n",
      "Loss  2.1077447 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6821105 C_bot  0.15 k_c 0.0\n",
      "1409 Train Loss 13.793629\n",
      "Loss  2.6821105 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7589836 C_bot  0.15 k_c 0.0\n",
      "1410 Train Loss 12.803753\n",
      "Loss  1.7589836 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2145993 C_bot  0.15 k_c 0.0\n",
      "1411 Train Loss 12.256156\n",
      "Loss  1.2145993 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9101578 C_bot  0.15 k_c 0.0\n",
      "1412 Train Loss 12.959885\n",
      "Loss  1.9101578 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1707137 C_bot  0.15 k_c 0.0\n",
      "1413 Train Loss 13.16123\n",
      "Loss  2.1707137 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4226824 C_bot  0.15 k_c 0.0\n",
      "1414 Train Loss 12.431877\n",
      "Loss  1.4226824 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2247248 C_bot  0.15 k_c 0.0\n",
      "1415 Train Loss 12.212273\n",
      "Loss  1.2247248 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7583634 C_bot  0.15 k_c 0.0\n",
      "1416 Train Loss 12.709658\n",
      "Loss  1.7583634 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7663796 C_bot  0.15 k_c 0.0\n",
      "1417 Train Loss 12.73888\n",
      "Loss  1.7663796 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2977307 C_bot  0.15 k_c 0.0\n",
      "1418 Train Loss 12.231027\n",
      "Loss  1.2977307 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2348397 C_bot  0.15 k_c 0.0\n",
      "1419 Train Loss 12.157736\n",
      "Loss  1.2348397 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5585905 C_bot  0.15 k_c 0.0\n",
      "1420 Train Loss 12.489576\n",
      "Loss  1.5585905 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5615033 C_bot  0.15 k_c 0.0\n",
      "1421 Train Loss 12.451607\n",
      "Loss  1.5615033 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2161449 C_bot  0.15 k_c 0.0\n",
      "1422 Train Loss 12.113897\n",
      "Loss  1.2161449 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2077162 C_bot  0.15 k_c 0.0\n",
      "1423 Train Loss 12.093858\n",
      "Loss  1.2077162 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4496566 C_bot  0.15 k_c 0.0\n",
      "1424 Train Loss 12.307581\n",
      "Loss  1.4496566 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3919512 C_bot  0.15 k_c 0.0\n",
      "1425 Train Loss 12.262178\n",
      "Loss  1.3919512 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1931424 C_bot  0.15 k_c 0.0\n",
      "1426 Train Loss 12.036919\n",
      "Loss  1.1931424 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1958947 C_bot  0.15 k_c 0.0\n",
      "1427 Train Loss 12.029173\n",
      "Loss  1.1958947 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3295735 C_bot  0.15 k_c 0.0\n",
      "1428 Train Loss 12.167022\n",
      "Loss  1.3295735 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3211888 C_bot  0.15 k_c 0.0\n",
      "1429 Train Loss 12.129659\n",
      "Loss  1.3211888 C_bot  0.15 k_c 0.0\n",
      "Loss  1.168396 C_bot  0.15 k_c 0.0\n",
      "1430 Train Loss 11.978832\n",
      "Loss  1.168396 C_bot  0.15 k_c 0.0\n",
      "Loss  1.168118 C_bot  0.15 k_c 0.0\n",
      "1431 Train Loss 11.96876\n",
      "Loss  1.168118 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2756584 C_bot  0.15 k_c 0.0\n",
      "1432 Train Loss 12.055971\n",
      "Loss  1.2756584 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2480932 C_bot  0.15 k_c 0.0\n",
      "1433 Train Loss 12.0337925\n",
      "Loss  1.2480932 C_bot  0.15 k_c 0.0\n",
      "Loss  1.163957 C_bot  0.15 k_c 0.0\n",
      "1434 Train Loss 11.930599\n",
      "Loss  1.163957 C_bot  0.15 k_c 0.0\n",
      "Loss  1.156403 C_bot  0.15 k_c 0.0\n",
      "1435 Train Loss 11.915042\n",
      "Loss  1.156403 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2110566 C_bot  0.15 k_c 0.0\n",
      "1436 Train Loss 11.9699545\n",
      "Loss  1.2110566 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2197689 C_bot  0.15 k_c 0.0\n",
      "1437 Train Loss 11.959302\n",
      "Loss  1.2197689 C_bot  0.15 k_c 0.0\n",
      "Loss  1.148923 C_bot  0.15 k_c 0.0\n",
      "1438 Train Loss 11.889164\n",
      "Loss  1.148923 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1368812 C_bot  0.15 k_c 0.0\n",
      "1439 Train Loss 11.868513\n",
      "Loss  1.1368812 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1822311 C_bot  0.15 k_c 0.0\n",
      "1440 Train Loss 11.900795\n",
      "Loss  1.1822311 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1782203 C_bot  0.15 k_c 0.0\n",
      "1441 Train Loss 11.899139\n",
      "Loss  1.1782203 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1448743 C_bot  0.15 k_c 0.0\n",
      "1442 Train Loss 11.851586\n",
      "Loss  1.1448743 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1266102 C_bot  0.15 k_c 0.0\n",
      "1443 Train Loss 11.828499\n",
      "Loss  1.1266102 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1458225 C_bot  0.15 k_c 0.0\n",
      "1444 Train Loss 11.845388\n",
      "Loss  1.1458225 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1617833 C_bot  0.15 k_c 0.0\n",
      "1445 Train Loss 11.847726\n",
      "Loss  1.1617833 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1309925 C_bot  0.15 k_c 0.0\n",
      "1446 Train Loss 11.817177\n",
      "Loss  1.1309925 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1164697 C_bot  0.15 k_c 0.0\n",
      "1447 Train Loss 11.793903\n",
      "Loss  1.1164697 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1304961 C_bot  0.15 k_c 0.0\n",
      "1448 Train Loss 11.799274\n",
      "Loss  1.1304961 C_bot  0.15 k_c 0.0\n",
      "Loss  1.135012 C_bot  0.15 k_c 0.0\n",
      "1449 Train Loss 11.803313\n",
      "Loss  1.135012 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1277791 C_bot  0.15 k_c 0.0\n",
      "1450 Train Loss 11.784356\n",
      "Loss  1.1277791 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1098789 C_bot  0.15 k_c 0.0\n",
      "1451 Train Loss 11.763368\n",
      "Loss  1.1098789 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1120989 C_bot  0.15 k_c 0.0\n",
      "1452 Train Loss 11.760723\n",
      "Loss  1.1120989 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1245471 C_bot  0.15 k_c 0.0\n",
      "1453 Train Loss 11.76342\n",
      "Loss  1.1245471 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1147923 C_bot  0.15 k_c 0.0\n",
      "1454 Train Loss 11.752838\n",
      "Loss  1.1147923 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1059581 C_bot  0.15 k_c 0.0\n",
      "1455 Train Loss 11.735361\n",
      "Loss  1.1059581 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1035599 C_bot  0.15 k_c 0.0\n",
      "1456 Train Loss 11.727688\n",
      "Loss  1.1035599 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1065475 C_bot  0.15 k_c 0.0\n",
      "1457 Train Loss 11.727976\n",
      "Loss  1.1065475 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1096851 C_bot  0.15 k_c 0.0\n",
      "1458 Train Loss 11.722147\n",
      "Loss  1.1096851 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0984344 C_bot  0.15 k_c 0.0\n",
      "1459 Train Loss 11.708985\n",
      "Loss  1.0984344 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0942868 C_bot  0.15 k_c 0.0\n",
      "1460 Train Loss 11.698866\n",
      "Loss  1.0942868 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0973771 C_bot  0.15 k_c 0.0\n",
      "1461 Train Loss 11.695795\n",
      "Loss  1.0973771 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0957228 C_bot  0.15 k_c 0.0\n",
      "1462 Train Loss 11.692226\n",
      "Loss  1.0957228 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0939505 C_bot  0.15 k_c 0.0\n",
      "1463 Train Loss 11.682932\n",
      "Loss  1.0939505 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0868809 C_bot  0.15 k_c 0.0\n",
      "1464 Train Loss 11.672808\n",
      "Loss  1.0868809 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0854887 C_bot  0.15 k_c 0.0\n",
      "1465 Train Loss 11.667082\n",
      "Loss  1.0854887 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0882338 C_bot  0.15 k_c 0.0\n",
      "1466 Train Loss 11.663435\n",
      "Loss  1.0882338 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0841445 C_bot  0.15 k_c 0.0\n",
      "1467 Train Loss 11.657219\n",
      "Loss  1.0841445 C_bot  0.15 k_c 0.0\n",
      "Loss  1.081499 C_bot  0.15 k_c 0.0\n",
      "1468 Train Loss 11.648272\n",
      "Loss  1.081499 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0783015 C_bot  0.15 k_c 0.0\n",
      "1469 Train Loss 11.641132\n",
      "Loss  1.0783015 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0772115 C_bot  0.15 k_c 0.0\n",
      "1470 Train Loss 11.636545\n",
      "Loss  1.0772115 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0782516 C_bot  0.15 k_c 0.0\n",
      "1471 Train Loss 11.631491\n",
      "Loss  1.0782516 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0737808 C_bot  0.15 k_c 0.0\n",
      "1472 Train Loss 11.624512\n",
      "Loss  1.0737808 C_bot  0.15 k_c 0.0\n",
      "Loss  1.071623 C_bot  0.15 k_c 0.0\n",
      "1473 Train Loss 11.617098\n",
      "Loss  1.071623 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0701972 C_bot  0.15 k_c 0.0\n",
      "1474 Train Loss 11.611374\n",
      "Loss  1.0701972 C_bot  0.15 k_c 0.0\n",
      "Loss  1.06854 C_bot  0.15 k_c 0.0\n",
      "1475 Train Loss 11.606655\n",
      "Loss  1.06854 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0684232 C_bot  0.15 k_c 0.0\n",
      "1476 Train Loss 11.601013\n",
      "Loss  1.0684232 C_bot  0.15 k_c 0.0\n",
      "Loss  1.064609 C_bot  0.15 k_c 0.0\n",
      "1477 Train Loss 11.59443\n",
      "Loss  1.064609 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0626605 C_bot  0.15 k_c 0.0\n",
      "1478 Train Loss 11.588052\n",
      "Loss  1.0626605 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0618123 C_bot  0.15 k_c 0.0\n",
      "1479 Train Loss 11.582951\n",
      "Loss  1.0618123 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0595784 C_bot  0.15 k_c 0.0\n",
      "1480 Train Loss 11.577894\n",
      "Loss  1.0595784 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0588791 C_bot  0.15 k_c 0.0\n",
      "1481 Train Loss 11.572277\n",
      "Loss  1.0588791 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0557045 C_bot  0.15 k_c 0.0\n",
      "1482 Train Loss 11.566178\n",
      "Loss  1.0557045 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0540248 C_bot  0.15 k_c 0.0\n",
      "1483 Train Loss 11.560601\n",
      "Loss  1.0540248 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0531838 C_bot  0.15 k_c 0.0\n",
      "1484 Train Loss 11.555658\n",
      "Loss  1.0531838 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0509676 C_bot  0.15 k_c 0.0\n",
      "1485 Train Loss 11.550671\n",
      "Loss  1.0509676 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0498914 C_bot  0.15 k_c 0.0\n",
      "1486 Train Loss 11.545145\n",
      "Loss  1.0498914 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0473679 C_bot  0.15 k_c 0.0\n",
      "1487 Train Loss 11.539619\n",
      "Loss  1.0473679 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0458208 C_bot  0.15 k_c 0.0\n",
      "1488 Train Loss 11.534502\n",
      "Loss  1.0458208 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0448047 C_bot  0.15 k_c 0.0\n",
      "1489 Train Loss 11.529597\n",
      "Loss  1.0448047 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0426176 C_bot  0.15 k_c 0.0\n",
      "1490 Train Loss 11.52463\n",
      "Loss  1.0426176 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0415654 C_bot  0.15 k_c 0.0\n",
      "1491 Train Loss 11.519493\n",
      "Loss  1.0415654 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0394351 C_bot  0.15 k_c 0.0\n",
      "1492 Train Loss 11.514355\n",
      "Loss  1.0394351 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0378569 C_bot  0.15 k_c 0.0\n",
      "1493 Train Loss 11.509405\n",
      "Loss  1.0378569 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0367088 C_bot  0.15 k_c 0.0\n",
      "1494 Train Loss 11.504584\n",
      "Loss  1.0367088 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0347557 C_bot  0.15 k_c 0.0\n",
      "1495 Train Loss 11.499849\n",
      "Loss  1.0347557 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0335773 C_bot  0.15 k_c 0.0\n",
      "1496 Train Loss 11.4948845\n",
      "Loss  1.0335773 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0316604 C_bot  0.15 k_c 0.0\n",
      "1497 Train Loss 11.490007\n",
      "Loss  1.0316604 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0300937 C_bot  0.15 k_c 0.0\n",
      "1498 Train Loss 11.4852\n",
      "Loss  1.0300937 C_bot  0.15 k_c 0.0\n",
      "Loss  1.028886 C_bot  0.15 k_c 0.0\n",
      "1499 Train Loss 11.480503\n",
      "Loss  1.028886 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0270349 C_bot  0.15 k_c 0.0\n",
      "1500 Train Loss 11.475843\n",
      "Loss  1.0270349 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0258868 C_bot  0.15 k_c 0.0\n",
      "1501 Train Loss 11.471098\n",
      "Loss  1.0258868 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0240204 C_bot  0.15 k_c 0.0\n",
      "1502 Train Loss 11.466288\n",
      "Loss  1.0240204 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0226367 C_bot  0.15 k_c 0.0\n",
      "1503 Train Loss 11.461679\n",
      "Loss  1.0226367 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0214245 C_bot  0.15 k_c 0.0\n",
      "1504 Train Loss 11.4571085\n",
      "Loss  1.0214245 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0196713 C_bot  0.15 k_c 0.0\n",
      "1505 Train Loss 11.45247\n",
      "Loss  1.0196713 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0185533 C_bot  0.15 k_c 0.0\n",
      "1506 Train Loss 11.447849\n",
      "Loss  1.0185533 C_bot  0.15 k_c 0.0\n",
      "Loss  1.016894 C_bot  0.15 k_c 0.0\n",
      "1507 Train Loss 11.4432335\n",
      "Loss  1.016894 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0154809 C_bot  0.15 k_c 0.0\n",
      "1508 Train Loss 11.438562\n",
      "Loss  1.0154809 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0142441 C_bot  0.15 k_c 0.0\n",
      "1509 Train Loss 11.43405\n",
      "Loss  1.0142441 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0126823 C_bot  0.15 k_c 0.0\n",
      "1510 Train Loss 11.429519\n",
      "Loss  1.0126823 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0115114 C_bot  0.15 k_c 0.0\n",
      "1511 Train Loss 11.42494\n",
      "Loss  1.0115114 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0099487 C_bot  0.15 k_c 0.0\n",
      "1512 Train Loss 11.42043\n",
      "Loss  1.0099487 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0086166 C_bot  0.15 k_c 0.0\n",
      "1513 Train Loss 11.415871\n",
      "Loss  1.0086166 C_bot  0.15 k_c 0.0\n",
      "Loss  1.007322 C_bot  0.15 k_c 0.0\n",
      "1514 Train Loss 11.411457\n",
      "Loss  1.007322 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0058581 C_bot  0.15 k_c 0.0\n",
      "1515 Train Loss 11.407054\n",
      "Loss  1.0058581 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0046623 C_bot  0.15 k_c 0.0\n",
      "1516 Train Loss 11.402651\n",
      "Loss  1.0046623 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0032876 C_bot  0.15 k_c 0.0\n",
      "1517 Train Loss 11.39847\n",
      "Loss  1.0032876 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0019784 C_bot  0.15 k_c 0.0\n",
      "1518 Train Loss 11.394106\n",
      "Loss  1.0019784 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0006312 C_bot  0.15 k_c 0.0\n",
      "1519 Train Loss 11.38991\n",
      "Loss  1.0006312 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9992822 C_bot  0.15 k_c 0.0\n",
      "1520 Train Loss 11.385777\n",
      "Loss  0.9992822 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9980738 C_bot  0.15 k_c 0.0\n",
      "1521 Train Loss 11.381673\n",
      "Loss  0.9980738 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9967382 C_bot  0.15 k_c 0.0\n",
      "1522 Train Loss 11.377735\n",
      "Loss  0.9967382 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99552894 C_bot  0.15 k_c 0.0\n",
      "1523 Train Loss 11.373723\n",
      "Loss  0.99552894 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99415755 C_bot  0.15 k_c 0.0\n",
      "1524 Train Loss 11.36977\n",
      "Loss  0.99415755 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99285775 C_bot  0.15 k_c 0.0\n",
      "1525 Train Loss 11.365859\n",
      "Loss  0.99285775 C_bot  0.15 k_c 0.0\n",
      "Loss  0.991755 C_bot  0.15 k_c 0.0\n",
      "1526 Train Loss 11.362135\n",
      "Loss  0.991755 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9904242 C_bot  0.15 k_c 0.0\n",
      "1527 Train Loss 11.35836\n",
      "Loss  0.9904242 C_bot  0.15 k_c 0.0\n",
      "Loss  0.989263 C_bot  0.15 k_c 0.0\n",
      "1528 Train Loss 11.354609\n",
      "Loss  0.989263 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9880028 C_bot  0.15 k_c 0.0\n",
      "1529 Train Loss 11.350956\n",
      "Loss  0.9880028 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9868179 C_bot  0.15 k_c 0.0\n",
      "1530 Train Loss 11.347303\n",
      "Loss  0.9868179 C_bot  0.15 k_c 0.0\n",
      "Loss  0.98562205 C_bot  0.15 k_c 0.0\n",
      "1531 Train Loss 11.343694\n",
      "Loss  0.98562205 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9843498 C_bot  0.15 k_c 0.0\n",
      "1532 Train Loss 11.340096\n",
      "Loss  0.9843498 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9832132 C_bot  0.15 k_c 0.0\n",
      "1533 Train Loss 11.336544\n",
      "Loss  0.9832132 C_bot  0.15 k_c 0.0\n",
      "Loss  0.98196185 C_bot  0.15 k_c 0.0\n",
      "1534 Train Loss 11.333042\n",
      "Loss  0.98196185 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9808437 C_bot  0.15 k_c 0.0\n",
      "1535 Train Loss 11.32958\n",
      "Loss  0.9808437 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9796589 C_bot  0.15 k_c 0.0\n",
      "1536 Train Loss 11.326149\n",
      "Loss  0.9796589 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97852033 C_bot  0.15 k_c 0.0\n",
      "1537 Train Loss 11.322779\n",
      "Loss  0.97852033 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97739345 C_bot  0.15 k_c 0.0\n",
      "1538 Train Loss 11.319393\n",
      "Loss  0.97739345 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97617567 C_bot  0.15 k_c 0.0\n",
      "1539 Train Loss 11.316027\n",
      "Loss  0.97617567 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9751211 C_bot  0.15 k_c 0.0\n",
      "1540 Train Loss 11.312744\n",
      "Loss  0.9751211 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97392476 C_bot  0.15 k_c 0.0\n",
      "1541 Train Loss 11.30943\n",
      "Loss  0.97392476 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9728695 C_bot  0.15 k_c 0.0\n",
      "1542 Train Loss 11.306213\n",
      "Loss  0.9728695 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9717481 C_bot  0.15 k_c 0.0\n",
      "1543 Train Loss 11.302977\n",
      "Loss  0.9717481 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97061116 C_bot  0.15 k_c 0.0\n",
      "1544 Train Loss 11.299751\n",
      "Loss  0.97061116 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96954054 C_bot  0.15 k_c 0.0\n",
      "1545 Train Loss 11.296572\n",
      "Loss  0.96954054 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9683937 C_bot  0.15 k_c 0.0\n",
      "1546 Train Loss 11.293388\n",
      "Loss  0.9683937 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9673352 C_bot  0.15 k_c 0.0\n",
      "1547 Train Loss 11.290249\n",
      "Loss  0.9673352 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9662562 C_bot  0.15 k_c 0.0\n",
      "1548 Train Loss 11.287161\n",
      "Loss  0.9662562 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96518594 C_bot  0.15 k_c 0.0\n",
      "1549 Train Loss 11.284056\n",
      "Loss  0.96518594 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96410674 C_bot  0.15 k_c 0.0\n",
      "1550 Train Loss 11.280978\n",
      "Loss  0.96410674 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96298206 C_bot  0.15 k_c 0.0\n",
      "1551 Train Loss 11.277872\n",
      "Loss  0.96298206 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96200585 C_bot  0.15 k_c 0.0\n",
      "1552 Train Loss 11.274904\n",
      "Loss  0.96200585 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9609459 C_bot  0.15 k_c 0.0\n",
      "1553 Train Loss 11.271908\n",
      "Loss  0.9609459 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9599633 C_bot  0.15 k_c 0.0\n",
      "1554 Train Loss 11.268959\n",
      "Loss  0.9599633 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9588835 C_bot  0.15 k_c 0.0\n",
      "1555 Train Loss 11.2659645\n",
      "Loss  0.9588835 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95784134 C_bot  0.15 k_c 0.0\n",
      "1556 Train Loss 11.262995\n",
      "Loss  0.95784134 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95681727 C_bot  0.15 k_c 0.0\n",
      "1557 Train Loss 11.260069\n",
      "Loss  0.95681727 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9558044 C_bot  0.15 k_c 0.0\n",
      "1558 Train Loss 11.25717\n",
      "Loss  0.9558044 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9547685 C_bot  0.15 k_c 0.0\n",
      "1559 Train Loss 11.254244\n",
      "Loss  0.9547685 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9538555 C_bot  0.15 k_c 0.0\n",
      "1560 Train Loss 11.251477\n",
      "Loss  0.9538555 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9527799 C_bot  0.15 k_c 0.0\n",
      "1561 Train Loss 11.248529\n",
      "Loss  0.9527799 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9517826 C_bot  0.15 k_c 0.0\n",
      "1562 Train Loss 11.245705\n",
      "Loss  0.9517826 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9508436 C_bot  0.15 k_c 0.0\n",
      "1563 Train Loss 11.242921\n",
      "Loss  0.9508436 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9498659 C_bot  0.15 k_c 0.0\n",
      "1564 Train Loss 11.240128\n",
      "Loss  0.9498659 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94894445 C_bot  0.15 k_c 0.0\n",
      "1565 Train Loss 11.237397\n",
      "Loss  0.94894445 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94793946 C_bot  0.15 k_c 0.0\n",
      "1566 Train Loss 11.234586\n",
      "Loss  0.94793946 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94697255 C_bot  0.15 k_c 0.0\n",
      "1567 Train Loss 11.231836\n",
      "Loss  0.94697255 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9459278 C_bot  0.15 k_c 0.0\n",
      "1568 Train Loss 11.229008\n",
      "Loss  0.9459278 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94510156 C_bot  0.15 k_c 0.0\n",
      "1569 Train Loss 11.226412\n",
      "Loss  0.94510156 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94412 C_bot  0.15 k_c 0.0\n",
      "1570 Train Loss 11.223675\n",
      "Loss  0.94412 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94316876 C_bot  0.15 k_c 0.0\n",
      "1571 Train Loss 11.220968\n",
      "Loss  0.94316876 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9422687 C_bot  0.15 k_c 0.0\n",
      "1572 Train Loss 11.218332\n",
      "Loss  0.9422687 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94133276 C_bot  0.15 k_c 0.0\n",
      "1573 Train Loss 11.215662\n",
      "Loss  0.94133276 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94038796 C_bot  0.15 k_c 0.0\n",
      "1574 Train Loss 11.212994\n",
      "Loss  0.94038796 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93944424 C_bot  0.15 k_c 0.0\n",
      "1575 Train Loss 11.2103405\n",
      "Loss  0.93944424 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9385925 C_bot  0.15 k_c 0.0\n",
      "1576 Train Loss 11.207775\n",
      "Loss  0.9385925 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9377262 C_bot  0.15 k_c 0.0\n",
      "1577 Train Loss 11.205221\n",
      "Loss  0.9377262 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9368239 C_bot  0.15 k_c 0.0\n",
      "1578 Train Loss 11.202619\n",
      "Loss  0.9368239 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9359238 C_bot  0.15 k_c 0.0\n",
      "1579 Train Loss 11.20005\n",
      "Loss  0.9359238 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9350523 C_bot  0.15 k_c 0.0\n",
      "1580 Train Loss 11.197502\n",
      "Loss  0.9350523 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9342219 C_bot  0.15 k_c 0.0\n",
      "1581 Train Loss 11.195012\n",
      "Loss  0.9342219 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93335134 C_bot  0.15 k_c 0.0\n",
      "1582 Train Loss 11.192485\n",
      "Loss  0.93335134 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9324243 C_bot  0.15 k_c 0.0\n",
      "1583 Train Loss 11.189915\n",
      "Loss  0.9324243 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9316411 C_bot  0.15 k_c 0.0\n",
      "1584 Train Loss 11.18749\n",
      "Loss  0.9316411 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9307517 C_bot  0.15 k_c 0.0\n",
      "1585 Train Loss 11.184973\n",
      "Loss  0.9307517 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9299183 C_bot  0.15 k_c 0.0\n",
      "1586 Train Loss 11.182516\n",
      "Loss  0.9299183 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9290695 C_bot  0.15 k_c 0.0\n",
      "1587 Train Loss 11.180059\n",
      "Loss  0.9290695 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9283372 C_bot  0.15 k_c 0.0\n",
      "1588 Train Loss 11.177713\n",
      "Loss  0.9283372 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9274633 C_bot  0.15 k_c 0.0\n",
      "1589 Train Loss 11.175252\n",
      "Loss  0.9274633 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92665863 C_bot  0.15 k_c 0.0\n",
      "1590 Train Loss 11.172848\n",
      "Loss  0.92665863 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9257787 C_bot  0.15 k_c 0.0\n",
      "1591 Train Loss 11.170395\n",
      "Loss  0.9257787 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92494863 C_bot  0.15 k_c 0.0\n",
      "1592 Train Loss 11.167982\n",
      "Loss  0.92494863 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9242092 C_bot  0.15 k_c 0.0\n",
      "1593 Train Loss 11.165686\n",
      "Loss  0.9242092 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92336786 C_bot  0.15 k_c 0.0\n",
      "1594 Train Loss 11.16328\n",
      "Loss  0.92336786 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9225963 C_bot  0.15 k_c 0.0\n",
      "1595 Train Loss 11.160961\n",
      "Loss  0.9225963 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9217635 C_bot  0.15 k_c 0.0\n",
      "1596 Train Loss 11.158579\n",
      "Loss  0.9217635 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92099327 C_bot  0.15 k_c 0.0\n",
      "1597 Train Loss 11.156281\n",
      "Loss  0.92099327 C_bot  0.15 k_c 0.0\n",
      "Loss  0.920209 C_bot  0.15 k_c 0.0\n",
      "1598 Train Loss 11.153959\n",
      "Loss  0.920209 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9194142 C_bot  0.15 k_c 0.0\n",
      "1599 Train Loss 11.151652\n",
      "Loss  0.9194142 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91871655 C_bot  0.15 k_c 0.0\n",
      "1600 Train Loss 11.149432\n",
      "Loss  0.91871655 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9179059 C_bot  0.15 k_c 0.0\n",
      "1601 Train Loss 11.147122\n",
      "Loss  0.9179059 C_bot  0.15 k_c 0.0\n",
      "Loss  0.917138 C_bot  0.15 k_c 0.0\n",
      "1602 Train Loss 11.144846\n",
      "Loss  0.917138 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91639453 C_bot  0.15 k_c 0.0\n",
      "1603 Train Loss 11.142618\n",
      "Loss  0.91639453 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91558844 C_bot  0.15 k_c 0.0\n",
      "1604 Train Loss 11.140316\n",
      "Loss  0.91558844 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9148622 C_bot  0.15 k_c 0.0\n",
      "1605 Train Loss 11.138121\n",
      "Loss  0.9148622 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91415274 C_bot  0.15 k_c 0.0\n",
      "1606 Train Loss 11.135927\n",
      "Loss  0.91415274 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9133223 C_bot  0.15 k_c 0.0\n",
      "1607 Train Loss 11.133641\n",
      "Loss  0.9133223 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9125526 C_bot  0.15 k_c 0.0\n",
      "1608 Train Loss 11.131405\n",
      "Loss  0.9125526 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9119054 C_bot  0.15 k_c 0.0\n",
      "1609 Train Loss 11.129312\n",
      "Loss  0.9119054 C_bot  0.15 k_c 0.0\n",
      "Loss  0.911165 C_bot  0.15 k_c 0.0\n",
      "1610 Train Loss 11.127117\n",
      "Loss  0.911165 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91037875 C_bot  0.15 k_c 0.0\n",
      "1611 Train Loss 11.124895\n",
      "Loss  0.91037875 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9096424 C_bot  0.15 k_c 0.0\n",
      "1612 Train Loss 11.12273\n",
      "Loss  0.9096424 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90899235 C_bot  0.15 k_c 0.0\n",
      "1613 Train Loss 11.120642\n",
      "Loss  0.90899235 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90821797 C_bot  0.15 k_c 0.0\n",
      "1614 Train Loss 11.118462\n",
      "Loss  0.90821797 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9075017 C_bot  0.15 k_c 0.0\n",
      "1615 Train Loss 11.116309\n",
      "Loss  0.9075017 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90682673 C_bot  0.15 k_c 0.0\n",
      "1616 Train Loss 11.114252\n",
      "Loss  0.90682673 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90608925 C_bot  0.15 k_c 0.0\n",
      "1617 Train Loss 11.1120825\n",
      "Loss  0.90608925 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90538925 C_bot  0.15 k_c 0.0\n",
      "1618 Train Loss 11.110012\n",
      "Loss  0.90538925 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90473914 C_bot  0.15 k_c 0.0\n",
      "1619 Train Loss 11.1079445\n",
      "Loss  0.90473914 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9040082 C_bot  0.15 k_c 0.0\n",
      "1620 Train Loss 11.105854\n",
      "Loss  0.9040082 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90338045 C_bot  0.15 k_c 0.0\n",
      "1621 Train Loss 11.103821\n",
      "Loss  0.90338045 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90262747 C_bot  0.15 k_c 0.0\n",
      "1622 Train Loss 11.101717\n",
      "Loss  0.90262747 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9019414 C_bot  0.15 k_c 0.0\n",
      "1623 Train Loss 11.09964\n",
      "Loss  0.9019414 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9012478 C_bot  0.15 k_c 0.0\n",
      "1624 Train Loss 11.097608\n",
      "Loss  0.9012478 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90060157 C_bot  0.15 k_c 0.0\n",
      "1625 Train Loss 11.095575\n",
      "Loss  0.90060157 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8999144 C_bot  0.15 k_c 0.0\n",
      "1626 Train Loss 11.093566\n",
      "Loss  0.8999144 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89920884 C_bot  0.15 k_c 0.0\n",
      "1627 Train Loss 11.09148\n",
      "Loss  0.89920884 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89858747 C_bot  0.15 k_c 0.0\n",
      "1628 Train Loss 11.089558\n",
      "Loss  0.89858747 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8979258 C_bot  0.15 k_c 0.0\n",
      "1629 Train Loss 11.087511\n",
      "Loss  0.8979258 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8972336 C_bot  0.15 k_c 0.0\n",
      "1630 Train Loss 11.0855465\n",
      "Loss  0.8972336 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8966385 C_bot  0.15 k_c 0.0\n",
      "1631 Train Loss 11.083553\n",
      "Loss  0.8966385 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8959097 C_bot  0.15 k_c 0.0\n",
      "1632 Train Loss 11.081593\n",
      "Loss  0.8959097 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89537424 C_bot  0.15 k_c 0.0\n",
      "1633 Train Loss 11.079628\n",
      "Loss  0.89537424 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89462554 C_bot  0.15 k_c 0.0\n",
      "1634 Train Loss 11.077713\n",
      "Loss  0.89462554 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8941166 C_bot  0.15 k_c 0.0\n",
      "1635 Train Loss 11.075724\n",
      "Loss  0.8941166 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89332294 C_bot  0.15 k_c 0.0\n",
      "1636 Train Loss 11.073841\n",
      "Loss  0.89332294 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89293057 C_bot  0.15 k_c 0.0\n",
      "1637 Train Loss 11.071894\n",
      "Loss  0.89293057 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8920161 C_bot  0.15 k_c 0.0\n",
      "1638 Train Loss 11.070011\n",
      "Loss  0.8920161 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8918706 C_bot  0.15 k_c 0.0\n",
      "1639 Train Loss 11.068182\n",
      "Loss  0.8918706 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89090765 C_bot  0.15 k_c 0.0\n",
      "1640 Train Loss 11.06643\n",
      "Loss  0.89090765 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8911443 C_bot  0.15 k_c 0.0\n",
      "1641 Train Loss 11.064772\n",
      "Loss  0.8911443 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89005387 C_bot  0.15 k_c 0.0\n",
      "1642 Train Loss 11.063195\n",
      "Loss  0.89005387 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8909274 C_bot  0.15 k_c 0.0\n",
      "1643 Train Loss 11.061807\n",
      "Loss  0.8909274 C_bot  0.15 k_c 0.0\n",
      "Loss  0.890056 C_bot  0.15 k_c 0.0\n",
      "1644 Train Loss 11.060944\n",
      "Loss  0.890056 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89257073 C_bot  0.15 k_c 0.0\n",
      "1645 Train Loss 11.0605755\n",
      "Loss  0.89257073 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89260876 C_bot  0.15 k_c 0.0\n",
      "1646 Train Loss 11.0614605\n",
      "Loss  0.89260876 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8990742 C_bot  0.15 k_c 0.0\n",
      "1647 Train Loss 11.063972\n",
      "Loss  0.8990742 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90296686 C_bot  0.15 k_c 0.0\n",
      "1648 Train Loss 11.070159\n",
      "Loss  0.90296686 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92055464 C_bot  0.15 k_c 0.0\n",
      "1649 Train Loss 11.081913\n",
      "Loss  0.92055464 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93833065 C_bot  0.15 k_c 0.0\n",
      "1650 Train Loss 11.10455\n",
      "Loss  0.93833065 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9883074 C_bot  0.15 k_c 0.0\n",
      "1651 Train Loss 11.145348\n",
      "Loss  0.9883074 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0549166 C_bot  0.15 k_c 0.0\n",
      "1652 Train Loss 11.221466\n",
      "Loss  1.0549166 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2074182 C_bot  0.15 k_c 0.0\n",
      "1653 Train Loss 11.358763\n",
      "Loss  1.2074182 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4444 C_bot  0.15 k_c 0.0\n",
      "1654 Train Loss 11.613863\n",
      "Loss  1.4444 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9360855 C_bot  0.15 k_c 0.0\n",
      "1655 Train Loss 12.079426\n",
      "Loss  1.9360855 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7775207 C_bot  0.15 k_c 0.0\n",
      "1656 Train Loss 12.955385\n",
      "Loss  2.7775207 C_bot  0.15 k_c 0.0\n",
      "Loss  4.4403353 C_bot  0.15 k_c 0.0\n",
      "1657 Train Loss 14.572302\n",
      "Loss  4.4403353 C_bot  0.15 k_c 0.0\n",
      "Loss  7.471211 C_bot  0.15 k_c 0.0\n",
      "1658 Train Loss 17.670216\n",
      "Loss  7.471211 C_bot  0.15 k_c 0.0\n",
      "Loss  13.29664 C_bot  0.15 k_c 0.0\n",
      "1659 Train Loss 23.414455\n",
      "Loss  13.29664 C_bot  0.15 k_c 0.0\n",
      "Loss  24.385899 C_bot  0.15 k_c 0.0\n",
      "1660 Train Loss 34.63906\n",
      "Loss  24.385899 C_bot  0.15 k_c 0.0\n",
      "Loss  45.047092 C_bot  0.15 k_c 0.0\n",
      "1661 Train Loss 55.158463\n",
      "Loss  45.047092 C_bot  0.15 k_c 0.0\n",
      "Loss  85.3439 C_bot  0.15 k_c 0.0\n",
      "1662 Train Loss 95.74659\n",
      "Loss  85.3439 C_bot  0.15 k_c 0.0\n",
      "Loss  154.84714 C_bot  0.15 k_c 0.0\n",
      "1663 Train Loss 165.00615\n",
      "Loss  154.84714 C_bot  0.15 k_c 0.0\n",
      "Loss  286.56277 C_bot  0.15 k_c 0.0\n",
      "1664 Train Loss 297.3963\n",
      "Loss  286.56277 C_bot  0.15 k_c 0.0\n",
      "Loss  461.55075 C_bot  0.15 k_c 0.0\n",
      "1665 Train Loss 471.90454\n",
      "Loss  461.55075 C_bot  0.15 k_c 0.0\n",
      "Loss  719.9361 C_bot  0.15 k_c 0.0\n",
      "1666 Train Loss 731.7564\n",
      "Loss  719.9361 C_bot  0.15 k_c 0.0\n",
      "Loss  789.4097 C_bot  0.15 k_c 0.0\n",
      "1667 Train Loss 799.8959\n",
      "Loss  789.4097 C_bot  0.15 k_c 0.0\n",
      "Loss  669.5664 C_bot  0.15 k_c 0.0\n",
      "1668 Train Loss 681.8659\n",
      "Loss  669.5664 C_bot  0.15 k_c 0.0\n",
      "Loss  245.1877 C_bot  0.15 k_c 0.0\n",
      "1669 Train Loss 255.56151\n",
      "Loss  245.1877 C_bot  0.15 k_c 0.0\n",
      "Loss  4.374755 C_bot  0.15 k_c 0.0\n",
      "1670 Train Loss 15.396137\n",
      "Loss  4.374755 C_bot  0.15 k_c 0.0\n",
      "Loss  138.26285 C_bot  0.15 k_c 0.0\n",
      "1671 Train Loss 150.18207\n",
      "Loss  138.26285 C_bot  0.15 k_c 0.0\n",
      "Loss  339.06302 C_bot  0.15 k_c 0.0\n",
      "1672 Train Loss 349.7261\n",
      "Loss  339.06302 C_bot  0.15 k_c 0.0\n",
      "Loss  282.02252 C_bot  0.15 k_c 0.0\n",
      "1673 Train Loss 294.7824\n",
      "Loss  282.02252 C_bot  0.15 k_c 0.0\n",
      "Loss  47.409702 C_bot  0.15 k_c 0.0\n",
      "1674 Train Loss 58.60087\n",
      "Loss  47.409702 C_bot  0.15 k_c 0.0\n",
      "Loss  36.410595 C_bot  0.15 k_c 0.0\n",
      "1675 Train Loss 47.70191\n",
      "Loss  36.410595 C_bot  0.15 k_c 0.0\n",
      "Loss  193.40738 C_bot  0.15 k_c 0.0\n",
      "1676 Train Loss 206.09743\n",
      "Loss  193.40738 C_bot  0.15 k_c 0.0\n",
      "Loss  172.5988 C_bot  0.15 k_c 0.0\n",
      "1677 Train Loss 183.73259\n",
      "Loss  172.5988 C_bot  0.15 k_c 0.0\n",
      "Loss  29.278292 C_bot  0.15 k_c 0.0\n",
      "1678 Train Loss 41.248837\n",
      "Loss  29.278292 C_bot  0.15 k_c 0.0\n",
      "Loss  26.95467 C_bot  0.15 k_c 0.0\n",
      "1679 Train Loss 38.894993\n",
      "Loss  26.95467 C_bot  0.15 k_c 0.0\n",
      "Loss  124.747604 C_bot  0.15 k_c 0.0\n",
      "1680 Train Loss 136.06825\n",
      "Loss  124.747604 C_bot  0.15 k_c 0.0\n",
      "Loss  102.54211 C_bot  0.15 k_c 0.0\n",
      "1681 Train Loss 114.79562\n",
      "Loss  102.54211 C_bot  0.15 k_c 0.0\n",
      "Loss  9.874505 C_bot  0.15 k_c 0.0\n",
      "1682 Train Loss 21.446714\n",
      "Loss  9.874505 C_bot  0.15 k_c 0.0\n",
      "Loss  36.088657 C_bot  0.15 k_c 0.0\n",
      "1683 Train Loss 47.54857\n",
      "Loss  36.088657 C_bot  0.15 k_c 0.0\n",
      "Loss  93.884926 C_bot  0.15 k_c 0.0\n",
      "1684 Train Loss 105.99291\n",
      "Loss  93.884926 C_bot  0.15 k_c 0.0\n",
      "Loss  45.17372 C_bot  0.15 k_c 0.0\n",
      "1685 Train Loss 56.574207\n",
      "Loss  45.17372 C_bot  0.15 k_c 0.0\n",
      "Loss  3.041721 C_bot  0.15 k_c 0.0\n",
      "1686 Train Loss 14.591688\n",
      "Loss  3.041721 C_bot  0.15 k_c 0.0\n",
      "Loss  43.59864 C_bot  0.15 k_c 0.0\n",
      "1687 Train Loss 55.43592\n",
      "Loss  43.59864 C_bot  0.15 k_c 0.0\n",
      "Loss  56.63837 C_bot  0.15 k_c 0.0\n",
      "1688 Train Loss 67.98712\n",
      "Loss  56.63837 C_bot  0.15 k_c 0.0\n",
      "Loss  13.335696 C_bot  0.15 k_c 0.0\n",
      "1689 Train Loss 25.000269\n",
      "Loss  13.335696 C_bot  0.15 k_c 0.0\n",
      "Loss  8.9552145 C_bot  0.15 k_c 0.0\n",
      "1690 Train Loss 20.581413\n",
      "Loss  8.9552145 C_bot  0.15 k_c 0.0\n",
      "Loss  39.689682 C_bot  0.15 k_c 0.0\n",
      "1691 Train Loss 51.041954\n",
      "Loss  39.689682 C_bot  0.15 k_c 0.0\n",
      "Loss  28.719267 C_bot  0.15 k_c 0.0\n",
      "1692 Train Loss 40.422024\n",
      "Loss  28.719267 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7778459 C_bot  0.15 k_c 0.0\n",
      "1693 Train Loss 14.215603\n",
      "Loss  2.7778459 C_bot  0.15 k_c 0.0\n",
      "Loss  16.981752 C_bot  0.15 k_c 0.0\n",
      "1694 Train Loss 28.294197\n",
      "Loss  16.981752 C_bot  0.15 k_c 0.0\n",
      "Loss  29.684843 C_bot  0.15 k_c 0.0\n",
      "1695 Train Loss 41.25602\n",
      "Loss  29.684843 C_bot  0.15 k_c 0.0\n",
      "Loss  10.310208 C_bot  0.15 k_c 0.0\n",
      "1696 Train Loss 21.562757\n",
      "Loss  10.310208 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8162138 C_bot  0.15 k_c 0.0\n",
      "1697 Train Loss 15.070759\n",
      "Loss  3.8162138 C_bot  0.15 k_c 0.0\n",
      "Loss  18.84885 C_bot  0.15 k_c 0.0\n",
      "1698 Train Loss 30.243809\n",
      "Loss  18.84885 C_bot  0.15 k_c 0.0\n",
      "Loss  16.31599 C_bot  0.15 k_c 0.0\n",
      "1699 Train Loss 27.460476\n",
      "Loss  16.31599 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7466319 C_bot  0.15 k_c 0.0\n",
      "1700 Train Loss 13.973822\n",
      "Loss  2.7466319 C_bot  0.15 k_c 0.0\n",
      "Loss  7.3820996 C_bot  0.15 k_c 0.0\n",
      "1701 Train Loss 18.626474\n",
      "Loss  7.3820996 C_bot  0.15 k_c 0.0\n",
      "Loss  14.959676 C_bot  0.15 k_c 0.0\n",
      "1702 Train Loss 26.033682\n",
      "Loss  14.959676 C_bot  0.15 k_c 0.0\n",
      "Loss  7.057665 C_bot  0.15 k_c 0.0\n",
      "1703 Train Loss 18.245075\n",
      "Loss  7.057665 C_bot  0.15 k_c 0.0\n",
      "Loss  2.124368 C_bot  0.15 k_c 0.0\n",
      "1704 Train Loss 13.23027\n",
      "Loss  2.124368 C_bot  0.15 k_c 0.0\n",
      "Loss  8.954053 C_bot  0.15 k_c 0.0\n",
      "1705 Train Loss 19.95998\n",
      "Loss  8.954053 C_bot  0.15 k_c 0.0\n",
      "Loss  9.581387 C_bot  0.15 k_c 0.0\n",
      "1706 Train Loss 20.694576\n",
      "Loss  9.581387 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8585799 C_bot  0.15 k_c 0.0\n",
      "1707 Train Loss 13.840651\n",
      "Loss  2.8585799 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5789418 C_bot  0.15 k_c 0.0\n",
      "1708 Train Loss 14.528839\n",
      "Loss  3.5789418 C_bot  0.15 k_c 0.0\n",
      "Loss  7.9434876 C_bot  0.15 k_c 0.0\n",
      "1709 Train Loss 18.972\n",
      "Loss  7.9434876 C_bot  0.15 k_c 0.0\n",
      "Loss  5.2534237 C_bot  0.15 k_c 0.0\n",
      "1710 Train Loss 16.149645\n",
      "Loss  5.2534237 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7970449 C_bot  0.15 k_c 0.0\n",
      "1711 Train Loss 12.718057\n",
      "Loss  1.7970449 C_bot  0.15 k_c 0.0\n",
      "Loss  4.4261713 C_bot  0.15 k_c 0.0\n",
      "1712 Train Loss 15.373428\n",
      "Loss  4.4261713 C_bot  0.15 k_c 0.0\n",
      "Loss  5.90166 C_bot  0.15 k_c 0.0\n",
      "1713 Train Loss 16.74512\n",
      "Loss  5.90166 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7894957 C_bot  0.15 k_c 0.0\n",
      "1714 Train Loss 13.684654\n",
      "Loss  2.7894957 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0775862 C_bot  0.15 k_c 0.0\n",
      "1715 Train Loss 12.943929\n",
      "Loss  2.0775862 C_bot  0.15 k_c 0.0\n",
      "Loss  4.407956 C_bot  0.15 k_c 0.0\n",
      "1716 Train Loss 15.211096\n",
      "Loss  4.407956 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9395645 C_bot  0.15 k_c 0.0\n",
      "1717 Train Loss 14.792894\n",
      "Loss  3.9395645 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9051447 C_bot  0.15 k_c 0.0\n",
      "1718 Train Loss 12.6995535\n",
      "Loss  1.9051447 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5142102 C_bot  0.15 k_c 0.0\n",
      "1719 Train Loss 13.285245\n",
      "Loss  2.5142102 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7417457 C_bot  0.15 k_c 0.0\n",
      "1720 Train Loss 14.545533\n",
      "Loss  3.7417457 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7304113 C_bot  0.15 k_c 0.0\n",
      "1721 Train Loss 13.473755\n",
      "Loss  2.7304113 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7348722 C_bot  0.15 k_c 0.0\n",
      "1722 Train Loss 12.482029\n",
      "Loss  1.7348722 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6109343 C_bot  0.15 k_c 0.0\n",
      "1723 Train Loss 13.365118\n",
      "Loss  2.6109343 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0519657 C_bot  0.15 k_c 0.0\n",
      "1724 Train Loss 13.756416\n",
      "Loss  3.0519657 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0522592 C_bot  0.15 k_c 0.0\n",
      "1725 Train Loss 12.77508\n",
      "Loss  2.0522592 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8004875 C_bot  0.15 k_c 0.0\n",
      "1726 Train Loss 12.505819\n",
      "Loss  1.8004875 C_bot  0.15 k_c 0.0\n",
      "Loss  2.540973 C_bot  0.15 k_c 0.0\n",
      "1727 Train Loss 13.2136135\n",
      "Loss  2.540973 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4552805 C_bot  0.15 k_c 0.0\n",
      "1728 Train Loss 13.149481\n",
      "Loss  2.4552805 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8004385 C_bot  0.15 k_c 0.0\n",
      "1729 Train Loss 12.461321\n",
      "Loss  1.8004385 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8870984 C_bot  0.15 k_c 0.0\n",
      "1730 Train Loss 12.535315\n",
      "Loss  1.8870984 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3153055 C_bot  0.15 k_c 0.0\n",
      "1731 Train Loss 12.977239\n",
      "Loss  2.3153055 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1131122 C_bot  0.15 k_c 0.0\n",
      "1732 Train Loss 12.737862\n",
      "Loss  2.1131122 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7091186 C_bot  0.15 k_c 0.0\n",
      "1733 Train Loss 12.337984\n",
      "Loss  1.7091186 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8920856 C_bot  0.15 k_c 0.0\n",
      "1734 Train Loss 12.518474\n",
      "Loss  1.8920856 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1442397 C_bot  0.15 k_c 0.0\n",
      "1735 Train Loss 12.739939\n",
      "Loss  2.1442397 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8852566 C_bot  0.15 k_c 0.0\n",
      "1736 Train Loss 12.492391\n",
      "Loss  1.8852566 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6958504 C_bot  0.15 k_c 0.0\n",
      "1737 Train Loss 12.285479\n",
      "Loss  1.6958504 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8860519 C_bot  0.15 k_c 0.0\n",
      "1738 Train Loss 12.458288\n",
      "Loss  1.8860519 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9683383 C_bot  0.15 k_c 0.0\n",
      "1739 Train Loss 12.549658\n",
      "Loss  1.9683383 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7898449 C_bot  0.15 k_c 0.0\n",
      "1740 Train Loss 12.346678\n",
      "Loss  1.7898449 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6992676 C_bot  0.15 k_c 0.0\n",
      "1741 Train Loss 12.251535\n",
      "Loss  1.6992676 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8311168 C_bot  0.15 k_c 0.0\n",
      "1742 Train Loss 12.383708\n",
      "Loss  1.8311168 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8752034 C_bot  0.15 k_c 0.0\n",
      "1743 Train Loss 12.4053955\n",
      "Loss  1.8752034 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7261593 C_bot  0.15 k_c 0.0\n",
      "1744 Train Loss 12.259404\n",
      "Loss  1.7261593 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6952484 C_bot  0.15 k_c 0.0\n",
      "1745 Train Loss 12.219206\n",
      "Loss  1.6952484 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7992127 C_bot  0.15 k_c 0.0\n",
      "1746 Train Loss 12.308296\n",
      "Loss  1.7992127 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7898662 C_bot  0.15 k_c 0.0\n",
      "1747 Train Loss 12.303097\n",
      "Loss  1.7898662 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7034879 C_bot  0.15 k_c 0.0\n",
      "1748 Train Loss 12.201168\n",
      "Loss  1.7034879 C_bot  0.15 k_c 0.0\n",
      "Loss  1.69311 C_bot  0.15 k_c 0.0\n",
      "1749 Train Loss 12.18427\n",
      "Loss  1.69311 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7508421 C_bot  0.15 k_c 0.0\n",
      "1750 Train Loss 12.241842\n",
      "Loss  1.7508421 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7524513 C_bot  0.15 k_c 0.0\n",
      "1751 Train Loss 12.22726\n",
      "Loss  1.7524513 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6838391 C_bot  0.15 k_c 0.0\n",
      "1752 Train Loss 12.158176\n",
      "Loss  1.6838391 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6820481 C_bot  0.15 k_c 0.0\n",
      "1753 Train Loss 12.149744\n",
      "Loss  1.6820481 C_bot  0.15 k_c 0.0\n",
      "Loss  1.728936 C_bot  0.15 k_c 0.0\n",
      "1754 Train Loss 12.184492\n",
      "Loss  1.728936 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7139118 C_bot  0.15 k_c 0.0\n",
      "1755 Train Loss 12.170588\n",
      "Loss  1.7139118 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6773694 C_bot  0.15 k_c 0.0\n",
      "1756 Train Loss 12.122393\n",
      "Loss  1.6773694 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6770757 C_bot  0.15 k_c 0.0\n",
      "1757 Train Loss 12.1155615\n",
      "Loss  1.6770757 C_bot  0.15 k_c 0.0\n",
      "Loss  1.699701 C_bot  0.15 k_c 0.0\n",
      "1758 Train Loss 12.1365185\n",
      "Loss  1.699701 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7002152 C_bot  0.15 k_c 0.0\n",
      "1759 Train Loss 12.124525\n",
      "Loss  1.7002152 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6686665 C_bot  0.15 k_c 0.0\n",
      "1760 Train Loss 12.090885\n",
      "Loss  1.6686665 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6673586 C_bot  0.15 k_c 0.0\n",
      "1761 Train Loss 12.0834675\n",
      "Loss  1.6673586 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6882526 C_bot  0.15 k_c 0.0\n",
      "1762 Train Loss 12.094748\n",
      "Loss  1.6882526 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6805853 C_bot  0.15 k_c 0.0\n",
      "1763 Train Loss 12.086243\n",
      "Loss  1.6805853 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6653949 C_bot  0.15 k_c 0.0\n",
      "1764 Train Loss 12.061717\n",
      "Loss  1.6653949 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6624949 C_bot  0.15 k_c 0.0\n",
      "1765 Train Loss 12.053337\n",
      "Loss  1.6624949 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6707504 C_bot  0.15 k_c 0.0\n",
      "1766 Train Loss 12.058828\n",
      "Loss  1.6707504 C_bot  0.15 k_c 0.0\n",
      "Loss  1.673776 C_bot  0.15 k_c 0.0\n",
      "1767 Train Loss 12.05232\n",
      "Loss  1.673776 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6582346 C_bot  0.15 k_c 0.0\n",
      "1768 Train Loss 12.034397\n",
      "Loss  1.6582346 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6548686 C_bot  0.15 k_c 0.0\n",
      "1769 Train Loss 12.02524\n",
      "Loss  1.6548686 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6632682 C_bot  0.15 k_c 0.0\n",
      "1770 Train Loss 12.026432\n",
      "Loss  1.6632682 C_bot  0.15 k_c 0.0\n",
      "Loss  1.660615 C_bot  0.15 k_c 0.0\n",
      "1771 Train Loss 12.0219145\n",
      "Loss  1.660615 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6547238 C_bot  0.15 k_c 0.0\n",
      "1772 Train Loss 12.008284\n",
      "Loss  1.6547238 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6496055 C_bot  0.15 k_c 0.0\n",
      "1773 Train Loss 11.998873\n",
      "Loss  1.6496055 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6516701 C_bot  0.15 k_c 0.0\n",
      "1774 Train Loss 11.997332\n",
      "Loss  1.6516701 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6552651 C_bot  0.15 k_c 0.0\n",
      "1775 Train Loss 11.993504\n",
      "Loss  1.6552651 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6476578 C_bot  0.15 k_c 0.0\n",
      "1776 Train Loss 11.983374\n",
      "Loss  1.6476578 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6441345 C_bot  0.15 k_c 0.0\n",
      "1777 Train Loss 11.974103\n",
      "Loss  1.6441345 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6458209 C_bot  0.15 k_c 0.0\n",
      "1778 Train Loss 11.9703045\n",
      "Loss  1.6458209 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6451014 C_bot  0.15 k_c 0.0\n",
      "1779 Train Loss 11.9668045\n",
      "Loss  1.6451014 C_bot  0.15 k_c 0.0\n",
      "Loss  1.643894 C_bot  0.15 k_c 0.0\n",
      "1780 Train Loss 11.95895\n",
      "Loss  1.643894 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6388276 C_bot  0.15 k_c 0.0\n",
      "1781 Train Loss 11.950359\n",
      "Loss  1.6388276 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6379204 C_bot  0.15 k_c 0.0\n",
      "1782 Train Loss 11.945165\n",
      "Loss  1.6379204 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6398176 C_bot  0.15 k_c 0.0\n",
      "1783 Train Loss 11.941259\n",
      "Loss  1.6398176 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6364093 C_bot  0.15 k_c 0.0\n",
      "1784 Train Loss 11.935101\n",
      "Loss  1.6364093 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6341506 C_bot  0.15 k_c 0.0\n",
      "1785 Train Loss 11.927335\n",
      "Loss  1.6341506 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6322541 C_bot  0.15 k_c 0.0\n",
      "1786 Train Loss 11.921274\n",
      "Loss  1.6322541 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6312541 C_bot  0.15 k_c 0.0\n",
      "1787 Train Loss 11.916868\n",
      "Loss  1.6312541 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6314068 C_bot  0.15 k_c 0.0\n",
      "1788 Train Loss 11.911507\n",
      "Loss  1.6314068 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6276722 C_bot  0.15 k_c 0.0\n",
      "1789 Train Loss 11.904751\n",
      "Loss  1.6276722 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6256703 C_bot  0.15 k_c 0.0\n",
      "1790 Train Loss 11.898226\n",
      "Loss  1.6256703 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6250238 C_bot  0.15 k_c 0.0\n",
      "1791 Train Loss 11.89315\n",
      "Loss  1.6250238 C_bot  0.15 k_c 0.0\n",
      "Loss  1.622986 C_bot  0.15 k_c 0.0\n",
      "1792 Train Loss 11.888099\n",
      "Loss  1.622986 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6218325 C_bot  0.15 k_c 0.0\n",
      "1793 Train Loss 11.881987\n",
      "Loss  1.6218325 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6186677 C_bot  0.15 k_c 0.0\n",
      "1794 Train Loss 11.87553\n",
      "Loss  1.6186677 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6169304 C_bot  0.15 k_c 0.0\n",
      "1795 Train Loss 11.86998\n",
      "Loss  1.6169304 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6160343 C_bot  0.15 k_c 0.0\n",
      "1796 Train Loss 11.864666\n",
      "Loss  1.6160343 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6132797 C_bot  0.15 k_c 0.0\n",
      "1797 Train Loss 11.858978\n",
      "Loss  1.6132797 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6113963 C_bot  0.15 k_c 0.0\n",
      "1798 Train Loss 11.852695\n",
      "Loss  1.6113963 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6086793 C_bot  0.15 k_c 0.0\n",
      "1799 Train Loss 11.846523\n",
      "Loss  1.6086793 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6064444 C_bot  0.15 k_c 0.0\n",
      "1800 Train Loss 11.840937\n",
      "Loss  1.6064444 C_bot  0.15 k_c 0.0\n",
      "Loss  1.604748 C_bot  0.15 k_c 0.0\n",
      "1801 Train Loss 11.83505\n",
      "Loss  1.604748 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6014948 C_bot  0.15 k_c 0.0\n",
      "1802 Train Loss 11.828882\n",
      "Loss  1.6014948 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5988815 C_bot  0.15 k_c 0.0\n",
      "1803 Train Loss 11.822372\n",
      "Loss  1.5988815 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5960534 C_bot  0.15 k_c 0.0\n",
      "1804 Train Loss 11.816097\n",
      "Loss  1.5960534 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5928909 C_bot  0.15 k_c 0.0\n",
      "1805 Train Loss 11.809866\n",
      "Loss  1.5928909 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5901487 C_bot  0.15 k_c 0.0\n",
      "1806 Train Loss 11.803255\n",
      "Loss  1.5901487 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5861108 C_bot  0.15 k_c 0.0\n",
      "1807 Train Loss 11.796362\n",
      "Loss  1.5861108 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5826057 C_bot  0.15 k_c 0.0\n",
      "1808 Train Loss 11.7893915\n",
      "Loss  1.5826057 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5787549 C_bot  0.15 k_c 0.0\n",
      "1809 Train Loss 11.782237\n",
      "Loss  1.5787549 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5743812 C_bot  0.15 k_c 0.0\n",
      "1810 Train Loss 11.775032\n",
      "Loss  1.5743812 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5701313 C_bot  0.15 k_c 0.0\n",
      "1811 Train Loss 11.7672615\n",
      "Loss  1.5701313 C_bot  0.15 k_c 0.0\n",
      "Loss  1.564839 C_bot  0.15 k_c 0.0\n",
      "1812 Train Loss 11.759227\n",
      "Loss  1.564839 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5595863 C_bot  0.15 k_c 0.0\n",
      "1813 Train Loss 11.750872\n",
      "Loss  1.5595863 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5541275 C_bot  0.15 k_c 0.0\n",
      "1814 Train Loss 11.742344\n",
      "Loss  1.5541275 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5477163 C_bot  0.15 k_c 0.0\n",
      "1815 Train Loss 11.733328\n",
      "Loss  1.5477163 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5412643 C_bot  0.15 k_c 0.0\n",
      "1816 Train Loss 11.723751\n",
      "Loss  1.5412643 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5338274 C_bot  0.15 k_c 0.0\n",
      "1817 Train Loss 11.71377\n",
      "Loss  1.5338274 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5260748 C_bot  0.15 k_c 0.0\n",
      "1818 Train Loss 11.703279\n",
      "Loss  1.5260748 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5179285 C_bot  0.15 k_c 0.0\n",
      "1819 Train Loss 11.692389\n",
      "Loss  1.5179285 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5087085 C_bot  0.15 k_c 0.0\n",
      "1820 Train Loss 11.680851\n",
      "Loss  1.5087085 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4992747 C_bot  0.15 k_c 0.0\n",
      "1821 Train Loss 11.668711\n",
      "Loss  1.4992747 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4887929 C_bot  0.15 k_c 0.0\n",
      "1822 Train Loss 11.656\n",
      "Loss  1.4887929 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4778903 C_bot  0.15 k_c 0.0\n",
      "1823 Train Loss 11.642759\n",
      "Loss  1.4778903 C_bot  0.15 k_c 0.0\n",
      "Loss  1.466452 C_bot  0.15 k_c 0.0\n",
      "1824 Train Loss 11.628995\n",
      "Loss  1.466452 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4541956 C_bot  0.15 k_c 0.0\n",
      "1825 Train Loss 11.614766\n",
      "Loss  1.4541956 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4417175 C_bot  0.15 k_c 0.0\n",
      "1826 Train Loss 11.600031\n",
      "Loss  1.4417175 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4285012 C_bot  0.15 k_c 0.0\n",
      "1827 Train Loss 11.584943\n",
      "Loss  1.4285012 C_bot  0.15 k_c 0.0\n",
      "Loss  1.41502 C_bot  0.15 k_c 0.0\n",
      "1828 Train Loss 11.569508\n",
      "Loss  1.41502 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4013349 C_bot  0.15 k_c 0.0\n",
      "1829 Train Loss 11.553894\n",
      "Loss  1.4013349 C_bot  0.15 k_c 0.0\n",
      "Loss  1.38735 C_bot  0.15 k_c 0.0\n",
      "1830 Train Loss 11.538239\n",
      "Loss  1.38735 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3735403 C_bot  0.15 k_c 0.0\n",
      "1831 Train Loss 11.5225315\n",
      "Loss  1.3735403 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3596158 C_bot  0.15 k_c 0.0\n",
      "1832 Train Loss 11.506995\n",
      "Loss  1.3596158 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3460504 C_bot  0.15 k_c 0.0\n",
      "1833 Train Loss 11.491713\n",
      "Loss  1.3460504 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3327321 C_bot  0.15 k_c 0.0\n",
      "1834 Train Loss 11.476684\n",
      "Loss  1.3327321 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3196793 C_bot  0.15 k_c 0.0\n",
      "1835 Train Loss 11.462069\n",
      "Loss  1.3196793 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3072637 C_bot  0.15 k_c 0.0\n",
      "1836 Train Loss 11.447884\n",
      "Loss  1.3072637 C_bot  0.15 k_c 0.0\n",
      "Loss  1.295313 C_bot  0.15 k_c 0.0\n",
      "1837 Train Loss 11.434347\n",
      "Loss  1.295313 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2839389 C_bot  0.15 k_c 0.0\n",
      "1838 Train Loss 11.421244\n",
      "Loss  1.2839389 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2733271 C_bot  0.15 k_c 0.0\n",
      "1839 Train Loss 11.408885\n",
      "Loss  1.2733271 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2630836 C_bot  0.15 k_c 0.0\n",
      "1840 Train Loss 11.396936\n",
      "Loss  1.2630836 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2538127 C_bot  0.15 k_c 0.0\n",
      "1841 Train Loss 11.385769\n",
      "Loss  1.2538127 C_bot  0.15 k_c 0.0\n",
      "Loss  1.244957 C_bot  0.15 k_c 0.0\n",
      "1842 Train Loss 11.375111\n",
      "Loss  1.244957 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2368116 C_bot  0.15 k_c 0.0\n",
      "1843 Train Loss 11.364998\n",
      "Loss  1.2368116 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2292819 C_bot  0.15 k_c 0.0\n",
      "1844 Train Loss 11.355471\n",
      "Loss  1.2292819 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2222127 C_bot  0.15 k_c 0.0\n",
      "1845 Train Loss 11.346384\n",
      "Loss  1.2222127 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2158796 C_bot  0.15 k_c 0.0\n",
      "1846 Train Loss 11.337873\n",
      "Loss  1.2158796 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2097456 C_bot  0.15 k_c 0.0\n",
      "1847 Train Loss 11.329607\n",
      "Loss  1.2097456 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2041765 C_bot  0.15 k_c 0.0\n",
      "1848 Train Loss 11.321756\n",
      "Loss  1.2041765 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1989526 C_bot  0.15 k_c 0.0\n",
      "1849 Train Loss 11.31424\n",
      "Loss  1.1989526 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1941019 C_bot  0.15 k_c 0.0\n",
      "1850 Train Loss 11.307053\n",
      "Loss  1.1941019 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1896007 C_bot  0.15 k_c 0.0\n",
      "1851 Train Loss 11.300123\n",
      "Loss  1.1896007 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1852424 C_bot  0.15 k_c 0.0\n",
      "1852 Train Loss 11.293377\n",
      "Loss  1.1852424 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1812156 C_bot  0.15 k_c 0.0\n",
      "1853 Train Loss 11.28687\n",
      "Loss  1.1812156 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1773914 C_bot  0.15 k_c 0.0\n",
      "1854 Train Loss 11.280598\n",
      "Loss  1.1773914 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1737063 C_bot  0.15 k_c 0.0\n",
      "1855 Train Loss 11.274454\n",
      "Loss  1.1737063 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1702143 C_bot  0.15 k_c 0.0\n",
      "1856 Train Loss 11.26848\n",
      "Loss  1.1702143 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1666998 C_bot  0.15 k_c 0.0\n",
      "1857 Train Loss 11.262566\n",
      "Loss  1.1666998 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1634914 C_bot  0.15 k_c 0.0\n",
      "1858 Train Loss 11.256916\n",
      "Loss  1.1634914 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1603094 C_bot  0.15 k_c 0.0\n",
      "1859 Train Loss 11.251389\n",
      "Loss  1.1603094 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1571792 C_bot  0.15 k_c 0.0\n",
      "1860 Train Loss 11.245928\n",
      "Loss  1.1571792 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1541104 C_bot  0.15 k_c 0.0\n",
      "1861 Train Loss 11.240578\n",
      "Loss  1.1541104 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1511406 C_bot  0.15 k_c 0.0\n",
      "1862 Train Loss 11.2354145\n",
      "Loss  1.1511406 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1482037 C_bot  0.15 k_c 0.0\n",
      "1863 Train Loss 11.230293\n",
      "Loss  1.1482037 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1452293 C_bot  0.15 k_c 0.0\n",
      "1864 Train Loss 11.225244\n",
      "Loss  1.1452293 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1424187 C_bot  0.15 k_c 0.0\n",
      "1865 Train Loss 11.220382\n",
      "Loss  1.1424187 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1396599 C_bot  0.15 k_c 0.0\n",
      "1866 Train Loss 11.215639\n",
      "Loss  1.1396599 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1367663 C_bot  0.15 k_c 0.0\n",
      "1867 Train Loss 11.210842\n",
      "Loss  1.1367663 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1341276 C_bot  0.15 k_c 0.0\n",
      "1868 Train Loss 11.206303\n",
      "Loss  1.1341276 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1313325 C_bot  0.15 k_c 0.0\n",
      "1869 Train Loss 11.201717\n",
      "Loss  1.1313325 C_bot  0.15 k_c 0.0\n",
      "Loss  1.12863 C_bot  0.15 k_c 0.0\n",
      "1870 Train Loss 11.197216\n",
      "Loss  1.12863 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1259834 C_bot  0.15 k_c 0.0\n",
      "1871 Train Loss 11.19285\n",
      "Loss  1.1259834 C_bot  0.15 k_c 0.0\n",
      "Loss  1.123363 C_bot  0.15 k_c 0.0\n",
      "1872 Train Loss 11.188522\n",
      "Loss  1.123363 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1206962 C_bot  0.15 k_c 0.0\n",
      "1873 Train Loss 11.184191\n",
      "Loss  1.1206962 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1180547 C_bot  0.15 k_c 0.0\n",
      "1874 Train Loss 11.179918\n",
      "Loss  1.1180547 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1154491 C_bot  0.15 k_c 0.0\n",
      "1875 Train Loss 11.17569\n",
      "Loss  1.1154491 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1128134 C_bot  0.15 k_c 0.0\n",
      "1876 Train Loss 11.171482\n",
      "Loss  1.1128134 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1102918 C_bot  0.15 k_c 0.0\n",
      "1877 Train Loss 11.167377\n",
      "Loss  1.1102918 C_bot  0.15 k_c 0.0\n",
      "Loss  1.107714 C_bot  0.15 k_c 0.0\n",
      "1878 Train Loss 11.163263\n",
      "Loss  1.107714 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1052309 C_bot  0.15 k_c 0.0\n",
      "1879 Train Loss 11.159235\n",
      "Loss  1.1052309 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1026797 C_bot  0.15 k_c 0.0\n",
      "1880 Train Loss 11.155172\n",
      "Loss  1.1026797 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1002327 C_bot  0.15 k_c 0.0\n",
      "1881 Train Loss 11.151217\n",
      "Loss  1.1002327 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0977325 C_bot  0.15 k_c 0.0\n",
      "1882 Train Loss 11.147224\n",
      "Loss  1.0977325 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0952557 C_bot  0.15 k_c 0.0\n",
      "1883 Train Loss 11.1432705\n",
      "Loss  1.0952557 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0928152 C_bot  0.15 k_c 0.0\n",
      "1884 Train Loss 11.139357\n",
      "Loss  1.0928152 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0904475 C_bot  0.15 k_c 0.0\n",
      "1885 Train Loss 11.13554\n",
      "Loss  1.0904475 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0880834 C_bot  0.15 k_c 0.0\n",
      "1886 Train Loss 11.13172\n",
      "Loss  1.0880834 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0856353 C_bot  0.15 k_c 0.0\n",
      "1887 Train Loss 11.127841\n",
      "Loss  1.0856353 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0832272 C_bot  0.15 k_c 0.0\n",
      "1888 Train Loss 11.124004\n",
      "Loss  1.0832272 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0809506 C_bot  0.15 k_c 0.0\n",
      "1889 Train Loss 11.120308\n",
      "Loss  1.0809506 C_bot  0.15 k_c 0.0\n",
      "Loss  1.078579 C_bot  0.15 k_c 0.0\n",
      "1890 Train Loss 11.116535\n",
      "Loss  1.078579 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0762607 C_bot  0.15 k_c 0.0\n",
      "1891 Train Loss 11.112814\n",
      "Loss  1.0762607 C_bot  0.15 k_c 0.0\n",
      "Loss  1.073914 C_bot  0.15 k_c 0.0\n",
      "1892 Train Loss 11.109083\n",
      "Loss  1.073914 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0716145 C_bot  0.15 k_c 0.0\n",
      "1893 Train Loss 11.105398\n",
      "Loss  1.0716145 C_bot  0.15 k_c 0.0\n",
      "Loss  1.069342 C_bot  0.15 k_c 0.0\n",
      "1894 Train Loss 11.10176\n",
      "Loss  1.069342 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0671779 C_bot  0.15 k_c 0.0\n",
      "1895 Train Loss 11.098232\n",
      "Loss  1.0671779 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0649259 C_bot  0.15 k_c 0.0\n",
      "1896 Train Loss 11.094628\n",
      "Loss  1.0649259 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0627027 C_bot  0.15 k_c 0.0\n",
      "1897 Train Loss 11.091061\n",
      "Loss  1.0627027 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0605339 C_bot  0.15 k_c 0.0\n",
      "1898 Train Loss 11.087559\n",
      "Loss  1.0605339 C_bot  0.15 k_c 0.0\n",
      "Loss  1.058315 C_bot  0.15 k_c 0.0\n",
      "1899 Train Loss 11.084012\n",
      "Loss  1.058315 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0561373 C_bot  0.15 k_c 0.0\n",
      "1900 Train Loss 11.080521\n",
      "Loss  1.0561373 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0540202 C_bot  0.15 k_c 0.0\n",
      "1901 Train Loss 11.077091\n",
      "Loss  1.0540202 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0518664 C_bot  0.15 k_c 0.0\n",
      "1902 Train Loss 11.073641\n",
      "Loss  1.0518664 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0498 C_bot  0.15 k_c 0.0\n",
      "1903 Train Loss 11.070277\n",
      "Loss  1.0498 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0476285 C_bot  0.15 k_c 0.0\n",
      "1904 Train Loss 11.066829\n",
      "Loss  1.0476285 C_bot  0.15 k_c 0.0\n",
      "Loss  1.045534 C_bot  0.15 k_c 0.0\n",
      "1905 Train Loss 11.06345\n",
      "Loss  1.045534 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0434363 C_bot  0.15 k_c 0.0\n",
      "1906 Train Loss 11.060091\n",
      "Loss  1.0434363 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0414118 C_bot  0.15 k_c 0.0\n",
      "1907 Train Loss 11.056803\n",
      "Loss  1.0414118 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0393759 C_bot  0.15 k_c 0.0\n",
      "1908 Train Loss 11.053513\n",
      "Loss  1.0393759 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0373545 C_bot  0.15 k_c 0.0\n",
      "1909 Train Loss 11.050245\n",
      "Loss  1.0373545 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0353316 C_bot  0.15 k_c 0.0\n",
      "1910 Train Loss 11.04698\n",
      "Loss  1.0353316 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0334191 C_bot  0.15 k_c 0.0\n",
      "1911 Train Loss 11.043837\n",
      "Loss  1.0334191 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0314 C_bot  0.15 k_c 0.0\n",
      "1912 Train Loss 11.040592\n",
      "Loss  1.0314 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0294219 C_bot  0.15 k_c 0.0\n",
      "1913 Train Loss 11.037392\n",
      "Loss  1.0294219 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0274447 C_bot  0.15 k_c 0.0\n",
      "1914 Train Loss 11.034206\n",
      "Loss  1.0274447 C_bot  0.15 k_c 0.0\n",
      "Loss  1.025543 C_bot  0.15 k_c 0.0\n",
      "1915 Train Loss 11.031088\n",
      "Loss  1.025543 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0236408 C_bot  0.15 k_c 0.0\n",
      "1916 Train Loss 11.027998\n",
      "Loss  1.0236408 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0217146 C_bot  0.15 k_c 0.0\n",
      "1917 Train Loss 11.024862\n",
      "Loss  1.0217146 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0198151 C_bot  0.15 k_c 0.0\n",
      "1918 Train Loss 11.02179\n",
      "Loss  1.0198151 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0179594 C_bot  0.15 k_c 0.0\n",
      "1919 Train Loss 11.018734\n",
      "Loss  1.0179594 C_bot  0.15 k_c 0.0\n",
      "Loss  1.016061 C_bot  0.15 k_c 0.0\n",
      "1920 Train Loss 11.015669\n",
      "Loss  1.016061 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0142088 C_bot  0.15 k_c 0.0\n",
      "1921 Train Loss 11.012638\n",
      "Loss  1.0142088 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0124786 C_bot  0.15 k_c 0.0\n",
      "1922 Train Loss 11.009741\n",
      "Loss  1.0124786 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0106503 C_bot  0.15 k_c 0.0\n",
      "1923 Train Loss 11.006752\n",
      "Loss  1.0106503 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0088377 C_bot  0.15 k_c 0.0\n",
      "1924 Train Loss 11.003774\n",
      "Loss  1.0088377 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0070788 C_bot  0.15 k_c 0.0\n",
      "1925 Train Loss 11.000869\n",
      "Loss  1.0070788 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0053238 C_bot  0.15 k_c 0.0\n",
      "1926 Train Loss 10.997955\n",
      "Loss  1.0053238 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0036143 C_bot  0.15 k_c 0.0\n",
      "1927 Train Loss 10.995104\n",
      "Loss  1.0036143 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0018817 C_bot  0.15 k_c 0.0\n",
      "1928 Train Loss 10.992229\n",
      "Loss  1.0018817 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0001742 C_bot  0.15 k_c 0.0\n",
      "1929 Train Loss 10.989376\n",
      "Loss  1.0001742 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99843174 C_bot  0.15 k_c 0.0\n",
      "1930 Train Loss 10.986508\n",
      "Loss  0.99843174 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9967841 C_bot  0.15 k_c 0.0\n",
      "1931 Train Loss 10.983711\n",
      "Loss  0.9967841 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9950943 C_bot  0.15 k_c 0.0\n",
      "1932 Train Loss 10.980912\n",
      "Loss  0.9950943 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99349934 C_bot  0.15 k_c 0.0\n",
      "1933 Train Loss 10.978165\n",
      "Loss  0.99349934 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9918831 C_bot  0.15 k_c 0.0\n",
      "1934 Train Loss 10.975454\n",
      "Loss  0.9918831 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9903221 C_bot  0.15 k_c 0.0\n",
      "1935 Train Loss 10.972736\n",
      "Loss  0.9903221 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9886136 C_bot  0.15 k_c 0.0\n",
      "1936 Train Loss 10.969945\n",
      "Loss  0.9886136 C_bot  0.15 k_c 0.0\n",
      "Loss  0.98704475 C_bot  0.15 k_c 0.0\n",
      "1937 Train Loss 10.967217\n",
      "Loss  0.98704475 C_bot  0.15 k_c 0.0\n",
      "Loss  0.985488 C_bot  0.15 k_c 0.0\n",
      "1938 Train Loss 10.964586\n",
      "Loss  0.985488 C_bot  0.15 k_c 0.0\n",
      "Loss  0.983913 C_bot  0.15 k_c 0.0\n",
      "1939 Train Loss 10.961857\n",
      "Loss  0.983913 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9824155 C_bot  0.15 k_c 0.0\n",
      "1940 Train Loss 10.959288\n",
      "Loss  0.9824155 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9808943 C_bot  0.15 k_c 0.0\n",
      "1941 Train Loss 10.956617\n",
      "Loss  0.9808943 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9794048 C_bot  0.15 k_c 0.0\n",
      "1942 Train Loss 10.954059\n",
      "Loss  0.9794048 C_bot  0.15 k_c 0.0\n",
      "Loss  0.977933 C_bot  0.15 k_c 0.0\n",
      "1943 Train Loss 10.951445\n",
      "Loss  0.977933 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9764389 C_bot  0.15 k_c 0.0\n",
      "1944 Train Loss 10.948881\n",
      "Loss  0.9764389 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9750095 C_bot  0.15 k_c 0.0\n",
      "1945 Train Loss 10.946314\n",
      "Loss  0.9750095 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9735599 C_bot  0.15 k_c 0.0\n",
      "1946 Train Loss 10.943796\n",
      "Loss  0.9735599 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9721269 C_bot  0.15 k_c 0.0\n",
      "1947 Train Loss 10.941235\n",
      "Loss  0.9721269 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9707545 C_bot  0.15 k_c 0.0\n",
      "1948 Train Loss 10.938789\n",
      "Loss  0.9707545 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9693268 C_bot  0.15 k_c 0.0\n",
      "1949 Train Loss 10.936245\n",
      "Loss  0.9693268 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96797425 C_bot  0.15 k_c 0.0\n",
      "1950 Train Loss 10.933817\n",
      "Loss  0.96797425 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9665943 C_bot  0.15 k_c 0.0\n",
      "1951 Train Loss 10.931323\n",
      "Loss  0.9665943 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9652039 C_bot  0.15 k_c 0.0\n",
      "1952 Train Loss 10.928864\n",
      "Loss  0.9652039 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96395427 C_bot  0.15 k_c 0.0\n",
      "1953 Train Loss 10.9265\n",
      "Loss  0.96395427 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9625507 C_bot  0.15 k_c 0.0\n",
      "1954 Train Loss 10.924033\n",
      "Loss  0.9625507 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9613146 C_bot  0.15 k_c 0.0\n",
      "1955 Train Loss 10.921682\n",
      "Loss  0.9613146 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9599633 C_bot  0.15 k_c 0.0\n",
      "1956 Train Loss 10.919273\n",
      "Loss  0.9599633 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9587095 C_bot  0.15 k_c 0.0\n",
      "1957 Train Loss 10.9169035\n",
      "Loss  0.9587095 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95736134 C_bot  0.15 k_c 0.0\n",
      "1958 Train Loss 10.914504\n",
      "Loss  0.95736134 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95615894 C_bot  0.15 k_c 0.0\n",
      "1959 Train Loss 10.912184\n",
      "Loss  0.95615894 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95494527 C_bot  0.15 k_c 0.0\n",
      "1960 Train Loss 10.9099245\n",
      "Loss  0.95494527 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9537131 C_bot  0.15 k_c 0.0\n",
      "1961 Train Loss 10.907572\n",
      "Loss  0.9537131 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95244664 C_bot  0.15 k_c 0.0\n",
      "1962 Train Loss 10.905268\n",
      "Loss  0.95244664 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95127904 C_bot  0.15 k_c 0.0\n",
      "1963 Train Loss 10.902977\n",
      "Loss  0.95127904 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94999695 C_bot  0.15 k_c 0.0\n",
      "1964 Train Loss 10.900669\n",
      "Loss  0.94999695 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9489156 C_bot  0.15 k_c 0.0\n",
      "1965 Train Loss 10.898449\n",
      "Loss  0.9489156 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9476878 C_bot  0.15 k_c 0.0\n",
      "1966 Train Loss 10.896221\n",
      "Loss  0.9476878 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94658077 C_bot  0.15 k_c 0.0\n",
      "1967 Train Loss 10.893946\n",
      "Loss  0.94658077 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9453836 C_bot  0.15 k_c 0.0\n",
      "1968 Train Loss 10.891787\n",
      "Loss  0.9453836 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94437194 C_bot  0.15 k_c 0.0\n",
      "1969 Train Loss 10.889568\n",
      "Loss  0.94437194 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9430327 C_bot  0.15 k_c 0.0\n",
      "1970 Train Loss 10.887319\n",
      "Loss  0.9430327 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94212407 C_bot  0.15 k_c 0.0\n",
      "1971 Train Loss 10.885139\n",
      "Loss  0.94212407 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94087154 C_bot  0.15 k_c 0.0\n",
      "1972 Train Loss 10.88306\n",
      "Loss  0.94087154 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94012505 C_bot  0.15 k_c 0.0\n",
      "1973 Train Loss 10.880942\n",
      "Loss  0.94012505 C_bot  0.15 k_c 0.0\n",
      "Loss  0.938798 C_bot  0.15 k_c 0.0\n",
      "1974 Train Loss 10.87892\n",
      "Loss  0.938798 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9382643 C_bot  0.15 k_c 0.0\n",
      "1975 Train Loss 10.87685\n",
      "Loss  0.9382643 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93685776 C_bot  0.15 k_c 0.0\n",
      "1976 Train Loss 10.874962\n",
      "Loss  0.93685776 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9369389 C_bot  0.15 k_c 0.0\n",
      "1977 Train Loss 10.873232\n",
      "Loss  0.9369389 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9356299 C_bot  0.15 k_c 0.0\n",
      "1978 Train Loss 10.871805\n",
      "Loss  0.9356299 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9367751 C_bot  0.15 k_c 0.0\n",
      "1979 Train Loss 10.870672\n",
      "Loss  0.9367751 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9360593 C_bot  0.15 k_c 0.0\n",
      "1980 Train Loss 10.870452\n",
      "Loss  0.9360593 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93998873 C_bot  0.15 k_c 0.0\n",
      "1981 Train Loss 10.871305\n",
      "Loss  0.93998873 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9418416 C_bot  0.15 k_c 0.0\n",
      "1982 Train Loss 10.874721\n",
      "Loss  0.9418416 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9533485 C_bot  0.15 k_c 0.0\n",
      "1983 Train Loss 10.881752\n",
      "Loss  0.9533485 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96447396 C_bot  0.15 k_c 0.0\n",
      "1984 Train Loss 10.896339\n",
      "Loss  0.96447396 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99825567 C_bot  0.15 k_c 0.0\n",
      "1985 Train Loss 10.92315\n",
      "Loss  0.99825567 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0423725 C_bot  0.15 k_c 0.0\n",
      "1986 Train Loss 10.974183\n",
      "Loss  1.0423725 C_bot  0.15 k_c 0.0\n",
      "Loss  1.146511 C_bot  0.15 k_c 0.0\n",
      "1987 Train Loss 11.066849\n",
      "Loss  1.146511 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3071845 C_bot  0.15 k_c 0.0\n",
      "1988 Train Loss 11.240862\n",
      "Loss  1.3071845 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6450505 C_bot  0.15 k_c 0.0\n",
      "1989 Train Loss 11.55906\n",
      "Loss  1.6450505 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2213764 C_bot  0.15 k_c 0.0\n",
      "1990 Train Loss 12.161009\n",
      "Loss  2.2213764 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3697362 C_bot  0.15 k_c 0.0\n",
      "1991 Train Loss 13.274788\n",
      "Loss  3.3697362 C_bot  0.15 k_c 0.0\n",
      "Loss  5.462688 C_bot  0.15 k_c 0.0\n",
      "1992 Train Loss 15.41777\n",
      "Loss  5.462688 C_bot  0.15 k_c 0.0\n",
      "Loss  9.509572 C_bot  0.15 k_c 0.0\n",
      "1993 Train Loss 19.40329\n",
      "Loss  9.509572 C_bot  0.15 k_c 0.0\n",
      "Loss  17.237825 C_bot  0.15 k_c 0.0\n",
      "1994 Train Loss 27.233063\n",
      "Loss  17.237825 C_bot  0.15 k_c 0.0\n",
      "Loss  31.744162 C_bot  0.15 k_c 0.0\n",
      "1995 Train Loss 41.63144\n",
      "Loss  31.744162 C_bot  0.15 k_c 0.0\n",
      "Loss  60.314598 C_bot  0.15 k_c 0.0\n",
      "1996 Train Loss 70.42237\n",
      "Loss  60.314598 C_bot  0.15 k_c 0.0\n",
      "Loss  110.44658 C_bot  0.15 k_c 0.0\n",
      "1997 Train Loss 120.36619\n",
      "Loss  110.44658 C_bot  0.15 k_c 0.0\n",
      "Loss  208.27632 C_bot  0.15 k_c 0.0\n",
      "1998 Train Loss 218.71992\n",
      "Loss  208.27632 C_bot  0.15 k_c 0.0\n",
      "Loss  346.5284 C_bot  0.15 k_c 0.0\n",
      "1999 Train Loss 356.5978\n",
      "Loss  346.5284 C_bot  0.15 k_c 0.0\n",
      "Loss  572.8315 C_bot  0.15 k_c 0.0\n",
      "2000 Train Loss 584.13605\n",
      "Loss  572.8315 C_bot  0.15 k_c 0.0\n",
      "Loss  692.77875 C_bot  0.15 k_c 0.0\n",
      "2001 Train Loss 703.0139\n",
      "Loss  692.77875 C_bot  0.15 k_c 0.0\n",
      "Loss  697.2828 C_bot  0.15 k_c 0.0\n",
      "2002 Train Loss 709.4027\n",
      "Loss  697.2828 C_bot  0.15 k_c 0.0\n",
      "Loss  363.1467 C_bot  0.15 k_c 0.0\n",
      "2003 Train Loss 373.347\n",
      "Loss  363.1467 C_bot  0.15 k_c 0.0\n",
      "Loss  52.169098 C_bot  0.15 k_c 0.0\n",
      "2004 Train Loss 63.373707\n",
      "Loss  52.169098 C_bot  0.15 k_c 0.0\n",
      "Loss  38.144302 C_bot  0.15 k_c 0.0\n",
      "2005 Train Loss 49.542923\n",
      "Loss  38.144302 C_bot  0.15 k_c 0.0\n",
      "Loss  246.07393 C_bot  0.15 k_c 0.0\n",
      "2006 Train Loss 256.68677\n",
      "Loss  246.07393 C_bot  0.15 k_c 0.0\n",
      "Loss  353.73233 C_bot  0.15 k_c 0.0\n",
      "2007 Train Loss 366.60245\n",
      "Loss  353.73233 C_bot  0.15 k_c 0.0\n",
      "Loss  179.57188 C_bot  0.15 k_c 0.0\n",
      "2008 Train Loss 190.37224\n",
      "Loss  179.57188 C_bot  0.15 k_c 0.0\n",
      "Loss  11.977975 C_bot  0.15 k_c 0.0\n",
      "2009 Train Loss 23.550737\n",
      "Loss  11.977975 C_bot  0.15 k_c 0.0\n",
      "Loss  60.080437 C_bot  0.15 k_c 0.0\n",
      "2010 Train Loss 71.95307\n",
      "Loss  60.080437 C_bot  0.15 k_c 0.0\n",
      "Loss  182.26962 C_bot  0.15 k_c 0.0\n",
      "2011 Train Loss 193.13072\n",
      "Loss  182.26962 C_bot  0.15 k_c 0.0\n",
      "Loss  158.7236 C_bot  0.15 k_c 0.0\n",
      "2012 Train Loss 170.94513\n",
      "Loss  158.7236 C_bot  0.15 k_c 0.0\n",
      "Loss  28.71567 C_bot  0.15 k_c 0.0\n",
      "2013 Train Loss 39.908512\n",
      "Loss  28.71567 C_bot  0.15 k_c 0.0\n",
      "Loss  21.693277 C_bot  0.15 k_c 0.0\n",
      "2014 Train Loss 32.929718\n",
      "Loss  21.693277 C_bot  0.15 k_c 0.0\n",
      "Loss  110.21014 C_bot  0.15 k_c 0.0\n",
      "2015 Train Loss 122.17819\n",
      "Loss  110.21014 C_bot  0.15 k_c 0.0\n",
      "Loss  102.725006 C_bot  0.15 k_c 0.0\n",
      "2016 Train Loss 113.82993\n",
      "Loss  102.725006 C_bot  0.15 k_c 0.0\n",
      "Loss  21.52267 C_bot  0.15 k_c 0.0\n",
      "2017 Train Loss 33.064236\n",
      "Loss  21.52267 C_bot  0.15 k_c 0.0\n",
      "Loss  13.516111 C_bot  0.15 k_c 0.0\n",
      "2018 Train Loss 24.965313\n",
      "Loss  13.516111 C_bot  0.15 k_c 0.0\n",
      "Loss  69.49516 C_bot  0.15 k_c 0.0\n",
      "2019 Train Loss 80.58938\n",
      "Loss  69.49516 C_bot  0.15 k_c 0.0\n",
      "Loss  66.34378 C_bot  0.15 k_c 0.0\n",
      "2020 Train Loss 77.928276\n",
      "Loss  66.34378 C_bot  0.15 k_c 0.0\n",
      "Loss  11.685908 C_bot  0.15 k_c 0.0\n",
      "2021 Train Loss 22.798765\n",
      "Loss  11.685908 C_bot  0.15 k_c 0.0\n",
      "Loss  13.502903 C_bot  0.15 k_c 0.0\n",
      "2022 Train Loss 24.562191\n",
      "Loss  13.502903 C_bot  0.15 k_c 0.0\n",
      "Loss  50.86474 C_bot  0.15 k_c 0.0\n",
      "2023 Train Loss 62.236546\n",
      "Loss  50.86474 C_bot  0.15 k_c 0.0\n",
      "Loss  38.402374 C_bot  0.15 k_c 0.0\n",
      "2024 Train Loss 49.338455\n",
      "Loss  38.402374 C_bot  0.15 k_c 0.0\n",
      "Loss  4.8197284 C_bot  0.15 k_c 0.0\n",
      "2025 Train Loss 15.932106\n",
      "Loss  4.8197284 C_bot  0.15 k_c 0.0\n",
      "Loss  13.855305 C_bot  0.15 k_c 0.0\n",
      "2026 Train Loss 25.024975\n",
      "Loss  13.855305 C_bot  0.15 k_c 0.0\n",
      "Loss  35.307526 C_bot  0.15 k_c 0.0\n",
      "2027 Train Loss 46.20464\n",
      "Loss  35.307526 C_bot  0.15 k_c 0.0\n",
      "Loss  21.61283 C_bot  0.15 k_c 0.0\n",
      "2028 Train Loss 32.769245\n",
      "Loss  21.61283 C_bot  0.15 k_c 0.0\n",
      "Loss  2.468469 C_bot  0.15 k_c 0.0\n",
      "2029 Train Loss 13.409962\n",
      "Loss  2.468469 C_bot  0.15 k_c 0.0\n",
      "Loss  13.52979 C_bot  0.15 k_c 0.0\n",
      "2030 Train Loss 24.357155\n",
      "Loss  13.52979 C_bot  0.15 k_c 0.0\n",
      "Loss  24.723436 C_bot  0.15 k_c 0.0\n",
      "2031 Train Loss 35.748657\n",
      "Loss  24.723436 C_bot  0.15 k_c 0.0\n",
      "Loss  11.491835 C_bot  0.15 k_c 0.0\n",
      "2032 Train Loss 22.233374\n",
      "Loss  11.491835 C_bot  0.15 k_c 0.0\n",
      "Loss  2.12436 C_bot  0.15 k_c 0.0\n",
      "2033 Train Loss 12.885411\n",
      "Loss  2.12436 C_bot  0.15 k_c 0.0\n",
      "Loss  12.12915 C_bot  0.15 k_c 0.0\n",
      "2034 Train Loss 22.956423\n",
      "Loss  12.12915 C_bot  0.15 k_c 0.0\n",
      "Loss  16.301714 C_bot  0.15 k_c 0.0\n",
      "2035 Train Loss 26.934868\n",
      "Loss  16.301714 C_bot  0.15 k_c 0.0\n",
      "Loss  5.9830976 C_bot  0.15 k_c 0.0\n",
      "2036 Train Loss 16.71678\n",
      "Loss  5.9830976 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5248337 C_bot  0.15 k_c 0.0\n",
      "2037 Train Loss 13.2017145\n",
      "Loss  2.5248337 C_bot  0.15 k_c 0.0\n",
      "Loss  10.126673 C_bot  0.15 k_c 0.0\n",
      "2038 Train Loss 20.708914\n",
      "Loss  10.126673 C_bot  0.15 k_c 0.0\n",
      "Loss  10.79305 C_bot  0.15 k_c 0.0\n",
      "2039 Train Loss 21.482185\n",
      "Loss  10.79305 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5535507 C_bot  0.15 k_c 0.0\n",
      "2040 Train Loss 14.115923\n",
      "Loss  3.5535507 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9319136 C_bot  0.15 k_c 0.0\n",
      "2041 Train Loss 13.477683\n",
      "Loss  2.9319136 C_bot  0.15 k_c 0.0\n",
      "Loss  8.002801 C_bot  0.15 k_c 0.0\n",
      "2042 Train Loss 18.613684\n",
      "Loss  8.002801 C_bot  0.15 k_c 0.0\n",
      "Loss  7.140705 C_bot  0.15 k_c 0.0\n",
      "2043 Train Loss 17.62876\n",
      "Loss  7.140705 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3497603 C_bot  0.15 k_c 0.0\n",
      "2044 Train Loss 12.885729\n",
      "Loss  2.3497603 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9111505 C_bot  0.15 k_c 0.0\n",
      "2045 Train Loss 13.443233\n",
      "Loss  2.9111505 C_bot  0.15 k_c 0.0\n",
      "Loss  6.196045 C_bot  0.15 k_c 0.0\n",
      "2046 Train Loss 16.651123\n",
      "Loss  6.196045 C_bot  0.15 k_c 0.0\n",
      "Loss  4.8786926 C_bot  0.15 k_c 0.0\n",
      "2047 Train Loss 15.407013\n",
      "Loss  4.8786926 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9487991 C_bot  0.15 k_c 0.0\n",
      "2048 Train Loss 12.4126\n",
      "Loss  1.9487991 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8191214 C_bot  0.15 k_c 0.0\n",
      "2049 Train Loss 13.2579365\n",
      "Loss  2.8191214 C_bot  0.15 k_c 0.0\n",
      "Loss  4.764902 C_bot  0.15 k_c 0.0\n",
      "2050 Train Loss 15.249143\n",
      "Loss  4.764902 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6469555 C_bot  0.15 k_c 0.0\n",
      "2051 Train Loss 14.05106\n",
      "Loss  3.6469555 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7805912 C_bot  0.15 k_c 0.0\n",
      "2052 Train Loss 12.200045\n",
      "Loss  1.7805912 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5323415 C_bot  0.15 k_c 0.0\n",
      "2053 Train Loss 12.951603\n",
      "Loss  2.5323415 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7838242 C_bot  0.15 k_c 0.0\n",
      "2054 Train Loss 14.148069\n",
      "Loss  3.7838242 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8615668 C_bot  0.15 k_c 0.0\n",
      "2055 Train Loss 13.259232\n",
      "Loss  2.8615668 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7312189 C_bot  0.15 k_c 0.0\n",
      "2056 Train Loss 12.094165\n",
      "Loss  1.7312189 C_bot  0.15 k_c 0.0\n",
      "Loss  2.316772 C_bot  0.15 k_c 0.0\n",
      "2057 Train Loss 12.6588335\n",
      "Loss  2.316772 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0587497 C_bot  0.15 k_c 0.0\n",
      "2058 Train Loss 13.42588\n",
      "Loss  3.0587497 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4718528 C_bot  0.15 k_c 0.0\n",
      "2059 Train Loss 12.791332\n",
      "Loss  2.4718528 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7079597 C_bot  0.15 k_c 0.0\n",
      "2060 Train Loss 12.033564\n",
      "Loss  1.7079597 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0817575 C_bot  0.15 k_c 0.0\n",
      "2061 Train Loss 12.407091\n",
      "Loss  2.0817575 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6172254 C_bot  0.15 k_c 0.0\n",
      "2062 Train Loss 12.904533\n",
      "Loss  2.6172254 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1950119 C_bot  0.15 k_c 0.0\n",
      "2063 Train Loss 12.503935\n",
      "Loss  2.1950119 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7040766 C_bot  0.15 k_c 0.0\n",
      "2064 Train Loss 11.988853\n",
      "Loss  1.7040766 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9390744 C_bot  0.15 k_c 0.0\n",
      "2065 Train Loss 12.209349\n",
      "Loss  1.9390744 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2691908 C_bot  0.15 k_c 0.0\n",
      "2066 Train Loss 12.556679\n",
      "Loss  2.2691908 C_bot  0.15 k_c 0.0\n",
      "Loss  2.06151 C_bot  0.15 k_c 0.0\n",
      "2067 Train Loss 12.315664\n",
      "Loss  2.06151 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6949685 C_bot  0.15 k_c 0.0\n",
      "2068 Train Loss 11.955875\n",
      "Loss  1.6949685 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8055755 C_bot  0.15 k_c 0.0\n",
      "2069 Train Loss 12.063833\n",
      "Loss  1.8055755 C_bot  0.15 k_c 0.0\n",
      "Loss  2.072124 C_bot  0.15 k_c 0.0\n",
      "2070 Train Loss 12.304872\n",
      "Loss  2.072124 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9369565 C_bot  0.15 k_c 0.0\n",
      "2071 Train Loss 12.18263\n",
      "Loss  1.9369565 C_bot  0.15 k_c 0.0\n",
      "Loss  1.699958 C_bot  0.15 k_c 0.0\n",
      "2072 Train Loss 11.925445\n",
      "Loss  1.699958 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7390537 C_bot  0.15 k_c 0.0\n",
      "2073 Train Loss 11.955517\n",
      "Loss  1.7390537 C_bot  0.15 k_c 0.0\n",
      "Loss  1.903038 C_bot  0.15 k_c 0.0\n",
      "2074 Train Loss 12.125221\n",
      "Loss  1.903038 C_bot  0.15 k_c 0.0\n",
      "Loss  1.878262 C_bot  0.15 k_c 0.0\n",
      "2075 Train Loss 12.078019\n",
      "Loss  1.878262 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6967621 C_bot  0.15 k_c 0.0\n",
      "2076 Train Loss 11.900436\n",
      "Loss  1.6967621 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6846552 C_bot  0.15 k_c 0.0\n",
      "2077 Train Loss 11.881502\n",
      "Loss  1.6846552 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8093908 C_bot  0.15 k_c 0.0\n",
      "2078 Train Loss 11.991676\n",
      "Loss  1.8093908 C_bot  0.15 k_c 0.0\n",
      "Loss  1.804555 C_bot  0.15 k_c 0.0\n",
      "2079 Train Loss 11.992953\n",
      "Loss  1.804555 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7024329 C_bot  0.15 k_c 0.0\n",
      "2080 Train Loss 11.875124\n",
      "Loss  1.7024329 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6611878 C_bot  0.15 k_c 0.0\n",
      "2081 Train Loss 11.829961\n",
      "Loss  1.6611878 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7247826 C_bot  0.15 k_c 0.0\n",
      "2082 Train Loss 11.893165\n",
      "Loss  1.7247826 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7626256 C_bot  0.15 k_c 0.0\n",
      "2083 Train Loss 11.915536\n",
      "Loss  1.7626256 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6903011 C_bot  0.15 k_c 0.0\n",
      "2084 Train Loss 11.846486\n",
      "Loss  1.6903011 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6455084 C_bot  0.15 k_c 0.0\n",
      "2085 Train Loss 11.7925625\n",
      "Loss  1.6455084 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6791068 C_bot  0.15 k_c 0.0\n",
      "2086 Train Loss 11.817876\n",
      "Loss  1.6791068 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7052392 C_bot  0.15 k_c 0.0\n",
      "2087 Train Loss 11.846354\n",
      "Loss  1.7052392 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6840664 C_bot  0.15 k_c 0.0\n",
      "2088 Train Loss 11.811996\n",
      "Loss  1.6840664 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6352092 C_bot  0.15 k_c 0.0\n",
      "2089 Train Loss 11.762571\n",
      "Loss  1.6352092 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6374239 C_bot  0.15 k_c 0.0\n",
      "2090 Train Loss 11.76045\n",
      "Loss  1.6374239 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6681138 C_bot  0.15 k_c 0.0\n",
      "2091 Train Loss 11.781145\n",
      "Loss  1.6681138 C_bot  0.15 k_c 0.0\n",
      "Loss  1.654906 C_bot  0.15 k_c 0.0\n",
      "2092 Train Loss 11.769766\n",
      "Loss  1.654906 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6258931 C_bot  0.15 k_c 0.0\n",
      "2093 Train Loss 11.730948\n",
      "Loss  1.6258931 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6109096 C_bot  0.15 k_c 0.0\n",
      "2094 Train Loss 11.712271\n",
      "Loss  1.6109096 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6203411 C_bot  0.15 k_c 0.0\n",
      "2095 Train Loss 11.720008\n",
      "Loss  1.6203411 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6277978 C_bot  0.15 k_c 0.0\n",
      "2096 Train Loss 11.718061\n",
      "Loss  1.6277978 C_bot  0.15 k_c 0.0\n",
      "Loss  1.601445 C_bot  0.15 k_c 0.0\n",
      "2097 Train Loss 11.692083\n",
      "Loss  1.601445 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5818596 C_bot  0.15 k_c 0.0\n",
      "2098 Train Loss 11.666115\n",
      "Loss  1.5818596 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5795937 C_bot  0.15 k_c 0.0\n",
      "2099 Train Loss 11.658966\n",
      "Loss  1.5795937 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5778272 C_bot  0.15 k_c 0.0\n",
      "2100 Train Loss 11.65673\n",
      "Loss  1.5778272 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5683047 C_bot  0.15 k_c 0.0\n",
      "2101 Train Loss 11.639402\n",
      "Loss  1.5683047 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5427297 C_bot  0.15 k_c 0.0\n",
      "2102 Train Loss 11.613003\n",
      "Loss  1.5427297 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5277938 C_bot  0.15 k_c 0.0\n",
      "2103 Train Loss 11.594053\n",
      "Loss  1.5277938 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5229573 C_bot  0.15 k_c 0.0\n",
      "2104 Train Loss 11.584099\n",
      "Loss  1.5229573 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5088392 C_bot  0.15 k_c 0.0\n",
      "2105 Train Loss 11.569874\n",
      "Loss  1.5088392 C_bot  0.15 k_c 0.0\n",
      "Loss  1.49043 C_bot  0.15 k_c 0.0\n",
      "2106 Train Loss 11.545427\n",
      "Loss  1.49043 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4663777 C_bot  0.15 k_c 0.0\n",
      "2107 Train Loss 11.519966\n",
      "Loss  1.4663777 C_bot  0.15 k_c 0.0\n",
      "Loss  1.449876 C_bot  0.15 k_c 0.0\n",
      "2108 Train Loss 11.501032\n",
      "Loss  1.449876 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4377593 C_bot  0.15 k_c 0.0\n",
      "2109 Train Loss 11.484201\n",
      "Loss  1.4377593 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4164022 C_bot  0.15 k_c 0.0\n",
      "2110 Train Loss 11.4627695\n",
      "Loss  1.4164022 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3946675 C_bot  0.15 k_c 0.0\n",
      "2111 Train Loss 11.436539\n",
      "Loss  1.3946675 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3723772 C_bot  0.15 k_c 0.0\n",
      "2112 Train Loss 11.412566\n",
      "Loss  1.3723772 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3543419 C_bot  0.15 k_c 0.0\n",
      "2113 Train Loss 11.393019\n",
      "Loss  1.3543419 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3393155 C_bot  0.15 k_c 0.0\n",
      "2114 Train Loss 11.373998\n",
      "Loss  1.3393155 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3179898 C_bot  0.15 k_c 0.0\n",
      "2115 Train Loss 11.352451\n",
      "Loss  1.3179898 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2992146 C_bot  0.15 k_c 0.0\n",
      "2116 Train Loss 11.330193\n",
      "Loss  1.2992146 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2819129 C_bot  0.15 k_c 0.0\n",
      "2117 Train Loss 11.3109255\n",
      "Loss  1.2819129 C_bot  0.15 k_c 0.0\n",
      "Loss  1.267385 C_bot  0.15 k_c 0.0\n",
      "2118 Train Loss 11.295023\n",
      "Loss  1.267385 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2554806 C_bot  0.15 k_c 0.0\n",
      "2119 Train Loss 11.279431\n",
      "Loss  1.2554806 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2400851 C_bot  0.15 k_c 0.0\n",
      "2120 Train Loss 11.263169\n",
      "Loss  1.2400851 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2277975 C_bot  0.15 k_c 0.0\n",
      "2121 Train Loss 11.247607\n",
      "Loss  1.2277975 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2172136 C_bot  0.15 k_c 0.0\n",
      "2122 Train Loss 11.234541\n",
      "Loss  1.2172136 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2080235 C_bot  0.15 k_c 0.0\n",
      "2123 Train Loss 11.223507\n",
      "Loss  1.2080235 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2011161 C_bot  0.15 k_c 0.0\n",
      "2124 Train Loss 11.212725\n",
      "Loss  1.2011161 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1919103 C_bot  0.15 k_c 0.0\n",
      "2125 Train Loss 11.201762\n",
      "Loss  1.1919103 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1849433 C_bot  0.15 k_c 0.0\n",
      "2126 Train Loss 11.191259\n",
      "Loss  1.1849433 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1788379 C_bot  0.15 k_c 0.0\n",
      "2127 Train Loss 11.18211\n",
      "Loss  1.1788379 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1733342 C_bot  0.15 k_c 0.0\n",
      "2128 Train Loss 11.174103\n",
      "Loss  1.1733342 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1693755 C_bot  0.15 k_c 0.0\n",
      "2129 Train Loss 11.166063\n",
      "Loss  1.1693755 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1634275 C_bot  0.15 k_c 0.0\n",
      "2130 Train Loss 11.157688\n",
      "Loss  1.1634275 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1589649 C_bot  0.15 k_c 0.0\n",
      "2131 Train Loss 11.149458\n",
      "Loss  1.1589649 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1548258 C_bot  0.15 k_c 0.0\n",
      "2132 Train Loss 11.141971\n",
      "Loss  1.1548258 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1507423 C_bot  0.15 k_c 0.0\n",
      "2133 Train Loss 11.135\n",
      "Loss  1.1507423 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1475878 C_bot  0.15 k_c 0.0\n",
      "2134 Train Loss 11.127861\n",
      "Loss  1.1475878 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1429199 C_bot  0.15 k_c 0.0\n",
      "2135 Train Loss 11.120574\n",
      "Loss  1.1429199 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1392457 C_bot  0.15 k_c 0.0\n",
      "2136 Train Loss 11.113279\n",
      "Loss  1.1392457 C_bot  0.15 k_c 0.0\n",
      "Loss  1.135463 C_bot  0.15 k_c 0.0\n",
      "2137 Train Loss 11.106364\n",
      "Loss  1.135463 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1318189 C_bot  0.15 k_c 0.0\n",
      "2138 Train Loss 11.099922\n",
      "Loss  1.1318189 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1287687 C_bot  0.15 k_c 0.0\n",
      "2139 Train Loss 11.093348\n",
      "Loss  1.1287687 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1246399 C_bot  0.15 k_c 0.0\n",
      "2140 Train Loss 11.086779\n",
      "Loss  1.1246399 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1212906 C_bot  0.15 k_c 0.0\n",
      "2141 Train Loss 11.08021\n",
      "Loss  1.1212906 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1176747 C_bot  0.15 k_c 0.0\n",
      "2142 Train Loss 11.0739155\n",
      "Loss  1.1176747 C_bot  0.15 k_c 0.0\n",
      "Loss  1.114168 C_bot  0.15 k_c 0.0\n",
      "2143 Train Loss 11.067887\n",
      "Loss  1.114168 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1112279 C_bot  0.15 k_c 0.0\n",
      "2144 Train Loss 11.061972\n",
      "Loss  1.1112279 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1075056 C_bot  0.15 k_c 0.0\n",
      "2145 Train Loss 11.05612\n",
      "Loss  1.1075056 C_bot  0.15 k_c 0.0\n",
      "Loss  1.104463 C_bot  0.15 k_c 0.0\n",
      "2146 Train Loss 11.050274\n",
      "Loss  1.104463 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1010329 C_bot  0.15 k_c 0.0\n",
      "2147 Train Loss 11.044584\n",
      "Loss  1.1010329 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0979068 C_bot  0.15 k_c 0.0\n",
      "2148 Train Loss 11.039164\n",
      "Loss  1.0979068 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0950006 C_bot  0.15 k_c 0.0\n",
      "2149 Train Loss 11.033726\n",
      "Loss  1.0950006 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0916831 C_bot  0.15 k_c 0.0\n",
      "2150 Train Loss 11.028481\n",
      "Loss  1.0916831 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0889233 C_bot  0.15 k_c 0.0\n",
      "2151 Train Loss 11.023211\n",
      "Loss  1.0889233 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0857258 C_bot  0.15 k_c 0.0\n",
      "2152 Train Loss 11.018038\n",
      "Loss  1.0857258 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0827506 C_bot  0.15 k_c 0.0\n",
      "2153 Train Loss 11.012878\n",
      "Loss  1.0827506 C_bot  0.15 k_c 0.0\n",
      "Loss  1.080068 C_bot  0.15 k_c 0.0\n",
      "2154 Train Loss 11.007982\n",
      "Loss  1.080068 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0770702 C_bot  0.15 k_c 0.0\n",
      "2155 Train Loss 11.003118\n",
      "Loss  1.0770702 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0744784 C_bot  0.15 k_c 0.0\n",
      "2156 Train Loss 10.998226\n",
      "Loss  1.0744784 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0715085 C_bot  0.15 k_c 0.0\n",
      "2157 Train Loss 10.993444\n",
      "Loss  1.0715085 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0687715 C_bot  0.15 k_c 0.0\n",
      "2158 Train Loss 10.988594\n",
      "Loss  1.0687715 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0661536 C_bot  0.15 k_c 0.0\n",
      "2159 Train Loss 10.984017\n",
      "Loss  1.0661536 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0633059 C_bot  0.15 k_c 0.0\n",
      "2160 Train Loss 10.979312\n",
      "Loss  1.0633059 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0608633 C_bot  0.15 k_c 0.0\n",
      "2161 Train Loss 10.974792\n",
      "Loss  1.0608633 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0581136 C_bot  0.15 k_c 0.0\n",
      "2162 Train Loss 10.970308\n",
      "Loss  1.0581136 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0556002 C_bot  0.15 k_c 0.0\n",
      "2163 Train Loss 10.965775\n",
      "Loss  1.0556002 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0530654 C_bot  0.15 k_c 0.0\n",
      "2164 Train Loss 10.961449\n",
      "Loss  1.0530654 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0505463 C_bot  0.15 k_c 0.0\n",
      "2165 Train Loss 10.957094\n",
      "Loss  1.0505463 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0481788 C_bot  0.15 k_c 0.0\n",
      "2166 Train Loss 10.95283\n",
      "Loss  1.0481788 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0456616 C_bot  0.15 k_c 0.0\n",
      "2167 Train Loss 10.948627\n",
      "Loss  1.0456616 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0434079 C_bot  0.15 k_c 0.0\n",
      "2168 Train Loss 10.944456\n",
      "Loss  1.0434079 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0409759 C_bot  0.15 k_c 0.0\n",
      "2169 Train Loss 10.940366\n",
      "Loss  1.0409759 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0387318 C_bot  0.15 k_c 0.0\n",
      "2170 Train Loss 10.936302\n",
      "Loss  1.0387318 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0364021 C_bot  0.15 k_c 0.0\n",
      "2171 Train Loss 10.932247\n",
      "Loss  1.0364021 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0341178 C_bot  0.15 k_c 0.0\n",
      "2172 Train Loss 10.928286\n",
      "Loss  1.0341178 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0319946 C_bot  0.15 k_c 0.0\n",
      "2173 Train Loss 10.924379\n",
      "Loss  1.0319946 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0296959 C_bot  0.15 k_c 0.0\n",
      "2174 Train Loss 10.920496\n",
      "Loss  1.0296959 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0276523 C_bot  0.15 k_c 0.0\n",
      "2175 Train Loss 10.916691\n",
      "Loss  1.0276523 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0254002 C_bot  0.15 k_c 0.0\n",
      "2176 Train Loss 10.912849\n",
      "Loss  1.0254002 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0233436 C_bot  0.15 k_c 0.0\n",
      "2177 Train Loss 10.909129\n",
      "Loss  1.0233436 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0212768 C_bot  0.15 k_c 0.0\n",
      "2178 Train Loss 10.90543\n",
      "Loss  1.0212768 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0192057 C_bot  0.15 k_c 0.0\n",
      "2179 Train Loss 10.901794\n",
      "Loss  1.0192057 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0172503 C_bot  0.15 k_c 0.0\n",
      "2180 Train Loss 10.898183\n",
      "Loss  1.0172503 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0152297 C_bot  0.15 k_c 0.0\n",
      "2181 Train Loss 10.894658\n",
      "Loss  1.0152297 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0132581 C_bot  0.15 k_c 0.0\n",
      "2182 Train Loss 10.891066\n",
      "Loss  1.0132581 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0112883 C_bot  0.15 k_c 0.0\n",
      "2183 Train Loss 10.887582\n",
      "Loss  1.0112883 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0094036 C_bot  0.15 k_c 0.0\n",
      "2184 Train Loss 10.884159\n",
      "Loss  1.0094036 C_bot  0.15 k_c 0.0\n",
      "Loss  1.007504 C_bot  0.15 k_c 0.0\n",
      "2185 Train Loss 10.88072\n",
      "Loss  1.007504 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0055708 C_bot  0.15 k_c 0.0\n",
      "2186 Train Loss 10.877318\n",
      "Loss  1.0055708 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0037447 C_bot  0.15 k_c 0.0\n",
      "2187 Train Loss 10.87395\n",
      "Loss  1.0037447 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0018914 C_bot  0.15 k_c 0.0\n",
      "2188 Train Loss 10.870663\n",
      "Loss  1.0018914 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0000544 C_bot  0.15 k_c 0.0\n",
      "2189 Train Loss 10.867324\n",
      "Loss  1.0000544 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99826294 C_bot  0.15 k_c 0.0\n",
      "2190 Train Loss 10.864096\n",
      "Loss  0.99826294 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99647295 C_bot  0.15 k_c 0.0\n",
      "2191 Train Loss 10.860861\n",
      "Loss  0.99647295 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99477375 C_bot  0.15 k_c 0.0\n",
      "2192 Train Loss 10.857718\n",
      "Loss  0.99477375 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99292463 C_bot  0.15 k_c 0.0\n",
      "2193 Train Loss 10.854474\n",
      "Loss  0.99292463 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9913366 C_bot  0.15 k_c 0.0\n",
      "2194 Train Loss 10.851446\n",
      "Loss  0.9913366 C_bot  0.15 k_c 0.0\n",
      "Loss  0.98958445 C_bot  0.15 k_c 0.0\n",
      "2195 Train Loss 10.848331\n",
      "Loss  0.98958445 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9879191 C_bot  0.15 k_c 0.0\n",
      "2196 Train Loss 10.845249\n",
      "Loss  0.9879191 C_bot  0.15 k_c 0.0\n",
      "Loss  0.98622286 C_bot  0.15 k_c 0.0\n",
      "2197 Train Loss 10.842206\n",
      "Loss  0.98622286 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9846306 C_bot  0.15 k_c 0.0\n",
      "2198 Train Loss 10.83923\n",
      "Loss  0.9846306 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9830456 C_bot  0.15 k_c 0.0\n",
      "2199 Train Loss 10.836298\n",
      "Loss  0.9830456 C_bot  0.15 k_c 0.0\n",
      "Loss  0.98130643 C_bot  0.15 k_c 0.0\n",
      "2200 Train Loss 10.833223\n",
      "Loss  0.98130643 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9797949 C_bot  0.15 k_c 0.0\n",
      "2201 Train Loss 10.830354\n",
      "Loss  0.9797949 C_bot  0.15 k_c 0.0\n",
      "Loss  0.978208 C_bot  0.15 k_c 0.0\n",
      "2202 Train Loss 10.827469\n",
      "Loss  0.978208 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97666615 C_bot  0.15 k_c 0.0\n",
      "2203 Train Loss 10.824577\n",
      "Loss  0.97666615 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97513455 C_bot  0.15 k_c 0.0\n",
      "2204 Train Loss 10.821767\n",
      "Loss  0.97513455 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9736786 C_bot  0.15 k_c 0.0\n",
      "2205 Train Loss 10.818984\n",
      "Loss  0.9736786 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9721101 C_bot  0.15 k_c 0.0\n",
      "2206 Train Loss 10.816136\n",
      "Loss  0.9721101 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97063625 C_bot  0.15 k_c 0.0\n",
      "2207 Train Loss 10.813368\n",
      "Loss  0.97063625 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9691789 C_bot  0.15 k_c 0.0\n",
      "2208 Train Loss 10.810628\n",
      "Loss  0.9691789 C_bot  0.15 k_c 0.0\n",
      "Loss  0.967697 C_bot  0.15 k_c 0.0\n",
      "2209 Train Loss 10.807882\n",
      "Loss  0.967697 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9662489 C_bot  0.15 k_c 0.0\n",
      "2210 Train Loss 10.805149\n",
      "Loss  0.9662489 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9648674 C_bot  0.15 k_c 0.0\n",
      "2211 Train Loss 10.80253\n",
      "Loss  0.9648674 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9635277 C_bot  0.15 k_c 0.0\n",
      "2212 Train Loss 10.799915\n",
      "Loss  0.9635277 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9620229 C_bot  0.15 k_c 0.0\n",
      "2213 Train Loss 10.797183\n",
      "Loss  0.9620229 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96066934 C_bot  0.15 k_c 0.0\n",
      "2214 Train Loss 10.794573\n",
      "Loss  0.96066934 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9593671 C_bot  0.15 k_c 0.0\n",
      "2215 Train Loss 10.7920475\n",
      "Loss  0.9593671 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95799977 C_bot  0.15 k_c 0.0\n",
      "2216 Train Loss 10.789442\n",
      "Loss  0.95799977 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9566692 C_bot  0.15 k_c 0.0\n",
      "2217 Train Loss 10.7869\n",
      "Loss  0.9566692 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9553427 C_bot  0.15 k_c 0.0\n",
      "2218 Train Loss 10.78435\n",
      "Loss  0.9553427 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95408016 C_bot  0.15 k_c 0.0\n",
      "2219 Train Loss 10.781883\n",
      "Loss  0.95408016 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9527238 C_bot  0.15 k_c 0.0\n",
      "2220 Train Loss 10.779317\n",
      "Loss  0.9527238 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9515574 C_bot  0.15 k_c 0.0\n",
      "2221 Train Loss 10.776962\n",
      "Loss  0.9515574 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95029676 C_bot  0.15 k_c 0.0\n",
      "2222 Train Loss 10.774498\n",
      "Loss  0.95029676 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94903755 C_bot  0.15 k_c 0.0\n",
      "2223 Train Loss 10.772065\n",
      "Loss  0.94903755 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94785756 C_bot  0.15 k_c 0.0\n",
      "2224 Train Loss 10.769688\n",
      "Loss  0.94785756 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94660926 C_bot  0.15 k_c 0.0\n",
      "2225 Train Loss 10.767286\n",
      "Loss  0.94660926 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9454201 C_bot  0.15 k_c 0.0\n",
      "2226 Train Loss 10.764906\n",
      "Loss  0.9454201 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9442028 C_bot  0.15 k_c 0.0\n",
      "2227 Train Loss 10.762545\n",
      "Loss  0.9442028 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9429705 C_bot  0.15 k_c 0.0\n",
      "2228 Train Loss 10.7601385\n",
      "Loss  0.9429705 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94186705 C_bot  0.15 k_c 0.0\n",
      "2229 Train Loss 10.757897\n",
      "Loss  0.94186705 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94073564 C_bot  0.15 k_c 0.0\n",
      "2230 Train Loss 10.755608\n",
      "Loss  0.94073564 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93956876 C_bot  0.15 k_c 0.0\n",
      "2231 Train Loss 10.753309\n",
      "Loss  0.93956876 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93844414 C_bot  0.15 k_c 0.0\n",
      "2232 Train Loss 10.7510395\n",
      "Loss  0.93844414 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9373118 C_bot  0.15 k_c 0.0\n",
      "2233 Train Loss 10.748781\n",
      "Loss  0.9373118 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9361834 C_bot  0.15 k_c 0.0\n",
      "2234 Train Loss 10.746527\n",
      "Loss  0.9361834 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9350973 C_bot  0.15 k_c 0.0\n",
      "2235 Train Loss 10.744319\n",
      "Loss  0.9350973 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9340014 C_bot  0.15 k_c 0.0\n",
      "2236 Train Loss 10.742115\n",
      "Loss  0.9340014 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9329211 C_bot  0.15 k_c 0.0\n",
      "2237 Train Loss 10.739916\n",
      "Loss  0.9329211 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9318176 C_bot  0.15 k_c 0.0\n",
      "2238 Train Loss 10.7377205\n",
      "Loss  0.9318176 C_bot  0.15 k_c 0.0\n",
      "Loss  0.930805 C_bot  0.15 k_c 0.0\n",
      "2239 Train Loss 10.735592\n",
      "Loss  0.930805 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9297277 C_bot  0.15 k_c 0.0\n",
      "2240 Train Loss 10.7334385\n",
      "Loss  0.9297277 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9287172 C_bot  0.15 k_c 0.0\n",
      "2241 Train Loss 10.731319\n",
      "Loss  0.9287172 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92762136 C_bot  0.15 k_c 0.0\n",
      "2242 Train Loss 10.72916\n",
      "Loss  0.92762136 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9267144 C_bot  0.15 k_c 0.0\n",
      "2243 Train Loss 10.72715\n",
      "Loss  0.9267144 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92558646 C_bot  0.15 k_c 0.0\n",
      "2244 Train Loss 10.724974\n",
      "Loss  0.92558646 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9246612 C_bot  0.15 k_c 0.0\n",
      "2245 Train Loss 10.722948\n",
      "Loss  0.9246612 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9235851 C_bot  0.15 k_c 0.0\n",
      "2246 Train Loss 10.720838\n",
      "Loss  0.9235851 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92266196 C_bot  0.15 k_c 0.0\n",
      "2247 Train Loss 10.718815\n",
      "Loss  0.92266196 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9215324 C_bot  0.15 k_c 0.0\n",
      "2248 Train Loss 10.716673\n",
      "Loss  0.9215324 C_bot  0.15 k_c 0.0\n",
      "Loss  0.920723 C_bot  0.15 k_c 0.0\n",
      "2249 Train Loss 10.714764\n",
      "Loss  0.920723 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91970176 C_bot  0.15 k_c 0.0\n",
      "2250 Train Loss 10.712744\n",
      "Loss  0.91970176 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9187851 C_bot  0.15 k_c 0.0\n",
      "2251 Train Loss 10.710728\n",
      "Loss  0.9187851 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9177665 C_bot  0.15 k_c 0.0\n",
      "2252 Train Loss 10.708733\n",
      "Loss  0.9177665 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9169361 C_bot  0.15 k_c 0.0\n",
      "2253 Train Loss 10.706796\n",
      "Loss  0.9169361 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91593003 C_bot  0.15 k_c 0.0\n",
      "2254 Train Loss 10.704838\n",
      "Loss  0.91593003 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9150041 C_bot  0.15 k_c 0.0\n",
      "2255 Train Loss 10.702799\n",
      "Loss  0.9150041 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9140376 C_bot  0.15 k_c 0.0\n",
      "2256 Train Loss 10.700904\n",
      "Loss  0.9140376 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91324687 C_bot  0.15 k_c 0.0\n",
      "2257 Train Loss 10.69899\n",
      "Loss  0.91324687 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91221863 C_bot  0.15 k_c 0.0\n",
      "2258 Train Loss 10.697062\n",
      "Loss  0.91221863 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91143453 C_bot  0.15 k_c 0.0\n",
      "2259 Train Loss 10.695139\n",
      "Loss  0.91143453 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91040903 C_bot  0.15 k_c 0.0\n",
      "2260 Train Loss 10.693254\n",
      "Loss  0.91040903 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90971184 C_bot  0.15 k_c 0.0\n",
      "2261 Train Loss 10.691383\n",
      "Loss  0.90971184 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9086466 C_bot  0.15 k_c 0.0\n",
      "2262 Train Loss 10.689516\n",
      "Loss  0.9086466 C_bot  0.15 k_c 0.0\n",
      "Loss  0.907999 C_bot  0.15 k_c 0.0\n",
      "2263 Train Loss 10.687643\n",
      "Loss  0.907999 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90691864 C_bot  0.15 k_c 0.0\n",
      "2264 Train Loss 10.685844\n",
      "Loss  0.90691864 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90644795 C_bot  0.15 k_c 0.0\n",
      "2265 Train Loss 10.68406\n",
      "Loss  0.90644795 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9053227 C_bot  0.15 k_c 0.0\n",
      "2266 Train Loss 10.682339\n",
      "Loss  0.9053227 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90503687 C_bot  0.15 k_c 0.0\n",
      "2267 Train Loss 10.680605\n",
      "Loss  0.90503687 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90383834 C_bot  0.15 k_c 0.0\n",
      "2268 Train Loss 10.678997\n",
      "Loss  0.90383834 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9040371 C_bot  0.15 k_c 0.0\n",
      "2269 Train Loss 10.677528\n",
      "Loss  0.9040371 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90282035 C_bot  0.15 k_c 0.0\n",
      "2270 Train Loss 10.676194\n",
      "Loss  0.90282035 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9037821 C_bot  0.15 k_c 0.0\n",
      "2271 Train Loss 10.675139\n",
      "Loss  0.9037821 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9029079 C_bot  0.15 k_c 0.0\n",
      "2272 Train Loss 10.674612\n",
      "Loss  0.9029079 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9055961 C_bot  0.15 k_c 0.0\n",
      "2273 Train Loss 10.674706\n",
      "Loss  0.9055961 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90607154 C_bot  0.15 k_c 0.0\n",
      "2274 Train Loss 10.6762905\n",
      "Loss  0.90607154 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9129367 C_bot  0.15 k_c 0.0\n",
      "2275 Train Loss 10.679601\n",
      "Loss  0.9129367 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9178676 C_bot  0.15 k_c 0.0\n",
      "2276 Train Loss 10.686922\n",
      "Loss  0.9178676 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9357626 C_bot  0.15 k_c 0.0\n",
      "2277 Train Loss 10.699633\n",
      "Loss  0.9357626 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9548735 C_bot  0.15 k_c 0.0\n",
      "2278 Train Loss 10.723328\n",
      "Loss  0.9548735 C_bot  0.15 k_c 0.0\n",
      "Loss  1.003672 C_bot  0.15 k_c 0.0\n",
      "2279 Train Loss 10.764141\n",
      "Loss  1.003672 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0687594 C_bot  0.15 k_c 0.0\n",
      "2280 Train Loss 10.837662\n",
      "Loss  1.0687594 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2091366 C_bot  0.15 k_c 0.0\n",
      "2281 Train Loss 10.965186\n",
      "Loss  1.2091366 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4240755 C_bot  0.15 k_c 0.0\n",
      "2282 Train Loss 11.19548\n",
      "Loss  1.4240755 C_bot  0.15 k_c 0.0\n",
      "Loss  1.850001 C_bot  0.15 k_c 0.0\n",
      "2283 Train Loss 11.60001\n",
      "Loss  1.850001 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5619924 C_bot  0.15 k_c 0.0\n",
      "2284 Train Loss 12.340202\n",
      "Loss  2.5619924 C_bot  0.15 k_c 0.0\n",
      "Loss  3.913893 C_bot  0.15 k_c 0.0\n",
      "2285 Train Loss 13.655714\n",
      "Loss  3.913893 C_bot  0.15 k_c 0.0\n",
      "Loss  6.3154273 C_bot  0.15 k_c 0.0\n",
      "2286 Train Loss 16.110298\n",
      "Loss  6.3154273 C_bot  0.15 k_c 0.0\n",
      "Loss  10.748964 C_bot  0.15 k_c 0.0\n",
      "2287 Train Loss 20.481417\n",
      "Loss  10.748964 C_bot  0.15 k_c 0.0\n",
      "Loss  18.978825 C_bot  0.15 k_c 0.0\n",
      "2288 Train Loss 28.815504\n",
      "Loss  18.978825 C_bot  0.15 k_c 0.0\n",
      "Loss  33.6455 C_bot  0.15 k_c 0.0\n",
      "2289 Train Loss 43.37542\n",
      "Loss  33.6455 C_bot  0.15 k_c 0.0\n",
      "Loss  61.60458 C_bot  0.15 k_c 0.0\n",
      "2290 Train Loss 71.553955\n",
      "Loss  61.60458 C_bot  0.15 k_c 0.0\n",
      "Loss  107.34694 C_bot  0.15 k_c 0.0\n",
      "2291 Train Loss 117.11074\n",
      "Loss  107.34694 C_bot  0.15 k_c 0.0\n",
      "Loss  192.49403 C_bot  0.15 k_c 0.0\n",
      "2292 Train Loss 202.75752\n",
      "Loss  192.49403 C_bot  0.15 k_c 0.0\n",
      "Loss  299.45886 C_bot  0.15 k_c 0.0\n",
      "2293 Train Loss 309.34\n",
      "Loss  299.45886 C_bot  0.15 k_c 0.0\n",
      "Loss  458.21582 C_bot  0.15 k_c 0.0\n",
      "2294 Train Loss 469.18475\n",
      "Loss  458.21582 C_bot  0.15 k_c 0.0\n",
      "Loss  511.77368 C_bot  0.15 k_c 0.0\n",
      "2295 Train Loss 521.74347\n",
      "Loss  511.77368 C_bot  0.15 k_c 0.0\n",
      "Loss  465.10834 C_bot  0.15 k_c 0.0\n",
      "2296 Train Loss 476.5888\n",
      "Loss  465.10834 C_bot  0.15 k_c 0.0\n",
      "Loss  228.62158 C_bot  0.15 k_c 0.0\n",
      "2297 Train Loss 238.63786\n",
      "Loss  228.62158 C_bot  0.15 k_c 0.0\n",
      "Loss  30.806515 C_bot  0.15 k_c 0.0\n",
      "2298 Train Loss 41.609547\n",
      "Loss  30.806515 C_bot  0.15 k_c 0.0\n",
      "Loss  25.155731 C_bot  0.15 k_c 0.0\n",
      "2299 Train Loss 36.11125\n",
      "Loss  25.155731 C_bot  0.15 k_c 0.0\n",
      "Loss  161.07227 C_bot  0.15 k_c 0.0\n",
      "2300 Train Loss 171.42969\n",
      "Loss  161.07227 C_bot  0.15 k_c 0.0\n",
      "Loss  256.1002 C_bot  0.15 k_c 0.0\n",
      "2301 Train Loss 268.11035\n",
      "Loss  256.1002 C_bot  0.15 k_c 0.0\n",
      "Loss  177.48502 C_bot  0.15 k_c 0.0\n",
      "2302 Train Loss 187.91599\n",
      "Loss  177.48502 C_bot  0.15 k_c 0.0\n",
      "Loss  45.625324 C_bot  0.15 k_c 0.0\n",
      "2303 Train Loss 56.879948\n",
      "Loss  45.625324 C_bot  0.15 k_c 0.0\n",
      "Loss  5.9846225 C_bot  0.15 k_c 0.0\n",
      "2304 Train Loss 16.960678\n",
      "Loss  5.9846225 C_bot  0.15 k_c 0.0\n",
      "Loss  79.16909 C_bot  0.15 k_c 0.0\n",
      "2305 Train Loss 89.82174\n",
      "Loss  79.16909 C_bot  0.15 k_c 0.0\n",
      "Loss  140.27904 C_bot  0.15 k_c 0.0\n",
      "2306 Train Loss 151.87193\n",
      "Loss  140.27904 C_bot  0.15 k_c 0.0\n",
      "Loss  92.178154 C_bot  0.15 k_c 0.0\n",
      "2307 Train Loss 102.904205\n",
      "Loss  92.178154 C_bot  0.15 k_c 0.0\n",
      "Loss  16.218515 C_bot  0.15 k_c 0.0\n",
      "2308 Train Loss 27.319109\n",
      "Loss  16.218515 C_bot  0.15 k_c 0.0\n",
      "Loss  11.16147 C_bot  0.15 k_c 0.0\n",
      "2309 Train Loss 22.209137\n",
      "Loss  11.16147 C_bot  0.15 k_c 0.0\n",
      "Loss  62.363777 C_bot  0.15 k_c 0.0\n",
      "2310 Train Loss 73.109566\n",
      "Loss  62.363777 C_bot  0.15 k_c 0.0\n",
      "Loss  78.68251 C_bot  0.15 k_c 0.0\n",
      "2311 Train Loss 89.93109\n",
      "Loss  78.68251 C_bot  0.15 k_c 0.0\n",
      "Loss  33.01752 C_bot  0.15 k_c 0.0\n",
      "2312 Train Loss 43.73889\n",
      "Loss  33.01752 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0999494 C_bot  0.15 k_c 0.0\n",
      "2313 Train Loss 12.902425\n",
      "Loss  2.0999494 C_bot  0.15 k_c 0.0\n",
      "Loss  24.074596 C_bot  0.15 k_c 0.0\n",
      "2314 Train Loss 34.97749\n",
      "Loss  24.074596 C_bot  0.15 k_c 0.0\n",
      "Loss  49.332615 C_bot  0.15 k_c 0.0\n",
      "2315 Train Loss 59.90826\n",
      "Loss  49.332615 C_bot  0.15 k_c 0.0\n",
      "Loss  34.3801 C_bot  0.15 k_c 0.0\n",
      "2316 Train Loss 45.228737\n",
      "Loss  34.3801 C_bot  0.15 k_c 0.0\n",
      "Loss  5.558834 C_bot  0.15 k_c 0.0\n",
      "2317 Train Loss 16.13536\n",
      "Loss  5.558834 C_bot  0.15 k_c 0.0\n",
      "Loss  8.183483 C_bot  0.15 k_c 0.0\n",
      "2318 Train Loss 18.732546\n",
      "Loss  8.183483 C_bot  0.15 k_c 0.0\n",
      "Loss  28.781698 C_bot  0.15 k_c 0.0\n",
      "2319 Train Loss 39.56759\n",
      "Loss  28.781698 C_bot  0.15 k_c 0.0\n",
      "Loss  27.645155 C_bot  0.15 k_c 0.0\n",
      "2320 Train Loss 38.12072\n",
      "Loss  27.645155 C_bot  0.15 k_c 0.0\n",
      "Loss  8.255785 C_bot  0.15 k_c 0.0\n",
      "2321 Train Loss 18.894634\n",
      "Loss  8.255785 C_bot  0.15 k_c 0.0\n",
      "Loss  2.664744 C_bot  0.15 k_c 0.0\n",
      "2322 Train Loss 13.216236\n",
      "Loss  2.664744 C_bot  0.15 k_c 0.0\n",
      "Loss  15.123726 C_bot  0.15 k_c 0.0\n",
      "2323 Train Loss 25.53384\n",
      "Loss  15.123726 C_bot  0.15 k_c 0.0\n",
      "Loss  20.294706 C_bot  0.15 k_c 0.0\n",
      "2324 Train Loss 30.870087\n",
      "Loss  20.294706 C_bot  0.15 k_c 0.0\n",
      "Loss  9.390578 C_bot  0.15 k_c 0.0\n",
      "2325 Train Loss 19.743036\n",
      "Loss  9.390578 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4718816 C_bot  0.15 k_c 0.0\n",
      "2326 Train Loss 11.846218\n",
      "Loss  1.4718816 C_bot  0.15 k_c 0.0\n",
      "Loss  7.2334056 C_bot  0.15 k_c 0.0\n",
      "2327 Train Loss 17.637453\n",
      "Loss  7.2334056 C_bot  0.15 k_c 0.0\n",
      "Loss  13.527816 C_bot  0.15 k_c 0.0\n",
      "2328 Train Loss 23.807848\n",
      "Loss  13.527816 C_bot  0.15 k_c 0.0\n",
      "Loss  9.03684 C_bot  0.15 k_c 0.0\n",
      "2329 Train Loss 19.412506\n",
      "Loss  9.03684 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9680301 C_bot  0.15 k_c 0.0\n",
      "2330 Train Loss 12.255236\n",
      "Loss  1.9680301 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1535878 C_bot  0.15 k_c 0.0\n",
      "2331 Train Loss 13.418104\n",
      "Loss  3.1535878 C_bot  0.15 k_c 0.0\n",
      "Loss  8.314387 C_bot  0.15 k_c 0.0\n",
      "2332 Train Loss 18.643892\n",
      "Loss  8.314387 C_bot  0.15 k_c 0.0\n",
      "Loss  7.7940288 C_bot  0.15 k_c 0.0\n",
      "2333 Train Loss 18.01365\n",
      "Loss  7.7940288 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7356055 C_bot  0.15 k_c 0.0\n",
      "2334 Train Loss 13.00769\n",
      "Loss  2.7356055 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3667188 C_bot  0.15 k_c 0.0\n",
      "2335 Train Loss 11.612951\n",
      "Loss  1.3667188 C_bot  0.15 k_c 0.0\n",
      "Loss  4.590666 C_bot  0.15 k_c 0.0\n",
      "2336 Train Loss 14.786545\n",
      "Loss  4.590666 C_bot  0.15 k_c 0.0\n",
      "Loss  5.989819 C_bot  0.15 k_c 0.0\n",
      "2337 Train Loss 16.263077\n",
      "Loss  5.989819 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3928902 C_bot  0.15 k_c 0.0\n",
      "2338 Train Loss 13.579079\n",
      "Loss  3.3928902 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1015546 C_bot  0.15 k_c 0.0\n",
      "2339 Train Loss 11.3117695\n",
      "Loss  1.1015546 C_bot  0.15 k_c 0.0\n",
      "Loss  2.264156 C_bot  0.15 k_c 0.0\n",
      "2340 Train Loss 12.485331\n",
      "Loss  2.264156 C_bot  0.15 k_c 0.0\n",
      "Loss  4.160945 C_bot  0.15 k_c 0.0\n",
      "2341 Train Loss 14.315039\n",
      "Loss  4.160945 C_bot  0.15 k_c 0.0\n",
      "Loss  3.416879 C_bot  0.15 k_c 0.0\n",
      "2342 Train Loss 13.622801\n",
      "Loss  3.416879 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4940425 C_bot  0.15 k_c 0.0\n",
      "2343 Train Loss 11.642038\n",
      "Loss  1.4940425 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2356092 C_bot  0.15 k_c 0.0\n",
      "2344 Train Loss 11.3764515\n",
      "Loss  1.2356092 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5128307 C_bot  0.15 k_c 0.0\n",
      "2345 Train Loss 12.674675\n",
      "Loss  2.5128307 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9877074 C_bot  0.15 k_c 0.0\n",
      "2346 Train Loss 13.095312\n",
      "Loss  2.9877074 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8808995 C_bot  0.15 k_c 0.0\n",
      "2347 Train Loss 12.017988\n",
      "Loss  1.8808995 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0279359 C_bot  0.15 k_c 0.0\n",
      "2348 Train Loss 11.137192\n",
      "Loss  1.0279359 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4736707 C_bot  0.15 k_c 0.0\n",
      "2349 Train Loss 11.565295\n",
      "Loss  1.4736707 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1863985 C_bot  0.15 k_c 0.0\n",
      "2350 Train Loss 12.299348\n",
      "Loss  2.1863985 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0172477 C_bot  0.15 k_c 0.0\n",
      "2351 Train Loss 12.086335\n",
      "Loss  2.0172477 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2231711 C_bot  0.15 k_c 0.0\n",
      "2352 Train Loss 11.308174\n",
      "Loss  1.2231711 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0046387 C_bot  0.15 k_c 0.0\n",
      "2353 Train Loss 11.0767975\n",
      "Loss  1.0046387 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4734598 C_bot  0.15 k_c 0.0\n",
      "2354 Train Loss 11.524986\n",
      "Loss  1.4734598 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7305313 C_bot  0.15 k_c 0.0\n",
      "2355 Train Loss 11.805389\n",
      "Loss  1.7305313 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4275717 C_bot  0.15 k_c 0.0\n",
      "2356 Train Loss 11.468892\n",
      "Loss  1.4275717 C_bot  0.15 k_c 0.0\n",
      "Loss  0.98638445 C_bot  0.15 k_c 0.0\n",
      "2357 Train Loss 11.038197\n",
      "Loss  0.98638445 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0166671 C_bot  0.15 k_c 0.0\n",
      "2358 Train Loss 11.064373\n",
      "Loss  1.0166671 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3380162 C_bot  0.15 k_c 0.0\n",
      "2359 Train Loss 11.363552\n",
      "Loss  1.3380162 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3742505 C_bot  0.15 k_c 0.0\n",
      "2360 Train Loss 11.417034\n",
      "Loss  1.3742505 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1259875 C_bot  0.15 k_c 0.0\n",
      "2361 Train Loss 11.142143\n",
      "Loss  1.1259875 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91265327 C_bot  0.15 k_c 0.0\n",
      "2362 Train Loss 10.931356\n",
      "Loss  0.91265327 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99531513 C_bot  0.15 k_c 0.0\n",
      "2363 Train Loss 11.012401\n",
      "Loss  0.99531513 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1801807 C_bot  0.15 k_c 0.0\n",
      "2364 Train Loss 11.178074\n",
      "Loss  1.1801807 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1444836 C_bot  0.15 k_c 0.0\n",
      "2365 Train Loss 11.154154\n",
      "Loss  1.1444836 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9795659 C_bot  0.15 k_c 0.0\n",
      "2366 Train Loss 10.970927\n",
      "Loss  0.9795659 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8794749 C_bot  0.15 k_c 0.0\n",
      "2367 Train Loss 10.870529\n",
      "Loss  0.8794749 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94716984 C_bot  0.15 k_c 0.0\n",
      "2368 Train Loss 10.938013\n",
      "Loss  0.94716984 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0487968 C_bot  0.15 k_c 0.0\n",
      "2369 Train Loss 11.023915\n",
      "Loss  1.0487968 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0042365 C_bot  0.15 k_c 0.0\n",
      "2370 Train Loss 10.987474\n",
      "Loss  1.0042365 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9025859 C_bot  0.15 k_c 0.0\n",
      "2371 Train Loss 10.871653\n",
      "Loss  0.9025859 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8499734 C_bot  0.15 k_c 0.0\n",
      "2372 Train Loss 10.817697\n",
      "Loss  0.8499734 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89233416 C_bot  0.15 k_c 0.0\n",
      "2373 Train Loss 10.860237\n",
      "Loss  0.89233416 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9505984 C_bot  0.15 k_c 0.0\n",
      "2374 Train Loss 10.905611\n",
      "Loss  0.9505984 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9164645 C_bot  0.15 k_c 0.0\n",
      "2375 Train Loss 10.877846\n",
      "Loss  0.9164645 C_bot  0.15 k_c 0.0\n",
      "Loss  0.85574424 C_bot  0.15 k_c 0.0\n",
      "2376 Train Loss 10.805731\n",
      "Loss  0.85574424 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8227107 C_bot  0.15 k_c 0.0\n",
      "2377 Train Loss 10.771149\n",
      "Loss  0.8227107 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8452295 C_bot  0.15 k_c 0.0\n",
      "2378 Train Loss 10.792843\n",
      "Loss  0.8452295 C_bot  0.15 k_c 0.0\n",
      "Loss  0.88091695 C_bot  0.15 k_c 0.0\n",
      "2379 Train Loss 10.817558\n",
      "Loss  0.88091695 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8603416 C_bot  0.15 k_c 0.0\n",
      "2380 Train Loss 10.800648\n",
      "Loss  0.8603416 C_bot  0.15 k_c 0.0\n",
      "Loss  0.82536596 C_bot  0.15 k_c 0.0\n",
      "2381 Train Loss 10.755595\n",
      "Loss  0.82536596 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8008516 C_bot  0.15 k_c 0.0\n",
      "2382 Train Loss 10.72915\n",
      "Loss  0.8008516 C_bot  0.15 k_c 0.0\n",
      "Loss  0.81013554 C_bot  0.15 k_c 0.0\n",
      "2383 Train Loss 10.736361\n",
      "Loss  0.81013554 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8326378 C_bot  0.15 k_c 0.0\n",
      "2384 Train Loss 10.750204\n",
      "Loss  0.8326378 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8228268 C_bot  0.15 k_c 0.0\n",
      "2385 Train Loss 10.742342\n",
      "Loss  0.8228268 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8035717 C_bot  0.15 k_c 0.0\n",
      "2386 Train Loss 10.714495\n",
      "Loss  0.8035717 C_bot  0.15 k_c 0.0\n",
      "Loss  0.78352046 C_bot  0.15 k_c 0.0\n",
      "2387 Train Loss 10.69285\n",
      "Loss  0.78352046 C_bot  0.15 k_c 0.0\n",
      "Loss  0.78466225 C_bot  0.15 k_c 0.0\n",
      "2388 Train Loss 10.690992\n",
      "Loss  0.78466225 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7982089 C_bot  0.15 k_c 0.0\n",
      "2389 Train Loss 10.697604\n",
      "Loss  0.7982089 C_bot  0.15 k_c 0.0\n",
      "Loss  0.79481494 C_bot  0.15 k_c 0.0\n",
      "2390 Train Loss 10.694897\n",
      "Loss  0.79481494 C_bot  0.15 k_c 0.0\n",
      "Loss  0.78595644 C_bot  0.15 k_c 0.0\n",
      "2391 Train Loss 10.678374\n",
      "Loss  0.78595644 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7700423 C_bot  0.15 k_c 0.0\n",
      "2392 Train Loss 10.661263\n",
      "Loss  0.7700423 C_bot  0.15 k_c 0.0\n",
      "Loss  0.76667374 C_bot  0.15 k_c 0.0\n",
      "2393 Train Loss 10.654123\n",
      "Loss  0.76667374 C_bot  0.15 k_c 0.0\n",
      "Loss  0.77325886 C_bot  0.15 k_c 0.0\n",
      "2394 Train Loss 10.655251\n",
      "Loss  0.77325886 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7730381 C_bot  0.15 k_c 0.0\n",
      "2395 Train Loss 10.654646\n",
      "Loss  0.7730381 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7710394 C_bot  0.15 k_c 0.0\n",
      "2396 Train Loss 10.645715\n",
      "Loss  0.7710394 C_bot  0.15 k_c 0.0\n",
      "Loss  0.759547 C_bot  0.15 k_c 0.0\n",
      "2397 Train Loss 10.633156\n",
      "Loss  0.759547 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7547241 C_bot  0.15 k_c 0.0\n",
      "2398 Train Loss 10.6238575\n",
      "Loss  0.7547241 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7556774 C_bot  0.15 k_c 0.0\n",
      "2399 Train Loss 10.620656\n",
      "Loss  0.7556774 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75611883 C_bot  0.15 k_c 0.0\n",
      "2400 Train Loss 10.619652\n",
      "Loss  0.75611883 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7574787 C_bot  0.15 k_c 0.0\n",
      "2401 Train Loss 10.615105\n",
      "Loss  0.7574787 C_bot  0.15 k_c 0.0\n",
      "Loss  0.750236 C_bot  0.15 k_c 0.0\n",
      "2402 Train Loss 10.606858\n",
      "Loss  0.750236 C_bot  0.15 k_c 0.0\n",
      "Loss  0.74612683 C_bot  0.15 k_c 0.0\n",
      "2403 Train Loss 10.598057\n",
      "Loss  0.74612683 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7433053 C_bot  0.15 k_c 0.0\n",
      "2404 Train Loss 10.592306\n",
      "Loss  0.7433053 C_bot  0.15 k_c 0.0\n",
      "Loss  0.742623 C_bot  0.15 k_c 0.0\n",
      "2405 Train Loss 10.589392\n",
      "Loss  0.742623 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7443434 C_bot  0.15 k_c 0.0\n",
      "2406 Train Loss 10.586405\n",
      "Loss  0.7443434 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7405224 C_bot  0.15 k_c 0.0\n",
      "2407 Train Loss 10.581457\n",
      "Loss  0.7405224 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7383022 C_bot  0.15 k_c 0.0\n",
      "2408 Train Loss 10.574661\n",
      "Loss  0.7383022 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7339523 C_bot  0.15 k_c 0.0\n",
      "2409 Train Loss 10.568253\n",
      "Loss  0.7339523 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7322352 C_bot  0.15 k_c 0.0\n",
      "2410 Train Loss 10.563587\n",
      "Loss  0.7322352 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73251444 C_bot  0.15 k_c 0.0\n",
      "2411 Train Loss 10.560205\n",
      "Loss  0.73251444 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7306945 C_bot  0.15 k_c 0.0\n",
      "2412 Train Loss 10.556786\n",
      "Loss  0.7306945 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7301677 C_bot  0.15 k_c 0.0\n",
      "2413 Train Loss 10.552019\n",
      "Loss  0.7301677 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7264404 C_bot  0.15 k_c 0.0\n",
      "2414 Train Loss 10.546612\n",
      "Loss  0.7264404 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7246625 C_bot  0.15 k_c 0.0\n",
      "2415 Train Loss 10.541384\n",
      "Loss  0.7246625 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7231427 C_bot  0.15 k_c 0.0\n",
      "2416 Train Loss 10.537104\n",
      "Loss  0.7231427 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7218335 C_bot  0.15 k_c 0.0\n",
      "2417 Train Loss 10.533569\n",
      "Loss  0.7218335 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7218038 C_bot  0.15 k_c 0.0\n",
      "2418 Train Loss 10.52991\n",
      "Loss  0.7218038 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7193851 C_bot  0.15 k_c 0.0\n",
      "2419 Train Loss 10.52582\n",
      "Loss  0.7193851 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7183414 C_bot  0.15 k_c 0.0\n",
      "2420 Train Loss 10.521259\n",
      "Loss  0.7183414 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7159541 C_bot  0.15 k_c 0.0\n",
      "2421 Train Loss 10.516806\n",
      "Loss  0.7159541 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7145388 C_bot  0.15 k_c 0.0\n",
      "2422 Train Loss 10.512701\n",
      "Loss  0.7145388 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7137698 C_bot  0.15 k_c 0.0\n",
      "2423 Train Loss 10.509107\n",
      "Loss  0.7137698 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7122301 C_bot  0.15 k_c 0.0\n",
      "2424 Train Loss 10.505648\n",
      "Loss  0.7122301 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7117301 C_bot  0.15 k_c 0.0\n",
      "2425 Train Loss 10.501942\n",
      "Loss  0.7117301 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70961434 C_bot  0.15 k_c 0.0\n",
      "2426 Train Loss 10.498063\n",
      "Loss  0.70961434 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7084976 C_bot  0.15 k_c 0.0\n",
      "2427 Train Loss 10.494009\n",
      "Loss  0.7084976 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70693654 C_bot  0.15 k_c 0.0\n",
      "2428 Train Loss 10.49028\n",
      "Loss  0.70693654 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7057283 C_bot  0.15 k_c 0.0\n",
      "2429 Train Loss 10.4867325\n",
      "Loss  0.7057283 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7050086 C_bot  0.15 k_c 0.0\n",
      "2430 Train Loss 10.483327\n",
      "Loss  0.7050086 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7035115 C_bot  0.15 k_c 0.0\n",
      "2431 Train Loss 10.47994\n",
      "Loss  0.7035115 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70294535 C_bot  0.15 k_c 0.0\n",
      "2432 Train Loss 10.476496\n",
      "Loss  0.70294535 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7012071 C_bot  0.15 k_c 0.0\n",
      "2433 Train Loss 10.472893\n",
      "Loss  0.7012071 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7003628 C_bot  0.15 k_c 0.0\n",
      "2434 Train Loss 10.46941\n",
      "Loss  0.7003628 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69911104 C_bot  0.15 k_c 0.0\n",
      "2435 Train Loss 10.4660015\n",
      "Loss  0.69911104 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6980464 C_bot  0.15 k_c 0.0\n",
      "2436 Train Loss 10.462725\n",
      "Loss  0.6980464 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69733495 C_bot  0.15 k_c 0.0\n",
      "2437 Train Loss 10.459545\n",
      "Loss  0.69733495 C_bot  0.15 k_c 0.0\n",
      "Loss  0.696057 C_bot  0.15 k_c 0.0\n",
      "2438 Train Loss 10.45636\n",
      "Loss  0.696057 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6954113 C_bot  0.15 k_c 0.0\n",
      "2439 Train Loss 10.4531555\n",
      "Loss  0.6954113 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69406986 C_bot  0.15 k_c 0.0\n",
      "2440 Train Loss 10.44995\n",
      "Loss  0.69406986 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6932928 C_bot  0.15 k_c 0.0\n",
      "2441 Train Loss 10.446777\n",
      "Loss  0.6932928 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6921519 C_bot  0.15 k_c 0.0\n",
      "2442 Train Loss 10.443619\n",
      "Loss  0.6921519 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6912212 C_bot  0.15 k_c 0.0\n",
      "2443 Train Loss 10.440572\n",
      "Loss  0.6912212 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69037586 C_bot  0.15 k_c 0.0\n",
      "2444 Train Loss 10.437512\n",
      "Loss  0.69037586 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68934494 C_bot  0.15 k_c 0.0\n",
      "2445 Train Loss 10.434595\n",
      "Loss  0.68934494 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6887173 C_bot  0.15 k_c 0.0\n",
      "2446 Train Loss 10.431664\n",
      "Loss  0.6887173 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6875337 C_bot  0.15 k_c 0.0\n",
      "2447 Train Loss 10.428667\n",
      "Loss  0.6875337 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6868384 C_bot  0.15 k_c 0.0\n",
      "2448 Train Loss 10.425734\n",
      "Loss  0.6868384 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6858201 C_bot  0.15 k_c 0.0\n",
      "2449 Train Loss 10.422834\n",
      "Loss  0.6858201 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6850572 C_bot  0.15 k_c 0.0\n",
      "2450 Train Loss 10.420006\n",
      "Loss  0.6850572 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68423885 C_bot  0.15 k_c 0.0\n",
      "2451 Train Loss 10.417184\n",
      "Loss  0.68423885 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68334 C_bot  0.15 k_c 0.0\n",
      "2452 Train Loss 10.414392\n",
      "Loss  0.68334 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68269044 C_bot  0.15 k_c 0.0\n",
      "2453 Train Loss 10.411656\n",
      "Loss  0.68269044 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68169963 C_bot  0.15 k_c 0.0\n",
      "2454 Train Loss 10.408883\n",
      "Loss  0.68169963 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6811078 C_bot  0.15 k_c 0.0\n",
      "2455 Train Loss 10.406206\n",
      "Loss  0.6811078 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68016535 C_bot  0.15 k_c 0.0\n",
      "2456 Train Loss 10.4035\n",
      "Loss  0.68016535 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67950726 C_bot  0.15 k_c 0.0\n",
      "2457 Train Loss 10.400847\n",
      "Loss  0.67950726 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6786229 C_bot  0.15 k_c 0.0\n",
      "2458 Train Loss 10.3981495\n",
      "Loss  0.6786229 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6779353 C_bot  0.15 k_c 0.0\n",
      "2459 Train Loss 10.395596\n",
      "Loss  0.6779353 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6772235 C_bot  0.15 k_c 0.0\n",
      "2460 Train Loss 10.393007\n",
      "Loss  0.6772235 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6764294 C_bot  0.15 k_c 0.0\n",
      "2461 Train Loss 10.390458\n",
      "Loss  0.6764294 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67580897 C_bot  0.15 k_c 0.0\n",
      "2462 Train Loss 10.387924\n",
      "Loss  0.67580897 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67501557 C_bot  0.15 k_c 0.0\n",
      "2463 Train Loss 10.385444\n",
      "Loss  0.67501557 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67442626 C_bot  0.15 k_c 0.0\n",
      "2464 Train Loss 10.382956\n",
      "Loss  0.67442626 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6736049 C_bot  0.15 k_c 0.0\n",
      "2465 Train Loss 10.380463\n",
      "Loss  0.6736049 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67297465 C_bot  0.15 k_c 0.0\n",
      "2466 Train Loss 10.377991\n",
      "Loss  0.67297465 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67232186 C_bot  0.15 k_c 0.0\n",
      "2467 Train Loss 10.375647\n",
      "Loss  0.67232186 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67165405 C_bot  0.15 k_c 0.0\n",
      "2468 Train Loss 10.3732195\n",
      "Loss  0.67165405 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6709851 C_bot  0.15 k_c 0.0\n",
      "2469 Train Loss 10.370823\n",
      "Loss  0.6709851 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6702836 C_bot  0.15 k_c 0.0\n",
      "2470 Train Loss 10.368446\n",
      "Loss  0.6702836 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66966975 C_bot  0.15 k_c 0.0\n",
      "2471 Train Loss 10.366079\n",
      "Loss  0.66966975 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66898805 C_bot  0.15 k_c 0.0\n",
      "2472 Train Loss 10.363785\n",
      "Loss  0.66898805 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66848916 C_bot  0.15 k_c 0.0\n",
      "2473 Train Loss 10.361534\n",
      "Loss  0.66848916 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6677445 C_bot  0.15 k_c 0.0\n",
      "2474 Train Loss 10.359219\n",
      "Loss  0.6677445 C_bot  0.15 k_c 0.0\n",
      "Loss  0.667213 C_bot  0.15 k_c 0.0\n",
      "2475 Train Loss 10.356957\n",
      "Loss  0.667213 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6665291 C_bot  0.15 k_c 0.0\n",
      "2476 Train Loss 10.354712\n",
      "Loss  0.6665291 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66597825 C_bot  0.15 k_c 0.0\n",
      "2477 Train Loss 10.35248\n",
      "Loss  0.66597825 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66534346 C_bot  0.15 k_c 0.0\n",
      "2478 Train Loss 10.350274\n",
      "Loss  0.66534346 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66479295 C_bot  0.15 k_c 0.0\n",
      "2479 Train Loss 10.348102\n",
      "Loss  0.66479295 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6642273 C_bot  0.15 k_c 0.0\n",
      "2480 Train Loss 10.345949\n",
      "Loss  0.6642273 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66366047 C_bot  0.15 k_c 0.0\n",
      "2481 Train Loss 10.343817\n",
      "Loss  0.66366047 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66309524 C_bot  0.15 k_c 0.0\n",
      "2482 Train Loss 10.341654\n",
      "Loss  0.66309524 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6625046 C_bot  0.15 k_c 0.0\n",
      "2483 Train Loss 10.339545\n",
      "Loss  0.6625046 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66194975 C_bot  0.15 k_c 0.0\n",
      "2484 Train Loss 10.337393\n",
      "Loss  0.66194975 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6614306 C_bot  0.15 k_c 0.0\n",
      "2485 Train Loss 10.335392\n",
      "Loss  0.6614306 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66088545 C_bot  0.15 k_c 0.0\n",
      "2486 Train Loss 10.333259\n",
      "Loss  0.66088545 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6602942 C_bot  0.15 k_c 0.0\n",
      "2487 Train Loss 10.331213\n",
      "Loss  0.6602942 C_bot  0.15 k_c 0.0\n",
      "Loss  0.659805 C_bot  0.15 k_c 0.0\n",
      "2488 Train Loss 10.329157\n",
      "Loss  0.659805 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65923584 C_bot  0.15 k_c 0.0\n",
      "2489 Train Loss 10.327147\n",
      "Loss  0.65923584 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65885377 C_bot  0.15 k_c 0.0\n",
      "2490 Train Loss 10.325226\n",
      "Loss  0.65885377 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6582342 C_bot  0.15 k_c 0.0\n",
      "2491 Train Loss 10.3231735\n",
      "Loss  0.6582342 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6578223 C_bot  0.15 k_c 0.0\n",
      "2492 Train Loss 10.321257\n",
      "Loss  0.6578223 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65721375 C_bot  0.15 k_c 0.0\n",
      "2493 Train Loss 10.319223\n",
      "Loss  0.65721375 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65679574 C_bot  0.15 k_c 0.0\n",
      "2494 Train Loss 10.317326\n",
      "Loss  0.65679574 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6562839 C_bot  0.15 k_c 0.0\n",
      "2495 Train Loss 10.315401\n",
      "Loss  0.6562839 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6557887 C_bot  0.15 k_c 0.0\n",
      "2496 Train Loss 10.313452\n",
      "Loss  0.6557887 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6552796 C_bot  0.15 k_c 0.0\n",
      "2497 Train Loss 10.31154\n",
      "Loss  0.6552796 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6548298 C_bot  0.15 k_c 0.0\n",
      "2498 Train Loss 10.309662\n",
      "Loss  0.6548298 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6543597 C_bot  0.15 k_c 0.0\n",
      "2499 Train Loss 10.307791\n",
      "Loss  0.6543597 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6538728 C_bot  0.15 k_c 0.0\n",
      "2500 Train Loss 10.305911\n",
      "Loss  0.6538728 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6534566 C_bot  0.15 k_c 0.0\n",
      "2501 Train Loss 10.304093\n",
      "Loss  0.6534566 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6530084 C_bot  0.15 k_c 0.0\n",
      "2502 Train Loss 10.302284\n",
      "Loss  0.6530084 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65250653 C_bot  0.15 k_c 0.0\n",
      "2503 Train Loss 10.300381\n",
      "Loss  0.65250653 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6520871 C_bot  0.15 k_c 0.0\n",
      "2504 Train Loss 10.2986355\n",
      "Loss  0.6520871 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65166456 C_bot  0.15 k_c 0.0\n",
      "2505 Train Loss 10.29681\n",
      "Loss  0.65166456 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6511745 C_bot  0.15 k_c 0.0\n",
      "2506 Train Loss 10.295028\n",
      "Loss  0.6511745 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6508187 C_bot  0.15 k_c 0.0\n",
      "2507 Train Loss 10.293266\n",
      "Loss  0.6508187 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6503019 C_bot  0.15 k_c 0.0\n",
      "2508 Train Loss 10.291493\n",
      "Loss  0.6503019 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6499499 C_bot  0.15 k_c 0.0\n",
      "2509 Train Loss 10.289732\n",
      "Loss  0.6499499 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6494661 C_bot  0.15 k_c 0.0\n",
      "2510 Train Loss 10.288023\n",
      "Loss  0.6494661 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6491323 C_bot  0.15 k_c 0.0\n",
      "2511 Train Loss 10.28628\n",
      "Loss  0.6491323 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6485516 C_bot  0.15 k_c 0.0\n",
      "2512 Train Loss 10.284504\n",
      "Loss  0.6485516 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6483541 C_bot  0.15 k_c 0.0\n",
      "2513 Train Loss 10.282895\n",
      "Loss  0.6483541 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64776146 C_bot  0.15 k_c 0.0\n",
      "2514 Train Loss 10.281142\n",
      "Loss  0.64776146 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6474934 C_bot  0.15 k_c 0.0\n",
      "2515 Train Loss 10.27945\n",
      "Loss  0.6474934 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6469383 C_bot  0.15 k_c 0.0\n",
      "2516 Train Loss 10.277781\n",
      "Loss  0.6469383 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6468091 C_bot  0.15 k_c 0.0\n",
      "2517 Train Loss 10.276199\n",
      "Loss  0.6468091 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64616996 C_bot  0.15 k_c 0.0\n",
      "2518 Train Loss 10.274513\n",
      "Loss  0.64616996 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64609355 C_bot  0.15 k_c 0.0\n",
      "2519 Train Loss 10.27293\n",
      "Loss  0.64609355 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6455003 C_bot  0.15 k_c 0.0\n",
      "2520 Train Loss 10.271395\n",
      "Loss  0.6455003 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64555526 C_bot  0.15 k_c 0.0\n",
      "2521 Train Loss 10.269838\n",
      "Loss  0.64555526 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64486724 C_bot  0.15 k_c 0.0\n",
      "2522 Train Loss 10.268367\n",
      "Loss  0.64486724 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6452169 C_bot  0.15 k_c 0.0\n",
      "2523 Train Loss 10.266937\n",
      "Loss  0.6452169 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6445824 C_bot  0.15 k_c 0.0\n",
      "2524 Train Loss 10.265764\n",
      "Loss  0.6445824 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6455131 C_bot  0.15 k_c 0.0\n",
      "2525 Train Loss 10.264631\n",
      "Loss  0.6455131 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6449779 C_bot  0.15 k_c 0.0\n",
      "2526 Train Loss 10.26395\n",
      "Loss  0.6449779 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6472766 C_bot  0.15 k_c 0.0\n",
      "2527 Train Loss 10.263714\n",
      "Loss  0.6472766 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6475486 C_bot  0.15 k_c 0.0\n",
      "2528 Train Loss 10.264475\n",
      "Loss  0.6475486 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65283114 C_bot  0.15 k_c 0.0\n",
      "2529 Train Loss 10.26644\n",
      "Loss  0.65283114 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6560737 C_bot  0.15 k_c 0.0\n",
      "2530 Train Loss 10.271227\n",
      "Loss  0.6560737 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66945595 C_bot  0.15 k_c 0.0\n",
      "2531 Train Loss 10.279955\n",
      "Loss  0.66945595 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68261486 C_bot  0.15 k_c 0.0\n",
      "2532 Train Loss 10.296474\n",
      "Loss  0.68261486 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71808493 C_bot  0.15 k_c 0.0\n",
      "2533 Train Loss 10.32498\n",
      "Loss  0.71808493 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7634844 C_bot  0.15 k_c 0.0\n",
      "2534 Train Loss 10.376921\n",
      "Loss  0.7634844 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8644735 C_bot  0.15 k_c 0.0\n",
      "2535 Train Loss 10.466918\n",
      "Loss  0.8644735 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0152452 C_bot  0.15 k_c 0.0\n",
      "2536 Train Loss 10.6299305\n",
      "Loss  1.0152452 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3199356 C_bot  0.15 k_c 0.0\n",
      "2537 Train Loss 10.9165535\n",
      "Loss  1.3199356 C_bot  0.15 k_c 0.0\n",
      "Loss  1.822005 C_bot  0.15 k_c 0.0\n",
      "2538 Train Loss 11.441401\n",
      "Loss  1.822005 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7870803 C_bot  0.15 k_c 0.0\n",
      "2539 Train Loss 12.37594\n",
      "Loss  2.7870803 C_bot  0.15 k_c 0.0\n",
      "Loss  4.484519 C_bot  0.15 k_c 0.0\n",
      "2540 Train Loss 14.116423\n",
      "Loss  4.484519 C_bot  0.15 k_c 0.0\n",
      "Loss  7.6527934 C_bot  0.15 k_c 0.0\n",
      "2541 Train Loss 17.232393\n",
      "Loss  7.6527934 C_bot  0.15 k_c 0.0\n",
      "Loss  13.494714 C_bot  0.15 k_c 0.0\n",
      "2542 Train Loss 23.158686\n",
      "Loss  13.494714 C_bot  0.15 k_c 0.0\n",
      "Loss  24.078173 C_bot  0.15 k_c 0.0\n",
      "2543 Train Loss 33.652573\n",
      "Loss  24.078173 C_bot  0.15 k_c 0.0\n",
      "Loss  44.220417 C_bot  0.15 k_c 0.0\n",
      "2544 Train Loss 53.971283\n",
      "Loss  44.220417 C_bot  0.15 k_c 0.0\n",
      "Loss  78.45022 C_bot  0.15 k_c 0.0\n",
      "2545 Train Loss 88.04648\n",
      "Loss  78.45022 C_bot  0.15 k_c 0.0\n",
      "Loss  143.37871 C_bot  0.15 k_c 0.0\n",
      "2546 Train Loss 153.37808\n",
      "Loss  143.37871 C_bot  0.15 k_c 0.0\n",
      "Loss  234.90198 C_bot  0.15 k_c 0.0\n",
      "2547 Train Loss 244.59709\n",
      "Loss  234.90198 C_bot  0.15 k_c 0.0\n",
      "Loss  386.5348 C_bot  0.15 k_c 0.0\n",
      "2548 Train Loss 397.16858\n",
      "Loss  386.5348 C_bot  0.15 k_c 0.0\n",
      "Loss  493.87552 C_bot  0.15 k_c 0.0\n",
      "2549 Train Loss 503.70078\n",
      "Loss  493.87552 C_bot  0.15 k_c 0.0\n",
      "Loss  560.44916 C_bot  0.15 k_c 0.0\n",
      "2550 Train Loss 571.87665\n",
      "Loss  560.44916 C_bot  0.15 k_c 0.0\n",
      "Loss  395.45038 C_bot  0.15 k_c 0.0\n",
      "2551 Train Loss 405.28043\n",
      "Loss  395.45038 C_bot  0.15 k_c 0.0\n",
      "Loss  158.24985 C_bot  0.15 k_c 0.0\n",
      "2552 Train Loss 169.27467\n",
      "Loss  158.24985 C_bot  0.15 k_c 0.0\n",
      "Loss  7.821422 C_bot  0.15 k_c 0.0\n",
      "2553 Train Loss 18.161045\n",
      "Loss  7.821422 C_bot  0.15 k_c 0.0\n",
      "Loss  58.296402 C_bot  0.15 k_c 0.0\n",
      "2554 Train Loss 68.537964\n",
      "Loss  58.296402 C_bot  0.15 k_c 0.0\n",
      "Loss  205.66786 C_bot  0.15 k_c 0.0\n",
      "2555 Train Loss 217.2232\n",
      "Loss  205.66786 C_bot  0.15 k_c 0.0\n",
      "Loss  249.95576 C_bot  0.15 k_c 0.0\n",
      "2556 Train Loss 260.1162\n",
      "Loss  249.95576 C_bot  0.15 k_c 0.0\n",
      "Loss  160.85153 C_bot  0.15 k_c 0.0\n",
      "2557 Train Loss 172.24962\n",
      "Loss  160.85153 C_bot  0.15 k_c 0.0\n",
      "Loss  28.294807 C_bot  0.15 k_c 0.0\n",
      "2558 Train Loss 38.68517\n",
      "Loss  28.294807 C_bot  0.15 k_c 0.0\n",
      "Loss  15.219741 C_bot  0.15 k_c 0.0\n",
      "2559 Train Loss 25.675526\n",
      "Loss  15.219741 C_bot  0.15 k_c 0.0\n",
      "Loss  100.58937 C_bot  0.15 k_c 0.0\n",
      "2560 Train Loss 111.65456\n",
      "Loss  100.58937 C_bot  0.15 k_c 0.0\n",
      "Loss  135.73459 C_bot  0.15 k_c 0.0\n",
      "2561 Train Loss 146.14284\n",
      "Loss  135.73459 C_bot  0.15 k_c 0.0\n",
      "Loss  77.03118 C_bot  0.15 k_c 0.0\n",
      "2562 Train Loss 87.96859\n",
      "Loss  77.03118 C_bot  0.15 k_c 0.0\n",
      "Loss  7.389898 C_bot  0.15 k_c 0.0\n",
      "2563 Train Loss 17.89824\n",
      "Loss  7.389898 C_bot  0.15 k_c 0.0\n",
      "Loss  22.41398 C_bot  0.15 k_c 0.0\n",
      "2564 Train Loss 32.84517\n",
      "Loss  22.41398 C_bot  0.15 k_c 0.0\n",
      "Loss  75.501076 C_bot  0.15 k_c 0.0\n",
      "2565 Train Loss 86.29112\n",
      "Loss  75.501076 C_bot  0.15 k_c 0.0\n",
      "Loss  69.09116 C_bot  0.15 k_c 0.0\n",
      "2566 Train Loss 79.38181\n",
      "Loss  69.09116 C_bot  0.15 k_c 0.0\n",
      "Loss  19.548527 C_bot  0.15 k_c 0.0\n",
      "2567 Train Loss 30.045437\n",
      "Loss  19.548527 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4230013 C_bot  0.15 k_c 0.0\n",
      "2568 Train Loss 13.800283\n",
      "Loss  3.4230013 C_bot  0.15 k_c 0.0\n",
      "Loss  34.469406 C_bot  0.15 k_c 0.0\n",
      "2569 Train Loss 44.700798\n",
      "Loss  34.469406 C_bot  0.15 k_c 0.0\n",
      "Loss  50.919567 C_bot  0.15 k_c 0.0\n",
      "2570 Train Loss 61.54315\n",
      "Loss  50.919567 C_bot  0.15 k_c 0.0\n",
      "Loss  24.171099 C_bot  0.15 k_c 0.0\n",
      "2571 Train Loss 34.43962\n",
      "Loss  24.171099 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8006103 C_bot  0.15 k_c 0.0\n",
      "2572 Train Loss 12.181562\n",
      "Loss  1.8006103 C_bot  0.15 k_c 0.0\n",
      "Loss  14.6532545 C_bot  0.15 k_c 0.0\n",
      "2573 Train Loss 25.110918\n",
      "Loss  14.6532545 C_bot  0.15 k_c 0.0\n",
      "Loss  31.898607 C_bot  0.15 k_c 0.0\n",
      "2574 Train Loss 42.09174\n",
      "Loss  31.898607 C_bot  0.15 k_c 0.0\n",
      "Loss  22.386055 C_bot  0.15 k_c 0.0\n",
      "2575 Train Loss 32.77117\n",
      "Loss  22.386055 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5559475 C_bot  0.15 k_c 0.0\n",
      "2576 Train Loss 13.719942\n",
      "Loss  3.5559475 C_bot  0.15 k_c 0.0\n",
      "Loss  5.2419147 C_bot  0.15 k_c 0.0\n",
      "2577 Train Loss 15.362574\n",
      "Loss  5.2419147 C_bot  0.15 k_c 0.0\n",
      "Loss  18.785566 C_bot  0.15 k_c 0.0\n",
      "2578 Train Loss 29.022314\n",
      "Loss  18.785566 C_bot  0.15 k_c 0.0\n",
      "Loss  18.129744 C_bot  0.15 k_c 0.0\n",
      "2579 Train Loss 28.190168\n",
      "Loss  18.129744 C_bot  0.15 k_c 0.0\n",
      "Loss  5.402594 C_bot  0.15 k_c 0.0\n",
      "2580 Train Loss 15.540335\n",
      "Loss  5.402594 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5814022 C_bot  0.15 k_c 0.0\n",
      "2581 Train Loss 11.675514\n",
      "Loss  1.5814022 C_bot  0.15 k_c 0.0\n",
      "Loss  9.769718 C_bot  0.15 k_c 0.0\n",
      "2582 Train Loss 19.799458\n",
      "Loss  9.769718 C_bot  0.15 k_c 0.0\n",
      "Loss  13.5628805 C_bot  0.15 k_c 0.0\n",
      "2583 Train Loss 23.680855\n",
      "Loss  13.5628805 C_bot  0.15 k_c 0.0\n",
      "Loss  6.6477704 C_bot  0.15 k_c 0.0\n",
      "2584 Train Loss 16.63999\n",
      "Loss  6.6477704 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9721831 C_bot  0.15 k_c 0.0\n",
      "2585 Train Loss 10.983999\n",
      "Loss  0.9721831 C_bot  0.15 k_c 0.0\n",
      "Loss  4.2713265 C_bot  0.15 k_c 0.0\n",
      "2586 Train Loss 14.309671\n",
      "Loss  4.2713265 C_bot  0.15 k_c 0.0\n",
      "Loss  8.849135 C_bot  0.15 k_c 0.0\n",
      "2587 Train Loss 18.800776\n",
      "Loss  8.849135 C_bot  0.15 k_c 0.0\n",
      "Loss  6.53347 C_bot  0.15 k_c 0.0\n",
      "2588 Train Loss 16.582956\n",
      "Loss  6.53347 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6635526 C_bot  0.15 k_c 0.0\n",
      "2589 Train Loss 11.635813\n",
      "Loss  1.6635526 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6769809 C_bot  0.15 k_c 0.0\n",
      "2590 Train Loss 11.641966\n",
      "Loss  1.6769809 C_bot  0.15 k_c 0.0\n",
      "Loss  5.1023865 C_bot  0.15 k_c 0.0\n",
      "2591 Train Loss 15.123007\n",
      "Loss  5.1023865 C_bot  0.15 k_c 0.0\n",
      "Loss  5.6258693 C_bot  0.15 k_c 0.0\n",
      "2592 Train Loss 15.547836\n",
      "Loss  5.6258693 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4943306 C_bot  0.15 k_c 0.0\n",
      "2593 Train Loss 12.468932\n",
      "Loss  2.4943306 C_bot  0.15 k_c 0.0\n",
      "Loss  0.84894586 C_bot  0.15 k_c 0.0\n",
      "2594 Train Loss 10.784676\n",
      "Loss  0.84894586 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5423255 C_bot  0.15 k_c 0.0\n",
      "2595 Train Loss 12.444513\n",
      "Loss  2.5423255 C_bot  0.15 k_c 0.0\n",
      "Loss  4.0741596 C_bot  0.15 k_c 0.0\n",
      "2596 Train Loss 14.026693\n",
      "Loss  4.0741596 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9833128 C_bot  0.15 k_c 0.0\n",
      "2597 Train Loss 12.870754\n",
      "Loss  2.9833128 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0712985 C_bot  0.15 k_c 0.0\n",
      "2598 Train Loss 10.982399\n",
      "Loss  1.0712985 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1335288 C_bot  0.15 k_c 0.0\n",
      "2599 Train Loss 11.037209\n",
      "Loss  1.1335288 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5174587 C_bot  0.15 k_c 0.0\n",
      "2600 Train Loss 12.382365\n",
      "Loss  2.5174587 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7393587 C_bot  0.15 k_c 0.0\n",
      "2601 Train Loss 12.639076\n",
      "Loss  2.7393587 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6010834 C_bot  0.15 k_c 0.0\n",
      "2602 Train Loss 11.45121\n",
      "Loss  1.6010834 C_bot  0.15 k_c 0.0\n",
      "Loss  0.80597913 C_bot  0.15 k_c 0.0\n",
      "2603 Train Loss 10.661751\n",
      "Loss  0.80597913 C_bot  0.15 k_c 0.0\n",
      "Loss  1.316678 C_bot  0.15 k_c 0.0\n",
      "2604 Train Loss 11.177393\n",
      "Loss  1.316678 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0611868 C_bot  0.15 k_c 0.0\n",
      "2605 Train Loss 11.885965\n",
      "Loss  2.0611868 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7903574 C_bot  0.15 k_c 0.0\n",
      "2606 Train Loss 11.646666\n",
      "Loss  1.7903574 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0381836 C_bot  0.15 k_c 0.0\n",
      "2607 Train Loss 10.863583\n",
      "Loss  1.0381836 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8197202 C_bot  0.15 k_c 0.0\n",
      "2608 Train Loss 10.645382\n",
      "Loss  0.8197202 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2656806 C_bot  0.15 k_c 0.0\n",
      "2609 Train Loss 11.100506\n",
      "Loss  1.2656806 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5937904 C_bot  0.15 k_c 0.0\n",
      "2610 Train Loss 11.39615\n",
      "Loss  1.5937904 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2755185 C_bot  0.15 k_c 0.0\n",
      "2611 Train Loss 11.096048\n",
      "Loss  1.2755185 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8519017 C_bot  0.15 k_c 0.0\n",
      "2612 Train Loss 10.650059\n",
      "Loss  0.8519017 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8385913 C_bot  0.15 k_c 0.0\n",
      "2613 Train Loss 10.631237\n",
      "Loss  0.8385913 C_bot  0.15 k_c 0.0\n",
      "Loss  1.132249 C_bot  0.15 k_c 0.0\n",
      "2614 Train Loss 10.932432\n",
      "Loss  1.132249 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2669585 C_bot  0.15 k_c 0.0\n",
      "2615 Train Loss 11.043667\n",
      "Loss  1.2669585 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0261271 C_bot  0.15 k_c 0.0\n",
      "2616 Train Loss 10.814997\n",
      "Loss  1.0261271 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7932554 C_bot  0.15 k_c 0.0\n",
      "2617 Train Loss 10.567778\n",
      "Loss  0.7932554 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8247196 C_bot  0.15 k_c 0.0\n",
      "2618 Train Loss 10.593412\n",
      "Loss  0.8247196 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9996347 C_bot  0.15 k_c 0.0\n",
      "2619 Train Loss 10.774214\n",
      "Loss  0.9996347 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0617533 C_bot  0.15 k_c 0.0\n",
      "2620 Train Loss 10.816961\n",
      "Loss  1.0617533 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9042089 C_bot  0.15 k_c 0.0\n",
      "2621 Train Loss 10.668558\n",
      "Loss  0.9042089 C_bot  0.15 k_c 0.0\n",
      "Loss  0.77164495 C_bot  0.15 k_c 0.0\n",
      "2622 Train Loss 10.524516\n",
      "Loss  0.77164495 C_bot  0.15 k_c 0.0\n",
      "Loss  0.79358506 C_bot  0.15 k_c 0.0\n",
      "2623 Train Loss 10.541552\n",
      "Loss  0.79358506 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89331293 C_bot  0.15 k_c 0.0\n",
      "2624 Train Loss 10.646516\n",
      "Loss  0.89331293 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9348829 C_bot  0.15 k_c 0.0\n",
      "2625 Train Loss 10.672251\n",
      "Loss  0.9348829 C_bot  0.15 k_c 0.0\n",
      "Loss  0.84095037 C_bot  0.15 k_c 0.0\n",
      "2626 Train Loss 10.585785\n",
      "Loss  0.84095037 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75940424 C_bot  0.15 k_c 0.0\n",
      "2627 Train Loss 10.494282\n",
      "Loss  0.75940424 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7630992 C_bot  0.15 k_c 0.0\n",
      "2628 Train Loss 10.494003\n",
      "Loss  0.7630992 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8196435 C_bot  0.15 k_c 0.0\n",
      "2629 Train Loss 10.552985\n",
      "Loss  0.8196435 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8542023 C_bot  0.15 k_c 0.0\n",
      "2630 Train Loss 10.575001\n",
      "Loss  0.8542023 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8038675 C_bot  0.15 k_c 0.0\n",
      "2631 Train Loss 10.529507\n",
      "Loss  0.8038675 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7523042 C_bot  0.15 k_c 0.0\n",
      "2632 Train Loss 10.469223\n",
      "Loss  0.7523042 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7419053 C_bot  0.15 k_c 0.0\n",
      "2633 Train Loss 10.456246\n",
      "Loss  0.7419053 C_bot  0.15 k_c 0.0\n",
      "Loss  0.77102536 C_bot  0.15 k_c 0.0\n",
      "2634 Train Loss 10.485825\n",
      "Loss  0.77102536 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8004022 C_bot  0.15 k_c 0.0\n",
      "2635 Train Loss 10.506071\n",
      "Loss  0.8004022 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7785759 C_bot  0.15 k_c 0.0\n",
      "2636 Train Loss 10.48773\n",
      "Loss  0.7785759 C_bot  0.15 k_c 0.0\n",
      "Loss  0.74764603 C_bot  0.15 k_c 0.0\n",
      "2637 Train Loss 10.4489975\n",
      "Loss  0.74764603 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7289402 C_bot  0.15 k_c 0.0\n",
      "2638 Train Loss 10.428999\n",
      "Loss  0.7289402 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7394342 C_bot  0.15 k_c 0.0\n",
      "2639 Train Loss 10.438295\n",
      "Loss  0.7394342 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7618046 C_bot  0.15 k_c 0.0\n",
      "2640 Train Loss 10.453606\n",
      "Loss  0.7618046 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7566769 C_bot  0.15 k_c 0.0\n",
      "2641 Train Loss 10.451004\n",
      "Loss  0.7566769 C_bot  0.15 k_c 0.0\n",
      "Loss  0.742423 C_bot  0.15 k_c 0.0\n",
      "2642 Train Loss 10.429416\n",
      "Loss  0.742423 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72285545 C_bot  0.15 k_c 0.0\n",
      "2643 Train Loss 10.409727\n",
      "Loss  0.72285545 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72168887 C_bot  0.15 k_c 0.0\n",
      "2644 Train Loss 10.405888\n",
      "Loss  0.72168887 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73413277 C_bot  0.15 k_c 0.0\n",
      "2645 Train Loss 10.413204\n",
      "Loss  0.73413277 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73685175 C_bot  0.15 k_c 0.0\n",
      "2646 Train Loss 10.417015\n",
      "Loss  0.73685175 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73506117 C_bot  0.15 k_c 0.0\n",
      "2647 Train Loss 10.408492\n",
      "Loss  0.73506117 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7203277 C_bot  0.15 k_c 0.0\n",
      "2648 Train Loss 10.394071\n",
      "Loss  0.7203277 C_bot  0.15 k_c 0.0\n",
      "Loss  0.714256 C_bot  0.15 k_c 0.0\n",
      "2649 Train Loss 10.384132\n",
      "Loss  0.714256 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71656096 C_bot  0.15 k_c 0.0\n",
      "2650 Train Loss 10.383284\n",
      "Loss  0.71656096 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7200086 C_bot  0.15 k_c 0.0\n",
      "2651 Train Loss 10.386385\n",
      "Loss  0.7200086 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72399384 C_bot  0.15 k_c 0.0\n",
      "2652 Train Loss 10.38508\n",
      "Loss  0.72399384 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71655065 C_bot  0.15 k_c 0.0\n",
      "2653 Train Loss 10.378023\n",
      "Loss  0.71655065 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71143264 C_bot  0.15 k_c 0.0\n",
      "2654 Train Loss 10.368631\n",
      "Loss  0.71143264 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7071636 C_bot  0.15 k_c 0.0\n",
      "2655 Train Loss 10.362785\n",
      "Loss  0.7071636 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7073429 C_bot  0.15 k_c 0.0\n",
      "2656 Train Loss 10.361347\n",
      "Loss  0.7073429 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71117765 C_bot  0.15 k_c 0.0\n",
      "2657 Train Loss 10.361398\n",
      "Loss  0.71117765 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70931333 C_bot  0.15 k_c 0.0\n",
      "2658 Train Loss 10.359473\n",
      "Loss  0.70931333 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7080647 C_bot  0.15 k_c 0.0\n",
      "2659 Train Loss 10.354048\n",
      "Loss  0.7080647 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70267373 C_bot  0.15 k_c 0.0\n",
      "2660 Train Loss 10.347953\n",
      "Loss  0.70267373 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7006193 C_bot  0.15 k_c 0.0\n",
      "2661 Train Loss 10.343182\n",
      "Loss  0.7006193 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70085067 C_bot  0.15 k_c 0.0\n",
      "2662 Train Loss 10.340948\n",
      "Loss  0.70085067 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7006666 C_bot  0.15 k_c 0.0\n",
      "2663 Train Loss 10.339766\n",
      "Loss  0.7006666 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70202357 C_bot  0.15 k_c 0.0\n",
      "2664 Train Loss 10.33754\n",
      "Loss  0.70202357 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69895893 C_bot  0.15 k_c 0.0\n",
      "2665 Train Loss 10.333952\n",
      "Loss  0.69895893 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6975436 C_bot  0.15 k_c 0.0\n",
      "2666 Train Loss 10.329315\n",
      "Loss  0.6975436 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6949317 C_bot  0.15 k_c 0.0\n",
      "2667 Train Loss 10.3253355\n",
      "Loss  0.6949317 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6940672 C_bot  0.15 k_c 0.0\n",
      "2668 Train Loss 10.322539\n",
      "Loss  0.6940672 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6945225 C_bot  0.15 k_c 0.0\n",
      "2669 Train Loss 10.320484\n",
      "Loss  0.6945225 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6934088 C_bot  0.15 k_c 0.0\n",
      "2670 Train Loss 10.318488\n",
      "Loss  0.6934088 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6935978 C_bot  0.15 k_c 0.0\n",
      "2671 Train Loss 10.315715\n",
      "Loss  0.6935978 C_bot  0.15 k_c 0.0\n",
      "Loss  0.691053 C_bot  0.15 k_c 0.0\n",
      "2672 Train Loss 10.31238\n",
      "Loss  0.691053 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6900189 C_bot  0.15 k_c 0.0\n",
      "2673 Train Loss 10.308861\n",
      "Loss  0.6900189 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68852526 C_bot  0.15 k_c 0.0\n",
      "2674 Train Loss 10.305883\n",
      "Loss  0.68852526 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68765515 C_bot  0.15 k_c 0.0\n",
      "2675 Train Loss 10.303432\n",
      "Loss  0.68765515 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6877384 C_bot  0.15 k_c 0.0\n",
      "2676 Train Loss 10.301263\n",
      "Loss  0.6877384 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68654114 C_bot  0.15 k_c 0.0\n",
      "2677 Train Loss 10.299111\n",
      "Loss  0.68654114 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68638796 C_bot  0.15 k_c 0.0\n",
      "2678 Train Loss 10.296442\n",
      "Loss  0.68638796 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6845636 C_bot  0.15 k_c 0.0\n",
      "2679 Train Loss 10.29364\n",
      "Loss  0.6845636 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6838229 C_bot  0.15 k_c 0.0\n",
      "2680 Train Loss 10.29072\n",
      "Loss  0.6838229 C_bot  0.15 k_c 0.0\n",
      "Loss  0.682664 C_bot  0.15 k_c 0.0\n",
      "2681 Train Loss 10.288092\n",
      "Loss  0.682664 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6819321 C_bot  0.15 k_c 0.0\n",
      "2682 Train Loss 10.285784\n",
      "Loss  0.6819321 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6816903 C_bot  0.15 k_c 0.0\n",
      "2683 Train Loss 10.283558\n",
      "Loss  0.6816903 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68066204 C_bot  0.15 k_c 0.0\n",
      "2684 Train Loss 10.281407\n",
      "Loss  0.68066204 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68045956 C_bot  0.15 k_c 0.0\n",
      "2685 Train Loss 10.279026\n",
      "Loss  0.68045956 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67907685 C_bot  0.15 k_c 0.0\n",
      "2686 Train Loss 10.276587\n",
      "Loss  0.67907685 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67851883 C_bot  0.15 k_c 0.0\n",
      "2687 Train Loss 10.274041\n",
      "Loss  0.67851883 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67746633 C_bot  0.15 k_c 0.0\n",
      "2688 Train Loss 10.271673\n",
      "Loss  0.67746633 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6767991 C_bot  0.15 k_c 0.0\n",
      "2689 Train Loss 10.269419\n",
      "Loss  0.6767991 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67626035 C_bot  0.15 k_c 0.0\n",
      "2690 Train Loss 10.267223\n",
      "Loss  0.67626035 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6754222 C_bot  0.15 k_c 0.0\n",
      "2691 Train Loss 10.265158\n",
      "Loss  0.6754222 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67514145 C_bot  0.15 k_c 0.0\n",
      "2692 Train Loss 10.263012\n",
      "Loss  0.67514145 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67410773 C_bot  0.15 k_c 0.0\n",
      "2693 Train Loss 10.260894\n",
      "Loss  0.67410773 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67372274 C_bot  0.15 k_c 0.0\n",
      "2694 Train Loss 10.258667\n",
      "Loss  0.67372274 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6726636 C_bot  0.15 k_c 0.0\n",
      "2695 Train Loss 10.256431\n",
      "Loss  0.6726636 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6721812 C_bot  0.15 k_c 0.0\n",
      "2696 Train Loss 10.25431\n",
      "Loss  0.6721812 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67144597 C_bot  0.15 k_c 0.0\n",
      "2697 Train Loss 10.25219\n",
      "Loss  0.67144597 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6707804 C_bot  0.15 k_c 0.0\n",
      "2698 Train Loss 10.250145\n",
      "Loss  0.6707804 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67033976 C_bot  0.15 k_c 0.0\n",
      "2699 Train Loss 10.248122\n",
      "Loss  0.67033976 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66957474 C_bot  0.15 k_c 0.0\n",
      "2700 Train Loss 10.246169\n",
      "Loss  0.66957474 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6692415 C_bot  0.15 k_c 0.0\n",
      "2701 Train Loss 10.244175\n",
      "Loss  0.6692415 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66836697 C_bot  0.15 k_c 0.0\n",
      "2702 Train Loss 10.242166\n",
      "Loss  0.66836697 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6679893 C_bot  0.15 k_c 0.0\n",
      "2703 Train Loss 10.240182\n",
      "Loss  0.6679893 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6672194 C_bot  0.15 k_c 0.0\n",
      "2704 Train Loss 10.23822\n",
      "Loss  0.6672194 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6667079 C_bot  0.15 k_c 0.0\n",
      "2705 Train Loss 10.236244\n",
      "Loss  0.6667079 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66607344 C_bot  0.15 k_c 0.0\n",
      "2706 Train Loss 10.234306\n",
      "Loss  0.66607344 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6654554 C_bot  0.15 k_c 0.0\n",
      "2707 Train Loss 10.232383\n",
      "Loss  0.6654554 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6650351 C_bot  0.15 k_c 0.0\n",
      "2708 Train Loss 10.2305565\n",
      "Loss  0.6650351 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6643627 C_bot  0.15 k_c 0.0\n",
      "2709 Train Loss 10.228693\n",
      "Loss  0.6643627 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66395426 C_bot  0.15 k_c 0.0\n",
      "2710 Train Loss 10.226834\n",
      "Loss  0.66395426 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66327816 C_bot  0.15 k_c 0.0\n",
      "2711 Train Loss 10.225018\n",
      "Loss  0.66327816 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6629237 C_bot  0.15 k_c 0.0\n",
      "2712 Train Loss 10.223221\n",
      "Loss  0.6629237 C_bot  0.15 k_c 0.0\n",
      "Loss  0.662246 C_bot  0.15 k_c 0.0\n",
      "2713 Train Loss 10.221401\n",
      "Loss  0.662246 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6618071 C_bot  0.15 k_c 0.0\n",
      "2714 Train Loss 10.219583\n",
      "Loss  0.6618071 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66120964 C_bot  0.15 k_c 0.0\n",
      "2715 Train Loss 10.217793\n",
      "Loss  0.66120964 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66071564 C_bot  0.15 k_c 0.0\n",
      "2716 Train Loss 10.21601\n",
      "Loss  0.66071564 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66021585 C_bot  0.15 k_c 0.0\n",
      "2717 Train Loss 10.214262\n",
      "Loss  0.66021585 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6597219 C_bot  0.15 k_c 0.0\n",
      "2718 Train Loss 10.212562\n",
      "Loss  0.6597219 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6592434 C_bot  0.15 k_c 0.0\n",
      "2719 Train Loss 10.210795\n",
      "Loss  0.6592434 C_bot  0.15 k_c 0.0\n",
      "Loss  0.658721 C_bot  0.15 k_c 0.0\n",
      "2720 Train Loss 10.209134\n",
      "Loss  0.658721 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6582973 C_bot  0.15 k_c 0.0\n",
      "2721 Train Loss 10.2074\n",
      "Loss  0.6582973 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6577576 C_bot  0.15 k_c 0.0\n",
      "2722 Train Loss 10.205762\n",
      "Loss  0.6577576 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65736854 C_bot  0.15 k_c 0.0\n",
      "2723 Train Loss 10.204071\n",
      "Loss  0.65736854 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65677613 C_bot  0.15 k_c 0.0\n",
      "2724 Train Loss 10.202391\n",
      "Loss  0.65677613 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6564364 C_bot  0.15 k_c 0.0\n",
      "2725 Train Loss 10.200778\n",
      "Loss  0.6564364 C_bot  0.15 k_c 0.0\n",
      "Loss  0.655866 C_bot  0.15 k_c 0.0\n",
      "2726 Train Loss 10.199118\n",
      "Loss  0.655866 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6555214 C_bot  0.15 k_c 0.0\n",
      "2727 Train Loss 10.197533\n",
      "Loss  0.6555214 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65496784 C_bot  0.15 k_c 0.0\n",
      "2728 Train Loss 10.195879\n",
      "Loss  0.65496784 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6545968 C_bot  0.15 k_c 0.0\n",
      "2729 Train Loss 10.1943035\n",
      "Loss  0.6545968 C_bot  0.15 k_c 0.0\n",
      "Loss  0.654117 C_bot  0.15 k_c 0.0\n",
      "2730 Train Loss 10.192713\n",
      "Loss  0.654117 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65368795 C_bot  0.15 k_c 0.0\n",
      "2731 Train Loss 10.191121\n",
      "Loss  0.65368795 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6532522 C_bot  0.15 k_c 0.0\n",
      "2732 Train Loss 10.18956\n",
      "Loss  0.6532522 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65282166 C_bot  0.15 k_c 0.0\n",
      "2733 Train Loss 10.1880045\n",
      "Loss  0.65282166 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65237963 C_bot  0.15 k_c 0.0\n",
      "2734 Train Loss 10.186428\n",
      "Loss  0.65237963 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6519653 C_bot  0.15 k_c 0.0\n",
      "2735 Train Loss 10.184922\n",
      "Loss  0.6519653 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6515662 C_bot  0.15 k_c 0.0\n",
      "2736 Train Loss 10.183386\n",
      "Loss  0.6515662 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6511193 C_bot  0.15 k_c 0.0\n",
      "2737 Train Loss 10.181875\n",
      "Loss  0.6511193 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65077555 C_bot  0.15 k_c 0.0\n",
      "2738 Train Loss 10.180395\n",
      "Loss  0.65077555 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65030104 C_bot  0.15 k_c 0.0\n",
      "2739 Train Loss 10.17888\n",
      "Loss  0.65030104 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6499349 C_bot  0.15 k_c 0.0\n",
      "2740 Train Loss 10.177383\n",
      "Loss  0.6499349 C_bot  0.15 k_c 0.0\n",
      "Loss  0.649526 C_bot  0.15 k_c 0.0\n",
      "2741 Train Loss 10.175951\n",
      "Loss  0.649526 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64917594 C_bot  0.15 k_c 0.0\n",
      "2742 Train Loss 10.174473\n",
      "Loss  0.64917594 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64872485 C_bot  0.15 k_c 0.0\n",
      "2743 Train Loss 10.173021\n",
      "Loss  0.64872485 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64836496 C_bot  0.15 k_c 0.0\n",
      "2744 Train Loss 10.171535\n",
      "Loss  0.64836496 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6479307 C_bot  0.15 k_c 0.0\n",
      "2745 Train Loss 10.170116\n",
      "Loss  0.6479307 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64757776 C_bot  0.15 k_c 0.0\n",
      "2746 Train Loss 10.16864\n",
      "Loss  0.64757776 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6471609 C_bot  0.15 k_c 0.0\n",
      "2747 Train Loss 10.167265\n",
      "Loss  0.6471609 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6469429 C_bot  0.15 k_c 0.0\n",
      "2748 Train Loss 10.165913\n",
      "Loss  0.6469429 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64643306 C_bot  0.15 k_c 0.0\n",
      "2749 Train Loss 10.16448\n",
      "Loss  0.64643306 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6461857 C_bot  0.15 k_c 0.0\n",
      "2750 Train Loss 10.163079\n",
      "Loss  0.6461857 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6456809 C_bot  0.15 k_c 0.0\n",
      "2751 Train Loss 10.161699\n",
      "Loss  0.6456809 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64550066 C_bot  0.15 k_c 0.0\n",
      "2752 Train Loss 10.160333\n",
      "Loss  0.64550066 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64501876 C_bot  0.15 k_c 0.0\n",
      "2753 Train Loss 10.159036\n",
      "Loss  0.64501876 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6448749 C_bot  0.15 k_c 0.0\n",
      "2754 Train Loss 10.157658\n",
      "Loss  0.6448749 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6443017 C_bot  0.15 k_c 0.0\n",
      "2755 Train Loss 10.156351\n",
      "Loss  0.6443017 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6442972 C_bot  0.15 k_c 0.0\n",
      "2756 Train Loss 10.155032\n",
      "Loss  0.6442972 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6437138 C_bot  0.15 k_c 0.0\n",
      "2757 Train Loss 10.153839\n",
      "Loss  0.6437138 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64386225 C_bot  0.15 k_c 0.0\n",
      "2758 Train Loss 10.152543\n",
      "Loss  0.64386225 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6433062 C_bot  0.15 k_c 0.0\n",
      "2759 Train Loss 10.15156\n",
      "Loss  0.6433062 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64392406 C_bot  0.15 k_c 0.0\n",
      "2760 Train Loss 10.15052\n",
      "Loss  0.64392406 C_bot  0.15 k_c 0.0\n",
      "Loss  0.643353 C_bot  0.15 k_c 0.0\n",
      "2761 Train Loss 10.149815\n",
      "Loss  0.643353 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6449058 C_bot  0.15 k_c 0.0\n",
      "2762 Train Loss 10.149357\n",
      "Loss  0.6449058 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64474046 C_bot  0.15 k_c 0.0\n",
      "2763 Train Loss 10.149539\n",
      "Loss  0.64474046 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64821404 C_bot  0.15 k_c 0.0\n",
      "2764 Train Loss 10.150404\n",
      "Loss  0.64821404 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6498223 C_bot  0.15 k_c 0.0\n",
      "2765 Train Loss 10.153155\n",
      "Loss  0.6498223 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6582801 C_bot  0.15 k_c 0.0\n",
      "2766 Train Loss 10.158007\n",
      "Loss  0.6582801 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6654511 C_bot  0.15 k_c 0.0\n",
      "2767 Train Loss 10.167662\n",
      "Loss  0.6654511 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6872518 C_bot  0.15 k_c 0.0\n",
      "2768 Train Loss 10.184151\n",
      "Loss  0.6872518 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7126656 C_bot  0.15 k_c 0.0\n",
      "2769 Train Loss 10.214368\n",
      "Loss  0.7126656 C_bot  0.15 k_c 0.0\n",
      "Loss  0.77254677 C_bot  0.15 k_c 0.0\n",
      "2770 Train Loss 10.265993\n",
      "Loss  0.77254677 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8570211 C_bot  0.15 k_c 0.0\n",
      "2771 Train Loss 10.359375\n",
      "Loss  0.8570211 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0325491 C_bot  0.15 k_c 0.0\n",
      "2772 Train Loss 10.521502\n",
      "Loss  1.0325491 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3107967 C_bot  0.15 k_c 0.0\n",
      "2773 Train Loss 10.816137\n",
      "Loss  1.3107967 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8523964 C_bot  0.15 k_c 0.0\n",
      "2774 Train Loss 11.335281\n",
      "Loss  1.8523964 C_bot  0.15 k_c 0.0\n",
      "Loss  2.780466 C_bot  0.15 k_c 0.0\n",
      "2775 Train Loss 12.293835\n",
      "Loss  2.780466 C_bot  0.15 k_c 0.0\n",
      "Loss  4.522367 C_bot  0.15 k_c 0.0\n",
      "2776 Train Loss 13.997421\n",
      "Loss  4.522367 C_bot  0.15 k_c 0.0\n",
      "Loss  7.674222 C_bot  0.15 k_c 0.0\n",
      "2777 Train Loss 17.207703\n",
      "Loss  7.674222 C_bot  0.15 k_c 0.0\n",
      "Loss  13.417206 C_bot  0.15 k_c 0.0\n",
      "2778 Train Loss 22.884933\n",
      "Loss  13.417206 C_bot  0.15 k_c 0.0\n",
      "Loss  24.222105 C_bot  0.15 k_c 0.0\n",
      "2779 Train Loss 33.808052\n",
      "Loss  24.222105 C_bot  0.15 k_c 0.0\n",
      "Loss  42.92525 C_bot  0.15 k_c 0.0\n",
      "2780 Train Loss 52.39788\n",
      "Loss  42.92525 C_bot  0.15 k_c 0.0\n",
      "Loss  78.56108 C_bot  0.15 k_c 0.0\n",
      "2781 Train Loss 88.29336\n",
      "Loss  78.56108 C_bot  0.15 k_c 0.0\n",
      "Loss  132.28665 C_bot  0.15 k_c 0.0\n",
      "2782 Train Loss 141.8088\n",
      "Loss  132.28665 C_bot  0.15 k_c 0.0\n",
      "Loss  226.84702 C_bot  0.15 k_c 0.0\n",
      "2783 Train Loss 236.97418\n",
      "Loss  226.84702 C_bot  0.15 k_c 0.0\n",
      "Loss  317.8851 C_bot  0.15 k_c 0.0\n",
      "2784 Train Loss 327.5092\n",
      "Loss  317.8851 C_bot  0.15 k_c 0.0\n",
      "Loss  414.53006 C_bot  0.15 k_c 0.0\n",
      "2785 Train Loss 425.34198\n",
      "Loss  414.53006 C_bot  0.15 k_c 0.0\n",
      "Loss  370.91168 C_bot  0.15 k_c 0.0\n",
      "2786 Train Loss 380.57745\n",
      "Loss  370.91168 C_bot  0.15 k_c 0.0\n",
      "Loss  231.82195 C_bot  0.15 k_c 0.0\n",
      "2787 Train Loss 242.71527\n",
      "Loss  231.82195 C_bot  0.15 k_c 0.0\n",
      "Loss  61.547764 C_bot  0.15 k_c 0.0\n",
      "2788 Train Loss 71.486244\n",
      "Loss  61.547764 C_bot  0.15 k_c 0.0\n",
      "Loss  2.866423 C_bot  0.15 k_c 0.0\n",
      "2789 Train Loss 13.127737\n",
      "Loss  2.866423 C_bot  0.15 k_c 0.0\n",
      "Loss  73.40902 C_bot  0.15 k_c 0.0\n",
      "2790 Train Loss 84.2824\n",
      "Loss  73.40902 C_bot  0.15 k_c 0.0\n",
      "Loss  172.11015 C_bot  0.15 k_c 0.0\n",
      "2791 Train Loss 182.18385\n",
      "Loss  172.11015 C_bot  0.15 k_c 0.0\n",
      "Loss  203.37784 C_bot  0.15 k_c 0.0\n",
      "2792 Train Loss 214.71713\n",
      "Loss  203.37784 C_bot  0.15 k_c 0.0\n",
      "Loss  121.0569 C_bot  0.15 k_c 0.0\n",
      "2793 Train Loss 131.21207\n",
      "Loss  121.0569 C_bot  0.15 k_c 0.0\n",
      "Loss  27.456516 C_bot  0.15 k_c 0.0\n",
      "2794 Train Loss 38.137424\n",
      "Loss  27.456516 C_bot  0.15 k_c 0.0\n",
      "Loss  5.088177 C_bot  0.15 k_c 0.0\n",
      "2795 Train Loss 15.620686\n",
      "Loss  5.088177 C_bot  0.15 k_c 0.0\n",
      "Loss  56.901012 C_bot  0.15 k_c 0.0\n",
      "2796 Train Loss 67.21843\n",
      "Loss  56.901012 C_bot  0.15 k_c 0.0\n",
      "Loss  105.19126 C_bot  0.15 k_c 0.0\n",
      "2797 Train Loss 116.07757\n",
      "Loss  105.19126 C_bot  0.15 k_c 0.0\n",
      "Loss  82.30503 C_bot  0.15 k_c 0.0\n",
      "2798 Train Loss 92.60207\n",
      "Loss  82.30503 C_bot  0.15 k_c 0.0\n",
      "Loss  26.149883 C_bot  0.15 k_c 0.0\n",
      "2799 Train Loss 36.697384\n",
      "Loss  26.149883 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9924202 C_bot  0.15 k_c 0.0\n",
      "2800 Train Loss 12.332876\n",
      "Loss  1.9924202 C_bot  0.15 k_c 0.0\n",
      "Loss  28.949959 C_bot  0.15 k_c 0.0\n",
      "2801 Train Loss 39.122543\n",
      "Loss  28.949959 C_bot  0.15 k_c 0.0\n",
      "Loss  58.463844 C_bot  0.15 k_c 0.0\n",
      "2802 Train Loss 68.914566\n",
      "Loss  58.463844 C_bot  0.15 k_c 0.0\n",
      "Loss  45.54453 C_bot  0.15 k_c 0.0\n",
      "2803 Train Loss 55.60249\n",
      "Loss  45.54453 C_bot  0.15 k_c 0.0\n",
      "Loss  12.417748 C_bot  0.15 k_c 0.0\n",
      "2804 Train Loss 22.647324\n",
      "Loss  12.417748 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1814907 C_bot  0.15 k_c 0.0\n",
      "2805 Train Loss 12.349867\n",
      "Loss  2.1814907 C_bot  0.15 k_c 0.0\n",
      "Loss  21.200792 C_bot  0.15 k_c 0.0\n",
      "2806 Train Loss 31.278152\n",
      "Loss  21.200792 C_bot  0.15 k_c 0.0\n",
      "Loss  35.52766 C_bot  0.15 k_c 0.0\n",
      "2807 Train Loss 45.89021\n",
      "Loss  35.52766 C_bot  0.15 k_c 0.0\n",
      "Loss  23.298086 C_bot  0.15 k_c 0.0\n",
      "2808 Train Loss 33.3667\n",
      "Loss  23.298086 C_bot  0.15 k_c 0.0\n",
      "Loss  4.3377457 C_bot  0.15 k_c 0.0\n",
      "2809 Train Loss 14.495733\n",
      "Loss  4.3377457 C_bot  0.15 k_c 0.0\n",
      "Loss  3.573126 C_bot  0.15 k_c 0.0\n",
      "2810 Train Loss 13.670937\n",
      "Loss  3.573126 C_bot  0.15 k_c 0.0\n",
      "Loss  16.607738 C_bot  0.15 k_c 0.0\n",
      "2811 Train Loss 26.566143\n",
      "Loss  16.607738 C_bot  0.15 k_c 0.0\n",
      "Loss  21.406868 C_bot  0.15 k_c 0.0\n",
      "2812 Train Loss 31.482668\n",
      "Loss  21.406868 C_bot  0.15 k_c 0.0\n",
      "Loss  11.20952 C_bot  0.15 k_c 0.0\n",
      "2813 Train Loss 21.114258\n",
      "Loss  11.20952 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5319324 C_bot  0.15 k_c 0.0\n",
      "2814 Train Loss 11.4640465\n",
      "Loss  1.5319324 C_bot  0.15 k_c 0.0\n",
      "Loss  4.1111655 C_bot  0.15 k_c 0.0\n",
      "2815 Train Loss 14.047056\n",
      "Loss  4.1111655 C_bot  0.15 k_c 0.0\n",
      "Loss  11.989614 C_bot  0.15 k_c 0.0\n",
      "2816 Train Loss 21.86062\n",
      "Loss  11.989614 C_bot  0.15 k_c 0.0\n",
      "Loss  12.570149 C_bot  0.15 k_c 0.0\n",
      "2817 Train Loss 22.514017\n",
      "Loss  12.570149 C_bot  0.15 k_c 0.0\n",
      "Loss  5.442078 C_bot  0.15 k_c 0.0\n",
      "2818 Train Loss 15.287018\n",
      "Loss  5.442078 C_bot  0.15 k_c 0.0\n",
      "Loss  0.88480073 C_bot  0.15 k_c 0.0\n",
      "2819 Train Loss 10.736399\n",
      "Loss  0.88480073 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7585135 C_bot  0.15 k_c 0.0\n",
      "2820 Train Loss 13.626522\n",
      "Loss  3.7585135 C_bot  0.15 k_c 0.0\n",
      "Loss  8.13575 C_bot  0.15 k_c 0.0\n",
      "2821 Train Loss 17.926153\n",
      "Loss  8.13575 C_bot  0.15 k_c 0.0\n",
      "Loss  7.2365932 C_bot  0.15 k_c 0.0\n",
      "2822 Train Loss 17.117283\n",
      "Loss  7.2365932 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8013875 C_bot  0.15 k_c 0.0\n",
      "2823 Train Loss 12.596641\n",
      "Loss  2.8013875 C_bot  0.15 k_c 0.0\n",
      "Loss  0.84351885 C_bot  0.15 k_c 0.0\n",
      "2824 Train Loss 10.657045\n",
      "Loss  0.84351885 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0475307 C_bot  0.15 k_c 0.0\n",
      "2825 Train Loss 12.893161\n",
      "Loss  3.0475307 C_bot  0.15 k_c 0.0\n",
      "Loss  5.4181314 C_bot  0.15 k_c 0.0\n",
      "2826 Train Loss 15.182662\n",
      "Loss  5.4181314 C_bot  0.15 k_c 0.0\n",
      "Loss  4.420284 C_bot  0.15 k_c 0.0\n",
      "2827 Train Loss 14.257122\n",
      "Loss  4.420284 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7743936 C_bot  0.15 k_c 0.0\n",
      "2828 Train Loss 11.536521\n",
      "Loss  1.7743936 C_bot  0.15 k_c 0.0\n",
      "Loss  0.834099 C_bot  0.15 k_c 0.0\n",
      "2829 Train Loss 10.598862\n",
      "Loss  0.834099 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2549877 C_bot  0.15 k_c 0.0\n",
      "2830 Train Loss 12.038702\n",
      "Loss  2.2549877 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6196306 C_bot  0.15 k_c 0.0\n",
      "2831 Train Loss 13.347849\n",
      "Loss  3.6196306 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9609883 C_bot  0.15 k_c 0.0\n",
      "2832 Train Loss 12.7341385\n",
      "Loss  2.9609883 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3826267 C_bot  0.15 k_c 0.0\n",
      "2833 Train Loss 11.110214\n",
      "Loss  1.3826267 C_bot  0.15 k_c 0.0\n",
      "Loss  0.787626 C_bot  0.15 k_c 0.0\n",
      "2834 Train Loss 10.5162735\n",
      "Loss  0.787626 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5818201 C_bot  0.15 k_c 0.0\n",
      "2835 Train Loss 11.318333\n",
      "Loss  1.5818201 C_bot  0.15 k_c 0.0\n",
      "Loss  2.441587 C_bot  0.15 k_c 0.0\n",
      "2836 Train Loss 12.137333\n",
      "Loss  2.441587 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1606846 C_bot  0.15 k_c 0.0\n",
      "2837 Train Loss 11.885092\n",
      "Loss  2.1606846 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2470332 C_bot  0.15 k_c 0.0\n",
      "2838 Train Loss 10.93535\n",
      "Loss  1.2470332 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7490653 C_bot  0.15 k_c 0.0\n",
      "2839 Train Loss 10.442662\n",
      "Loss  0.7490653 C_bot  0.15 k_c 0.0\n",
      "Loss  1.100204 C_bot  0.15 k_c 0.0\n",
      "2840 Train Loss 10.800039\n",
      "Loss  1.100204 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6776332 C_bot  0.15 k_c 0.0\n",
      "2841 Train Loss 11.351017\n",
      "Loss  1.6776332 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6625088 C_bot  0.15 k_c 0.0\n",
      "2842 Train Loss 11.361811\n",
      "Loss  1.6625088 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1792026 C_bot  0.15 k_c 0.0\n",
      "2843 Train Loss 10.847784\n",
      "Loss  1.1792026 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7617394 C_bot  0.15 k_c 0.0\n",
      "2844 Train Loss 10.436538\n",
      "Loss  0.7617394 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8369834 C_bot  0.15 k_c 0.0\n",
      "2845 Train Loss 10.508093\n",
      "Loss  0.8369834 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1893573 C_bot  0.15 k_c 0.0\n",
      "2846 Train Loss 10.840887\n",
      "Loss  1.1893573 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3159118 C_bot  0.15 k_c 0.0\n",
      "2847 Train Loss 10.982931\n",
      "Loss  1.3159118 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1296786 C_bot  0.15 k_c 0.0\n",
      "2848 Train Loss 10.772295\n",
      "Loss  1.1296786 C_bot  0.15 k_c 0.0\n",
      "Loss  0.81880337 C_bot  0.15 k_c 0.0\n",
      "2849 Train Loss 10.469549\n",
      "Loss  0.81880337 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7332347 C_bot  0.15 k_c 0.0\n",
      "2850 Train Loss 10.376861\n",
      "Loss  0.7332347 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8898418 C_bot  0.15 k_c 0.0\n",
      "2851 Train Loss 10.52356\n",
      "Loss  0.8898418 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0433159 C_bot  0.15 k_c 0.0\n",
      "2852 Train Loss 10.6862545\n",
      "Loss  1.0433159 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0426322 C_bot  0.15 k_c 0.0\n",
      "2853 Train Loss 10.666523\n",
      "Loss  1.0426322 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8679227 C_bot  0.15 k_c 0.0\n",
      "2854 Train Loss 10.500601\n",
      "Loss  0.8679227 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7378531 C_bot  0.15 k_c 0.0\n",
      "2855 Train Loss 10.359756\n",
      "Loss  0.7378531 C_bot  0.15 k_c 0.0\n",
      "Loss  0.74283284 C_bot  0.15 k_c 0.0\n",
      "2856 Train Loss 10.361145\n",
      "Loss  0.74283284 C_bot  0.15 k_c 0.0\n",
      "Loss  0.83638954 C_bot  0.15 k_c 0.0\n",
      "2857 Train Loss 10.458939\n",
      "Loss  0.83638954 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9139903 C_bot  0.15 k_c 0.0\n",
      "2858 Train Loss 10.522596\n",
      "Loss  0.9139903 C_bot  0.15 k_c 0.0\n",
      "Loss  0.866918 C_bot  0.15 k_c 0.0\n",
      "2859 Train Loss 10.48461\n",
      "Loss  0.866918 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7791378 C_bot  0.15 k_c 0.0\n",
      "2860 Train Loss 10.384725\n",
      "Loss  0.7791378 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7119794 C_bot  0.15 k_c 0.0\n",
      "2861 Train Loss 10.319012\n",
      "Loss  0.7119794 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7250722 C_bot  0.15 k_c 0.0\n",
      "2862 Train Loss 10.330215\n",
      "Loss  0.7250722 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7857854 C_bot  0.15 k_c 0.0\n",
      "2863 Train Loss 10.382296\n",
      "Loss  0.7857854 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8095969 C_bot  0.15 k_c 0.0\n",
      "2864 Train Loss 10.411234\n",
      "Loss  0.8095969 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7948156 C_bot  0.15 k_c 0.0\n",
      "2865 Train Loss 10.385176\n",
      "Loss  0.7948156 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73715746 C_bot  0.15 k_c 0.0\n",
      "2866 Train Loss 10.331045\n",
      "Loss  0.73715746 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7050833 C_bot  0.15 k_c 0.0\n",
      "2867 Train Loss 10.293181\n",
      "Loss  0.7050833 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71010935 C_bot  0.15 k_c 0.0\n",
      "2868 Train Loss 10.295132\n",
      "Loss  0.71010935 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73500866 C_bot  0.15 k_c 0.0\n",
      "2869 Train Loss 10.321263\n",
      "Loss  0.73500866 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75976473 C_bot  0.15 k_c 0.0\n",
      "2870 Train Loss 10.33785\n",
      "Loss  0.75976473 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7464418 C_bot  0.15 k_c 0.0\n",
      "2871 Train Loss 10.328262\n",
      "Loss  0.7464418 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7250612 C_bot  0.15 k_c 0.0\n",
      "2872 Train Loss 10.299213\n",
      "Loss  0.7250612 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6990309 C_bot  0.15 k_c 0.0\n",
      "2873 Train Loss 10.273974\n",
      "Loss  0.6990309 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6946916 C_bot  0.15 k_c 0.0\n",
      "2874 Train Loss 10.266936\n",
      "Loss  0.6946916 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70799017 C_bot  0.15 k_c 0.0\n",
      "2875 Train Loss 10.276026\n",
      "Loss  0.70799017 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71753067 C_bot  0.15 k_c 0.0\n",
      "2876 Train Loss 10.2873535\n",
      "Loss  0.71753067 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7243532 C_bot  0.15 k_c 0.0\n",
      "2877 Train Loss 10.287193\n",
      "Loss  0.7243532 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7100625 C_bot  0.15 k_c 0.0\n",
      "2878 Train Loss 10.275144\n",
      "Loss  0.7100625 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69884926 C_bot  0.15 k_c 0.0\n",
      "2879 Train Loss 10.25832\n",
      "Loss  0.69884926 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68854725 C_bot  0.15 k_c 0.0\n",
      "2880 Train Loss 10.247347\n",
      "Loss  0.68854725 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68881947 C_bot  0.15 k_c 0.0\n",
      "2881 Train Loss 10.2457\n",
      "Loss  0.68881947 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69694954 C_bot  0.15 k_c 0.0\n",
      "2882 Train Loss 10.24983\n",
      "Loss  0.69694954 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6995888 C_bot  0.15 k_c 0.0\n",
      "2883 Train Loss 10.253261\n",
      "Loss  0.6995888 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70234287 C_bot  0.15 k_c 0.0\n",
      "2884 Train Loss 10.250715\n",
      "Loss  0.70234287 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69379246 C_bot  0.15 k_c 0.0\n",
      "2885 Train Loss 10.243105\n",
      "Loss  0.69379246 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6885139 C_bot  0.15 k_c 0.0\n",
      "2886 Train Loss 10.233695\n",
      "Loss  0.6885139 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68273526 C_bot  0.15 k_c 0.0\n",
      "2887 Train Loss 10.227085\n",
      "Loss  0.68273526 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6821655 C_bot  0.15 k_c 0.0\n",
      "2888 Train Loss 10.224746\n",
      "Loss  0.6821655 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6855584 C_bot  0.15 k_c 0.0\n",
      "2889 Train Loss 10.225193\n",
      "Loss  0.6855584 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68628937 C_bot  0.15 k_c 0.0\n",
      "2890 Train Loss 10.226003\n",
      "Loss  0.68628937 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6886066 C_bot  0.15 k_c 0.0\n",
      "2891 Train Loss 10.224303\n",
      "Loss  0.6886066 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6841962 C_bot  0.15 k_c 0.0\n",
      "2892 Train Loss 10.220313\n",
      "Loss  0.6841962 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6821448 C_bot  0.15 k_c 0.0\n",
      "2893 Train Loss 10.214694\n",
      "Loss  0.6821448 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6776971 C_bot  0.15 k_c 0.0\n",
      "2894 Train Loss 10.209675\n",
      "Loss  0.6776971 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6763691 C_bot  0.15 k_c 0.0\n",
      "2895 Train Loss 10.206198\n",
      "Loss  0.6763691 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6766733 C_bot  0.15 k_c 0.0\n",
      "2896 Train Loss 10.204454\n",
      "Loss  0.6766733 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67668915 C_bot  0.15 k_c 0.0\n",
      "2897 Train Loss 10.203713\n",
      "Loss  0.67668915 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6785354 C_bot  0.15 k_c 0.0\n",
      "2898 Train Loss 10.202495\n",
      "Loss  0.6785354 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67677957 C_bot  0.15 k_c 0.0\n",
      "2899 Train Loss 10.200633\n",
      "Loss  0.67677957 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6768433 C_bot  0.15 k_c 0.0\n",
      "2900 Train Loss 10.1975565\n",
      "Loss  0.6768433 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6737083 C_bot  0.15 k_c 0.0\n",
      "2901 Train Loss 10.194098\n",
      "Loss  0.6737083 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6725909 C_bot  0.15 k_c 0.0\n",
      "2902 Train Loss 10.1905365\n",
      "Loss  0.6725909 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67093474 C_bot  0.15 k_c 0.0\n",
      "2903 Train Loss 10.187786\n",
      "Loss  0.67093474 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6702438 C_bot  0.15 k_c 0.0\n",
      "2904 Train Loss 10.185623\n",
      "Loss  0.6702438 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67044383 C_bot  0.15 k_c 0.0\n",
      "2905 Train Loss 10.1839\n",
      "Loss  0.67044383 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6697493 C_bot  0.15 k_c 0.0\n",
      "2906 Train Loss 10.182503\n",
      "Loss  0.6697493 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6703383 C_bot  0.15 k_c 0.0\n",
      "2907 Train Loss 10.180696\n",
      "Loss  0.6703383 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6687699 C_bot  0.15 k_c 0.0\n",
      "2908 Train Loss 10.178725\n",
      "Loss  0.6687699 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6686981 C_bot  0.15 k_c 0.0\n",
      "2909 Train Loss 10.17625\n",
      "Loss  0.6686981 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66683155 C_bot  0.15 k_c 0.0\n",
      "2910 Train Loss 10.173805\n",
      "Loss  0.66683155 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6663079 C_bot  0.15 k_c 0.0\n",
      "2911 Train Loss 10.171238\n",
      "Loss  0.6663079 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66503805 C_bot  0.15 k_c 0.0\n",
      "2912 Train Loss 10.168928\n",
      "Loss  0.66503805 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66446704 C_bot  0.15 k_c 0.0\n",
      "2913 Train Loss 10.166836\n",
      "Loss  0.66446704 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66410273 C_bot  0.15 k_c 0.0\n",
      "2914 Train Loss 10.164944\n",
      "Loss  0.66410273 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66350263 C_bot  0.15 k_c 0.0\n",
      "2915 Train Loss 10.1633005\n",
      "Loss  0.66350263 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66360193 C_bot  0.15 k_c 0.0\n",
      "2916 Train Loss 10.161533\n",
      "Loss  0.66360193 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6626297 C_bot  0.15 k_c 0.0\n",
      "2917 Train Loss 10.159804\n",
      "Loss  0.6626297 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6627548 C_bot  0.15 k_c 0.0\n",
      "2918 Train Loss 10.157947\n",
      "Loss  0.6627548 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6615107 C_bot  0.15 k_c 0.0\n",
      "2919 Train Loss 10.156013\n",
      "Loss  0.6615107 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66138995 C_bot  0.15 k_c 0.0\n",
      "2920 Train Loss 10.154003\n",
      "Loss  0.66138995 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66022193 C_bot  0.15 k_c 0.0\n",
      "2921 Train Loss 10.1520405\n",
      "Loss  0.66022193 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6598937 C_bot  0.15 k_c 0.0\n",
      "2922 Train Loss 10.150051\n",
      "Loss  0.6598937 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65900105 C_bot  0.15 k_c 0.0\n",
      "2923 Train Loss 10.148159\n",
      "Loss  0.65900105 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6585472 C_bot  0.15 k_c 0.0\n",
      "2924 Train Loss 10.14631\n",
      "Loss  0.6585472 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6579775 C_bot  0.15 k_c 0.0\n",
      "2925 Train Loss 10.144511\n",
      "Loss  0.6579775 C_bot  0.15 k_c 0.0\n",
      "Loss  0.657426 C_bot  0.15 k_c 0.0\n",
      "2926 Train Loss 10.142809\n",
      "Loss  0.657426 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6571989 C_bot  0.15 k_c 0.0\n",
      "2927 Train Loss 10.141163\n",
      "Loss  0.6571989 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6564918 C_bot  0.15 k_c 0.0\n",
      "2928 Train Loss 10.139492\n",
      "Loss  0.6564918 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6563911 C_bot  0.15 k_c 0.0\n",
      "2929 Train Loss 10.13785\n",
      "Loss  0.6563911 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65561837 C_bot  0.15 k_c 0.0\n",
      "2930 Train Loss 10.13623\n",
      "Loss  0.65561837 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65551835 C_bot  0.15 k_c 0.0\n",
      "2931 Train Loss 10.134531\n",
      "Loss  0.65551835 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6546792 C_bot  0.15 k_c 0.0\n",
      "2932 Train Loss 10.132902\n",
      "Loss  0.6546792 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65458953 C_bot  0.15 k_c 0.0\n",
      "2933 Train Loss 10.131222\n",
      "Loss  0.65458953 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6537256 C_bot  0.15 k_c 0.0\n",
      "2934 Train Loss 10.129576\n",
      "Loss  0.6537256 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6535704 C_bot  0.15 k_c 0.0\n",
      "2935 Train Loss 10.127882\n",
      "Loss  0.6535704 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6527873 C_bot  0.15 k_c 0.0\n",
      "2936 Train Loss 10.126301\n",
      "Loss  0.6527873 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6526112 C_bot  0.15 k_c 0.0\n",
      "2937 Train Loss 10.124653\n",
      "Loss  0.6526112 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6518451 C_bot  0.15 k_c 0.0\n",
      "2938 Train Loss 10.123055\n",
      "Loss  0.6518451 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6516557 C_bot  0.15 k_c 0.0\n",
      "2939 Train Loss 10.121466\n",
      "Loss  0.6516557 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6509422 C_bot  0.15 k_c 0.0\n",
      "2940 Train Loss 10.119886\n",
      "Loss  0.6509422 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6506737 C_bot  0.15 k_c 0.0\n",
      "2941 Train Loss 10.118277\n",
      "Loss  0.6506737 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6500488 C_bot  0.15 k_c 0.0\n",
      "2942 Train Loss 10.116765\n",
      "Loss  0.6500488 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6498113 C_bot  0.15 k_c 0.0\n",
      "2943 Train Loss 10.115231\n",
      "Loss  0.6498113 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6491908 C_bot  0.15 k_c 0.0\n",
      "2944 Train Loss 10.1137085\n",
      "Loss  0.6491908 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6489703 C_bot  0.15 k_c 0.0\n",
      "2945 Train Loss 10.112221\n",
      "Loss  0.6489703 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64837605 C_bot  0.15 k_c 0.0\n",
      "2946 Train Loss 10.11073\n",
      "Loss  0.64837605 C_bot  0.15 k_c 0.0\n",
      "Loss  0.648122 C_bot  0.15 k_c 0.0\n",
      "2947 Train Loss 10.109221\n",
      "Loss  0.648122 C_bot  0.15 k_c 0.0\n",
      "Loss  0.647551 C_bot  0.15 k_c 0.0\n",
      "2948 Train Loss 10.107773\n",
      "Loss  0.647551 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64730674 C_bot  0.15 k_c 0.0\n",
      "2949 Train Loss 10.106277\n",
      "Loss  0.64730674 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6467911 C_bot  0.15 k_c 0.0\n",
      "2950 Train Loss 10.104916\n",
      "Loss  0.6467911 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6465583 C_bot  0.15 k_c 0.0\n",
      "2951 Train Loss 10.103416\n",
      "Loss  0.6465583 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6460088 C_bot  0.15 k_c 0.0\n",
      "2952 Train Loss 10.102081\n",
      "Loss  0.6460088 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6459116 C_bot  0.15 k_c 0.0\n",
      "2953 Train Loss 10.100671\n",
      "Loss  0.6459116 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64526284 C_bot  0.15 k_c 0.0\n",
      "2954 Train Loss 10.099325\n",
      "Loss  0.64526284 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64530325 C_bot  0.15 k_c 0.0\n",
      "2955 Train Loss 10.097977\n",
      "Loss  0.64530325 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64463 C_bot  0.15 k_c 0.0\n",
      "2956 Train Loss 10.096728\n",
      "Loss  0.64463 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64485896 C_bot  0.15 k_c 0.0\n",
      "2957 Train Loss 10.095438\n",
      "Loss  0.64485896 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6441784 C_bot  0.15 k_c 0.0\n",
      "2958 Train Loss 10.094376\n",
      "Loss  0.6441784 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6448997 C_bot  0.15 k_c 0.0\n",
      "2959 Train Loss 10.093363\n",
      "Loss  0.6448997 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6442162 C_bot  0.15 k_c 0.0\n",
      "2960 Train Loss 10.092588\n",
      "Loss  0.6442162 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6457778 C_bot  0.15 k_c 0.0\n",
      "2961 Train Loss 10.09208\n",
      "Loss  0.6457778 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6455092 C_bot  0.15 k_c 0.0\n",
      "2962 Train Loss 10.09217\n",
      "Loss  0.6455092 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64883083 C_bot  0.15 k_c 0.0\n",
      "2963 Train Loss 10.092877\n",
      "Loss  0.64883083 C_bot  0.15 k_c 0.0\n",
      "Loss  0.650012 C_bot  0.15 k_c 0.0\n",
      "2964 Train Loss 10.095142\n",
      "Loss  0.650012 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6576183 C_bot  0.15 k_c 0.0\n",
      "2965 Train Loss 10.0992365\n",
      "Loss  0.6576183 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66338784 C_bot  0.15 k_c 0.0\n",
      "2966 Train Loss 10.107289\n",
      "Loss  0.66338784 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68167305 C_bot  0.15 k_c 0.0\n",
      "2967 Train Loss 10.120565\n",
      "Loss  0.68167305 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70149624 C_bot  0.15 k_c 0.0\n",
      "2968 Train Loss 10.144688\n",
      "Loss  0.70149624 C_bot  0.15 k_c 0.0\n",
      "Loss  0.749046 C_bot  0.15 k_c 0.0\n",
      "2969 Train Loss 10.1847\n",
      "Loss  0.749046 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8121789 C_bot  0.15 k_c 0.0\n",
      "2970 Train Loss 10.255607\n",
      "Loss  0.8121789 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9441353 C_bot  0.15 k_c 0.0\n",
      "2971 Train Loss 10.375698\n",
      "Loss  0.9441353 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1440282 C_bot  0.15 k_c 0.0\n",
      "2972 Train Loss 10.589537\n",
      "Loss  1.1440282 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5315758 C_bot  0.15 k_c 0.0\n",
      "2973 Train Loss 10.957729\n",
      "Loss  1.5315758 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1717405 C_bot  0.15 k_c 0.0\n",
      "2974 Train Loss 11.623173\n",
      "Loss  2.1717405 C_bot  0.15 k_c 0.0\n",
      "Loss  3.362439 C_bot  0.15 k_c 0.0\n",
      "2975 Train Loss 12.781553\n",
      "Loss  3.362439 C_bot  0.15 k_c 0.0\n",
      "Loss  5.4527955 C_bot  0.15 k_c 0.0\n",
      "2976 Train Loss 14.91893\n",
      "Loss  5.4527955 C_bot  0.15 k_c 0.0\n",
      "Loss  9.230304 C_bot  0.15 k_c 0.0\n",
      "2977 Train Loss 18.641823\n",
      "Loss  9.230304 C_bot  0.15 k_c 0.0\n",
      "Loss  16.159851 C_bot  0.15 k_c 0.0\n",
      "2978 Train Loss 25.663048\n",
      "Loss  16.159851 C_bot  0.15 k_c 0.0\n",
      "Loss  28.167496 C_bot  0.15 k_c 0.0\n",
      "2979 Train Loss 37.577732\n",
      "Loss  28.167496 C_bot  0.15 k_c 0.0\n",
      "Loss  50.7003 C_bot  0.15 k_c 0.0\n",
      "2980 Train Loss 60.302895\n",
      "Loss  50.7003 C_bot  0.15 k_c 0.0\n",
      "Loss  85.93459 C_bot  0.15 k_c 0.0\n",
      "2981 Train Loss 95.371506\n",
      "Loss  85.93459 C_bot  0.15 k_c 0.0\n",
      "Loss  149.40793 C_bot  0.15 k_c 0.0\n",
      "2982 Train Loss 159.2799\n",
      "Loss  149.40793 C_bot  0.15 k_c 0.0\n",
      "Loss  222.49551 C_bot  0.15 k_c 0.0\n",
      "2983 Train Loss 232.00926\n",
      "Loss  222.49551 C_bot  0.15 k_c 0.0\n",
      "Loss  320.86203 C_bot  0.15 k_c 0.0\n",
      "2984 Train Loss 331.29205\n",
      "Loss  320.86203 C_bot  0.15 k_c 0.0\n",
      "Loss  342.49286 C_bot  0.15 k_c 0.0\n",
      "2985 Train Loss 352.06604\n",
      "Loss  342.49286 C_bot  0.15 k_c 0.0\n",
      "Loss  292.537 C_bot  0.15 k_c 0.0\n",
      "2986 Train Loss 303.31604\n",
      "Loss  292.537 C_bot  0.15 k_c 0.0\n",
      "Loss  148.00365 C_bot  0.15 k_c 0.0\n",
      "2987 Train Loss 157.70737\n",
      "Loss  148.00365 C_bot  0.15 k_c 0.0\n",
      "Loss  26.9451 C_bot  0.15 k_c 0.0\n",
      "2988 Train Loss 37.278786\n",
      "Loss  26.9451 C_bot  0.15 k_c 0.0\n",
      "Loss  7.4173484 C_bot  0.15 k_c 0.0\n",
      "2989 Train Loss 17.72445\n",
      "Loss  7.4173484 C_bot  0.15 k_c 0.0\n",
      "Loss  76.87069 C_bot  0.15 k_c 0.0\n",
      "2990 Train Loss 86.86344\n",
      "Loss  76.87069 C_bot  0.15 k_c 0.0\n",
      "Loss  156.09602 C_bot  0.15 k_c 0.0\n",
      "2991 Train Loss 167.07837\n",
      "Loss  156.09602 C_bot  0.15 k_c 0.0\n",
      "Loss  160.72043 C_bot  0.15 k_c 0.0\n",
      "2992 Train Loss 170.73206\n",
      "Loss  160.72043 C_bot  0.15 k_c 0.0\n",
      "Loss  101.85908 C_bot  0.15 k_c 0.0\n",
      "2993 Train Loss 112.64354\n",
      "Loss  101.85908 C_bot  0.15 k_c 0.0\n",
      "Loss  24.390614 C_bot  0.15 k_c 0.0\n",
      "2994 Train Loss 34.57231\n",
      "Loss  24.390614 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4645984 C_bot  0.15 k_c 0.0\n",
      "2995 Train Loss 13.748283\n",
      "Loss  3.4645984 C_bot  0.15 k_c 0.0\n",
      "Loss  41.997776 C_bot  0.15 k_c 0.0\n",
      "2996 Train Loss 52.535736\n",
      "Loss  41.997776 C_bot  0.15 k_c 0.0\n",
      "Loss  80.6308 C_bot  0.15 k_c 0.0\n",
      "2997 Train Loss 90.80448\n",
      "Loss  80.6308 C_bot  0.15 k_c 0.0\n",
      "Loss  74.94327 C_bot  0.15 k_c 0.0\n",
      "2998 Train Loss 85.49717\n",
      "Loss  74.94327 C_bot  0.15 k_c 0.0\n",
      "Loss  30.042603 C_bot  0.15 k_c 0.0\n",
      "2999 Train Loss 40.146595\n",
      "Loss  30.042603 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9070823 C_bot  0.15 k_c 0.0\n",
      "3000 Train Loss 12.051572\n",
      "Loss  1.9070823 C_bot  0.15 k_c 0.0\n",
      "Loss  14.986309 C_bot  0.15 k_c 0.0\n",
      "3001 Train Loss 25.159258\n",
      "Loss  14.986309 C_bot  0.15 k_c 0.0\n",
      "Loss  41.721123 C_bot  0.15 k_c 0.0\n",
      "3002 Train Loss 51.659325\n",
      "Loss  41.721123 C_bot  0.15 k_c 0.0\n",
      "Loss  44.40302 C_bot  0.15 k_c 0.0\n",
      "3003 Train Loss 54.62421\n",
      "Loss  44.40302 C_bot  0.15 k_c 0.0\n",
      "Loss  19.875937 C_bot  0.15 k_c 0.0\n",
      "3004 Train Loss 29.81156\n",
      "Loss  19.875937 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7100374 C_bot  0.15 k_c 0.0\n",
      "3005 Train Loss 11.764069\n",
      "Loss  1.7100374 C_bot  0.15 k_c 0.0\n",
      "Loss  8.638733 C_bot  0.15 k_c 0.0\n",
      "3006 Train Loss 18.756462\n",
      "Loss  8.638733 C_bot  0.15 k_c 0.0\n",
      "Loss  24.605326 C_bot  0.15 k_c 0.0\n",
      "3007 Train Loss 34.548805\n",
      "Loss  24.605326 C_bot  0.15 k_c 0.0\n",
      "Loss  25.690845 C_bot  0.15 k_c 0.0\n",
      "3008 Train Loss 35.817413\n",
      "Loss  25.690845 C_bot  0.15 k_c 0.0\n",
      "Loss  11.247133 C_bot  0.15 k_c 0.0\n",
      "3009 Train Loss 21.137318\n",
      "Loss  11.247133 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2032006 C_bot  0.15 k_c 0.0\n",
      "3010 Train Loss 11.101644\n",
      "Loss  1.2032006 C_bot  0.15 k_c 0.0\n",
      "Loss  6.0462556 C_bot  0.15 k_c 0.0\n",
      "3011 Train Loss 15.940792\n",
      "Loss  6.0462556 C_bot  0.15 k_c 0.0\n",
      "Loss  15.328615 C_bot  0.15 k_c 0.0\n",
      "3012 Train Loss 25.124756\n",
      "Loss  15.328615 C_bot  0.15 k_c 0.0\n",
      "Loss  15.138697 C_bot  0.15 k_c 0.0\n",
      "3013 Train Loss 25.014309\n",
      "Loss  15.138697 C_bot  0.15 k_c 0.0\n",
      "Loss  6.2607307 C_bot  0.15 k_c 0.0\n",
      "3014 Train Loss 16.04114\n",
      "Loss  6.2607307 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9057228 C_bot  0.15 k_c 0.0\n",
      "3015 Train Loss 10.695045\n",
      "Loss  0.9057228 C_bot  0.15 k_c 0.0\n",
      "Loss  4.3434796 C_bot  0.15 k_c 0.0\n",
      "3016 Train Loss 14.1426735\n",
      "Loss  4.3434796 C_bot  0.15 k_c 0.0\n",
      "Loss  9.721832 C_bot  0.15 k_c 0.0\n",
      "3017 Train Loss 19.455574\n",
      "Loss  9.721832 C_bot  0.15 k_c 0.0\n",
      "Loss  9.2051935 C_bot  0.15 k_c 0.0\n",
      "3018 Train Loss 18.99554\n",
      "Loss  9.2051935 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9166534 C_bot  0.15 k_c 0.0\n",
      "3019 Train Loss 13.620938\n",
      "Loss  3.9166534 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8229662 C_bot  0.15 k_c 0.0\n",
      "3020 Train Loss 10.542667\n",
      "Loss  0.8229662 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8803115 C_bot  0.15 k_c 0.0\n",
      "3021 Train Loss 12.62281\n",
      "Loss  2.8803115 C_bot  0.15 k_c 0.0\n",
      "Loss  6.133694 C_bot  0.15 k_c 0.0\n",
      "3022 Train Loss 15.807327\n",
      "Loss  6.133694 C_bot  0.15 k_c 0.0\n",
      "Loss  5.832642 C_bot  0.15 k_c 0.0\n",
      "3023 Train Loss 15.588299\n",
      "Loss  5.832642 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7411351 C_bot  0.15 k_c 0.0\n",
      "3024 Train Loss 12.414957\n",
      "Loss  2.7411351 C_bot  0.15 k_c 0.0\n",
      "Loss  0.78417355 C_bot  0.15 k_c 0.0\n",
      "3025 Train Loss 10.476626\n",
      "Loss  0.78417355 C_bot  0.15 k_c 0.0\n",
      "Loss  1.867891 C_bot  0.15 k_c 0.0\n",
      "3026 Train Loss 11.568236\n",
      "Loss  1.867891 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8555171 C_bot  0.15 k_c 0.0\n",
      "3027 Train Loss 13.494193\n",
      "Loss  3.8555171 C_bot  0.15 k_c 0.0\n",
      "Loss  3.891892 C_bot  0.15 k_c 0.0\n",
      "3028 Train Loss 13.582214\n",
      "Loss  3.891892 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1926537 C_bot  0.15 k_c 0.0\n",
      "3029 Train Loss 11.822695\n",
      "Loss  2.1926537 C_bot  0.15 k_c 0.0\n",
      "Loss  0.814667 C_bot  0.15 k_c 0.0\n",
      "3030 Train Loss 10.45922\n",
      "Loss  0.814667 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1658581 C_bot  0.15 k_c 0.0\n",
      "3031 Train Loss 10.81016\n",
      "Loss  1.1658581 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3804784 C_bot  0.15 k_c 0.0\n",
      "3032 Train Loss 11.992678\n",
      "Loss  2.3804784 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7331676 C_bot  0.15 k_c 0.0\n",
      "3033 Train Loss 12.374738\n",
      "Loss  2.7331676 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9282486 C_bot  0.15 k_c 0.0\n",
      "3034 Train Loss 11.527103\n",
      "Loss  1.9282486 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92482466 C_bot  0.15 k_c 0.0\n",
      "3035 Train Loss 10.534644\n",
      "Loss  0.92482466 C_bot  0.15 k_c 0.0\n",
      "Loss  0.80127853 C_bot  0.15 k_c 0.0\n",
      "3036 Train Loss 10.40184\n",
      "Loss  0.80127853 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4304163 C_bot  0.15 k_c 0.0\n",
      "3037 Train Loss 11.011914\n",
      "Loss  1.4304163 C_bot  0.15 k_c 0.0\n",
      "Loss  1.887924 C_bot  0.15 k_c 0.0\n",
      "3038 Train Loss 11.4927025\n",
      "Loss  1.887924 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7015146 C_bot  0.15 k_c 0.0\n",
      "3039 Train Loss 11.274175\n",
      "Loss  1.7015146 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0694515 C_bot  0.15 k_c 0.0\n",
      "3040 Train Loss 10.660257\n",
      "Loss  1.0694515 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7189478 C_bot  0.15 k_c 0.0\n",
      "3041 Train Loss 10.2954\n",
      "Loss  0.7189478 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8907041 C_bot  0.15 k_c 0.0\n",
      "3042 Train Loss 10.45772\n",
      "Loss  0.8907041 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2536199 C_bot  0.15 k_c 0.0\n",
      "3043 Train Loss 10.832132\n",
      "Loss  1.2536199 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3991367 C_bot  0.15 k_c 0.0\n",
      "3044 Train Loss 10.951212\n",
      "Loss  1.3991367 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1461815 C_bot  0.15 k_c 0.0\n",
      "3045 Train Loss 10.713575\n",
      "Loss  1.1461815 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8272715 C_bot  0.15 k_c 0.0\n",
      "3046 Train Loss 10.376317\n",
      "Loss  0.8272715 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7040677 C_bot  0.15 k_c 0.0\n",
      "3047 Train Loss 10.25316\n",
      "Loss  0.7040677 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8393252 C_bot  0.15 k_c 0.0\n",
      "3048 Train Loss 10.390652\n",
      "Loss  0.8393252 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0453444 C_bot  0.15 k_c 0.0\n",
      "3049 Train Loss 10.5814495\n",
      "Loss  1.0453444 C_bot  0.15 k_c 0.0\n",
      "Loss  1.066504 C_bot  0.15 k_c 0.0\n",
      "3050 Train Loss 10.614607\n",
      "Loss  1.066504 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93202406 C_bot  0.15 k_c 0.0\n",
      "3051 Train Loss 10.462669\n",
      "Loss  0.93202406 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7470102 C_bot  0.15 k_c 0.0\n",
      "3052 Train Loss 10.28345\n",
      "Loss  0.7470102 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69085747 C_bot  0.15 k_c 0.0\n",
      "3053 Train Loss 10.221485\n",
      "Loss  0.69085747 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7684562 C_bot  0.15 k_c 0.0\n",
      "3054 Train Loss 10.292197\n",
      "Loss  0.7684562 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8635577 C_bot  0.15 k_c 0.0\n",
      "3055 Train Loss 10.394236\n",
      "Loss  0.8635577 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9005713 C_bot  0.15 k_c 0.0\n",
      "3056 Train Loss 10.4170685\n",
      "Loss  0.9005713 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8200077 C_bot  0.15 k_c 0.0\n",
      "3057 Train Loss 10.345335\n",
      "Loss  0.8200077 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7289917 C_bot  0.15 k_c 0.0\n",
      "3058 Train Loss 10.243988\n",
      "Loss  0.7289917 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6785151 C_bot  0.15 k_c 0.0\n",
      "3059 Train Loss 10.1941395\n",
      "Loss  0.6785151 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7009586 C_bot  0.15 k_c 0.0\n",
      "3060 Train Loss 10.215849\n",
      "Loss  0.7009586 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7617779 C_bot  0.15 k_c 0.0\n",
      "3061 Train Loss 10.268238\n",
      "Loss  0.7617779 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7850849 C_bot  0.15 k_c 0.0\n",
      "3062 Train Loss 10.296867\n",
      "Loss  0.7850849 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7731624 C_bot  0.15 k_c 0.0\n",
      "3063 Train Loss 10.274215\n",
      "Loss  0.7731624 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7171421 C_bot  0.15 k_c 0.0\n",
      "3064 Train Loss 10.22228\n",
      "Loss  0.7171421 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67972493 C_bot  0.15 k_c 0.0\n",
      "3065 Train Loss 10.178661\n",
      "Loss  0.67972493 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67192703 C_bot  0.15 k_c 0.0\n",
      "3066 Train Loss 10.169151\n",
      "Loss  0.67192703 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6907718 C_bot  0.15 k_c 0.0\n",
      "3067 Train Loss 10.188263\n",
      "Loss  0.6907718 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7207461 C_bot  0.15 k_c 0.0\n",
      "3068 Train Loss 10.211342\n",
      "Loss  0.7207461 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7232066 C_bot  0.15 k_c 0.0\n",
      "3069 Train Loss 10.217538\n",
      "Loss  0.7232066 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71356034 C_bot  0.15 k_c 0.0\n",
      "3070 Train Loss 10.200026\n",
      "Loss  0.71356034 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6835627 C_bot  0.15 k_c 0.0\n",
      "3071 Train Loss 10.17266\n",
      "Loss  0.6835627 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66671836 C_bot  0.15 k_c 0.0\n",
      "3072 Train Loss 10.15121\n",
      "Loss  0.66671836 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66250426 C_bot  0.15 k_c 0.0\n",
      "3073 Train Loss 10.145501\n",
      "Loss  0.66250426 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6700908 C_bot  0.15 k_c 0.0\n",
      "3074 Train Loss 10.152967\n",
      "Loss  0.6700908 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6854035 C_bot  0.15 k_c 0.0\n",
      "3075 Train Loss 10.162962\n",
      "Loss  0.6854035 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6866069 C_bot  0.15 k_c 0.0\n",
      "3076 Train Loss 10.166504\n",
      "Loss  0.6866069 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68552274 C_bot  0.15 k_c 0.0\n",
      "3077 Train Loss 10.159179\n",
      "Loss  0.68552274 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67058253 C_bot  0.15 k_c 0.0\n",
      "3078 Train Loss 10.145949\n",
      "Loss  0.67058253 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66160405 C_bot  0.15 k_c 0.0\n",
      "3079 Train Loss 10.132607\n",
      "Loss  0.66160405 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6549523 C_bot  0.15 k_c 0.0\n",
      "3080 Train Loss 10.125127\n",
      "Loss  0.6549523 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65550995 C_bot  0.15 k_c 0.0\n",
      "3081 Train Loss 10.12425\n",
      "Loss  0.65550995 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6618316 C_bot  0.15 k_c 0.0\n",
      "3082 Train Loss 10.1272545\n",
      "Loss  0.6618316 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6640201 C_bot  0.15 k_c 0.0\n",
      "3083 Train Loss 10.130141\n",
      "Loss  0.6640201 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6675692 C_bot  0.15 k_c 0.0\n",
      "3084 Train Loss 10.129249\n",
      "Loss  0.6675692 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6619693 C_bot  0.15 k_c 0.0\n",
      "3085 Train Loss 10.12479\n",
      "Loss  0.6619693 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65867954 C_bot  0.15 k_c 0.0\n",
      "3086 Train Loss 10.117525\n",
      "Loss  0.65867954 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6515982 C_bot  0.15 k_c 0.0\n",
      "3087 Train Loss 10.110584\n",
      "Loss  0.6515982 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64895785 C_bot  0.15 k_c 0.0\n",
      "3088 Train Loss 10.1054945\n",
      "Loss  0.64895785 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6480716 C_bot  0.15 k_c 0.0\n",
      "3089 Train Loss 10.1031275\n",
      "Loss  0.6480716 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64838725 C_bot  0.15 k_c 0.0\n",
      "3090 Train Loss 10.102691\n",
      "Loss  0.64838725 C_bot  0.15 k_c 0.0\n",
      "Loss  0.651302 C_bot  0.15 k_c 0.0\n",
      "3091 Train Loss 10.102755\n",
      "Loss  0.651302 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65063685 C_bot  0.15 k_c 0.0\n",
      "3092 Train Loss 10.102381\n",
      "Loss  0.65063685 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65208757 C_bot  0.15 k_c 0.0\n",
      "3093 Train Loss 10.100397\n",
      "Loss  0.65208757 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64852333 C_bot  0.15 k_c 0.0\n",
      "3094 Train Loss 10.097228\n",
      "Loss  0.64852333 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64763415 C_bot  0.15 k_c 0.0\n",
      "3095 Train Loss 10.093224\n",
      "Loss  0.64763415 C_bot  0.15 k_c 0.0\n",
      "Loss  0.643894 C_bot  0.15 k_c 0.0\n",
      "3096 Train Loss 10.089282\n",
      "Loss  0.643894 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6426781 C_bot  0.15 k_c 0.0\n",
      "3097 Train Loss 10.085867\n",
      "Loss  0.6426781 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6412608 C_bot  0.15 k_c 0.0\n",
      "3098 Train Loss 10.083336\n",
      "Loss  0.6412608 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64067894 C_bot  0.15 k_c 0.0\n",
      "3099 Train Loss 10.08157\n",
      "Loss  0.64067894 C_bot  0.15 k_c 0.0\n",
      "Loss  0.641292 C_bot  0.15 k_c 0.0\n",
      "3100 Train Loss 10.080243\n",
      "Loss  0.641292 C_bot  0.15 k_c 0.0\n",
      "Loss  0.640685 C_bot  0.15 k_c 0.0\n",
      "3101 Train Loss 10.0792055\n",
      "Loss  0.640685 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64169675 C_bot  0.15 k_c 0.0\n",
      "3102 Train Loss 10.077797\n",
      "Loss  0.64169675 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6401716 C_bot  0.15 k_c 0.0\n",
      "3103 Train Loss 10.076202\n",
      "Loss  0.6401716 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64048374 C_bot  0.15 k_c 0.0\n",
      "3104 Train Loss 10.074015\n",
      "Loss  0.64048374 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6382631 C_bot  0.15 k_c 0.0\n",
      "3105 Train Loss 10.07168\n",
      "Loss  0.6382631 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63794935 C_bot  0.15 k_c 0.0\n",
      "3106 Train Loss 10.069105\n",
      "Loss  0.63794935 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63598806 C_bot  0.15 k_c 0.0\n",
      "3107 Train Loss 10.066695\n",
      "Loss  0.63598806 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63548976 C_bot  0.15 k_c 0.0\n",
      "3108 Train Loss 10.064348\n",
      "Loss  0.63548976 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63424486 C_bot  0.15 k_c 0.0\n",
      "3109 Train Loss 10.062222\n",
      "Loss  0.63424486 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63371164 C_bot  0.15 k_c 0.0\n",
      "3110 Train Loss 10.060303\n",
      "Loss  0.63371164 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63324845 C_bot  0.15 k_c 0.0\n",
      "3111 Train Loss 10.05854\n",
      "Loss  0.63324845 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6326413 C_bot  0.15 k_c 0.0\n",
      "3112 Train Loss 10.056956\n",
      "Loss  0.6326413 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63268286 C_bot  0.15 k_c 0.0\n",
      "3113 Train Loss 10.055381\n",
      "Loss  0.63268286 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63185376 C_bot  0.15 k_c 0.0\n",
      "3114 Train Loss 10.053874\n",
      "Loss  0.63185376 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6321108 C_bot  0.15 k_c 0.0\n",
      "3115 Train Loss 10.052326\n",
      "Loss  0.6321108 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63103276 C_bot  0.15 k_c 0.0\n",
      "3116 Train Loss 10.050762\n",
      "Loss  0.63103276 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6312599 C_bot  0.15 k_c 0.0\n",
      "3117 Train Loss 10.04911\n",
      "Loss  0.6312599 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63005096 C_bot  0.15 k_c 0.0\n",
      "3118 Train Loss 10.047503\n",
      "Loss  0.63005096 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6302495 C_bot  0.15 k_c 0.0\n",
      "3119 Train Loss 10.045826\n",
      "Loss  0.6302495 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62903553 C_bot  0.15 k_c 0.0\n",
      "3120 Train Loss 10.0442295\n",
      "Loss  0.62903553 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62913895 C_bot  0.15 k_c 0.0\n",
      "3121 Train Loss 10.042496\n",
      "Loss  0.62913895 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62787014 C_bot  0.15 k_c 0.0\n",
      "3122 Train Loss 10.040825\n",
      "Loss  0.62787014 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62796456 C_bot  0.15 k_c 0.0\n",
      "3123 Train Loss 10.039147\n",
      "Loss  0.62796456 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62683153 C_bot  0.15 k_c 0.0\n",
      "3124 Train Loss 10.037577\n",
      "Loss  0.62683153 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6268215 C_bot  0.15 k_c 0.0\n",
      "3125 Train Loss 10.035852\n",
      "Loss  0.6268215 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6257913 C_bot  0.15 k_c 0.0\n",
      "3126 Train Loss 10.034351\n",
      "Loss  0.6257913 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6258189 C_bot  0.15 k_c 0.0\n",
      "3127 Train Loss 10.032709\n",
      "Loss  0.6258189 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6248095 C_bot  0.15 k_c 0.0\n",
      "3128 Train Loss 10.031221\n",
      "Loss  0.6248095 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62492883 C_bot  0.15 k_c 0.0\n",
      "3129 Train Loss 10.029696\n",
      "Loss  0.62492883 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62398165 C_bot  0.15 k_c 0.0\n",
      "3130 Train Loss 10.028301\n",
      "Loss  0.62398165 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6241246 C_bot  0.15 k_c 0.0\n",
      "3131 Train Loss 10.026787\n",
      "Loss  0.6241246 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6231627 C_bot  0.15 k_c 0.0\n",
      "3132 Train Loss 10.025453\n",
      "Loss  0.6231627 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6235022 C_bot  0.15 k_c 0.0\n",
      "3133 Train Loss 10.024067\n",
      "Loss  0.6235022 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6225989 C_bot  0.15 k_c 0.0\n",
      "3134 Train Loss 10.022926\n",
      "Loss  0.6225989 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62329113 C_bot  0.15 k_c 0.0\n",
      "3135 Train Loss 10.021755\n",
      "Loss  0.62329113 C_bot  0.15 k_c 0.0\n",
      "Loss  0.622438 C_bot  0.15 k_c 0.0\n",
      "3136 Train Loss 10.020881\n",
      "Loss  0.622438 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62367046 C_bot  0.15 k_c 0.0\n",
      "3137 Train Loss 10.020016\n",
      "Loss  0.62367046 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62311435 C_bot  0.15 k_c 0.0\n",
      "3138 Train Loss 10.019767\n",
      "Loss  0.62311435 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6255157 C_bot  0.15 k_c 0.0\n",
      "3139 Train Loss 10.019685\n",
      "Loss  0.6255157 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6256142 C_bot  0.15 k_c 0.0\n",
      "3140 Train Loss 10.0206\n",
      "Loss  0.6256142 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6304077 C_bot  0.15 k_c 0.0\n",
      "3141 Train Loss 10.022306\n",
      "Loss  0.6304077 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6326035 C_bot  0.15 k_c 0.0\n",
      "3142 Train Loss 10.026104\n",
      "Loss  0.6326035 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6424867 C_bot  0.15 k_c 0.0\n",
      "3143 Train Loss 10.031954\n",
      "Loss  0.6424867 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65023303 C_bot  0.15 k_c 0.0\n",
      "3144 Train Loss 10.042543\n",
      "Loss  0.65023303 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6723841 C_bot  0.15 k_c 0.0\n",
      "3145 Train Loss 10.059143\n",
      "Loss  0.6723841 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69571793 C_bot  0.15 k_c 0.0\n",
      "3146 Train Loss 10.087336\n",
      "Loss  0.69571793 C_bot  0.15 k_c 0.0\n",
      "Loss  0.74838173 C_bot  0.15 k_c 0.0\n",
      "3147 Train Loss 10.131983\n",
      "Loss  0.74838173 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8156462 C_bot  0.15 k_c 0.0\n",
      "3148 Train Loss 10.207445\n",
      "Loss  0.8156462 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94936216 C_bot  0.15 k_c 0.0\n",
      "3149 Train Loss 10.329094\n",
      "Loss  0.94936216 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1431779 C_bot  0.15 k_c 0.0\n",
      "3150 Train Loss 10.536802\n",
      "Loss  1.1431779 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5033536 C_bot  0.15 k_c 0.0\n",
      "3151 Train Loss 10.878162\n",
      "Loss  1.5033536 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0725646 C_bot  0.15 k_c 0.0\n",
      "3152 Train Loss 11.471307\n",
      "Loss  2.0725646 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0902903 C_bot  0.15 k_c 0.0\n",
      "3153 Train Loss 12.458919\n",
      "Loss  3.0902903 C_bot  0.15 k_c 0.0\n",
      "Loss  4.8017087 C_bot  0.15 k_c 0.0\n",
      "3154 Train Loss 14.212757\n",
      "Loss  4.8017087 C_bot  0.15 k_c 0.0\n",
      "Loss  7.776929 C_bot  0.15 k_c 0.0\n",
      "3155 Train Loss 17.138948\n",
      "Loss  7.776929 C_bot  0.15 k_c 0.0\n",
      "Loss  13.011299 C_bot  0.15 k_c 0.0\n",
      "3156 Train Loss 22.45194\n",
      "Loss  13.011299 C_bot  0.15 k_c 0.0\n",
      "Loss  21.751127 C_bot  0.15 k_c 0.0\n",
      "3157 Train Loss 31.110802\n",
      "Loss  21.751127 C_bot  0.15 k_c 0.0\n",
      "Loss  37.49786 C_bot  0.15 k_c 0.0\n",
      "3158 Train Loss 47.01306\n",
      "Loss  37.49786 C_bot  0.15 k_c 0.0\n",
      "Loss  61.43742 C_bot  0.15 k_c 0.0\n",
      "3159 Train Loss 70.813\n",
      "Loss  61.43742 C_bot  0.15 k_c 0.0\n",
      "Loss  103.16397 C_bot  0.15 k_c 0.0\n",
      "3160 Train Loss 112.86856\n",
      "Loss  103.16397 C_bot  0.15 k_c 0.0\n",
      "Loss  151.91426 C_bot  0.15 k_c 0.0\n",
      "3161 Train Loss 161.33987\n",
      "Loss  151.91426 C_bot  0.15 k_c 0.0\n",
      "Loss  218.91585 C_bot  0.15 k_c 0.0\n",
      "3162 Train Loss 229.0085\n",
      "Loss  218.91585 C_bot  0.15 k_c 0.0\n",
      "Loss  244.36472 C_bot  0.15 k_c 0.0\n",
      "3163 Train Loss 253.83833\n",
      "Loss  244.36472 C_bot  0.15 k_c 0.0\n",
      "Loss  228.8527 C_bot  0.15 k_c 0.0\n",
      "3164 Train Loss 239.26349\n",
      "Loss  228.8527 C_bot  0.15 k_c 0.0\n",
      "Loss  139.73167 C_bot  0.15 k_c 0.0\n",
      "3165 Train Loss 149.28915\n",
      "Loss  139.73167 C_bot  0.15 k_c 0.0\n",
      "Loss  43.60162 C_bot  0.15 k_c 0.0\n",
      "3166 Train Loss 53.765087\n",
      "Loss  43.60162 C_bot  0.15 k_c 0.0\n",
      "Loss  1.742282 C_bot  0.15 k_c 0.0\n",
      "3167 Train Loss 11.695831\n",
      "Loss  1.742282 C_bot  0.15 k_c 0.0\n",
      "Loss  29.934015 C_bot  0.15 k_c 0.0\n",
      "3168 Train Loss 39.79692\n",
      "Loss  29.934015 C_bot  0.15 k_c 0.0\n",
      "Loss  87.34392 C_bot  0.15 k_c 0.0\n",
      "3169 Train Loss 97.84128\n",
      "Loss  87.34392 C_bot  0.15 k_c 0.0\n",
      "Loss  114.723076 C_bot  0.15 k_c 0.0\n",
      "3170 Train Loss 124.60742\n",
      "Loss  114.723076 C_bot  0.15 k_c 0.0\n",
      "Loss  95.51972 C_bot  0.15 k_c 0.0\n",
      "3171 Train Loss 106.05297\n",
      "Loss  95.51972 C_bot  0.15 k_c 0.0\n",
      "Loss  41.25407 C_bot  0.15 k_c 0.0\n",
      "3172 Train Loss 51.259087\n",
      "Loss  41.25407 C_bot  0.15 k_c 0.0\n",
      "Loss  4.4185677 C_bot  0.15 k_c 0.0\n",
      "3173 Train Loss 14.610041\n",
      "Loss  4.4185677 C_bot  0.15 k_c 0.0\n",
      "Loss  9.234802 C_bot  0.15 k_c 0.0\n",
      "3174 Train Loss 19.446667\n",
      "Loss  9.234802 C_bot  0.15 k_c 0.0\n",
      "Loss  39.188175 C_bot  0.15 k_c 0.0\n",
      "3175 Train Loss 49.217876\n",
      "Loss  39.188175 C_bot  0.15 k_c 0.0\n",
      "Loss  58.968887 C_bot  0.15 k_c 0.0\n",
      "3176 Train Loss 69.27266\n",
      "Loss  58.968887 C_bot  0.15 k_c 0.0\n",
      "Loss  45.82417 C_bot  0.15 k_c 0.0\n",
      "3177 Train Loss 55.760735\n",
      "Loss  45.82417 C_bot  0.15 k_c 0.0\n",
      "Loss  17.582386 C_bot  0.15 k_c 0.0\n",
      "3178 Train Loss 27.648067\n",
      "Loss  17.582386 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3216949 C_bot  0.15 k_c 0.0\n",
      "3179 Train Loss 11.235086\n",
      "Loss  1.3216949 C_bot  0.15 k_c 0.0\n",
      "Loss  9.400295 C_bot  0.15 k_c 0.0\n",
      "3180 Train Loss 19.253372\n",
      "Loss  9.400295 C_bot  0.15 k_c 0.0\n",
      "Loss  26.687141 C_bot  0.15 k_c 0.0\n",
      "3181 Train Loss 36.721043\n",
      "Loss  26.687141 C_bot  0.15 k_c 0.0\n",
      "Loss  30.888489 C_bot  0.15 k_c 0.0\n",
      "3182 Train Loss 40.71774\n",
      "Loss  30.888489 C_bot  0.15 k_c 0.0\n",
      "Loss  18.832203 C_bot  0.15 k_c 0.0\n",
      "3183 Train Loss 28.854837\n",
      "Loss  18.832203 C_bot  0.15 k_c 0.0\n",
      "Loss  4.309179 C_bot  0.15 k_c 0.0\n",
      "3184 Train Loss 14.175869\n",
      "Loss  4.309179 C_bot  0.15 k_c 0.0\n",
      "Loss  2.04492 C_bot  0.15 k_c 0.0\n",
      "3185 Train Loss 11.897417\n",
      "Loss  2.04492 C_bot  0.15 k_c 0.0\n",
      "Loss  10.926322 C_bot  0.15 k_c 0.0\n",
      "3186 Train Loss 20.82109\n",
      "Loss  10.926322 C_bot  0.15 k_c 0.0\n",
      "Loss  18.021074 C_bot  0.15 k_c 0.0\n",
      "3187 Train Loss 27.776384\n",
      "Loss  18.021074 C_bot  0.15 k_c 0.0\n",
      "Loss  15.011015 C_bot  0.15 k_c 0.0\n",
      "3188 Train Loss 24.837626\n",
      "Loss  15.011015 C_bot  0.15 k_c 0.0\n",
      "Loss  5.941107 C_bot  0.15 k_c 0.0\n",
      "3189 Train Loss 15.664507\n",
      "Loss  5.941107 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0127494 C_bot  0.15 k_c 0.0\n",
      "3190 Train Loss 10.74054\n",
      "Loss  1.0127494 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8976989 C_bot  0.15 k_c 0.0\n",
      "3191 Train Loss 13.631752\n",
      "Loss  3.8976989 C_bot  0.15 k_c 0.0\n",
      "Loss  9.286344 C_bot  0.15 k_c 0.0\n",
      "3192 Train Loss 18.97465\n",
      "Loss  9.286344 C_bot  0.15 k_c 0.0\n",
      "Loss  10.369686 C_bot  0.15 k_c 0.0\n",
      "3193 Train Loss 20.09999\n",
      "Loss  10.369686 C_bot  0.15 k_c 0.0\n",
      "Loss  6.144216 C_bot  0.15 k_c 0.0\n",
      "3194 Train Loss 15.798485\n",
      "Loss  6.144216 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6253144 C_bot  0.15 k_c 0.0\n",
      "3195 Train Loss 11.293619\n",
      "Loss  1.6253144 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2134658 C_bot  0.15 k_c 0.0\n",
      "3196 Train Loss 10.869439\n",
      "Loss  1.2134658 C_bot  0.15 k_c 0.0\n",
      "Loss  4.138802 C_bot  0.15 k_c 0.0\n",
      "3197 Train Loss 13.757288\n",
      "Loss  4.138802 C_bot  0.15 k_c 0.0\n",
      "Loss  6.258672 C_bot  0.15 k_c 0.0\n",
      "3198 Train Loss 15.943504\n",
      "Loss  6.258672 C_bot  0.15 k_c 0.0\n",
      "Loss  5.271699 C_bot  0.15 k_c 0.0\n",
      "3199 Train Loss 14.876235\n",
      "Loss  5.271699 C_bot  0.15 k_c 0.0\n",
      "Loss  2.418802 C_bot  0.15 k_c 0.0\n",
      "3200 Train Loss 12.073168\n",
      "Loss  2.418802 C_bot  0.15 k_c 0.0\n",
      "Loss  0.79949224 C_bot  0.15 k_c 0.0\n",
      "3201 Train Loss 10.420174\n",
      "Loss  0.79949224 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5803447 C_bot  0.15 k_c 0.0\n",
      "3202 Train Loss 11.181918\n",
      "Loss  1.5803447 C_bot  0.15 k_c 0.0\n",
      "Loss  3.275439 C_bot  0.15 k_c 0.0\n",
      "3203 Train Loss 12.913391\n",
      "Loss  3.275439 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8783479 C_bot  0.15 k_c 0.0\n",
      "3204 Train Loss 13.452512\n",
      "Loss  3.8783479 C_bot  0.15 k_c 0.0\n",
      "Loss  2.748505 C_bot  0.15 k_c 0.0\n",
      "3205 Train Loss 12.363732\n",
      "Loss  2.748505 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2725072 C_bot  0.15 k_c 0.0\n",
      "3206 Train Loss 10.846897\n",
      "Loss  1.2725072 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7581133 C_bot  0.15 k_c 0.0\n",
      "3207 Train Loss 10.334758\n",
      "Loss  0.7581133 C_bot  0.15 k_c 0.0\n",
      "Loss  1.417853 C_bot  0.15 k_c 0.0\n",
      "3208 Train Loss 11.001717\n",
      "Loss  1.417853 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3248487 C_bot  0.15 k_c 0.0\n",
      "3209 Train Loss 11.87553\n",
      "Loss  2.3248487 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4308867 C_bot  0.15 k_c 0.0\n",
      "3210 Train Loss 12.006428\n",
      "Loss  2.4308867 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7668724 C_bot  0.15 k_c 0.0\n",
      "3211 Train Loss 11.303913\n",
      "Loss  1.7668724 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9610692 C_bot  0.15 k_c 0.0\n",
      "3212 Train Loss 10.508563\n",
      "Loss  0.9610692 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7358047 C_bot  0.15 k_c 0.0\n",
      "3213 Train Loss 10.271949\n",
      "Loss  0.7358047 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1068803 C_bot  0.15 k_c 0.0\n",
      "3214 Train Loss 10.629541\n",
      "Loss  1.1068803 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5616856 C_bot  0.15 k_c 0.0\n",
      "3215 Train Loss 11.101765\n",
      "Loss  1.5616856 C_bot  0.15 k_c 0.0\n",
      "Loss  1.68811 C_bot  0.15 k_c 0.0\n",
      "3216 Train Loss 11.198925\n",
      "Loss  1.68811 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3398267 C_bot  0.15 k_c 0.0\n",
      "3217 Train Loss 10.869972\n",
      "Loss  1.3398267 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91524637 C_bot  0.15 k_c 0.0\n",
      "3218 Train Loss 10.422953\n",
      "Loss  0.91524637 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70853853 C_bot  0.15 k_c 0.0\n",
      "3219 Train Loss 10.217112\n",
      "Loss  0.70853853 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8261848 C_bot  0.15 k_c 0.0\n",
      "3220 Train Loss 10.334187\n",
      "Loss  0.8261848 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0950813 C_bot  0.15 k_c 0.0\n",
      "3221 Train Loss 10.586617\n",
      "Loss  1.0950813 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2225168 C_bot  0.15 k_c 0.0\n",
      "3222 Train Loss 10.726803\n",
      "Loss  1.2225168 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1517315 C_bot  0.15 k_c 0.0\n",
      "3223 Train Loss 10.635279\n",
      "Loss  1.1517315 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9160975 C_bot  0.15 k_c 0.0\n",
      "3224 Train Loss 10.409411\n",
      "Loss  0.9160975 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7385666 C_bot  0.15 k_c 0.0\n",
      "3225 Train Loss 10.220298\n",
      "Loss  0.7385666 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70222205 C_bot  0.15 k_c 0.0\n",
      "3226 Train Loss 10.18201\n",
      "Loss  0.70222205 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7939201 C_bot  0.15 k_c 0.0\n",
      "3227 Train Loss 10.27538\n",
      "Loss  0.7939201 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9238251 C_bot  0.15 k_c 0.0\n",
      "3228 Train Loss 10.392875\n",
      "Loss  0.9238251 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95811427 C_bot  0.15 k_c 0.0\n",
      "3229 Train Loss 10.436119\n",
      "Loss  0.95811427 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9097572 C_bot  0.15 k_c 0.0\n",
      "3230 Train Loss 10.373064\n",
      "Loss  0.9097572 C_bot  0.15 k_c 0.0\n",
      "Loss  0.78914684 C_bot  0.15 k_c 0.0\n",
      "3231 Train Loss 10.259268\n",
      "Loss  0.78914684 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70502174 C_bot  0.15 k_c 0.0\n",
      "3232 Train Loss 10.166843\n",
      "Loss  0.70502174 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6820272 C_bot  0.15 k_c 0.0\n",
      "3233 Train Loss 10.142841\n",
      "Loss  0.6820272 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71887726 C_bot  0.15 k_c 0.0\n",
      "3234 Train Loss 10.1805525\n",
      "Loss  0.71887726 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7834283 C_bot  0.15 k_c 0.0\n",
      "3235 Train Loss 10.2363615\n",
      "Loss  0.7834283 C_bot  0.15 k_c 0.0\n",
      "Loss  0.80753046 C_bot  0.15 k_c 0.0\n",
      "3236 Train Loss 10.26646\n",
      "Loss  0.80753046 C_bot  0.15 k_c 0.0\n",
      "Loss  0.80186564 C_bot  0.15 k_c 0.0\n",
      "3237 Train Loss 10.249499\n",
      "Loss  0.80186564 C_bot  0.15 k_c 0.0\n",
      "Loss  0.74828184 C_bot  0.15 k_c 0.0\n",
      "3238 Train Loss 10.200976\n",
      "Loss  0.74828184 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70254415 C_bot  0.15 k_c 0.0\n",
      "3239 Train Loss 10.147451\n",
      "Loss  0.70254415 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67053884 C_bot  0.15 k_c 0.0\n",
      "3240 Train Loss 10.115857\n",
      "Loss  0.67053884 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67104506 C_bot  0.15 k_c 0.0\n",
      "3241 Train Loss 10.114434\n",
      "Loss  0.67104506 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6948837 C_bot  0.15 k_c 0.0\n",
      "3242 Train Loss 10.133507\n",
      "Loss  0.6948837 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7146632 C_bot  0.15 k_c 0.0\n",
      "3243 Train Loss 10.15596\n",
      "Loss  0.7146632 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73198074 C_bot  0.15 k_c 0.0\n",
      "3244 Train Loss 10.165455\n",
      "Loss  0.73198074 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72030807 C_bot  0.15 k_c 0.0\n",
      "3245 Train Loss 10.15799\n",
      "Loss  0.72030807 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7057408 C_bot  0.15 k_c 0.0\n",
      "3246 Train Loss 10.135998\n",
      "Loss  0.7057408 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6785275 C_bot  0.15 k_c 0.0\n",
      "3247 Train Loss 10.111347\n",
      "Loss  0.6785275 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6639311 C_bot  0.15 k_c 0.0\n",
      "3248 Train Loss 10.092324\n",
      "Loss  0.6639311 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65682393 C_bot  0.15 k_c 0.0\n",
      "3249 Train Loss 10.08432\n",
      "Loss  0.65682393 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65969837 C_bot  0.15 k_c 0.0\n",
      "3250 Train Loss 10.086334\n",
      "Loss  0.65969837 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6710865 C_bot  0.15 k_c 0.0\n",
      "3251 Train Loss 10.0935755\n",
      "Loss  0.6710865 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67639744 C_bot  0.15 k_c 0.0\n",
      "3252 Train Loss 10.100595\n",
      "Loss  0.67639744 C_bot  0.15 k_c 0.0\n",
      "Loss  0.684003 C_bot  0.15 k_c 0.0\n",
      "3253 Train Loss 10.102407\n",
      "Loss  0.684003 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6781273 C_bot  0.15 k_c 0.0\n",
      "3254 Train Loss 10.098941\n",
      "Loss  0.6781273 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6747179 C_bot  0.15 k_c 0.0\n",
      "3255 Train Loss 10.089982\n",
      "Loss  0.6747179 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6626848 C_bot  0.15 k_c 0.0\n",
      "3256 Train Loss 10.079426\n",
      "Loss  0.6626848 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65632534 C_bot  0.15 k_c 0.0\n",
      "3257 Train Loss 10.069072\n",
      "Loss  0.65632534 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6490791 C_bot  0.15 k_c 0.0\n",
      "3258 Train Loss 10.06165\n",
      "Loss  0.6490791 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6469261 C_bot  0.15 k_c 0.0\n",
      "3259 Train Loss 10.057466\n",
      "Loss  0.6469261 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6476271 C_bot  0.15 k_c 0.0\n",
      "3260 Train Loss 10.056261\n",
      "Loss  0.6476271 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6486514 C_bot  0.15 k_c 0.0\n",
      "3261 Train Loss 10.056967\n",
      "Loss  0.6486514 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65283686 C_bot  0.15 k_c 0.0\n",
      "3262 Train Loss 10.057903\n",
      "Loss  0.65283686 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6527504 C_bot  0.15 k_c 0.0\n",
      "3263 Train Loss 10.058586\n",
      "Loss  0.6527504 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65576637 C_bot  0.15 k_c 0.0\n",
      "3264 Train Loss 10.057707\n",
      "Loss  0.65576637 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65252733 C_bot  0.15 k_c 0.0\n",
      "3265 Train Loss 10.055622\n",
      "Loss  0.65252733 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65278053 C_bot  0.15 k_c 0.0\n",
      "3266 Train Loss 10.05197\n",
      "Loss  0.65278053 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6478434 C_bot  0.15 k_c 0.0\n",
      "3267 Train Loss 10.047964\n",
      "Loss  0.6478434 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6466055 C_bot  0.15 k_c 0.0\n",
      "3268 Train Loss 10.043261\n",
      "Loss  0.6466055 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64204764 C_bot  0.15 k_c 0.0\n",
      "3269 Train Loss 10.03902\n",
      "Loss  0.64204764 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64072824 C_bot  0.15 k_c 0.0\n",
      "3270 Train Loss 10.034985\n",
      "Loss  0.64072824 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63779277 C_bot  0.15 k_c 0.0\n",
      "3271 Train Loss 10.03164\n",
      "Loss  0.63779277 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63677037 C_bot  0.15 k_c 0.0\n",
      "3272 Train Loss 10.028721\n",
      "Loss  0.63677037 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6356133 C_bot  0.15 k_c 0.0\n",
      "3273 Train Loss 10.026476\n",
      "Loss  0.6356133 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6349282 C_bot  0.15 k_c 0.0\n",
      "3274 Train Loss 10.024604\n",
      "Loss  0.6349282 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6349457 C_bot  0.15 k_c 0.0\n",
      "3275 Train Loss 10.022968\n",
      "Loss  0.6349457 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6342716 C_bot  0.15 k_c 0.0\n",
      "3276 Train Loss 10.021692\n",
      "Loss  0.6342716 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6349864 C_bot  0.15 k_c 0.0\n",
      "3277 Train Loss 10.0203285\n",
      "Loss  0.6349864 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63397187 C_bot  0.15 k_c 0.0\n",
      "3278 Train Loss 10.019157\n",
      "Loss  0.63397187 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6351286 C_bot  0.15 k_c 0.0\n",
      "3279 Train Loss 10.01793\n",
      "Loss  0.6351286 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63388914 C_bot  0.15 k_c 0.0\n",
      "3280 Train Loss 10.016853\n",
      "Loss  0.63388914 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6353044 C_bot  0.15 k_c 0.0\n",
      "3281 Train Loss 10.015626\n",
      "Loss  0.6353044 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6339749 C_bot  0.15 k_c 0.0\n",
      "3282 Train Loss 10.014725\n",
      "Loss  0.6339749 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63576406 C_bot  0.15 k_c 0.0\n",
      "3283 Train Loss 10.013632\n",
      "Loss  0.63576406 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63445556 C_bot  0.15 k_c 0.0\n",
      "3284 Train Loss 10.013023\n",
      "Loss  0.63445556 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63693947 C_bot  0.15 k_c 0.0\n",
      "3285 Train Loss 10.012365\n",
      "Loss  0.63693947 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6360391 C_bot  0.15 k_c 0.0\n",
      "3286 Train Loss 10.012497\n",
      "Loss  0.6360391 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6396848 C_bot  0.15 k_c 0.0\n",
      "3287 Train Loss 10.012642\n",
      "Loss  0.6396848 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6394789 C_bot  0.15 k_c 0.0\n",
      "3288 Train Loss 10.013944\n",
      "Loss  0.6394789 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6455289 C_bot  0.15 k_c 0.0\n",
      "3289 Train Loss 10.01597\n",
      "Loss  0.6455289 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64740205 C_bot  0.15 k_c 0.0\n",
      "3290 Train Loss 10.020068\n",
      "Loss  0.64740205 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6579265 C_bot  0.15 k_c 0.0\n",
      "3291 Train Loss 10.025774\n",
      "Loss  0.6579265 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6642694 C_bot  0.15 k_c 0.0\n",
      "3292 Train Loss 10.03541\n",
      "Loss  0.6642694 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6841467 C_bot  0.15 k_c 0.0\n",
      "3293 Train Loss 10.049226\n",
      "Loss  0.6841467 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70138866 C_bot  0.15 k_c 0.0\n",
      "3294 Train Loss 10.071404\n",
      "Loss  0.70138866 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7416794 C_bot  0.15 k_c 0.0\n",
      "3295 Train Loss 10.10369\n",
      "Loss  0.7416794 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7855365 C_bot  0.15 k_c 0.0\n",
      "3296 Train Loss 10.15505\n",
      "Loss  0.7855365 C_bot  0.15 k_c 0.0\n",
      "Loss  0.87323844 C_bot  0.15 k_c 0.0\n",
      "3297 Train Loss 10.231712\n",
      "Loss  0.87323844 C_bot  0.15 k_c 0.0\n",
      "Loss  0.98473626 C_bot  0.15 k_c 0.0\n",
      "3298 Train Loss 10.354813\n",
      "Loss  0.98473626 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1889844 C_bot  0.15 k_c 0.0\n",
      "3299 Train Loss 10.543205\n",
      "Loss  1.1889844 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4782513 C_bot  0.15 k_c 0.0\n",
      "3300 Train Loss 10.850824\n",
      "Loss  1.4782513 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9830874 C_bot  0.15 k_c 0.0\n",
      "3301 Train Loss 11.332104\n",
      "Loss  1.9830874 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7563884 C_bot  0.15 k_c 0.0\n",
      "3302 Train Loss 12.135275\n",
      "Loss  2.7563884 C_bot  0.15 k_c 0.0\n",
      "Loss  4.064648 C_bot  0.15 k_c 0.0\n",
      "3303 Train Loss 13.407553\n",
      "Loss  4.064648 C_bot  0.15 k_c 0.0\n",
      "Loss  6.189664 C_bot  0.15 k_c 0.0\n",
      "3304 Train Loss 15.583002\n",
      "Loss  6.189664 C_bot  0.15 k_c 0.0\n",
      "Loss  9.69114 C_bot  0.15 k_c 0.0\n",
      "3305 Train Loss 19.028294\n",
      "Loss  9.69114 C_bot  0.15 k_c 0.0\n",
      "Loss  15.622853 C_bot  0.15 k_c 0.0\n",
      "3306 Train Loss 25.049458\n",
      "Loss  15.622853 C_bot  0.15 k_c 0.0\n",
      "Loss  24.975285 C_bot  0.15 k_c 0.0\n",
      "3307 Train Loss 34.312057\n",
      "Loss  24.975285 C_bot  0.15 k_c 0.0\n",
      "Loss  41.094486 C_bot  0.15 k_c 0.0\n",
      "3308 Train Loss 50.600227\n",
      "Loss  41.094486 C_bot  0.15 k_c 0.0\n",
      "Loss  63.984776 C_bot  0.15 k_c 0.0\n",
      "3309 Train Loss 73.33868\n",
      "Loss  63.984776 C_bot  0.15 k_c 0.0\n",
      "Loss  101.61963 C_bot  0.15 k_c 0.0\n",
      "3310 Train Loss 111.30925\n",
      "Loss  101.61963 C_bot  0.15 k_c 0.0\n",
      "Loss  141.86493 C_bot  0.15 k_c 0.0\n",
      "3311 Train Loss 151.26265\n",
      "Loss  141.86493 C_bot  0.15 k_c 0.0\n",
      "Loss  192.75497 C_bot  0.15 k_c 0.0\n",
      "3312 Train Loss 202.77544\n",
      "Loss  192.75497 C_bot  0.15 k_c 0.0\n",
      "Loss  207.40096 C_bot  0.15 k_c 0.0\n",
      "3313 Train Loss 216.84149\n",
      "Loss  207.40096 C_bot  0.15 k_c 0.0\n",
      "Loss  190.67879 C_bot  0.15 k_c 0.0\n",
      "3314 Train Loss 200.92735\n",
      "Loss  190.67879 C_bot  0.15 k_c 0.0\n",
      "Loss  120.52772 C_bot  0.15 k_c 0.0\n",
      "3315 Train Loss 130.04066\n",
      "Loss  120.52772 C_bot  0.15 k_c 0.0\n",
      "Loss  44.754158 C_bot  0.15 k_c 0.0\n",
      "3316 Train Loss 54.784706\n",
      "Loss  44.754158 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5722146 C_bot  0.15 k_c 0.0\n",
      "3317 Train Loss 13.351116\n",
      "Loss  3.5722146 C_bot  0.15 k_c 0.0\n",
      "Loss  13.589743 C_bot  0.15 k_c 0.0\n",
      "3318 Train Loss 23.355673\n",
      "Loss  13.589743 C_bot  0.15 k_c 0.0\n",
      "Loss  54.042637 C_bot  0.15 k_c 0.0\n",
      "3319 Train Loss 64.21708\n",
      "Loss  54.042637 C_bot  0.15 k_c 0.0\n",
      "Loss  86.03954 C_bot  0.15 k_c 0.0\n",
      "3320 Train Loss 95.81056\n",
      "Loss  86.03954 C_bot  0.15 k_c 0.0\n",
      "Loss  88.274315 C_bot  0.15 k_c 0.0\n",
      "3321 Train Loss 98.568665\n",
      "Loss  88.274315 C_bot  0.15 k_c 0.0\n",
      "Loss  54.91819 C_bot  0.15 k_c 0.0\n",
      "3322 Train Loss 64.765114\n",
      "Loss  54.91819 C_bot  0.15 k_c 0.0\n",
      "Loss  17.664225 C_bot  0.15 k_c 0.0\n",
      "3323 Train Loss 27.728409\n",
      "Loss  17.664225 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2831848 C_bot  0.15 k_c 0.0\n",
      "3324 Train Loss 11.218761\n",
      "Loss  1.2831848 C_bot  0.15 k_c 0.0\n",
      "Loss  12.288291 C_bot  0.15 k_c 0.0\n",
      "3325 Train Loss 22.152386\n",
      "Loss  12.288291 C_bot  0.15 k_c 0.0\n",
      "Loss  34.142902 C_bot  0.15 k_c 0.0\n",
      "3326 Train Loss 44.173557\n",
      "Loss  34.142902 C_bot  0.15 k_c 0.0\n",
      "Loss  43.52509 C_bot  0.15 k_c 0.0\n",
      "3327 Train Loss 53.299904\n",
      "Loss  43.52509 C_bot  0.15 k_c 0.0\n",
      "Loss  33.873795 C_bot  0.15 k_c 0.0\n",
      "3328 Train Loss 43.832413\n",
      "Loss  33.873795 C_bot  0.15 k_c 0.0\n",
      "Loss  13.59717 C_bot  0.15 k_c 0.0\n",
      "3329 Train Loss 23.33132\n",
      "Loss  13.59717 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4214813 C_bot  0.15 k_c 0.0\n",
      "3330 Train Loss 11.209107\n",
      "Loss  1.4214813 C_bot  0.15 k_c 0.0\n",
      "Loss  4.9465556 C_bot  0.15 k_c 0.0\n",
      "3331 Train Loss 14.761002\n",
      "Loss  4.9465556 C_bot  0.15 k_c 0.0\n",
      "Loss  16.571339 C_bot  0.15 k_c 0.0\n",
      "3332 Train Loss 26.290714\n",
      "Loss  16.571339 C_bot  0.15 k_c 0.0\n",
      "Loss  23.186295 C_bot  0.15 k_c 0.0\n",
      "3333 Train Loss 33.073265\n",
      "Loss  23.186295 C_bot  0.15 k_c 0.0\n",
      "Loss  18.308956 C_bot  0.15 k_c 0.0\n",
      "3334 Train Loss 28.010046\n",
      "Loss  18.308956 C_bot  0.15 k_c 0.0\n",
      "Loss  7.7261596 C_bot  0.15 k_c 0.0\n",
      "3335 Train Loss 17.502224\n",
      "Loss  7.7261596 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2309003 C_bot  0.15 k_c 0.0\n",
      "3336 Train Loss 10.917585\n",
      "Loss  1.2309003 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2072148 C_bot  0.15 k_c 0.0\n",
      "3337 Train Loss 12.861046\n",
      "Loss  3.2072148 C_bot  0.15 k_c 0.0\n",
      "Loss  9.467766 C_bot  0.15 k_c 0.0\n",
      "3338 Train Loss 19.163664\n",
      "Loss  9.467766 C_bot  0.15 k_c 0.0\n",
      "Loss  12.801801 C_bot  0.15 k_c 0.0\n",
      "3339 Train Loss 22.42405\n",
      "Loss  12.801801 C_bot  0.15 k_c 0.0\n",
      "Loss  10.239803 C_bot  0.15 k_c 0.0\n",
      "3340 Train Loss 19.91149\n",
      "Loss  10.239803 C_bot  0.15 k_c 0.0\n",
      "Loss  4.522253 C_bot  0.15 k_c 0.0\n",
      "3341 Train Loss 14.127755\n",
      "Loss  4.522253 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9880248 C_bot  0.15 k_c 0.0\n",
      "3342 Train Loss 10.599458\n",
      "Loss  0.9880248 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9877192 C_bot  0.15 k_c 0.0\n",
      "3343 Train Loss 11.595937\n",
      "Loss  1.9877192 C_bot  0.15 k_c 0.0\n",
      "Loss  5.3552923 C_bot  0.15 k_c 0.0\n",
      "3344 Train Loss 14.920387\n",
      "Loss  5.3552923 C_bot  0.15 k_c 0.0\n",
      "Loss  7.2579026 C_bot  0.15 k_c 0.0\n",
      "3345 Train Loss 16.878136\n",
      "Loss  7.2579026 C_bot  0.15 k_c 0.0\n",
      "Loss  6.0228395 C_bot  0.15 k_c 0.0\n",
      "3346 Train Loss 15.569102\n",
      "Loss  6.0228395 C_bot  0.15 k_c 0.0\n",
      "Loss  2.976614 C_bot  0.15 k_c 0.0\n",
      "3347 Train Loss 12.574194\n",
      "Loss  2.976614 C_bot  0.15 k_c 0.0\n",
      "Loss  0.937085 C_bot  0.15 k_c 0.0\n",
      "3348 Train Loss 10.498448\n",
      "Loss  0.937085 C_bot  0.15 k_c 0.0\n",
      "Loss  1.233673 C_bot  0.15 k_c 0.0\n",
      "3349 Train Loss 10.785679\n",
      "Loss  1.233673 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9395735 C_bot  0.15 k_c 0.0\n",
      "3350 Train Loss 12.524387\n",
      "Loss  2.9395735 C_bot  0.15 k_c 0.0\n",
      "Loss  4.2126617 C_bot  0.15 k_c 0.0\n",
      "3351 Train Loss 13.737736\n",
      "Loss  4.2126617 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8205113 C_bot  0.15 k_c 0.0\n",
      "3352 Train Loss 13.396749\n",
      "Loss  3.8205113 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3540397 C_bot  0.15 k_c 0.0\n",
      "3353 Train Loss 11.873741\n",
      "Loss  2.3540397 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0087935 C_bot  0.15 k_c 0.0\n",
      "3354 Train Loss 10.546593\n",
      "Loss  1.0087935 C_bot  0.15 k_c 0.0\n",
      "Loss  0.80731106 C_bot  0.15 k_c 0.0\n",
      "3355 Train Loss 10.334418\n",
      "Loss  0.80731106 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5810127 C_bot  0.15 k_c 0.0\n",
      "3356 Train Loss 11.088463\n",
      "Loss  1.5810127 C_bot  0.15 k_c 0.0\n",
      "Loss  2.40059 C_bot  0.15 k_c 0.0\n",
      "3357 Train Loss 11.931499\n",
      "Loss  2.40059 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6020646 C_bot  0.15 k_c 0.0\n",
      "3358 Train Loss 12.094149\n",
      "Loss  2.6020646 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0165615 C_bot  0.15 k_c 0.0\n",
      "3359 Train Loss 11.531608\n",
      "Loss  2.0165615 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2236596 C_bot  0.15 k_c 0.0\n",
      "3360 Train Loss 10.70846\n",
      "Loss  1.2236596 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75020725 C_bot  0.15 k_c 0.0\n",
      "3361 Train Loss 10.238309\n",
      "Loss  0.75020725 C_bot  0.15 k_c 0.0\n",
      "Loss  0.853313 C_bot  0.15 k_c 0.0\n",
      "3362 Train Loss 10.338685\n",
      "Loss  0.853313 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3029112 C_bot  0.15 k_c 0.0\n",
      "3363 Train Loss 10.770639\n",
      "Loss  1.3029112 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6428947 C_bot  0.15 k_c 0.0\n",
      "3364 Train Loss 11.129688\n",
      "Loss  1.6428947 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6790848 C_bot  0.15 k_c 0.0\n",
      "3365 Train Loss 11.137341\n",
      "Loss  1.6790848 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3506129 C_bot  0.15 k_c 0.0\n",
      "3366 Train Loss 10.827965\n",
      "Loss  1.3506129 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97079915 C_bot  0.15 k_c 0.0\n",
      "3367 Train Loss 10.426063\n",
      "Loss  0.97079915 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73230785 C_bot  0.15 k_c 0.0\n",
      "3368 Train Loss 10.190987\n",
      "Loss  0.73230785 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7530021 C_bot  0.15 k_c 0.0\n",
      "3369 Train Loss 10.20822\n",
      "Loss  0.7530021 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9510101 C_bot  0.15 k_c 0.0\n",
      "3370 Train Loss 10.394005\n",
      "Loss  0.9510101 C_bot  0.15 k_c 0.0\n",
      "Loss  1.134208 C_bot  0.15 k_c 0.0\n",
      "3371 Train Loss 10.587616\n",
      "Loss  1.134208 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2130979 C_bot  0.15 k_c 0.0\n",
      "3372 Train Loss 10.647114\n",
      "Loss  1.2130979 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1066508 C_bot  0.15 k_c 0.0\n",
      "3373 Train Loss 10.5526905\n",
      "Loss  1.1066508 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9392342 C_bot  0.15 k_c 0.0\n",
      "3374 Train Loss 10.369114\n",
      "Loss  0.9392342 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7705242 C_bot  0.15 k_c 0.0\n",
      "3375 Train Loss 10.205498\n",
      "Loss  0.7705242 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7017981 C_bot  0.15 k_c 0.0\n",
      "3376 Train Loss 10.130277\n",
      "Loss  0.7017981 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73330545 C_bot  0.15 k_c 0.0\n",
      "3377 Train Loss 10.157292\n",
      "Loss  0.73330545 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8149594 C_bot  0.15 k_c 0.0\n",
      "3378 Train Loss 10.242447\n",
      "Loss  0.8149594 C_bot  0.15 k_c 0.0\n",
      "Loss  0.903779 C_bot  0.15 k_c 0.0\n",
      "3379 Train Loss 10.319518\n",
      "Loss  0.903779 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92404884 C_bot  0.15 k_c 0.0\n",
      "3380 Train Loss 10.348299\n",
      "Loss  0.92404884 C_bot  0.15 k_c 0.0\n",
      "Loss  0.902609 C_bot  0.15 k_c 0.0\n",
      "3381 Train Loss 10.313602\n",
      "Loss  0.902609 C_bot  0.15 k_c 0.0\n",
      "Loss  0.82178855 C_bot  0.15 k_c 0.0\n",
      "3382 Train Loss 10.240205\n",
      "Loss  0.82178855 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75193006 C_bot  0.15 k_c 0.0\n",
      "3383 Train Loss 10.160834\n",
      "Loss  0.75193006 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69725007 C_bot  0.15 k_c 0.0\n",
      "3384 Train Loss 10.108143\n",
      "Loss  0.69725007 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68526036 C_bot  0.15 k_c 0.0\n",
      "3385 Train Loss 10.092797\n",
      "Loss  0.68526036 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7067806 C_bot  0.15 k_c 0.0\n",
      "3386 Train Loss 10.109962\n",
      "Loss  0.7067806 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73742706 C_bot  0.15 k_c 0.0\n",
      "3387 Train Loss 10.142956\n",
      "Loss  0.73742706 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7735515 C_bot  0.15 k_c 0.0\n",
      "3388 Train Loss 10.170716\n",
      "Loss  0.7735515 C_bot  0.15 k_c 0.0\n",
      "Loss  0.78038305 C_bot  0.15 k_c 0.0\n",
      "3389 Train Loss 10.182778\n",
      "Loss  0.78038305 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7801886 C_bot  0.15 k_c 0.0\n",
      "3390 Train Loss 10.17325\n",
      "Loss  0.7801886 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7508753 C_bot  0.15 k_c 0.0\n",
      "3391 Train Loss 10.148833\n",
      "Loss  0.7508753 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72641814 C_bot  0.15 k_c 0.0\n",
      "3392 Train Loss 10.116615\n",
      "Loss  0.72641814 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69521534 C_bot  0.15 k_c 0.0\n",
      "3393 Train Loss 10.08794\n",
      "Loss  0.69521534 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67916334 C_bot  0.15 k_c 0.0\n",
      "3394 Train Loss 10.067389\n",
      "Loss  0.67916334 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6708389 C_bot  0.15 k_c 0.0\n",
      "3395 Train Loss 10.058376\n",
      "Loss  0.6708389 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6726988 C_bot  0.15 k_c 0.0\n",
      "3396 Train Loss 10.059335\n",
      "Loss  0.6726988 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6832089 C_bot  0.15 k_c 0.0\n",
      "3397 Train Loss 10.066056\n",
      "Loss  0.6832089 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69057816 C_bot  0.15 k_c 0.0\n",
      "3398 Train Loss 10.075148\n",
      "Loss  0.69057816 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7032633 C_bot  0.15 k_c 0.0\n",
      "3399 Train Loss 10.082043\n",
      "Loss  0.7032633 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7038463 C_bot  0.15 k_c 0.0\n",
      "3400 Train Loss 10.085684\n",
      "Loss  0.7038463 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70847136 C_bot  0.15 k_c 0.0\n",
      "3401 Train Loss 10.083857\n",
      "Loss  0.70847136 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70025134 C_bot  0.15 k_c 0.0\n",
      "3402 Train Loss 10.07885\n",
      "Loss  0.70025134 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6977114 C_bot  0.15 k_c 0.0\n",
      "3403 Train Loss 10.070211\n",
      "Loss  0.6977114 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6857321 C_bot  0.15 k_c 0.0\n",
      "3404 Train Loss 10.06071\n",
      "Loss  0.6857321 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68056136 C_bot  0.15 k_c 0.0\n",
      "3405 Train Loss 10.05052\n",
      "Loss  0.68056136 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6700578 C_bot  0.15 k_c 0.0\n",
      "3406 Train Loss 10.041424\n",
      "Loss  0.6700578 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66560733 C_bot  0.15 k_c 0.0\n",
      "3407 Train Loss 10.033273\n",
      "Loss  0.66560733 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65901244 C_bot  0.15 k_c 0.0\n",
      "3408 Train Loss 10.026976\n",
      "Loss  0.65901244 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65654135 C_bot  0.15 k_c 0.0\n",
      "3409 Train Loss 10.022011\n",
      "Loss  0.65654135 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6537337 C_bot  0.15 k_c 0.0\n",
      "3410 Train Loss 10.018436\n",
      "Loss  0.6537337 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6526499 C_bot  0.15 k_c 0.0\n",
      "3411 Train Loss 10.015937\n",
      "Loss  0.6526499 C_bot  0.15 k_c 0.0\n",
      "Loss  0.652563 C_bot  0.15 k_c 0.0\n",
      "3412 Train Loss 10.014189\n",
      "Loss  0.652563 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6519291 C_bot  0.15 k_c 0.0\n",
      "3413 Train Loss 10.013051\n",
      "Loss  0.6519291 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6533917 C_bot  0.15 k_c 0.0\n",
      "3414 Train Loss 10.012143\n",
      "Loss  0.6533917 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6529053 C_bot  0.15 k_c 0.0\n",
      "3415 Train Loss 10.011843\n",
      "Loss  0.6529053 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65552866 C_bot  0.15 k_c 0.0\n",
      "3416 Train Loss 10.011465\n",
      "Loss  0.65552866 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6550182 C_bot  0.15 k_c 0.0\n",
      "3417 Train Loss 10.011745\n",
      "Loss  0.6550182 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6589106 C_bot  0.15 k_c 0.0\n",
      "3418 Train Loss 10.012071\n",
      "Loss  0.6589106 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6587631 C_bot  0.15 k_c 0.0\n",
      "3419 Train Loss 10.013355\n",
      "Loss  0.6587631 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66450906 C_bot  0.15 k_c 0.0\n",
      "3420 Train Loss 10.014963\n",
      "Loss  0.66450906 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6656998 C_bot  0.15 k_c 0.0\n",
      "3421 Train Loss 10.018295\n",
      "Loss  0.6656998 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67502105 C_bot  0.15 k_c 0.0\n",
      "3422 Train Loss 10.02275\n",
      "Loss  0.67502105 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6795361 C_bot  0.15 k_c 0.0\n",
      "3423 Train Loss 10.030353\n",
      "Loss  0.6795361 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6958848 C_bot  0.15 k_c 0.0\n",
      "3424 Train Loss 10.040795\n",
      "Loss  0.6958848 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70830536 C_bot  0.15 k_c 0.0\n",
      "3425 Train Loss 10.057707\n",
      "Loss  0.70830536 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7397372 C_bot  0.15 k_c 0.0\n",
      "3426 Train Loss 10.081653\n",
      "Loss  0.7397372 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7709066 C_bot  0.15 k_c 0.0\n",
      "3427 Train Loss 10.119423\n",
      "Loss  0.7709066 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8358865 C_bot  0.15 k_c 0.0\n",
      "3428 Train Loss 10.17444\n",
      "Loss  0.8358865 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9130488 C_bot  0.15 k_c 0.0\n",
      "3429 Train Loss 10.261509\n",
      "Loss  0.9130488 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0573901 C_bot  0.15 k_c 0.0\n",
      "3430 Train Loss 10.391989\n",
      "Loss  1.0573901 C_bot  0.15 k_c 0.0\n",
      "Loss  1.251833 C_bot  0.15 k_c 0.0\n",
      "3431 Train Loss 10.601719\n",
      "Loss  1.251833 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5940561 C_bot  0.15 k_c 0.0\n",
      "3432 Train Loss 10.923872\n",
      "Loss  1.5940561 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0980515 C_bot  0.15 k_c 0.0\n",
      "3433 Train Loss 11.452158\n",
      "Loss  2.0980515 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9542694 C_bot  0.15 k_c 0.0\n",
      "3434 Train Loss 12.278349\n",
      "Loss  2.9542694 C_bot  0.15 k_c 0.0\n",
      "Loss  4.3039556 C_bot  0.15 k_c 0.0\n",
      "3435 Train Loss 13.667971\n",
      "Loss  4.3039556 C_bot  0.15 k_c 0.0\n",
      "Loss  6.5421042 C_bot  0.15 k_c 0.0\n",
      "3436 Train Loss 15.860043\n",
      "Loss  6.5421042 C_bot  0.15 k_c 0.0\n",
      "Loss  10.253233 C_bot  0.15 k_c 0.0\n",
      "3437 Train Loss 19.639856\n",
      "Loss  10.253233 C_bot  0.15 k_c 0.0\n",
      "Loss  16.218603 C_bot  0.15 k_c 0.0\n",
      "3438 Train Loss 25.532856\n",
      "Loss  16.218603 C_bot  0.15 k_c 0.0\n",
      "Loss  26.4255 C_bot  0.15 k_c 0.0\n",
      "3439 Train Loss 35.86503\n",
      "Loss  26.4255 C_bot  0.15 k_c 0.0\n",
      "Loss  41.75811 C_bot  0.15 k_c 0.0\n",
      "3440 Train Loss 51.079723\n",
      "Loss  41.75811 C_bot  0.15 k_c 0.0\n",
      "Loss  67.75236 C_bot  0.15 k_c 0.0\n",
      "3441 Train Loss 77.31732\n",
      "Loss  67.75236 C_bot  0.15 k_c 0.0\n",
      "Loss  100.57098 C_bot  0.15 k_c 0.0\n",
      "3442 Train Loss 109.92493\n",
      "Loss  100.57098 C_bot  0.15 k_c 0.0\n",
      "Loss  149.55174 C_bot  0.15 k_c 0.0\n",
      "3443 Train Loss 159.38092\n",
      "Loss  149.55174 C_bot  0.15 k_c 0.0\n",
      "Loss  186.23457 C_bot  0.15 k_c 0.0\n",
      "3444 Train Loss 195.63846\n",
      "Loss  186.23457 C_bot  0.15 k_c 0.0\n",
      "Loss  214.05006 C_bot  0.15 k_c 0.0\n",
      "3445 Train Loss 224.20871\n",
      "Loss  214.05006 C_bot  0.15 k_c 0.0\n",
      "Loss  185.42767 C_bot  0.15 k_c 0.0\n",
      "3446 Train Loss 194.87785\n",
      "Loss  185.42767 C_bot  0.15 k_c 0.0\n",
      "Loss  123.84381 C_bot  0.15 k_c 0.0\n",
      "3447 Train Loss 133.99617\n",
      "Loss  123.84381 C_bot  0.15 k_c 0.0\n",
      "Loss  48.417927 C_bot  0.15 k_c 0.0\n",
      "3448 Train Loss 57.99917\n",
      "Loss  48.417927 C_bot  0.15 k_c 0.0\n",
      "Loss  4.803551 C_bot  0.15 k_c 0.0\n",
      "3449 Train Loss 14.633836\n",
      "Loss  4.803551 C_bot  0.15 k_c 0.0\n",
      "Loss  9.627827 C_bot  0.15 k_c 0.0\n",
      "3450 Train Loss 19.52676\n",
      "Loss  9.627827 C_bot  0.15 k_c 0.0\n",
      "Loss  46.228943 C_bot  0.15 k_c 0.0\n",
      "3451 Train Loss 55.93468\n",
      "Loss  46.228943 C_bot  0.15 k_c 0.0\n",
      "Loss  82.25609 C_bot  0.15 k_c 0.0\n",
      "3452 Train Loss 92.44966\n",
      "Loss  82.25609 C_bot  0.15 k_c 0.0\n",
      "Loss  86.74082 C_bot  0.15 k_c 0.0\n",
      "3453 Train Loss 96.50212\n",
      "Loss  86.74082 C_bot  0.15 k_c 0.0\n",
      "Loss  63.46622 C_bot  0.15 k_c 0.0\n",
      "3454 Train Loss 73.610245\n",
      "Loss  63.46622 C_bot  0.15 k_c 0.0\n",
      "Loss  25.442745 C_bot  0.15 k_c 0.0\n",
      "3455 Train Loss 35.24783\n",
      "Loss  25.442745 C_bot  0.15 k_c 0.0\n",
      "Loss  2.710228 C_bot  0.15 k_c 0.0\n",
      "3456 Train Loss 12.594461\n",
      "Loss  2.710228 C_bot  0.15 k_c 0.0\n",
      "Loss  6.4633384 C_bot  0.15 k_c 0.0\n",
      "3457 Train Loss 16.344265\n",
      "Loss  6.4633384 C_bot  0.15 k_c 0.0\n",
      "Loss  26.090555 C_bot  0.15 k_c 0.0\n",
      "3458 Train Loss 35.82621\n",
      "Loss  26.090555 C_bot  0.15 k_c 0.0\n",
      "Loss  41.20523 C_bot  0.15 k_c 0.0\n",
      "3459 Train Loss 51.13951\n",
      "Loss  41.20523 C_bot  0.15 k_c 0.0\n",
      "Loss  36.976597 C_bot  0.15 k_c 0.0\n",
      "3460 Train Loss 46.649418\n",
      "Loss  36.976597 C_bot  0.15 k_c 0.0\n",
      "Loss  19.76674 C_bot  0.15 k_c 0.0\n",
      "3461 Train Loss 29.589823\n",
      "Loss  19.76674 C_bot  0.15 k_c 0.0\n",
      "Loss  4.1126947 C_bot  0.15 k_c 0.0\n",
      "3462 Train Loss 13.794756\n",
      "Loss  4.1126947 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8932338 C_bot  0.15 k_c 0.0\n",
      "3463 Train Loss 11.589428\n",
      "Loss  1.8932338 C_bot  0.15 k_c 0.0\n",
      "Loss  11.082354 C_bot  0.15 k_c 0.0\n",
      "3464 Train Loss 20.864317\n",
      "Loss  11.082354 C_bot  0.15 k_c 0.0\n",
      "Loss  20.315664 C_bot  0.15 k_c 0.0\n",
      "3465 Train Loss 29.967834\n",
      "Loss  20.315664 C_bot  0.15 k_c 0.0\n",
      "Loss  20.641373 C_bot  0.15 k_c 0.0\n",
      "3466 Train Loss 30.426464\n",
      "Loss  20.641373 C_bot  0.15 k_c 0.0\n",
      "Loss  12.13268 C_bot  0.15 k_c 0.0\n",
      "3467 Train Loss 21.755037\n",
      "Loss  12.13268 C_bot  0.15 k_c 0.0\n",
      "Loss  3.279487 C_bot  0.15 k_c 0.0\n",
      "3468 Train Loss 12.934161\n",
      "Loss  3.279487 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1410065 C_bot  0.15 k_c 0.0\n",
      "3469 Train Loss 10.757401\n",
      "Loss  1.1410065 C_bot  0.15 k_c 0.0\n",
      "Loss  5.5753975 C_bot  0.15 k_c 0.0\n",
      "3470 Train Loss 15.156584\n",
      "Loss  5.5753975 C_bot  0.15 k_c 0.0\n",
      "Loss  10.860337 C_bot  0.15 k_c 0.0\n",
      "3471 Train Loss 20.493366\n",
      "Loss  10.860337 C_bot  0.15 k_c 0.0\n",
      "Loss  11.626837 C_bot  0.15 k_c 0.0\n",
      "3472 Train Loss 21.186892\n",
      "Loss  11.626837 C_bot  0.15 k_c 0.0\n",
      "Loss  7.639347 C_bot  0.15 k_c 0.0\n",
      "3473 Train Loss 17.244205\n",
      "Loss  7.639347 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6970775 C_bot  0.15 k_c 0.0\n",
      "3474 Train Loss 12.241327\n",
      "Loss  2.6970775 C_bot  0.15 k_c 0.0\n",
      "Loss  0.81962115 C_bot  0.15 k_c 0.0\n",
      "3475 Train Loss 10.365908\n",
      "Loss  0.81962115 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6294577 C_bot  0.15 k_c 0.0\n",
      "3476 Train Loss 12.1897545\n",
      "Loss  2.6294577 C_bot  0.15 k_c 0.0\n",
      "Loss  5.5994334 C_bot  0.15 k_c 0.0\n",
      "3477 Train Loss 15.108063\n",
      "Loss  5.5994334 C_bot  0.15 k_c 0.0\n",
      "Loss  6.684544 C_bot  0.15 k_c 0.0\n",
      "3478 Train Loss 16.266151\n",
      "Loss  6.684544 C_bot  0.15 k_c 0.0\n",
      "Loss  5.135729 C_bot  0.15 k_c 0.0\n",
      "3479 Train Loss 14.63755\n",
      "Loss  5.135729 C_bot  0.15 k_c 0.0\n",
      "Loss  2.409609 C_bot  0.15 k_c 0.0\n",
      "3480 Train Loss 11.962679\n",
      "Loss  2.409609 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8457902 C_bot  0.15 k_c 0.0\n",
      "3481 Train Loss 10.364056\n",
      "Loss  0.8457902 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2452956 C_bot  0.15 k_c 0.0\n",
      "3482 Train Loss 10.750708\n",
      "Loss  1.2452956 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7225754 C_bot  0.15 k_c 0.0\n",
      "3483 Train Loss 12.258569\n",
      "Loss  2.7225754 C_bot  0.15 k_c 0.0\n",
      "Loss  3.837624 C_bot  0.15 k_c 0.0\n",
      "3484 Train Loss 13.31773\n",
      "Loss  3.837624 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5673509 C_bot  0.15 k_c 0.0\n",
      "3485 Train Loss 13.092445\n",
      "Loss  3.5673509 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3496673 C_bot  0.15 k_c 0.0\n",
      "3486 Train Loss 11.824905\n",
      "Loss  2.3496673 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1166265 C_bot  0.15 k_c 0.0\n",
      "3487 Train Loss 10.6104355\n",
      "Loss  1.1166265 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7465696 C_bot  0.15 k_c 0.0\n",
      "3488 Train Loss 10.227492\n",
      "Loss  0.7465696 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2389629 C_bot  0.15 k_c 0.0\n",
      "3489 Train Loss 10.705547\n",
      "Loss  1.2389629 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9847058 C_bot  0.15 k_c 0.0\n",
      "3490 Train Loss 11.468418\n",
      "Loss  1.9847058 C_bot  0.15 k_c 0.0\n",
      "Loss  2.393398 C_bot  0.15 k_c 0.0\n",
      "3491 Train Loss 11.842175\n",
      "Loss  2.393398 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1262038 C_bot  0.15 k_c 0.0\n",
      "3492 Train Loss 11.598949\n",
      "Loss  2.1262038 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5084174 C_bot  0.15 k_c 0.0\n",
      "3493 Train Loss 10.949198\n",
      "Loss  1.5084174 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91654897 C_bot  0.15 k_c 0.0\n",
      "3494 Train Loss 10.368857\n",
      "Loss  0.91654897 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72295624 C_bot  0.15 k_c 0.0\n",
      "3495 Train Loss 10.166371\n",
      "Loss  0.72295624 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92666316 C_bot  0.15 k_c 0.0\n",
      "3496 Train Loss 10.361\n",
      "Loss  0.92666316 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2744888 C_bot  0.15 k_c 0.0\n",
      "3497 Train Loss 10.722143\n",
      "Loss  1.2744888 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5363948 C_bot  0.15 k_c 0.0\n",
      "3498 Train Loss 10.958878\n",
      "Loss  1.5363948 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4967353 C_bot  0.15 k_c 0.0\n",
      "3499 Train Loss 10.938656\n",
      "Loss  1.4967353 C_bot  0.15 k_c 0.0\n",
      "Loss  1.27247 C_bot  0.15 k_c 0.0\n",
      "3500 Train Loss 10.688862\n",
      "Loss  1.27247 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9533859 C_bot  0.15 k_c 0.0\n",
      "3501 Train Loss 10.381138\n",
      "Loss  0.9533859 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7558988 C_bot  0.15 k_c 0.0\n",
      "3502 Train Loss 10.171146\n",
      "Loss  0.7558988 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72517735 C_bot  0.15 k_c 0.0\n",
      "3503 Train Loss 10.138205\n",
      "Loss  0.72517735 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8319917 C_bot  0.15 k_c 0.0\n",
      "3504 Train Loss 10.247259\n",
      "Loss  0.8319917 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99680215 C_bot  0.15 k_c 0.0\n",
      "3505 Train Loss 10.399235\n",
      "Loss  0.99680215 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0890781 C_bot  0.15 k_c 0.0\n",
      "3506 Train Loss 10.501488\n",
      "Loss  1.0890781 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1009607 C_bot  0.15 k_c 0.0\n",
      "3507 Train Loss 10.49681\n",
      "Loss  1.1009607 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9984859 C_bot  0.15 k_c 0.0\n",
      "3508 Train Loss 10.4043\n",
      "Loss  0.9984859 C_bot  0.15 k_c 0.0\n",
      "Loss  0.877314 C_bot  0.15 k_c 0.0\n",
      "3509 Train Loss 10.269606\n",
      "Loss  0.877314 C_bot  0.15 k_c 0.0\n",
      "Loss  0.759543 C_bot  0.15 k_c 0.0\n",
      "3510 Train Loss 10.156525\n",
      "Loss  0.759543 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7093063 C_bot  0.15 k_c 0.0\n",
      "3511 Train Loss 10.100506\n",
      "Loss  0.7093063 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72016066 C_bot  0.15 k_c 0.0\n",
      "3512 Train Loss 10.108421\n",
      "Loss  0.72016066 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7675157 C_bot  0.15 k_c 0.0\n",
      "3513 Train Loss 10.158283\n",
      "Loss  0.7675157 C_bot  0.15 k_c 0.0\n",
      "Loss  0.83397084 C_bot  0.15 k_c 0.0\n",
      "3514 Train Loss 10.21534\n",
      "Loss  0.83397084 C_bot  0.15 k_c 0.0\n",
      "Loss  0.86512715 C_bot  0.15 k_c 0.0\n",
      "3515 Train Loss 10.253618\n",
      "Loss  0.86512715 C_bot  0.15 k_c 0.0\n",
      "Loss  0.87908185 C_bot  0.15 k_c 0.0\n",
      "3516 Train Loss 10.255438\n",
      "Loss  0.87908185 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8432007 C_bot  0.15 k_c 0.0\n",
      "3517 Train Loss 10.226737\n",
      "Loss  0.8432007 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8046471 C_bot  0.15 k_c 0.0\n",
      "3518 Train Loss 10.177549\n",
      "Loss  0.8046471 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7504022 C_bot  0.15 k_c 0.0\n",
      "3519 Train Loss 10.127637\n",
      "Loss  0.7504022 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7178761 C_bot  0.15 k_c 0.0\n",
      "3520 Train Loss 10.088615\n",
      "Loss  0.7178761 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6981403 C_bot  0.15 k_c 0.0\n",
      "3521 Train Loss 10.068933\n",
      "Loss  0.6981403 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6985846 C_bot  0.15 k_c 0.0\n",
      "3522 Train Loss 10.067598\n",
      "Loss  0.6985846 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7143236 C_bot  0.15 k_c 0.0\n",
      "3523 Train Loss 10.079237\n",
      "Loss  0.7143236 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73015887 C_bot  0.15 k_c 0.0\n",
      "3524 Train Loss 10.097041\n",
      "Loss  0.73015887 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75255066 C_bot  0.15 k_c 0.0\n",
      "3525 Train Loss 10.112614\n",
      "Loss  0.75255066 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7588092 C_bot  0.15 k_c 0.0\n",
      "3526 Train Loss 10.122965\n",
      "Loss  0.7588092 C_bot  0.15 k_c 0.0\n",
      "Loss  0.76779276 C_bot  0.15 k_c 0.0\n",
      "3527 Train Loss 10.12402\n",
      "Loss  0.76779276 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7575136 C_bot  0.15 k_c 0.0\n",
      "3528 Train Loss 10.118341\n",
      "Loss  0.7575136 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75261515 C_bot  0.15 k_c 0.0\n",
      "3529 Train Loss 10.105757\n",
      "Loss  0.75261515 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7340965 C_bot  0.15 k_c 0.0\n",
      "3530 Train Loss 10.091002\n",
      "Loss  0.7340965 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7242115 C_bot  0.15 k_c 0.0\n",
      "3531 Train Loss 10.0748\n",
      "Loss  0.7242115 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7079793 C_bot  0.15 k_c 0.0\n",
      "3532 Train Loss 10.060686\n",
      "Loss  0.7079793 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70040834 C_bot  0.15 k_c 0.0\n",
      "3533 Train Loss 10.048628\n",
      "Loss  0.70040834 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69148976 C_bot  0.15 k_c 0.0\n",
      "3534 Train Loss 10.040024\n",
      "Loss  0.69148976 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68838245 C_bot  0.15 k_c 0.0\n",
      "3535 Train Loss 10.034182\n",
      "Loss  0.68838245 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68645656 C_bot  0.15 k_c 0.0\n",
      "3536 Train Loss 10.03105\n",
      "Loss  0.68645656 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6864318 C_bot  0.15 k_c 0.0\n",
      "3537 Train Loss 10.029842\n",
      "Loss  0.6864318 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68883514 C_bot  0.15 k_c 0.0\n",
      "3538 Train Loss 10.0297985\n",
      "Loss  0.68883514 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6899039 C_bot  0.15 k_c 0.0\n",
      "3539 Train Loss 10.030939\n",
      "Loss  0.6899039 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69457537 C_bot  0.15 k_c 0.0\n",
      "3540 Train Loss 10.032185\n",
      "Loss  0.69457537 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6956344 C_bot  0.15 k_c 0.0\n",
      "3541 Train Loss 10.034252\n",
      "Loss  0.6956344 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70157546 C_bot  0.15 k_c 0.0\n",
      "3542 Train Loss 10.036041\n",
      "Loss  0.70157546 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7023814 C_bot  0.15 k_c 0.0\n",
      "3543 Train Loss 10.038655\n",
      "Loss  0.7023814 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70972186 C_bot  0.15 k_c 0.0\n",
      "3544 Train Loss 10.04118\n",
      "Loss  0.70972186 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7110341 C_bot  0.15 k_c 0.0\n",
      "3545 Train Loss 10.045092\n",
      "Loss  0.7110341 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72093177 C_bot  0.15 k_c 0.0\n",
      "3546 Train Loss 10.0494175\n",
      "Loss  0.72093177 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7243064 C_bot  0.15 k_c 0.0\n",
      "3547 Train Loss 10.056231\n",
      "Loss  0.7243064 C_bot  0.15 k_c 0.0\n",
      "Loss  0.739172 C_bot  0.15 k_c 0.0\n",
      "3548 Train Loss 10.064648\n",
      "Loss  0.739172 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7478328 C_bot  0.15 k_c 0.0\n",
      "3549 Train Loss 10.077826\n",
      "Loss  0.7478328 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7726503 C_bot  0.15 k_c 0.0\n",
      "3550 Train Loss 10.095007\n",
      "Loss  0.7726503 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7928444 C_bot  0.15 k_c 0.0\n",
      "3551 Train Loss 10.121289\n",
      "Loss  0.7928444 C_bot  0.15 k_c 0.0\n",
      "Loss  0.83825076 C_bot  0.15 k_c 0.0\n",
      "3552 Train Loss 10.15728\n",
      "Loss  0.83825076 C_bot  0.15 k_c 0.0\n",
      "Loss  0.88480794 C_bot  0.15 k_c 0.0\n",
      "3553 Train Loss 10.212289\n",
      "Loss  0.88480794 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9746638 C_bot  0.15 k_c 0.0\n",
      "3554 Train Loss 10.290049\n",
      "Loss  0.9746638 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0824028 C_bot  0.15 k_c 0.0\n",
      "3555 Train Loss 10.4099045\n",
      "Loss  1.0824028 C_bot  0.15 k_c 0.0\n",
      "Loss  1.273354 C_bot  0.15 k_c 0.0\n",
      "3556 Train Loss 10.584591\n",
      "Loss  1.273354 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5300758 C_bot  0.15 k_c 0.0\n",
      "3557 Train Loss 10.859333\n",
      "Loss  1.5300758 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9624298 C_bot  0.15 k_c 0.0\n",
      "3558 Train Loss 11.268776\n",
      "Loss  1.9624298 C_bot  0.15 k_c 0.0\n",
      "Loss  2.593343 C_bot  0.15 k_c 0.0\n",
      "3559 Train Loss 11.927522\n",
      "Loss  2.593343 C_bot  0.15 k_c 0.0\n",
      "Loss  3.624742 C_bot  0.15 k_c 0.0\n",
      "3560 Train Loss 12.925447\n",
      "Loss  3.624742 C_bot  0.15 k_c 0.0\n",
      "Loss  5.2262936 C_bot  0.15 k_c 0.0\n",
      "3561 Train Loss 14.571714\n",
      "Loss  5.2262936 C_bot  0.15 k_c 0.0\n",
      "Loss  7.7804074 C_bot  0.15 k_c 0.0\n",
      "3562 Train Loss 17.075481\n",
      "Loss  7.7804074 C_bot  0.15 k_c 0.0\n",
      "Loss  11.931636 C_bot  0.15 k_c 0.0\n",
      "3563 Train Loss 21.30198\n",
      "Loss  11.931636 C_bot  0.15 k_c 0.0\n",
      "Loss  18.301786 C_bot  0.15 k_c 0.0\n",
      "3564 Train Loss 27.594296\n",
      "Loss  18.301786 C_bot  0.15 k_c 0.0\n",
      "Loss  28.895382 C_bot  0.15 k_c 0.0\n",
      "3565 Train Loss 38.321777\n",
      "Loss  28.895382 C_bot  0.15 k_c 0.0\n",
      "Loss  43.815636 C_bot  0.15 k_c 0.0\n",
      "3566 Train Loss 53.11621\n",
      "Loss  43.815636 C_bot  0.15 k_c 0.0\n",
      "Loss  67.938545 C_bot  0.15 k_c 0.0\n",
      "3567 Train Loss 77.489136\n",
      "Loss  67.938545 C_bot  0.15 k_c 0.0\n",
      "Loss  95.340096 C_bot  0.15 k_c 0.0\n",
      "3568 Train Loss 104.6677\n",
      "Loss  95.340096 C_bot  0.15 k_c 0.0\n",
      "Loss  132.48695 C_bot  0.15 k_c 0.0\n",
      "3569 Train Loss 142.26778\n",
      "Loss  132.48695 C_bot  0.15 k_c 0.0\n",
      "Loss  153.55139 C_bot  0.15 k_c 0.0\n",
      "3570 Train Loss 162.91525\n",
      "Loss  153.55139 C_bot  0.15 k_c 0.0\n",
      "Loss  161.52167 C_bot  0.15 k_c 0.0\n",
      "3571 Train Loss 171.52751\n",
      "Loss  161.52167 C_bot  0.15 k_c 0.0\n",
      "Loss  129.32764 C_bot  0.15 k_c 0.0\n",
      "3572 Train Loss 138.74039\n",
      "Loss  129.32764 C_bot  0.15 k_c 0.0\n",
      "Loss  78.38149 C_bot  0.15 k_c 0.0\n",
      "3573 Train Loss 88.32519\n",
      "Loss  78.38149 C_bot  0.15 k_c 0.0\n",
      "Loss  27.388828 C_bot  0.15 k_c 0.0\n",
      "3574 Train Loss 36.93527\n",
      "Loss  27.388828 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0869508 C_bot  0.15 k_c 0.0\n",
      "3575 Train Loss 11.79768\n",
      "Loss  2.0869508 C_bot  0.15 k_c 0.0\n",
      "Loss  9.238594 C_bot  0.15 k_c 0.0\n",
      "3576 Train Loss 19.036093\n",
      "Loss  9.238594 C_bot  0.15 k_c 0.0\n",
      "Loss  35.758827 C_bot  0.15 k_c 0.0\n",
      "3577 Train Loss 45.40333\n",
      "Loss  35.758827 C_bot  0.15 k_c 0.0\n",
      "Loss  60.844555 C_bot  0.15 k_c 0.0\n",
      "3578 Train Loss 70.85542\n",
      "Loss  60.844555 C_bot  0.15 k_c 0.0\n",
      "Loss  65.76382 C_bot  0.15 k_c 0.0\n",
      "3579 Train Loss 75.45275\n",
      "Loss  65.76382 C_bot  0.15 k_c 0.0\n",
      "Loss  52.11255 C_bot  0.15 k_c 0.0\n",
      "3580 Train Loss 62.10034\n",
      "Loss  52.11255 C_bot  0.15 k_c 0.0\n",
      "Loss  25.992105 C_bot  0.15 k_c 0.0\n",
      "3581 Train Loss 35.700638\n",
      "Loss  25.992105 C_bot  0.15 k_c 0.0\n",
      "Loss  5.859828 C_bot  0.15 k_c 0.0\n",
      "3582 Train Loss 15.656862\n",
      "Loss  5.859828 C_bot  0.15 k_c 0.0\n",
      "Loss  1.490439 C_bot  0.15 k_c 0.0\n",
      "3583 Train Loss 11.231276\n",
      "Loss  1.490439 C_bot  0.15 k_c 0.0\n",
      "Loss  11.228945 C_bot  0.15 k_c 0.0\n",
      "3584 Train Loss 20.888659\n",
      "Loss  11.228945 C_bot  0.15 k_c 0.0\n",
      "Loss  24.453732 C_bot  0.15 k_c 0.0\n",
      "3585 Train Loss 34.25196\n",
      "Loss  24.453732 C_bot  0.15 k_c 0.0\n",
      "Loss  29.808508 C_bot  0.15 k_c 0.0\n",
      "3586 Train Loss 39.417816\n",
      "Loss  29.808508 C_bot  0.15 k_c 0.0\n",
      "Loss  24.545977 C_bot  0.15 k_c 0.0\n",
      "3587 Train Loss 34.316486\n",
      "Loss  24.545977 C_bot  0.15 k_c 0.0\n",
      "Loss  12.558948 C_bot  0.15 k_c 0.0\n",
      "3588 Train Loss 22.16447\n",
      "Loss  12.558948 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9186728 C_bot  0.15 k_c 0.0\n",
      "3589 Train Loss 12.592066\n",
      "Loss  2.9186728 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2516668 C_bot  0.15 k_c 0.0\n",
      "3590 Train Loss 10.898606\n",
      "Loss  1.2516668 C_bot  0.15 k_c 0.0\n",
      "Loss  6.4342923 C_bot  0.15 k_c 0.0\n",
      "3591 Train Loss 16.029552\n",
      "Loss  6.4342923 C_bot  0.15 k_c 0.0\n",
      "Loss  12.705728 C_bot  0.15 k_c 0.0\n",
      "3592 Train Loss 22.377682\n",
      "Loss  12.705728 C_bot  0.15 k_c 0.0\n",
      "Loss  14.765195 C_bot  0.15 k_c 0.0\n",
      "3593 Train Loss 24.321018\n",
      "Loss  14.765195 C_bot  0.15 k_c 0.0\n",
      "Loss  11.497981 C_bot  0.15 k_c 0.0\n",
      "3594 Train Loss 21.121593\n",
      "Loss  11.497981 C_bot  0.15 k_c 0.0\n",
      "Loss  5.61269 C_bot  0.15 k_c 0.0\n",
      "3595 Train Loss 15.1514225\n",
      "Loss  5.61269 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4268168 C_bot  0.15 k_c 0.0\n",
      "3596 Train Loss 10.981018\n",
      "Loss  1.4268168 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2233891 C_bot  0.15 k_c 0.0\n",
      "3597 Train Loss 10.76692\n",
      "Loss  1.2233891 C_bot  0.15 k_c 0.0\n",
      "Loss  4.017329 C_bot  0.15 k_c 0.0\n",
      "3598 Train Loss 13.530478\n",
      "Loss  4.017329 C_bot  0.15 k_c 0.0\n",
      "Loss  6.9411387 C_bot  0.15 k_c 0.0\n",
      "3599 Train Loss 16.49593\n",
      "Loss  6.9411387 C_bot  0.15 k_c 0.0\n",
      "Loss  7.6859803 C_bot  0.15 k_c 0.0\n",
      "3600 Train Loss 17.17392\n",
      "Loss  7.6859803 C_bot  0.15 k_c 0.0\n",
      "Loss  5.8797626 C_bot  0.15 k_c 0.0\n",
      "3601 Train Loss 15.420052\n",
      "Loss  5.8797626 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0449874 C_bot  0.15 k_c 0.0\n",
      "3602 Train Loss 12.525017\n",
      "Loss  3.0449874 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0386243 C_bot  0.15 k_c 0.0\n",
      "3603 Train Loss 10.543451\n",
      "Loss  1.0386243 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9063793 C_bot  0.15 k_c 0.0\n",
      "3604 Train Loss 10.406044\n",
      "Loss  0.9063793 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2116659 C_bot  0.15 k_c 0.0\n",
      "3605 Train Loss 11.684241\n",
      "Loss  2.2116659 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6316502 C_bot  0.15 k_c 0.0\n",
      "3606 Train Loss 13.150345\n",
      "Loss  3.6316502 C_bot  0.15 k_c 0.0\n",
      "Loss  4.193827 C_bot  0.15 k_c 0.0\n",
      "3607 Train Loss 13.649396\n",
      "Loss  4.193827 C_bot  0.15 k_c 0.0\n",
      "Loss  3.487772 C_bot  0.15 k_c 0.0\n",
      "3608 Train Loss 12.992955\n",
      "Loss  3.487772 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2040007 C_bot  0.15 k_c 0.0\n",
      "3609 Train Loss 11.656368\n",
      "Loss  2.2040007 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0700095 C_bot  0.15 k_c 0.0\n",
      "3610 Train Loss 10.541153\n",
      "Loss  1.0700095 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71930414 C_bot  0.15 k_c 0.0\n",
      "3611 Train Loss 10.176905\n",
      "Loss  0.71930414 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1211708 C_bot  0.15 k_c 0.0\n",
      "3612 Train Loss 10.565369\n",
      "Loss  1.1211708 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8146607 C_bot  0.15 k_c 0.0\n",
      "3613 Train Loss 11.27586\n",
      "Loss  1.8146607 C_bot  0.15 k_c 0.0\n",
      "Loss  2.342665 C_bot  0.15 k_c 0.0\n",
      "3614 Train Loss 11.771482\n",
      "Loss  2.342665 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3350391 C_bot  0.15 k_c 0.0\n",
      "3615 Train Loss 11.788576\n",
      "Loss  2.3350391 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9254397 C_bot  0.15 k_c 0.0\n",
      "3616 Train Loss 11.344681\n",
      "Loss  1.9254397 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3084811 C_bot  0.15 k_c 0.0\n",
      "3617 Train Loss 10.7438545\n",
      "Loss  1.3084811 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8585671 C_bot  0.15 k_c 0.0\n",
      "3618 Train Loss 10.274168\n",
      "Loss  0.8585671 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7039385 C_bot  0.15 k_c 0.0\n",
      "3619 Train Loss 10.119595\n",
      "Loss  0.7039385 C_bot  0.15 k_c 0.0\n",
      "Loss  0.84625566 C_bot  0.15 k_c 0.0\n",
      "3620 Train Loss 10.263776\n",
      "Loss  0.84625566 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1509557 C_bot  0.15 k_c 0.0\n",
      "3621 Train Loss 10.551943\n",
      "Loss  1.1509557 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3899364 C_bot  0.15 k_c 0.0\n",
      "3622 Train Loss 10.807359\n",
      "Loss  1.3899364 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5049732 C_bot  0.15 k_c 0.0\n",
      "3623 Train Loss 10.896844\n",
      "Loss  1.5049732 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3984088 C_bot  0.15 k_c 0.0\n",
      "3624 Train Loss 10.80851\n",
      "Loss  1.3984088 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2012103 C_bot  0.15 k_c 0.0\n",
      "3625 Train Loss 10.587988\n",
      "Loss  1.2012103 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94805247 C_bot  0.15 k_c 0.0\n",
      "3626 Train Loss 10.345873\n",
      "Loss  0.94805247 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7766042 C_bot  0.15 k_c 0.0\n",
      "3627 Train Loss 10.161104\n",
      "Loss  0.7766042 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69742346 C_bot  0.15 k_c 0.0\n",
      "3628 Train Loss 10.082441\n",
      "Loss  0.69742346 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7233454 C_bot  0.15 k_c 0.0\n",
      "3629 Train Loss 10.106773\n",
      "Loss  0.7233454 C_bot  0.15 k_c 0.0\n",
      "Loss  0.821465 C_bot  0.15 k_c 0.0\n",
      "3630 Train Loss 10.196165\n",
      "Loss  0.821465 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9202495 C_bot  0.15 k_c 0.0\n",
      "3631 Train Loss 10.301638\n",
      "Loss  0.9202495 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0096147 C_bot  0.15 k_c 0.0\n",
      "3632 Train Loss 10.376897\n",
      "Loss  1.0096147 C_bot  0.15 k_c 0.0\n",
      "Loss  1.027192 C_bot  0.15 k_c 0.0\n",
      "3633 Train Loss 10.404493\n",
      "Loss  1.027192 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0131732 C_bot  0.15 k_c 0.0\n",
      "3634 Train Loss 10.3752775\n",
      "Loss  1.0131732 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93835723 C_bot  0.15 k_c 0.0\n",
      "3635 Train Loss 10.30999\n",
      "Loss  0.93835723 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8659951 C_bot  0.15 k_c 0.0\n",
      "3636 Train Loss 10.2248125\n",
      "Loss  0.8659951 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7808473 C_bot  0.15 k_c 0.0\n",
      "3637 Train Loss 10.145919\n",
      "Loss  0.7808473 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7277172 C_bot  0.15 k_c 0.0\n",
      "3638 Train Loss 10.084675\n",
      "Loss  0.7277172 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6925741 C_bot  0.15 k_c 0.0\n",
      "3639 Train Loss 10.05068\n",
      "Loss  0.6925741 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6870671 C_bot  0.15 k_c 0.0\n",
      "3640 Train Loss 10.042501\n",
      "Loss  0.6870671 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7026777 C_bot  0.15 k_c 0.0\n",
      "3641 Train Loss 10.05412\n",
      "Loss  0.7026777 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7245644 C_bot  0.15 k_c 0.0\n",
      "3642 Train Loss 10.077894\n",
      "Loss  0.7245644 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75915486 C_bot  0.15 k_c 0.0\n",
      "3643 Train Loss 10.104869\n",
      "Loss  0.75915486 C_bot  0.15 k_c 0.0\n",
      "Loss  0.77970845 C_bot  0.15 k_c 0.0\n",
      "3644 Train Loss 10.130302\n",
      "Loss  0.77970845 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8067516 C_bot  0.15 k_c 0.0\n",
      "3645 Train Loss 10.1477165\n",
      "Loss  0.8067516 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8111944 C_bot  0.15 k_c 0.0\n",
      "3646 Train Loss 10.158611\n",
      "Loss  0.8111944 C_bot  0.15 k_c 0.0\n",
      "Loss  0.82287973 C_bot  0.15 k_c 0.0\n",
      "3647 Train Loss 10.15988\n",
      "Loss  0.82287973 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8123626 C_bot  0.15 k_c 0.0\n",
      "3648 Train Loss 10.156224\n",
      "Loss  0.8123626 C_bot  0.15 k_c 0.0\n",
      "Loss  0.812332 C_bot  0.15 k_c 0.0\n",
      "3649 Train Loss 10.145992\n",
      "Loss  0.812332 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7945311 C_bot  0.15 k_c 0.0\n",
      "3650 Train Loss 10.13465\n",
      "Loss  0.7945311 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7897874 C_bot  0.15 k_c 0.0\n",
      "3651 Train Loss 10.120483\n",
      "Loss  0.7897874 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7714182 C_bot  0.15 k_c 0.0\n",
      "3652 Train Loss 10.107882\n",
      "Loss  0.7714182 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7670098 C_bot  0.15 k_c 0.0\n",
      "3653 Train Loss 10.094882\n",
      "Loss  0.7670098 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7518159 C_bot  0.15 k_c 0.0\n",
      "3654 Train Loss 10.084772\n",
      "Loss  0.7518159 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75003725 C_bot  0.15 k_c 0.0\n",
      "3655 Train Loss 10.075127\n",
      "Loss  0.75003725 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73913807 C_bot  0.15 k_c 0.0\n",
      "3656 Train Loss 10.068686\n",
      "Loss  0.73913807 C_bot  0.15 k_c 0.0\n",
      "Loss  0.74104494 C_bot  0.15 k_c 0.0\n",
      "3657 Train Loss 10.06328\n",
      "Loss  0.74104494 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7347225 C_bot  0.15 k_c 0.0\n",
      "3658 Train Loss 10.061055\n",
      "Loss  0.7347225 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7410255 C_bot  0.15 k_c 0.0\n",
      "3659 Train Loss 10.060244\n",
      "Loss  0.7410255 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7398438 C_bot  0.15 k_c 0.0\n",
      "3660 Train Loss 10.063321\n",
      "Loss  0.7398438 C_bot  0.15 k_c 0.0\n",
      "Loss  0.752743 C_bot  0.15 k_c 0.0\n",
      "3661 Train Loss 10.068807\n",
      "Loss  0.752743 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75904864 C_bot  0.15 k_c 0.0\n",
      "3662 Train Loss 10.080093\n",
      "Loss  0.75904864 C_bot  0.15 k_c 0.0\n",
      "Loss  0.78348464 C_bot  0.15 k_c 0.0\n",
      "3663 Train Loss 10.096243\n",
      "Loss  0.78348464 C_bot  0.15 k_c 0.0\n",
      "Loss  0.803478 C_bot  0.15 k_c 0.0\n",
      "3664 Train Loss 10.12261\n",
      "Loss  0.803478 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8507706 C_bot  0.15 k_c 0.0\n",
      "3665 Train Loss 10.159948\n",
      "Loss  0.8507706 C_bot  0.15 k_c 0.0\n",
      "Loss  0.900391 C_bot  0.15 k_c 0.0\n",
      "3666 Train Loss 10.218393\n",
      "Loss  0.900391 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9972137 C_bot  0.15 k_c 0.0\n",
      "3667 Train Loss 10.302364\n",
      "Loss  0.9972137 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1152852 C_bot  0.15 k_c 0.0\n",
      "3668 Train Loss 10.433339\n",
      "Loss  1.1152852 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3256673 C_bot  0.15 k_c 0.0\n",
      "3669 Train Loss 10.626179\n",
      "Loss  1.3256673 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6114029 C_bot  0.15 k_c 0.0\n",
      "3670 Train Loss 10.931402\n",
      "Loss  1.6114029 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0952382 C_bot  0.15 k_c 0.0\n",
      "3671 Train Loss 11.390329\n",
      "Loss  2.0952382 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8079894 C_bot  0.15 k_c 0.0\n",
      "3672 Train Loss 12.133446\n",
      "Loss  2.8079894 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9783514 C_bot  0.15 k_c 0.0\n",
      "3673 Train Loss 13.267319\n",
      "Loss  3.9783514 C_bot  0.15 k_c 0.0\n",
      "Loss  5.812449 C_bot  0.15 k_c 0.0\n",
      "3674 Train Loss 15.150515\n",
      "Loss  5.812449 C_bot  0.15 k_c 0.0\n",
      "Loss  8.746539 C_bot  0.15 k_c 0.0\n",
      "3675 Train Loss 18.029757\n",
      "Loss  8.746539 C_bot  0.15 k_c 0.0\n",
      "Loss  13.55209 C_bot  0.15 k_c 0.0\n",
      "3676 Train Loss 22.91851\n",
      "Loss  13.55209 C_bot  0.15 k_c 0.0\n",
      "Loss  20.922668 C_bot  0.15 k_c 0.0\n",
      "3677 Train Loss 30.204287\n",
      "Loss  20.922668 C_bot  0.15 k_c 0.0\n",
      "Loss  33.228516 C_bot  0.15 k_c 0.0\n",
      "3678 Train Loss 42.659786\n",
      "Loss  33.228516 C_bot  0.15 k_c 0.0\n",
      "Loss  50.395805 C_bot  0.15 k_c 0.0\n",
      "3679 Train Loss 59.688526\n",
      "Loss  50.395805 C_bot  0.15 k_c 0.0\n",
      "Loss  77.978516 C_bot  0.15 k_c 0.0\n",
      "3680 Train Loss 87.55447\n",
      "Loss  77.978516 C_bot  0.15 k_c 0.0\n",
      "Loss  108.274284 C_bot  0.15 k_c 0.0\n",
      "3681 Train Loss 117.598404\n",
      "Loss  108.274284 C_bot  0.15 k_c 0.0\n",
      "Loss  147.93558 C_bot  0.15 k_c 0.0\n",
      "3682 Train Loss 157.77159\n",
      "Loss  147.93558 C_bot  0.15 k_c 0.0\n",
      "Loss  167.24814 C_bot  0.15 k_c 0.0\n",
      "3683 Train Loss 176.61186\n",
      "Loss  167.24814 C_bot  0.15 k_c 0.0\n",
      "Loss  170.6489 C_bot  0.15 k_c 0.0\n",
      "3684 Train Loss 180.70668\n",
      "Loss  170.6489 C_bot  0.15 k_c 0.0\n",
      "Loss  132.41081 C_bot  0.15 k_c 0.0\n",
      "3685 Train Loss 141.83383\n",
      "Loss  132.41081 C_bot  0.15 k_c 0.0\n",
      "Loss  78.23224 C_bot  0.15 k_c 0.0\n",
      "3686 Train Loss 88.17983\n",
      "Loss  78.23224 C_bot  0.15 k_c 0.0\n",
      "Loss  26.440413 C_bot  0.15 k_c 0.0\n",
      "3687 Train Loss 35.99248\n",
      "Loss  26.440413 C_bot  0.15 k_c 0.0\n",
      "Loss  1.865473 C_bot  0.15 k_c 0.0\n",
      "3688 Train Loss 11.558449\n",
      "Loss  1.865473 C_bot  0.15 k_c 0.0\n",
      "Loss  10.077172 C_bot  0.15 k_c 0.0\n",
      "3689 Train Loss 19.849493\n",
      "Loss  10.077172 C_bot  0.15 k_c 0.0\n",
      "Loss  37.153866 C_bot  0.15 k_c 0.0\n",
      "3690 Train Loss 46.784065\n",
      "Loss  37.153866 C_bot  0.15 k_c 0.0\n",
      "Loss  62.196045 C_bot  0.15 k_c 0.0\n",
      "3691 Train Loss 72.159515\n",
      "Loss  62.196045 C_bot  0.15 k_c 0.0\n",
      "Loss  66.75932 C_bot  0.15 k_c 0.0\n",
      "3692 Train Loss 76.41998\n",
      "Loss  66.75932 C_bot  0.15 k_c 0.0\n",
      "Loss  53.1139 C_bot  0.15 k_c 0.0\n",
      "3693 Train Loss 63.049915\n",
      "Loss  53.1139 C_bot  0.15 k_c 0.0\n",
      "Loss  26.493816 C_bot  0.15 k_c 0.0\n",
      "3694 Train Loss 36.146645\n",
      "Loss  26.493816 C_bot  0.15 k_c 0.0\n",
      "Loss  5.80919 C_bot  0.15 k_c 0.0\n",
      "3695 Train Loss 15.544535\n",
      "Loss  5.80919 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6183826 C_bot  0.15 k_c 0.0\n",
      "3696 Train Loss 11.299986\n",
      "Loss  1.6183826 C_bot  0.15 k_c 0.0\n",
      "Loss  11.878405 C_bot  0.15 k_c 0.0\n",
      "3697 Train Loss 21.473204\n",
      "Loss  11.878405 C_bot  0.15 k_c 0.0\n",
      "Loss  25.10475 C_bot  0.15 k_c 0.0\n",
      "3698 Train Loss 34.85504\n",
      "Loss  25.10475 C_bot  0.15 k_c 0.0\n",
      "Loss  30.258028 C_bot  0.15 k_c 0.0\n",
      "3699 Train Loss 39.813927\n",
      "Loss  30.258028 C_bot  0.15 k_c 0.0\n",
      "Loss  24.94967 C_bot  0.15 k_c 0.0\n",
      "3700 Train Loss 34.66936\n",
      "Loss  24.94967 C_bot  0.15 k_c 0.0\n",
      "Loss  12.873936 C_bot  0.15 k_c 0.0\n",
      "3701 Train Loss 22.4353\n",
      "Loss  12.873936 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9673393 C_bot  0.15 k_c 0.0\n",
      "3702 Train Loss 12.588835\n",
      "Loss  2.9673393 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3871326 C_bot  0.15 k_c 0.0\n",
      "3703 Train Loss 10.981113\n",
      "Loss  1.3871326 C_bot  0.15 k_c 0.0\n",
      "Loss  6.7533517 C_bot  0.15 k_c 0.0\n",
      "3704 Train Loss 16.30054\n",
      "Loss  6.7533517 C_bot  0.15 k_c 0.0\n",
      "Loss  12.880609 C_bot  0.15 k_c 0.0\n",
      "3705 Train Loss 22.492651\n",
      "Loss  12.880609 C_bot  0.15 k_c 0.0\n",
      "Loss  14.86322 C_bot  0.15 k_c 0.0\n",
      "3706 Train Loss 24.376963\n",
      "Loss  14.86322 C_bot  0.15 k_c 0.0\n",
      "Loss  11.856991 C_bot  0.15 k_c 0.0\n",
      "3707 Train Loss 21.431602\n",
      "Loss  11.856991 C_bot  0.15 k_c 0.0\n",
      "Loss  6.0338006 C_bot  0.15 k_c 0.0\n",
      "3708 Train Loss 15.530626\n",
      "Loss  6.0338006 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5732737 C_bot  0.15 k_c 0.0\n",
      "3709 Train Loss 11.085878\n",
      "Loss  1.5732737 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1222155 C_bot  0.15 k_c 0.0\n",
      "3710 Train Loss 10.622784\n",
      "Loss  1.1222155 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8374858 C_bot  0.15 k_c 0.0\n",
      "3711 Train Loss 13.306417\n",
      "Loss  3.8374858 C_bot  0.15 k_c 0.0\n",
      "Loss  6.788383 C_bot  0.15 k_c 0.0\n",
      "3712 Train Loss 16.31014\n",
      "Loss  6.788383 C_bot  0.15 k_c 0.0\n",
      "Loss  7.816645 C_bot  0.15 k_c 0.0\n",
      "3713 Train Loss 17.261904\n",
      "Loss  7.816645 C_bot  0.15 k_c 0.0\n",
      "Loss  6.3750644 C_bot  0.15 k_c 0.0\n",
      "3714 Train Loss 15.890186\n",
      "Loss  6.3750644 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6071026 C_bot  0.15 k_c 0.0\n",
      "3715 Train Loss 13.052942\n",
      "Loss  3.6071026 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2808098 C_bot  0.15 k_c 0.0\n",
      "3716 Train Loss 10.761301\n",
      "Loss  1.2808098 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7887655 C_bot  0.15 k_c 0.0\n",
      "3717 Train Loss 10.255345\n",
      "Loss  0.7887655 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8683498 C_bot  0.15 k_c 0.0\n",
      "3718 Train Loss 11.312799\n",
      "Loss  1.8683498 C_bot  0.15 k_c 0.0\n",
      "Loss  3.307397 C_bot  0.15 k_c 0.0\n",
      "3719 Train Loss 12.790955\n",
      "Loss  3.307397 C_bot  0.15 k_c 0.0\n",
      "Loss  4.1750283 C_bot  0.15 k_c 0.0\n",
      "3720 Train Loss 13.5991955\n",
      "Loss  4.1750283 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8672395 C_bot  0.15 k_c 0.0\n",
      "3721 Train Loss 13.34078\n",
      "Loss  3.8672395 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7367244 C_bot  0.15 k_c 0.0\n",
      "3722 Train Loss 12.157479\n",
      "Loss  2.7367244 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4447473 C_bot  0.15 k_c 0.0\n",
      "3723 Train Loss 10.889097\n",
      "Loss  1.4447473 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7787782 C_bot  0.15 k_c 0.0\n",
      "3724 Train Loss 10.204172\n",
      "Loss  0.7787782 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8620028 C_bot  0.15 k_c 0.0\n",
      "3725 Train Loss 10.281205\n",
      "Loss  0.8620028 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4214318 C_bot  0.15 k_c 0.0\n",
      "3726 Train Loss 10.85022\n",
      "Loss  1.4214318 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0807729 C_bot  0.15 k_c 0.0\n",
      "3727 Train Loss 11.481958\n",
      "Loss  2.0807729 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3879404 C_bot  0.15 k_c 0.0\n",
      "3728 Train Loss 11.811485\n",
      "Loss  2.3879404 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2578094 C_bot  0.15 k_c 0.0\n",
      "3729 Train Loss 11.646126\n",
      "Loss  2.2578094 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7493277 C_bot  0.15 k_c 0.0\n",
      "3730 Train Loss 11.15995\n",
      "Loss  1.7493277 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2221652 C_bot  0.15 k_c 0.0\n",
      "3731 Train Loss 10.605486\n",
      "Loss  1.2221652 C_bot  0.15 k_c 0.0\n",
      "Loss  0.81827784 C_bot  0.15 k_c 0.0\n",
      "3732 Train Loss 10.212635\n",
      "Loss  0.81827784 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6925985 C_bot  0.15 k_c 0.0\n",
      "3733 Train Loss 10.078905\n",
      "Loss  0.6925985 C_bot  0.15 k_c 0.0\n",
      "Loss  0.82356983 C_bot  0.15 k_c 0.0\n",
      "3734 Train Loss 10.20186\n",
      "Loss  0.82356983 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0735633 C_bot  0.15 k_c 0.0\n",
      "3735 Train Loss 10.463005\n",
      "Loss  1.0735633 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3317821 C_bot  0.15 k_c 0.0\n",
      "3736 Train Loss 10.698448\n",
      "Loss  1.3317821 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4376323 C_bot  0.15 k_c 0.0\n",
      "3737 Train Loss 10.822968\n",
      "Loss  1.4376323 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4370036 C_bot  0.15 k_c 0.0\n",
      "3738 Train Loss 10.797226\n",
      "Loss  1.4370036 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2779592 C_bot  0.15 k_c 0.0\n",
      "3739 Train Loss 10.654015\n",
      "Loss  1.2779592 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0819312 C_bot  0.15 k_c 0.0\n",
      "3740 Train Loss 10.438855\n",
      "Loss  1.0819312 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8742818 C_bot  0.15 k_c 0.0\n",
      "3741 Train Loss 10.2401905\n",
      "Loss  0.8742818 C_bot  0.15 k_c 0.0\n",
      "Loss  0.74634963 C_bot  0.15 k_c 0.0\n",
      "3742 Train Loss 10.101749\n",
      "Loss  0.74634963 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6843268 C_bot  0.15 k_c 0.0\n",
      "3743 Train Loss 10.040525\n",
      "Loss  0.6843268 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6971541 C_bot  0.15 k_c 0.0\n",
      "3744 Train Loss 10.051769\n",
      "Loss  0.6971541 C_bot  0.15 k_c 0.0\n",
      "Loss  0.76841277 C_bot  0.15 k_c 0.0\n",
      "3745 Train Loss 10.115943\n",
      "Loss  0.76841277 C_bot  0.15 k_c 0.0\n",
      "Loss  0.84653145 C_bot  0.15 k_c 0.0\n",
      "3746 Train Loss 10.199871\n",
      "Loss  0.84653145 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9287894 C_bot  0.15 k_c 0.0\n",
      "3747 Train Loss 10.269488\n",
      "Loss  0.9287894 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96547925 C_bot  0.15 k_c 0.0\n",
      "3748 Train Loss 10.316222\n",
      "Loss  0.96547925 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9919459 C_bot  0.15 k_c 0.0\n",
      "3749 Train Loss 10.327813\n",
      "Loss  0.9919459 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96257746 C_bot  0.15 k_c 0.0\n",
      "3750 Train Loss 10.30961\n",
      "Loss  0.96257746 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9311748 C_bot  0.15 k_c 0.0\n",
      "3751 Train Loss 10.26353\n",
      "Loss  0.9311748 C_bot  0.15 k_c 0.0\n",
      "Loss  0.86691236 C_bot  0.15 k_c 0.0\n",
      "3752 Train Loss 10.209216\n",
      "Loss  0.86691236 C_bot  0.15 k_c 0.0\n",
      "Loss  0.820512 C_bot  0.15 k_c 0.0\n",
      "3753 Train Loss 10.150244\n",
      "Loss  0.820512 C_bot  0.15 k_c 0.0\n",
      "Loss  0.76022786 C_bot  0.15 k_c 0.0\n",
      "3754 Train Loss 10.096791\n",
      "Loss  0.76022786 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7240227 C_bot  0.15 k_c 0.0\n",
      "3755 Train Loss 10.0519085\n",
      "Loss  0.7240227 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6905639 C_bot  0.15 k_c 0.0\n",
      "3756 Train Loss 10.021268\n",
      "Loss  0.6905639 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67515886 C_bot  0.15 k_c 0.0\n",
      "3757 Train Loss 10.001326\n",
      "Loss  0.67515886 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6655659 C_bot  0.15 k_c 0.0\n",
      "3758 Train Loss 9.991143\n",
      "Loss Less than 7.5...\n",
      "Training time: 904.83\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ./Models_Trained does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 69\u001b[0m\n\u001b[1;32m     65\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     66\u001b[0m train_model(max_iter,reps,n_batches)\n\u001b[0;32m---> 69\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_PINN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Models_Trained/AFSD_Exp_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOmega\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrpm_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmms.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# train_loss_full.append(train_loss)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# test_mse_full.append(test_mse_loss)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# test_re_full.append(test_re_loss)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining time: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (elapsed_time[reps]))\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ./Models_Trained does not exist."
     ]
    }
   ],
   "source": [
    "# from Seq_model import Sequentialmodel\n",
    "from Seq_Model_Parallel_600_calibration import coupled_PINN\n",
    "from training_samples_calibration import trainingdata_uvw,trainingdata_T\n",
    "\n",
    "\n",
    "folder_main = '/home/smartlab/Documents/jupyterNB/raghav/Projects_git_summer2024/PINN_AFSD/Code_Final_Sept2024/AFSD_PINN/Experimental_Comparison_Only/ExperimentalData_and_Plots/'\n",
    "# filename = 'Models_Trained_AFSD_Exp_2mms_z1mm_300rpm_2mms_8.pt'\n",
    "filename = 'AFSD_Exp_600rpm_1mms.pt'\n",
    "\n",
    "sheet_name = '600rpm_1mms'\n",
    "\n",
    "label = 'meltpool'\n",
    "max_reps = 1\n",
    "max_iter = 10000\n",
    "p_iters = 10\n",
    "\n",
    "N_B = 1000\n",
    "N_f = 10000\n",
    "n_batches = 5\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "\n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*3)\n",
    "     #Total number of collocation points\n",
    "\n",
    "\n",
    "    layers1 = np.array([3,50,50,50,4]) #9 hidden layers\n",
    "    layers2 = np.array([3,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([3,50,50,50,5])\n",
    "    # layers = np.array([3,64,64,64,1])\n",
    "    model_PINN = coupled_PINN(layers1,layers2,device1,device2,lb_xyz,ub_xyz,sheet_name)\n",
    "    # PINN = nn.DataParallel(PINN)\n",
    "    #PINN.to(device)\n",
    "\n",
    "    model_PINN.load_state_dict(torch.load(folder_main + filename),strict = False)\n",
    "    'Neural Network Summary'\n",
    "    #print(PINN)\n",
    "\n",
    "    #params = list(PINN.parameters())\n",
    "\n",
    "    # optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25,\n",
    "    #                           max_iter = 30,\n",
    "    #                           max_eval = 50,\n",
    "    #                           tolerance_grad = 1e-5,\n",
    "    #                           tolerance_change = 1e-5,\n",
    "    #                           history_size = 100,\n",
    "    #                           line_search_fn = 'strong_wolfe')\n",
    "\n",
    "    optimizer = torch.optim.Adam(model_PINN.PINN_T.parameters(),lr=0.008, betas=(0.9, 0.999))\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_model(max_iter,reps,n_batches)\n",
    "\n",
    "\n",
    "    torch.save(model_PINN.state_dict(),'./Models_Trained/AFSD_Exp_'+str(Omega)+'rpm_'+str(V)+ 'mms.pt')\n",
    "    # train_loss_full.append(train_loss)\n",
    "    # test_mse_full.append(test_mse_loss)\n",
    "    # test_re_full.append(test_re_loss)\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c8eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_PINN.state_dict(),'AFSD_Exp_calib_'+str(Omega)+'rpm_'+str(V)+ 'mms_1data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fccb21-7030-4050-ae16-7f138f7ba249",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_min,y_min,z_min] = lb_xyz\n",
    "[x_max,y_max,z_max] = ub_xyz\n",
    "\n",
    "x_min = -20.0\n",
    "x_max = 20.0\n",
    "\n",
    "x = np.linspace(x_min,x_max,200).reshape(-1,1)\n",
    "# y = np.linspace(y_min,y_max,200).reshape(-1,1)\n",
    "y = 0.0\n",
    "z = np.linspace(z_min,z_max,50).reshape(-1,1)\n",
    "# z = 0.0\n",
    "X,Y,Z = np.meshgrid(x,y,z)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "Z = Z.flatten('F').reshape(-1,1)\n",
    "\n",
    "xyz = np.hstack((X,Y,Z))\n",
    "xyz_test_tensor = torch.from_numpy(xyz).float().to(device1)\n",
    "\n",
    "uvwp = model_PINN.PINN_uvw.forward(xyz_test_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac24ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fd7203c89a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAGFCAYAAACothrZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABZJUlEQVR4nO29fZQU1Z3//67qeUJhBlFgxIwimgRdFQwI8k1iTJwVxM3GlRh0yVFZFrMJkOhkd8VsIrrJLhpN4kaJxhzFbCIb13PUJJrFH0HRRFHcIR6jMZzougHFgRiWGYTMU9f9/VEPXVV9q+rWQ3dXN+/XOTU9XXXvrVuP913vz63bmhBCgBBCCCEkAXqtK0AIIYSQ+oVCghBCCCGJoZAghBBCSGIoJAghhBCSGAoJQgghhCSGQoIQQgghiaGQIIQQQkhimmpdAUIIISTvDA4OYnh4OHU5LS0taGtry6BG+YFCghBCCAlhcHAQJ54wFn17i6nL6uzsxBtvvNFQYoJCghBCCAlheHgYfXuL+H3vVLSPS94jYOCAgRNm/S+Gh4cpJAghhJDDjbHjNIwdpyXObyB53jxDIUEIIYQoUBQGiil+naoojOwqkyP41gYhhBBCEkNHghBCCFHAgICB5JZEmrx5hkKCEEIIUcCAgTTBiXS58wtDG4QQQghJDB0JQgghRIGiECiK5OGJNHnzDIUEIYQQogD7SMhhaIMQQgjJMevWrcPUqVPR1taGuXPnYtu2bYFpH3roIcyePRvjx4/HkUceiZkzZ+IHP/hBRetHIUEIIYQoYECgmGJK4kg88MAD6OnpwZo1a7B9+3bMmDED8+fPx969e6XpJ0yYgH/6p3/C1q1b8dJLL2Hp0qVYunQpHn/88bSbH4gmRIMGbQghhJAMGBgYQEdHB17/bSfGpRgi+8ABAydN70N/fz/a29uV8sydOxdnnXUW7rjjDgCAYRjo6urCqlWrsHr1aqUyPvCBD+DCCy/EV7/61cR1D4OOBCGEEKKA3dkyzQSYwsQ9DQ0NSdc3PDyM3t5edHd3O/N0XUd3dze2bt0aWV8hBDZv3owdO3bgnHPOyWYnSKCQIIQQQqpIV1cXOjo6nGnt2rXSdO+88w6KxSImT57smT958mT09fUFlt/f34+xY8eipaUFF154IW6//Xb8+Z//eabb4IZvbRBCCCEKGNaUJj8A7Nq1yxPaaG1tTVOtMsaNG4cXX3wR7777LjZv3oyenh5MmzYN5557bqbrsaGQIIQQQhSwO02myQ8A7e3tSn0kjjnmGBQKBezZs8czf8+ePejs7AzMp+s6Tj75ZADAzJkz8eqrr2Lt2rUVExIMbRBCCCE5pKWlBbNmzcLmzZudeYZhYPPmzZg3b55yOYZhBPbDyAI6EoQQQogCRYGUPyMeP09PTw+uuOIKzJ49G3PmzMFtt92GgwcPYunSpQCAyy+/HMcdd5zTz2Lt2rWYPXs2TjrpJAwNDeFnP/sZfvCDH+DOO+9MXvEIKCQIIYQQBbLqIxGHxYsX4w9/+AOuv/569PX1YebMmdi4caPTAXPnzp3Q9VJw4eDBg/jc5z6HN998E2PGjMH06dPxwx/+EIsXL05R83A4jgQhhBASgj2OxIu/mZR6HImZp+6NNY5EPUBHghBCCFHAgIYitFT5GxEKCUIIIUQBQ5hTmvyNCN/aIIQQQkhi6EgQQgghChRThjbS5M0zFBKEEEKIAhQScigkCCGEEAUMocEQKTpbpsibZ9hHghBCCCGJoSNBCCGEKMDQhhwKCUIIIUSBInQUUxj5xQzrkicY2iCEEEJIYuhIEEIIIQqIlJ0tRYN2tqSQIIQQQhRgHwk5DG0QQgghJDF0JAghhBAFikJHUaTobNmgv7VBIUEIIYQoYECDkcLIN9CYSoJCghBCCFGAfSTksI8EIYQQQhJDR4IQQghRIH0fCYY2CCGEkMMWs49Eih/tYmiDEEIIIcQLHQlCCCFEASPlb23wrQ1CCCHkMIZ9JOQwtEEIIYSQxNCRIIQQQhQwoHNAKgkUEoQQQogCRaGhmOIXPNPkzTMMbRBCCCEkMXQkCCGEEAWKKd/aKDK0QQghhBy+GEKHkeKtDaNB39qgkCCEEEIUoCMhh30kCCGEEJIYOhKEEEKIAgbSvXlhZFeVXEEhQQghhCiQfhyJxgwCNOZWEUIIIaQq0JEghBBCFEj/WxuN+exOIUEIIYQoYECDgTR9JDiyJSGEEEKIBzoShBBCiAIMbcihkCCEEEIUSD8gVWMKicbcKkIIIYRUBToShBBCiAKG0GCkGZCqQX9GnEKCEEIIUcBIGdpo1AGpKCQIIYQQBdL/+mdjConG3CpCCCGEVAU6EoQQQogCRWgophhUKk3ePEMhQQghhCjA0IacxtwqQgghpEFYt24dpk6dira2NsydOxfbtm0LTPu9730PH/7wh3HUUUfhqKOOQnd3d2j6LKCQIIQQQhQoohTeSDbF54EHHkBPTw/WrFmD7du3Y8aMGZg/fz727t0rTb9lyxZcdtllePLJJ7F161Z0dXXh/PPPx1tvvZVq28PQhBCiYqUTQgghdc7AwAA6Ojrw5efOR9vY5sTlDL47gq+d/f+hv78f7e3tSnnmzp2Ls846C3fccQcAwDAMdHV1YdWqVVi9enVk/mKxiKOOOgp33HEHLr/88sR1D4OOBCGEEFJFBgYGPNPQ0JA03fDwMHp7e9Hd3e3M03Ud3d3d2Lp1q9K6Dh06hJGREUyYMCGTusugkCCEEEIUsH+0K80EAF1dXejo6HCmtWvXStf3zjvvoFgsYvLkyZ75kydPRl9fn1Kdr732WkyZMsUjRrKGb20QQgghCghoMFK8wimsvLt27fKENlpbW1PXTcZNN92EH/3oR9iyZQva2toqsg6AQoIQQgipKu3t7Up9JI455hgUCgXs2bPHM3/Pnj3o7OwMzXvrrbfipptuws9//nOcccYZqeobBUMbhBBCiAJZhTZUaWlpwaxZs7B582ZnnmEY2Lx5M+bNmxeY7+tf/zq++tWvYuPGjZg9e3bi7VWFjgQhhBCiQC1+/bOnpwdXXHEFZs+ejTlz5uC2227DwYMHsXTpUgDA5ZdfjuOOO87pZ3HzzTfj+uuvx4YNGzB16lSnL8XYsWMxduzYxHUPg0KCEEIIUaCY8tc/k+RdvHgx/vCHP+D6669HX18fZs6ciY0bNzodMHfu3AldL5V75513Ynh4GJ/85Cc95axZswY33HBD4rqHwXEkCCGEkBDscSSufuYv0ZpiHImhd0dw2wd/EmsciXqAjgQhhBCiQC1CG/UAhQQhhBCigAEdRorQRpq8eaYxt4oQQgghVYGOBCGEEKJAUWgopghPpMmbZygkCCGEEAXYR0IOQxuEEEIISQwdCUIIIUQBIXQYMUen9OdvRCgkCCGEEAWK0FBM8aNdafLmmcaUR4QQQgipCnQkCCGEEAUMka7DpNGg40hTSBBCCCEKGCn7SKTJm2coJAghhBAFDGgwUvRzSJM3zzSmPCKEEEJIVaAjQQghhCjAkS3lUEgQQgghCrCPhJzG3CpCCCGEVAU6EoQQQogCBlL+1kaDdrakkCCEEEIUECnf2hANKiQY2iCEEEJIYuhIEEIIIQrwZ8TlUEgQQgghCvCtDTmNuVWEEEIIqQp0JAghhBAFGNqQQyFBCCGEKMDf2pBDIUEIIYQoQEdCDvtIEEIIISQxdCQIIYQQBehIyKGQIIQQQhSgkJDD0AYhhBBCEkNHghBCCFGAjoQcCglCCCFEAYF0r3CK7KqSKxjaIIQQQkhi6EgQQgghCjC0IYdCghBCCFGAQkIOQxuEEEIISQwdCUIIIUQBOhJyKCQIIYQQBSgk5FBIEEIIIQoIoUGkEANp8uYZ9pEghBBCSGLoSBBCCCEKGNBSDUiVJm+eoZAghBBCFGAfCTkMbRBCCCEkMXQkCCGEEAXY2VIOhQQhhBCiAEMbchjaIIQQQkhi6EgQQgghCjC0IYeOBCGEEKKAsEIbSaekQmLdunWYOnUq2traMHfuXGzbti0w7SuvvIJFixZh6tSp0DQNt912W8KtVYdCghBCCMkpDzzwAHp6erBmzRps374dM2bMwPz587F3715p+kOHDmHatGm46aab0NnZWZU6UkgQQgghCggAQqSYEqzzm9/8JpYvX46lS5fi1FNPxV133YUjjjgC9957rzT9WWedhVtuuQWXXnopWltbU22vKhQShBBCiAL2yJZpJgAYGBjwTENDQ9L1DQ8Po7e3F93d3c48XdfR3d2NrVu3VmWbVaCQIIQQQhSwO1ummQCgq6sLHR0dzrR27Vrp+t555x0Ui0VMnjzZM3/y5Mno6+ur+Paqwrc2CCGEkCqya9cutLe3O9+rFYKoFBQShBBCiAKG0KBlMCBVe3u7R0gEccwxx6BQKGDPnj2e+Xv27KlaR0oVGNoghBBCFEjV0dKa4tDS0oJZs2Zh8+bNzjzDMLB582bMmzcv461LDh0JQgghJKf09PTgiiuuwOzZszFnzhzcdtttOHjwIJYuXQoAuPzyy3Hcccc5/SyGh4fxm9/8xvn/rbfewosvvoixY8fi5JNPrkgdKSQIIYQQBWoxsuXixYvxhz/8Addffz36+vowc+ZMbNy40emAuXPnTuh6Kbiwe/dunHnmmc73W2+9Fbfeeis+8pGPYMuWLYnrHoYmRFyzRY1169bhlltuQV9fH2bMmIHbb78dc+bMqcSqCCGEkIoxMDCAjo4OnPIf16JwRPKOkcVDQ3j1spvR39+v1EeiXqhIH4m4I3ERQgghpD6pSGjDPRIXANx111147LHHcO+992L16tWheQ3DwO7duzFu3DhoWmP+wAkhhJBsEELgwIEDmDJlisfirwRZvbXRaGQuJOyRuK677jpnXthIXENDQ55Rvd566y2ceuqpWVeLEEJIA7Nr1y685z3vqeg6krx54c/fiGQuJMJG4vrtb39bln7t2rW48cYby+a/54YvQ29ry7p6hBzeNOiNjBy+GIODePPGr2HcuHG1rsphS83f2rjuuuvQ09PjfB8YGEBXVxf0tjYKCUKSQsFADjOqEQo3HYk0b21kWJkckbmQiDsSV2tra90PD0pIVWnQmxEheacWr3/WA5n3TKmXkbgIqTsEKCIIqSEig6kRqUhoI2okLkKIIo165yGENAwVERJRI3EREkhWzl8jNMCNsA0WWhW2pUFdY5IjGNqQU7HOlitXrsTKlSsrVTypB2p5zaisO88NdQ7qVo3GP0vqrb5uGrR9aTzSxifq+BwNo+ZvbZAGoR5vhO465+kCr1Fd6rkhrncOh31PsdS4UEiQYA6nC9+/rbW6sVdhvYdDo0XyR6XOu6qezylDG42qpigkiEljnt/JsfdHAzW6FBCEpIMjW8qhkGgkKAayJy9ORQKq+6RWxXWlhdcJIZlCIVGP8EZYOzTUV6NZCep9+5PWn9fdYQ/f2pBDIVErGvN8OjyoZCfNDIRKZk5EvQuGrOH+4H1LaOn6OVBIkNg05jmTOarXVi5j/DlzKDLZRznaHpIz0p4bvCc2JBQSKvDkl1JtcZ10fRUXIFk7FAnFSeLtrOT+yeMTWC4V6WFCVru+RqcVO1vKoZBwk8N7Xl7IY3ugirvuVREV9XSzyLKu9XKSZFFPipHaIgL+r8Z6OSBVGY0lJOrkPlZr6uV+XwnCtj2ztiELhyKmIIlV91Q3wsP45HGT1/1AgVNR2NlSTn0JicY8BhWlQc/bilAR56LeHIogeCLVB3Xd4YjUK/kVEhooHELI9X29mjepCu0IWbGJNyvp4FaKIkS5XrFci2z26+HYXuX62rRheCc5h+lmh5FfIUE85O7mlJebSFA9KrDD7CJTCYp6GHo7xb7Ly2lRS+Lug9xd26pkqrbrA4Y25FBI5Iian2ONdBOI2pY0NwNf1li7La47kYX4UMkfc3/k4lSJqkOtrydFstqXNb9/AGqVyMXJQ7KEQqLG1PTiP5wvaP+2ZyAsYguKvOz+GNue+SlT0VdPK1g2kDuhIjs2uRAXfqr6GlXG8K0NKRQSVaAmF3O1LtA83ajSbHIGIZLY90dVdyKp6IjKo7htiU6lBr1heqjUNmZ4Takeu5oJjroLj6TtvJenG2Z2UEhUiIYVD3m+DmR1Sz0Sn1VAzAMay6WohTuhsD2xT6d66P+R5/PXRrY9Fa53wtO8MqTujESqDYVESqp+4VXq4qrmdqisq1oj4Cn3VUjmWCi7FFmPZhlWVkidK/IGSBb5sqKW609zjcXpU5OCsONf9XtdHkMgDG1IoZBIQMO4DZXajizKzUoAxFlPkjI1oXxCCK0yYiIWaUUEwxzJCdoPWV6H/nVUIExSk/tf5MVTrXqAQkIChUQINbP5srxgstqGPFieblTrk4XtHdmHQb3jZqRrGyQm4oiMQJdCXq/I063CLkXeTq20xN4NlQzNVEC8ZNhPOR4MeeQWCgkfFA8ZlpEH/NuRyHWImV/Bpaj6A1YSEVEhAdEop1YQSfWoEu5CsgiVZDQuVVXvm7V0J/gz4lIOSyFR82OZF9HQSIIjqxhy3LEJAp/4oh/bAu+HaUa0lM6LKSJSiotUp0Q9PWzG3NDMTbSoMFmSMhIePPe5VPP7awXhr3/KOWyERC5O7kYQEHnYjzKycB7c5cQVJgnXV6uHq0qIiNinRr3fVCvU5yGTUzmp45CBU1EVh6JWFw77SEhpCCGRC5EgI6sTPen2VTufhajwBa4pjZ4XsTyu8xCVLyr8EdJTTXpPTNLxUtGNUHcywlcXeRQa7YZbzX45CkmUVpPUcUgZQqlKx8y8dMAk9SskcisegPoUEAnXVWnRoLpOJXHhyeAuMEG+pG9fVDOgnEZEhJC5gKiXtqASDkSKBjuRGZbEcRAx07uoev+JSsM+ElJyKyQE6mSfHwaiIZVYyOoYRlQhqo6hQiOsjqqNR9iTX9my8rtrNR6uyspXFBWhh7BSr4wiHw+bSvegrByIhH0eZIsiqxRXwKQRPA0kJjSR7rzMwzldCXIrJHJPrfs7xM1TLfFQqRtGysCxe3tiuReqj32hLoRkWZXvrknHiAisYVR5MY5Pnm+umf+4bNIGOaaTEMutiOs4JHAoKna6N4pCqXMoJFSotWhIki9G+liioZodNSvRKx3h2xsoMlSETKgLIZvnvbumciXK3IZSuZFOhO97bPEQ1ZeiHkMdEedXJr9hkSRUErPPg3IEL6lDEUeTV6rfRDXFBDtbStHjJF67di3OOussjBs3DpMmTcJFF12EHTt2eNIMDg5ixYoVOProozF27FgsWrQIe/bsybTSVcH2sLIMXSR1HuLkU0wvNOFMFa2He4qLrIwkgiqmqFLaJ1HlypZV2EVyiHNjVXUqgsIgAfljXT7CN+UBf50S1i3RbSTOumKkVT4r4tY1Jnl2oCKx+0ikmRqQWELiqaeewooVK/Dcc89h06ZNGBkZwfnnn4+DBw86aa655hr89Kc/xYMPPoinnnoKu3fvxsUXX5x5xTPFfbVnJR6SNn5x8sVoZN3CIbShVG28g9IlFQ1xiFp33PpK8O+vwH0Wtc6oeQnPNWX9507nb3Rc/5dthqzxDGhUIy+foEZZ1ghGpa3GFEaK/LL9FDkgmGrdFOuvfInGEU8JRFZdiwlSRqzQxsaNGz3f77vvPkyaNAm9vb0455xz0N/fj3vuuQcbNmzAxz72MQDA+vXrccopp+C5557D2WefnV3NsyBPv19RoafVWI5DlulqjbKnq57W3peh4Q9/ftm8rElSvk9EhJYXpKGiGraY9cgNsjrFOe/d+RXyxbL8hUKZ9voVwh5Ku19lnXHS2esXdfiAnkA0leVvQFL1kejv7wcATJgwAQDQ29uLkZERdHd3O2mmT5+O448/Hlu3bpUKiaGhIQwNDTnfBwYG0lRJTh5/MTOuS6FApqKhUhd43GORxZ0mrAhZwx+RJrTjpv3V35iEffeUnfJ0DeobEeJESNNIvldqJMzQsqtM4OkWR4xG5QvSoWXnmUKZqud2iPb1Jw0tKyMR46y/3sQEhYSUWKENN4Zh4Oqrr8YHP/hBnHbaaQCAvr4+tLS0YPz48Z60kydPRl9fn7SctWvXoqOjw5m6urqSVqmcLPs4eMpFOuehViIiTrgkK9KGjGL7wXHLR6p9Ehj2KAthhJVf4btLXBHhu1kG7vKgm2oCmz8vJD7VKhAKUFp/2obNXhdqZzbm6fiTZCR2JFasWIGXX34Zv/zlL1NV4LrrrkNPT4/zfWBgILmYyFOoIml+hfTKoiGLNCpU660PzxNWxDrTDFAVuM7gZdKwR5gTUYmQh8yNkIiIUAHhIum4E4H5y/Lm7FE0oMJh2yHdBFUXQsUN860/0qVI6WJEOhQVdCaA/J0SZdCRkJJISKxcuRKPPvoonn76abznPe9x5nd2dmJ4eBj79+/3uBJ79uxBZ2entKzW1la0trYmqUaJw0RAAAoioloCIuu+F0nLCqqG0t03xjqDGgdJ2CNUTGSNzAxRbfCDnIoUAqIS4qFq0bCyMFX0ipVPM5WGVSFNZChARKxDNU0UcQRF3sVBHDiypZRYoQ0hBFauXImHH34YTzzxBE488UTP8lmzZqG5uRmbN2925u3YsQM7d+7EvHnzsqkxkL0vqkmmSudXTB/55kBUOam3TSG0IFtHnPokmVTLU92GyP0QsX4XZcfJn176v3p95EJBsrN9roSnqjKnwr1b/Fa9KJ8XuEsjXn0LOhxZRbHilh8cugnfjqj1SvHv1wRpMl1HAMq3CpUn9BhP8XkLdflJem7lMYyXJbGExIoVK/DDH/4QGzZswLhx49DX14e+vj786U9/AgB0dHRg2bJl6OnpwZNPPone3l4sXboU8+bNy+aNjVrEx7POr5hHaTyDqHJSbVvEvlYVJmlETBblhi1P1VqFf08zrHgqA0VltRIREbhc8l26y0Ia2Vg3Ur9gSTPFJNbpoPBkGlmWaiMcsY5UpLzFZLkuEsy6deswdepUtLW1Ye7cudi2bVto+gcffBDTp09HW1sbTj/9dPzsZz+raP1iCYk777wT/f39OPfcc3Hsscc60wMPPOCk+da3voW/+Iu/wKJFi3DOOeegs7MTDz30UPIaVtJ5qEb+rJyHqLKydh7ilK3kHGQg5UOniDokqV/kPgtYh4XnOKq4EnGxi3c96TvzhTdNmRPhSuNsrj+fNZXtlphOg7+8yMY/K9GQIn9i10KCsoMQRMTyVGWrlA+F01RlPTHS5fbpPcm5qXKuhvDAAw+gp6cHa9aswfbt2zFjxgzMnz8fe/fulaZ/9tlncdlll2HZsmX41a9+hYsuuggXXXQRXn755fgrV0QTQuTqcA0MDJhvb9z8NehHpOw7YZNWVicVHYrU3Hmo5Hrj3g2CylQtJupxPuyGm7RMWX63hnDnF+XL/YLAzBOcvnyZREi4PqPCGYH1ge/wqf6aqGx9SZZnRRLXMILIUyJkx4TmTXHNRdcpYrlCGqVDlsF6POuMSGsMDuL3X/4n9Pf3o729Xb3gGNjt0vE3fw36mLbE5Rh/GsTOa78cq65z587FWWedhTvuuMMswzDQ1dWFVatWYfXq1WXpFy9ejIMHD+LRRx915p199tmYOXMm7rrrrsR1DyPx658VJ40czbHzACRwH7Kon5M34BEriesQVKZq+XFcFNX8UXVRLsdVHxWnomyflL5LnQnpcY0+51OLCOupqMwtkCwrcx8QsCsSPplVypwqI+4TokKaaJch2qGQ5wuok8LyyKf4qLIRvTwzd0Iljb3OqO2qQwYGBjyTeywlN8PDw+jt7fWMzaTrOrq7u7F161Zpnq1bt3rSA8D8+fMD02dBfoVELUgjPBRRch/SPLEE5otoBJPUJ+oKVxU7cRv3pCIr7O4fVZ6snKBtiUvSY5oFfuHh3iyfQ+JdBnljoNj4VrJhiL2elA1spKAIyZdkfVFEbnPa5aqo7ntF8iAmop5VIiernK6uLs/4SWvXrpWu75133kGxWMTkyZM988PGZurr64uVPgsa59c/09yMay0eospLIx6yWlelQyBR60hduB/JuoQmL05IViPgra//lU93PlE6BzR7Ha5liUngRgSmlQiIMuGAkO+QlFNW35BlWeI7VkF1Kmvj/enClkvOE3s95eVqgRUJzONeX9xlVrmpXhONKt+XLPF6FNblWW/Y/qoGGb3+uWvXLk9oI/UQCDWmMYQERYQkX0wRkURAJCkvTtkq+MtQGbI6aL6KMHDPi6p+VoLBT5xTyi8cJOWUxIXXgZCuL8BpkJJkmyMa69hlhJQT2ShFNeRx65d6/PN4pBYTKutARmIio/rUC+3t7Up9JI455hgUCoWyX9AOG5ups7MzVvosqP/QRuKGNkHeGHmUX9/MWkRkYd2rlOPPFzg/xOezk2gZTnrAunRRXsfQKcCXVEnv31+uT+ec0OTLwxoa6eGQOAxBIkITKAs9+EWEswkBk/QwZjm5yaIMWTmSfZio30JEefKy5Bd1Yicn6hYT1cqrLFe4jUWiUE6cdDXrN5H1OR5BS0sLZs2a5RmbyTAMbN68OXBspnnz5nnSA8CmTZuyHcvJR2M4EnGpB9WbVETEKStIQKQtI6wce3FsERdQnuxNAtcszztJMschrmMRNGql5/+AdNanM/plyONcoofXoMYOvrJCRISnHL8mkjX0KnUIKyMGyo6y+5jEXB75FE+kZG26Ka+32oIigRgoyx+Tnp4eXHHFFZg9ezbmzJmD2267DQcPHsTSpUsBAJdffjmOO+44p5/FF77wBXzkIx/BN77xDVx44YX40Y9+hP/+7//G3XffnaLi4dS3kKjWBR9zPTUJZ8QRAHEa/wxESKhoiHMXCFtn0OY7gsCbWZS1kuVp5AUK37okeQTKW6QgMSFZpoTslVJ3bVw3PM1983PfeKP6WEjER+B3f/rAeiukAQIb+cji3fmCxKF/uW9+cF8Heb2ysuQTi5iI9WcS4lBIo3T6Rom8uOkOAxYvXow//OEPuP7669HX14eZM2di48aNTofKnTt3QtdLwYX/9//+HzZs2IAvf/nL+NKXvoT3vve9eOSRR5wf16wE9Sskkp5gFT4xM/tBrTgk6VSpWoZquXFFRNK+F6rpyxoRb+tg10vqWMTpH+HO4xcEEWKirKyYqPRjCBUD7uWqIiKOgKjEk1tUYxbWaGbU4Ncb1XRYauVMVIu0DkjSvCtXrsTKlSuly7Zs2VI275JLLsEll1ySbGUJqE8hUS0RUW0nIsE6MwtFqKZVFBFSARHH8XDKSdrKmh8i6IeY7AZT5lhoAuXDtPnLge+OGfQI5RMnLjEh4ApxeIoIaQ1Ddocnh8d5gFcguJ2IIAGhGt6IqFPmyNal6ijY+VWdhqD1V6hhTtzgV0soKG57QzsTNQht1AP1KSSSkAcnIopaXSwJGvjQvBmsI7GACClHhDkNUY5FkFvhdxZsERAWrnDNi/y10Ki7clTIIcCdiCsilPpH1IqABq5h+jtkHQatR/IiKCgkpNSXkKhnJyJJPbImRkhCOb8smUo6/1NkFuGZqFXK+lNoftfCWw/NV4HQvhUeMeFbJnMmrNlCE6X1uIpX7nApAtwI4f/ucyIiBERUWCSItBowy34CmYsJRZcucJ2SnZN4yOyI7VLe7grcl2QRQSlxBUJeBAXxUD9CIu+2X57I2zanDE9IF8UVe/6nfMAV3hBWmoAwAxDdtyKs46S7zLA3P9yEhjdihD0Egp0IwCsighyIiMOXda/50NBELVGsTxwRkXh9WYmIvFDBkFGW1KqPRN6pDyHRCCIi674ROSX2a52BBcUsW+V1U8lgVW5BoLnfyPD3sfC9rVFWnqdfhXe+mc8V7oAr/GEh4HIlgMjGOxC3G6HiRPhdC4X1Jx7zILDA8PVkMJBgrPVL8yjMqysXQqGsLFDqL2ETR0zUypnIaGTLRiP/A1I15n6vLHFu5nFObIVypb8lW8mLJ84jgp3Wld49mJU5A14d4Hmcl5Tn/qr55nvK9JWT8tHE7yzETS/rI+EQFGUK2tU+gRKbtHHnoGLLjhckx1ChIJVyAvPGEBFh5SqsM28iIhFxz4MKnTskHvl2JNKc7PXmYlTD2gtahywYr6r4Jb8jIESS0IPmbbQldY1TbnS1y+8+HpfB5Vb4nQqlPhW2Q+Ep0yrH3W/C5UyUuRK+Oc4u8TkHzrwANyLQiXB/L98U7zL55uaDKGdAQTxE5lFZDxAoEEPFQxB5Ew4Jy4jlSgBQvvfUgrTCJY/XTwbkV0jUQkRUkkoJhaAeeYGiIWh+QDmy/Agow53M3+j7y5eUoyImsiJQCrj8dE9/CFdrrtqnQrPFiGYV4N+9tgKQlVMh4oz5kAcRkdrMihAISmGMSoQw6klAZFlOHKrxcBUT9pGQk18hUStqefImXXeYmICkTHdSf2PvzBflad3p/WVIxmvw9j+IKN9ptDUrfdByV3nuOqe4QuW6yhv+sNfj3WyXC+Pv32Dlt/0EYVsHwlIXAc6E0AU0wydzZGNhyIYGj3Aj/B0rg5yINAIi6DDE6RMQ2VCmcCAq6Tw0jGjIuiwkcCVscigmSDkUEtVE5aJIIyaAeIIibFlQebL00nne/JECIIGgCHM80rqjZTc+q/Eucymc7RKujpnuCpTylfUfCRAE/rEllF8DVSGtNRtCbBGhEmIIyVO3AuIwEQ8NCUMbUigkZMRszO2bvtJ4EiotXJpWMGgkR3e5nuUhy0IroRhO8Y2bEDTAk+avhzt84Kun5hYnbpPD80WU1TLu7izTSm6XwnEa3OklDoXPnfA6EzB/ldR2KQyttJ/czoQvtFKG7+YW1DfCs20BboSUyHPEWhzTSYjME9awB/0vKzPie+4FQxYNfI1FQqr2M0+uRMrQBoVEPZHFiZegDE1o6oNTqboTiF8PbxkR1n9US6sSBnGXnzAU4h7oSRoGce0Lj1vhme9eRbCoyPQhzr1emX/rmyd1JpyFPofCzitxLuK6FHHf8pAXkrAMlYY7IH2geAhLF5E2OI9845RfB1VZFlRegnIqlpeQmDSmkAAyaoR93xXK0spu+CF3XtXyw5wEVZTuXlGPnCHr9jeAQUX6xmNw0rut/LJ1eFtNJ7zgm+99SvW13q5/hSyNpEqy6nvKlw1S5RgoLkfFJwjMOvhthvL/BQQ0zXa7SqvMdBwHiTgIM7XinHeqgiFUBKQQCw3pNNShQGioh3CGNqQ0rpCwyfIxNEFZsV0K1fLTePaBZUoKCutz4UmnuFzacVCStqwMt9AoDzE463XcB5d48IQc3CUGt5i5vN5VHIGwNK5lHkESUa5Kf1alxjNBqELVkQith6p4SOgyUDgEk8vrKA0UElLyKyTsA5ZZIxmyLPbTfbz8fpfCKUYl3BBYaMz0QXmjUL1Lhtn1ocsDyg98GvSeFOVPqbKQRqmTZJlYsBtJX7llGiOgPmVhisTWv7V+v5h019t2N7RScln/CTOZZAwKO62VT3gWllYTtC2qT+6ZOAwqIqEKb04kEUiZp09AFu1VkmpWpJ3MkZji659y8iskbCoR2A5aR9L1JKyjt2d+zDMsTbgjrlBJQ9CdOEpgBOIvL+Ix2RN2KA9H2C1sWKfOUv6QasmMG7tMf4OcUHx4XQSXsPAIiIDy3BolJKoSFKEKqo9sPUEFxHEXGkI0VOCeVc12KBdtXo5EBAkm/0LCplqNX5gtXMG8Qa5F5Cqj3spIioqFnoqIAlS3RdWi1rwLvMJNkzaApmNR3jcDvvmhuMWi8M1z26T2WxxBuNwHRz9ontlOkZpurcser8K1TieSFOA8hJ1Oyg13TFFQ9T4KVXQQctEY1ysUEXVD/QgJFWKGHBKXXeFQSBwyESCJCoiZPoaREJqvrB4yD9zOK2kVnRbX9+jtedJ3rz8gjKIQ+ih3HnwOhV9ECF+asvOm5EIImI6JgOZUWXNl9Wym5bo4hoxVhqyPRNKn8kQOQgKhkKdQA0VCBcmriGAfCSmNJST8ZNVYqZabZWihwiQVIMEFRiyv8DbLhZGkUpFPq4r7JeqpWiUM4nco7HnCXoVWduNywhe2mBCiJA5EKb8jJlzrcvpJWDMDX0MNI00jn5FTUJXLJ68NWaWp1b3pcN3fDUJ+hUTWDV3oulz/p1ltJR2RvFNjcRQpjNzefwihTo17FZI+FQEVk61EMg9eARFUpsuFcMSEldgWFE73E3fIQiuf51l3GKrncdZC4HC6fvJCUucwy3XmGHa2lJNfIQGoi4ksj05UnDqrsmpJXusFpBaQaU+FsldCIwgfmdEdZIhJWMGaKDMxSn0ghLcPRED/B2/mw4wqPKTkosHIog5Z3vPqSDCEkodjmzP0NJlvuukmaJqGq6++2pk3ODiIFStW4Oijj8bYsWOxaNEi7NmzJ209wxGad6rYeuB5cswNIuaU6bq1zCbN0BzFHzkZ8snZRiN80orZTPqod/IsH9XkU1Fh8m2vFA3mFawDKAhAFxAF/wRnMprg+S4KgJDNC5r0fE/Oq61Rk656kqkchOwui8wJ2v5KErbfK7k+UlMSOxIvvPACvvvd7+KMM87wzL/mmmvw2GOP4cEHH0RHRwdWrlyJiy++GM8880zqyiqjclVWu7NhpcjoDpTZE5RqORHpyupT9t273dHpfeWr1CduHRPgbIbrUwCAbi3TREkwaIDQhXPzdP/vVCjMmhZa9OGJSqCwzZFhprAygpYFztcCkwQen5jzPa/chpHmfBBa6ktZ+XyMs5683Odsai0a0j6M5W1/ZkQiIfHuu+9iyZIl+N73voevfe1rzvz+/n7cc8892LBhAz72sY8BANavX49TTjkFzz33HM4+++xsap0F/qs2F16khBpb/aV6ZJte+SYfJhgC/vfkCBAUsYWHVGikv6s5P0DmeWKG6ZxoADTNFAzuKEnZ056whIbwpimrsygTFuXbFFDR0MbfW44IS6wg2KRCJChfyPuqpQG3/Nd6vOsi1K13L4w6HZQLcudRP8dkSVNf/7XoMyGj1gLCgn0k5CQSEitWrMCFF16I7u5uj5Do7e3FyMgIuru7nXnTp0/H8ccfj61bt0qFxNDQEIaGhpzvAwMDAEr3RzcVDW1Ws3NnAmKdgElO1ph5Iuuj0PCGjaLoNPiyMt2iwT/PLxRc4yeEp4uY7yNSiESh2dXTnO+ORa+bboMdTrDf4fT0i9DNUIYd1tCs75ouoGmmQNFCDpIIepKXjXshSSg8lfGn08rzy9IH5hOhy4PqFCxIysuLHBQsyvGy8khvG0G73ZVW6Xr2C6XI9OWVybybWRqxFId8346Jj9hC4kc/+hG2b9+OF154oWxZX18fWlpaMH78eM/8yZMno6+vT1re2rVrceONNyqtu6rCogYkUqsVFBjKNzvp/BihB5mbIFmuIhriCAaZWPDPCyqvLL2s3jIcAWH+r9kxch1mHw+7iLCfCZXF+20RoQvomi0oSqJChpA0+EImJDzzSo2zk62sHNP50Dx5XG5IoNAQ8v3svMUiExha+b92Ms2XXnOJC79jU+bgePeZgOR8DnpaVxAXSoZoHJEiKySFm5H4yTmpg1Ev93KBdGKJjgSwa9cufOELX8CmTZvQ1taWSQWuu+469PT0ON8HBgbQ1dWllDelWE9Mxe2pNA24C+V6RroL8p0X+RaATCAEpAlv6F2ugqyhFwgsx17umS8i5sObxlue8H2XbBPk+8YWD6Zw0AAdMAowP61Oj2ZmSVvpmoRLPEAX0AoCekFA1w3oBQMFe9LMeQVdoKAb0CWVMpxGXXO+l/6HZ5kQmrkc5fPNT+88UZbfvSOsNK6dI3z70jPEeEAZZeLC/+qsT5CUhV2k56ImSSM8aYUrvbt8N4Fhj6BzI2CZp8zwxd4yVG4AAdd2Zt3M6kUgKMLQhpxYQqK3txd79+7FBz7wAWdesVjE008/jTvuuAOPP/44hoeHsX//fo8rsWfPHnR2dkrLbG1tRWtra7LaxyC3BzCjxj6Ve+BJk1A0+L4nEQ7e+VpZI1+Wzy8EXMvtp/tA4WB407kFieYaWlrzrzuwvvDgCd3bD8GW82C+K2WNB+EMZ11ehpnJV45WvkxzvVmgaYCum8/Pum6guWCgoFuiwgp3+AWFTEy4BYNXXHiFhvAvs+vqml8uMIRnfcISCs531z509g3M30PRUPruFR+W+tKsY6dZ89wNtL3MvUNl0RJfOueV4DLXwp0JZQc98Ck/7Kk94ok+kZMRdt1n5GLk9v6aNUHXaZz8DUgsIXHeeefh17/+tWfe0qVLMX36dFx77bXo6upCc3MzNm/ejEWLFgEAduzYgZ07d2LevHnZ1ToPZHlCpBEJUfUIuTHE6tUeQyR4yq60UPAJAc0vEFzpbIHgERUyoeH5FGX1KBMXgOtR2YWmOWELoQOioJkOBOB1Hdxug+Y6ZH4RIUmvWW9umMLBdCA0zXQgbCeipVBEk26gWTc/W/RR6BJBYWMLi1FDt77rMKA5AsMWE+55AFC00hd9oqP0KRcefhfDTuN2NGyx4XyH+7t5PMp+JM0nVLzLrD8RDoY5SwSm8bgXnrz+BlpyKbrDLE55vjRh4iV8Uam8KG3gETIKN7YEfTGyFhoi6NogNSGWkBg3bhxOO+00z7wjjzwSRx99tDN/2bJl6OnpwYQJE9De3o5Vq1Zh3rx5+XpjIw5ZK0jF8mI18s6y7EUDECIcXN/TdHr0P+l7vsPXcIcIhbL5biFQNt/36SwX8vWYLV6wQ+FHs55sdeuL5m1bytwFVWLkcQsFHaZwaNKK1qeBJr2IgpVGd22IYa2kKDRTRPhEg2HP94sL3ZtOuJdBLiwAwHAES0lYlAsJ08kQwtyRmrUThctV8DoYpf1tHyfnF1ztPMLOJJlvlmB9+Bp8Vxp3qCRwMDN/Y25nkdhW0qd8VQdDci4quQZxHAx/QYqtuJKTErOMmhB2zavmb0AyH9nyW9/6FnRdx6JFizA0NIT58+fjO9/5TvyCKrXDsyg3ZRmJHIY4IYfQcnz5w5b7G/OA5Yn7MkjEQlnooayhd306eUS5UAj8booBr6Aw87tdCK1YSl9ebyF3hDXNch80s79DwXpytl0G9+TKF+sGGXB8gpAVrWsCTXoRrXoRzXoRLfoomi2BIcN2HEasThyjRgEGNEdojApTCIwYBY/oGDV0j+AYdRwL3SM2Rn1OhuNsGJZz4VvuFhr+/wFAGDLnQnj6YAg7FOIsh+ttEZdLIewMAc6F6+AJiIDrw3cUZMfQ0zj7ii5rhcuzOPNDzgllfZClgxFwcudCFCSAfSTkpBYSW7Zs8Xxva2vDunXrsG7durRFhz7tJc6bZT0UiTx5YoiHNM4CECEcXN812c1OtlzmNMjEgkCgeADg6dMQGnpwOwehgsG66CXp/PPdroVbOHhEgyHK6l/aEGvSAaFpMIepLr/5S8MT7u9JEKXWwx02cBZbn4ZkBbpmQIdAAWZHzGatiII1z03JoTAFQFEvCYEidEdYtOijjrAoCg2GlW7UFg56SXgYQnMEQ8FK12SVWdDM53xdswSE3XAaLqGhCUvgCBg+wSE0r3MhrPlwN8yufjBe58LdIVPBuXD3p3C5I95jUNqfmjuNXZ7/YPnnBTgAlXQvPGX6iSgnsJB6VQ8kknz/1kYQNRQJiRRlWB7fxSUtP6lI8KfzN+IhaVRCEmXzRXk6ad8CV7rI0IQr1ODJ7wgCuzwhmS/KhUPRSuuebwhHUJjfURIQZW9pCHPsB8eB0CAKms99sOZrKH1aecociKBYr+9E8PT/8wsa4ftqCYqioZs/Ne4PSQjDbNCNAgoFgSJ0NMFAQTPQrBXRqo+YogICumagYB2cIkp9JoCSQzEiCigKHSPCFBQjRsESGDqK0J31jgjdIzRsAWI6F6Vwif09zLkI6nshC48IYfgcjNIOF27h4HYurLTuY1/q3CngdO70LA/6jHYtzGMscS5CRYXr3xD3IrBDZuh9Kbzdr6Z7kSuCHibi5G9A6lNIpCXGwcxcOADSC6ZsPQriIVI4+L5LxYNsuat+Kk5D2TzX98BQhV9U2J+yEISVvzwk4UsX9N3lNNgCQx8VrvQCKApnvY4wMVwhDCHg/ISmJgDdDGNIj4IW8OlCuH+uXPH+6RETgNXYuR5wXY2f4TqGhtBQsD5td8HpIClJX4BAAQLNmtkp0xYSzTAdi6IlJGyRMCLM28iIKKAIDSNakykodJfAEBqarM9RUTCFhGaY6TR7vlmeDiuE4nIuDGjOeBi6JTSEVW/T2RAoGpo5KKihm1rQElHmfhHOeBaGE/qAJRg1e3dabbftOJREpJ1XcxwJW3C43AmppeCab+/jgOMd6ly488lW48wrVxdS5yIov2yZZHnF3YugFdUaCgkpjS0kFA+akliIcwIEnPyRYiFKKESlD3jSCRMLSk6D9RkamnAJA8DlLCgKBvd8t4AIFQhhgqFoLS+6BEPRchwc58H1vSjsltgleoS1qzRrCGoNokmHpuswzJGeIAolV8Kw/7ff0tDKP90hDelpovKEZzdg1s4WQivZ8laDKTQBQ5hhgIImUDR0NGkGRg0do5oO6MCI0AEDGNUM87tRsOabDbkZ+iiiWRtFi1Z0hT4MpzoGSv0eijBdhWFRgAEdw6LJERpFaJag0DFoNEudC9uhsPtaDBnm7WnYetVluGh+9wsMx6lwnIxSCETNsbCFhc+1cM93iQG7L4Vm5/VdU0KI0sF1XzOyT62Uz+NOeXrmek8B6ZsifpFhV9A3L8y5cGeJhSgvzlN0kL7ylRGeOYRG7XhQRzSmkMjq3FM9P0OuoshQRYXFg3d5QvEQkCaoD0RgCMOZJ5xl3vluYQDIO1HaAsFaXizN9ywfFZ5QhVY0LIFhmHUaNaxyjZKQAACj1EiaCTQrzq4BBe8i57Br3v9Lk6+B0Hz/uz6Dwh2hOI2YqyMh4HnbAa7nXAO2M2H+mIchdBiacDpDFqFDFwJFoUPXzOVOr1PAEREFzUDBKdXulQoMiwKgAc2WcGgWRRSFhhFRRBG6IySatSKK0DCkNZuOheVI2J86TKGhW/0g7Lo4361OnKP2d6suo57lGvRCscyx0GxBAcAe+dLpWyHcDkZpP9quhbCcCLvxF4Dpkjj7G+Y5BpdjYQsFAZelFPK4H+FamI12Kb3nTRF7ff5iFZ0Lz+r99x1V90Jyvwt0RGKUkRc0EbINivkbkfoXEmlFQ1T+CGstsOwQARAqFmIKBU+aoJCE6zN0vrRMuTAIFQxA1R0HvWiYZdsOw2hJMJhhCmt5sWiOpGQJBq1oj0tttRxW4y8Kuvl/U8H8LGgQug5RsCdrXqHkSkCH9fsYdr8IWE6E5ogNe4p0JlRxHQMhNBiGBl3XYBg6hGY2ngXdfGrXNAEdAqOagG6YDTMMoMlyJEaNIqADQ6IJhqGhoJvLoQMGRqELAy0a0GK5FGY/CsPpS2FjWO6EHfIoORTm56DR7AiLYdFUcipEk9WXwgyJDBlNUsdiqNjkcS5sh8Lf58IOwYxazkRwH4tioGNROjVkDoZ58EoDaQlIHQtYAiLSsXCldR/fANfCKcud1sITGnEvS+tcWGUkbRDDsin3u1AtsBL47pOJ8jcg9Ssk0giIGogHwHd9hAmNGokH9zx/3wil+c7/wpkX5jgA0QJCH7Vuyu4QhQh2HPRR02FA0er74BYSRQMwDEdseB477UENdDNkoRnCFAvOjrHCG7rmuA1C0zzCwO73IGw3IsyxgEtUoDQvEmE2Ep5Oey7nQUOp8TKf1uGEOgC4xnmwOl3aboTfkYBAERp0l1thCgSBoqZBt5yFUodMUXIpNMN0JLSi5UCMoggdzZZA0HXDERZtYgSDwnQmmsUoRixhUYTm9MewnYohmMJCh+miNGmGNwTiOBS2oDDrY6e3O57CeuvDFhSaJRAMn/Pgfd0UHsfCnG+LCVs4lDrclg6wcMSAsmPhFg7uAw9XuTYB501gfwu7qIycC3+SqL4VUiETVWYYbpeP1Iz6EBJpRENY/gDBELssVcFQK7EgK1e2PIVgcDsOAMrfqvC9fVH2VoUVWih1gjSX+ztFaqMCnj4ORbfT4HUcNEs4mMLC/iyaT3Fu4QBA03VA14FCkykSmgpAQYcoFEznoUm3+j+U+kR4Pq2xI4QlNJx+EpY7AQ3W66FwBIgnDALf/35cx8w/334ydveTMAwNmmY6E/brk0Wt1LDaroS7r8SwJmBomjOexJDRDMPqT1GEjoIwzPAFgKI2ChiAoelowwgKWhHN1qujLS53AgCK1kaNOE6F7vSZKMLuM2EKi5KQKDkXQ0azk37EaHLeDhk0mq0+GN5OnMNGk/StkFE7ne1QCG/firCBs6rrWLiOddlngGthnz8S58LjWrjTI71zUapSwL1UOjcCEVhcWVWqDUMbcvIrJIJunD7iN/rBZ2gsB6MexYM/jV9QCMl8aafJkoCQvlVh53MEQMR3hbcqHAFhhywMwxQf/pBFsWiW5Q5hGAaEYVg/DuEKZWjW06lu33xdn/ZUcP2vu/73N/qOK+E7xVzz/fPc38uWRxFwfZQaOHOhYTWE9lsbutB8roRw+koUhQbdCiVAB5pF0XyaFzoMCAyLJrRoo6YwEE1o0YoownCcCzc6zF0HAM1WXQpWf4phmJ0kR6y8Bd1wORamQ2FYvkLR9TlkNKO5UHRCIbbTYAsKXQhnHIqi0DDsbJMpKHTD7nNhCgrNsBwK3dw/tqAw28WSO1ERx8JuwFUdC/uQhroW9onhWxbiRuTSuZCV70+uyf+vOIrtUmj+BiS/QkJC7FBFHMchrljwL48SDIHLNe+8FGLBme8XC/58CQRDmRtheOd7B3iSOA4h4ziU3qaASyjYAsJwBIT70wlT2E7DaBEQAmJ0FMIQwOiouUGOA+F6StZ1aAUdsNwGTdeBpibTgWhuMp2JpoLlNuilvhABboSnb4SO8jc3bDFhLYN7nu+GaH8PvTn6zx+rsRIGgIK5O2xHArrZ0NljSsD+BJw+EnZIAAAMzTD7OxjAEJpg6BpgAEXr09A0q8OlKDkUemmMiRbLkmrRDDSb1UGzpqGAUiNVtE4isxMmMCKGYQAYtF8ftfpJDBfsvhOmIzFotFifzZ6+Fo5jYbkVtkNR6mNRehtkVOiRfSv8vyPi/w0R+3tNHQv3eVD2WRKSZcv8AiTIufCJiLw6F1WHQkJKXQiJLAREUvEAJBAQkuWh4sGdJ0RAhIoHWRqJoPAKBe8nAE8Iwv0pDVnY6ZMICEswxBYQlmDQrE8UDVMs2I7D6CggDAh3WMMtIgrWqxfWqIlmY6sDdudKy3kQzv+A3R+i9N0nEDxjQmiu5S7nQnKnlImJsuWqOA2OBk9DAlgNXOm1UPdYE4amOZ/m07vpVBQ14fSZMNPoZt8I6FYnylEMiwJaNDidKltQxLAGNFtOgwHhedFFtwSF/ZZFAQJFCOsT0FE0BQUKaNYM860PTYNuDaBV0M1+G2Z6U9C4nYshCDRj1BEU9lse7r4Vzdb6TYfCekukrG+FXnIoNNdySyhoumGZA8GOhfutECXHwnZCAKljIewejgLOWBaeETjd2K6FbJm5Zt95E5IU9mlVyhM6xkXkPPm6I50L2b1a832SmpFbISGNRZV9V3QckgiGKLHgnh+4PDu3ITA0ETBPJhgAlzAQEY6D/elxHoTv9Uy/kEj3Oqanc6RfMDifo+YNeXQUMOxPo+Q8FIumI2GHMDQdmq4BhQI0TYNWKJghiqYm05WwnAhYb2TY/9tvaZjzLXEh6yPh6hvhdyDcgkNYjgRcn0FTuBvhe0K1GxrXd/vtDU0zX/MsWiEcZ6hpV3Hu1yd1mO6CbjSVBq6yRFLREl7uPhN2Hwnzu5mu2QpftAgDRa2IFs1AKwRaNKDVSnOE1mKGQqyKGBAwYKAozM8RYaAIA4Ni1HIqhlEUGoYsx2JQb/L0rbA7a5qfGgZFCwyhmSES91sgosn8LNjjW5iOx5Bhfy+NvBn1WyFA6W0QWf8KwO1c2GIiuWPhHcfCvIDLHAvn/ICiawFfXveJFiAwfKKi/KEmpnMhuQ9LnQst5IGyikIi4JkgVv5GJHdCwrbXjMFB18ygxN7DInXUFERE2TkeIEQ8573s4iu7SNVcBP86/OkDHQfJPL8j4YgAuzD3YEshIkLa18FdboTzYA4/IEqvafqcB7MjpCjVI8h5KLqEhCEgRoumSCh6hYQomuJBFK1xDew7qWa23JreZN4EBGAa7ho0QzPLEjqEKJj9JYwCBHTA0M1OkUUN5kuT5i3EKOpW262bwsF5GtWc79DN0ILQneLNzyJMATIKS3y4Pn0TCqL0vw4IXZhpNXuZsN4iEUBBALqAVhBm2EIX0HSjlK5gHiStYJgHTjcnrVCE0AwMFcxGXxSKKGoGhDaKUb0IQy9iVCsChRFr0KoRMwyij2IYBoQ+anXQNPtSFHXzLY4RDWjSBNo0gWZNYIxmOhNjdKAADa2aAR0aCvZvaVidAUzZoGFQCAghMAKBohAYtK67IWE6EcNWv44R6/uIsN7uEKZDUbS+jwoDQpQGxiqKUbPDpTFqhTyarIZ/xPy0BsgqWqGO0lDj7u/uXyu1Pl0DYpnzNc9ylUGx7FO2fDAsuMSEfW1rHqHg/K5LoJjwL0cJlWUyZPc9WEIiLK3se+A8ibMsSWa3FWWdSiuBfZ9Mk78ByZ2QOHDgAABg1z9/rcY1IQ2BfeEPWd8HQ9ISQuqWAwcOoKOjo9bVOCzJnZCYMmUKfvOb3+DUU0/Frl270N7eXusqJWZgYABdXV11vR2NsA0AtyNPNMI2AI2xHY2wDUIIHDhwAFOmTKn4uqQh95j5K8W+ffuwatUq/PSnP4Wu61i0aBH+7d/+DWPHjg3Mc/fdd2PDhg3Yvn07Dhw4gP/7v//D+PHjY687d0JC13Ucd9xxAID29va6PbndNMJ2NMI2ANyOPNEI2wA0xnbU+zZUzYnIcWhjyZIlePvtt7Fp0yaMjIxg6dKluOqqq7Bhw4bAPIcOHcKCBQuwYMECXHfddYnXnTshQQghhBB1Xn31VWzcuBEvvPACZs+eDQC4/fbbsXDhQtx6662Bbs3VV18NANiyZUuq9eupchNCCCGHEyLFZDEwMOCZhoaGkIatW7di/PjxjogAgO7ubui6jueffz5V2SrkUki0trZizZo1aG1trXVVUtEI29EI2wBwO/JEI2wD0Bjb0QjbUE3sPhJpJgDo6upCR0eHM61duzZVvfr6+jBp0iTPvKamJkyYMAF9fX2pylZBE1V5Z4YQQgipTwYGBtDR0YHTrvpXFFraEpdTHB7Ey3d/qaxza2trq1TMrV69GjfffHNoma+++ioeeughfP/738eOHTs8yyZNmoQbb7wRn/3sZ0PL2LJlCz760Y82TmdLQgghJJdk1NlStXPrF7/4RVx55ZWhaaZNm4bOzk7s3bvXM390dBT79u1DZ2dn0toqQyFBCCGEKFDt1z8nTpyIiRMnRqabN28e9u/fj97eXsyaNQsA8MQTT8AwDMydOzdJVWORyz4ShBBCSO5I09EyrZsRwimnnIIFCxZg+fLl2LZtG5555hmsXLkSl156qfPGxltvvYXp06dj27ZtTr6+vj68+OKLeO211wAAv/71r/Hiiy9i3759sdZPIUEIIYTUOffffz+mT5+O8847DwsXLsSHPvQh3H333c7ykZER7NixA4cOHXLm3XXXXTjzzDOxfPlyAMA555yDM888Ez/5yU9irTuXQmLdunWYOnUq2traMHfuXI+Cyhtr167FWWedhXHjxmHSpEm46KKLyjq8nHvuueYPRrmmv/u7v6tRjeXccMMNZXWcPn26s3xwcBArVqzA0UcfjbFjx2LRokXYs2dPDWtcztSpU8u2QdM0rFixAkB+j8PTTz+Nj3/845gyZQo0TcMjjzziWS6EwPXXX49jjz0WY8aMQXd3N373u9950uzbtw9LlixBe3s7xo8fj2XLluHdd9+t4laEb8fIyAiuvfZanH766TjyyCMxZcoUXH755di9e7enDNkxvOmmm3KxDQBw5ZVXltVvwYIFnjR5PxYApNeJpmm45ZZbnDS1PhZ5JKu3NirBhAkTsGHDBhw4cAD9/f249957PaNaTp06FUIInHvuuc68G264wfpVWu8U1S/DT+6ExAMPPICenh6sWbMG27dvx4wZMzB//vyyjiR54amnnsKKFSvw3HPPOSOKnX/++Th48KAn3fLly/H2228709e//vUa1TiYP/uzP/PU8Ze//KWz7JprrsFPf/pTPPjgg3jqqaewe/duXHzxxTWsbTkvvPCCp/6bNm0CAFxyySVOmjweh4MHD2LGjBlYt26ddPnXv/51fPvb38Zdd92F559/HkceeSTmz5+PQdcP2y1ZsgSvvPIKNm3ahEcffRRPP/00rrrqqmptAoDw7Th06BC2b9+Or3zlK9i+fTseeugh7NixA3/5l39Zlvaf//mfPcdo1apV1ag+gOhjAQALFizw1O8//uM/PMvzfiwAeOr/9ttv495774WmaVi0aJEnXS2PRS7JaWij1uSus+U3v/lNLF++HEuXLgVgWi+PPfYY7r33XqxevbrGtStn48aNnu/33XcfJk2ahN7eXpxzzjnO/COOOKIqvWfT0NTUJK1jf38/7rnnHmzYsAEf+9jHAADr16/HKaecgueeew5nn312tasqxd8p6aabbsJJJ52Ej3zkI868PB6HCy64ABdccIF0mRACt912G7785S/jE5/4BADg3//93zF58mQ88sgjuPTSSxOPalfN7ejo6HCEnc0dd9yBOXPmYOfOnTj++OOd+ePGjavZMQrbBpvW1tbA+tXDsQBQVv8f//jH+OhHP4pp06Z55tfyWJD6IVeOxPDwMHp7e9Hd3e3M03Ud3d3d2Lp1aw1rpk5/fz8A02Zyc//99+OYY47Baaedhuuuu84Tp8oLv/vd7zBlyhRMmzYNS5Yswc6dOwEAvb29GBkZ8RyX6dOn4/jjj8/tcRkeHsYPf/hD/M3f/A00rfTjw/VwHNy88cYb6Ovr8+z7jo4OzJ0719n3tR7VLin9/f3QNK3svfWbbroJRx99NM4880zccsstGB0drU0FA9iyZQsmTZqE97///fjsZz+LP/7xj86yejwWe/bswWOPPYZly5aVLcv7sag6dCSk5MqReOedd1AsFjF58mTP/MmTJ+O3v/1tjWqljmEYuPrqq/HBD34Qp512mjP/r//6r3HCCSdgypQpeOmll3Dttddix44deOihh2pYWy9z587Ffffdh/e///14++23ceONN+LDH/4wXn75ZfT19aGlpaXshj958uSqjJqWhEceeQT79+/3xPrq4Tj4sfev7Jqwl9V6VLskDA4O4tprr8Vll13meZ/+85//PD7wgQ9gwoQJePbZZ3Hdddfh7bffxje/+c0a1rbEggULcPHFF+PEE0/E66+/ji996Uu44IILsHXrVhQKhbo8Ft///vcxbty4slBl3o9FLcjzr3/WklwJiXpnxYoVePnllz19CwB44qOnn346jj32WJx33nl4/fXXcdJJJ1W7mlLcNugZZ5yBuXPn4oQTTsB//ud/YsyYMTWsWTLuueceXHDBBR4ruR6Ow+HAyMgIPvWpT0EIgTvvvNOzrKenx/n/jDPOQEtLCz7zmc9g7dq1uRjG+dJLL3X+P/3003HGGWfgpJNOwpYtW3DeeefVsGbJuffee7FkyRK0tXlHbMz7sSD5IVehjWOOOQaFQqHsbYA9e/bkPk63cuVKPProo3jyySfxnve8JzStPUCI/e5uHhk/fjze97734bXXXkNnZyeGh4exf/9+T5q8Hpff//73+PnPf46//du/DU1XD8fB3r9h10StR7WLgy0ifv/732PTpk2Ro/vNnTsXo6Oj+N///d/qVDAm06ZNwzHHHOOcQ/V0LADgF7/4BXbs2BF5rQD5PxZVgaENKbkSEi0tLZg1axY2b97szDMMA5s3b8a8efNqWLNghBBYuXIlHn74YTzxxBM48cQTI/O8+OKLAIBjjz22wrVLzrvvvovXX38dxx57LGbNmoXm5mbPcdmxYwd27tyZy+Oyfv16TJo0CRdeeGFouno4DieeeCI6Ozs9+35gYADPP/+8s+/do9rZVHNUO1VsEfG73/0OP//5z3H00UdH5nnxxReh63pZuCAvvPnmm/jjH//onEP1cixs7rnnHsyaNQszZsyITJv3Y1ENNCFST41I7kIbPT09uOKKKzB79mzMmTMHt912Gw4ePOi8xZE3VqxYgQ0bNuDHP/4xxo0b58RBOzo6MGbMGLz++uvYsGEDFi5ciKOPPhovvfQSrrnmGpxzzjk444wzalz7En//93+Pj3/84zjhhBOwe/durFmzBoVCAZdddhk6OjqwbNky9PT0YMKECWhvb8eqVaswb9683LyxYWMYBtavX48rrrgCTU2l0zvPx+Hdd9/1uCJvvPEGXnzxRUyYMAHHH388rr76anzta1/De9/7Xpx44on4yle+gilTpuCiiy4C4B3V7q677sLIyEjZqHa13o5jjz0Wn/zkJ7F9+3Y8+uijKBaLzrUyYcIEtLS0YOvWrXj++efx0Y9+FOPGjcPWrVtxzTXX4NOf/jSOOuqomm/DhAkTcOONN2LRokXo7OzE66+/jn/8x3/EySefjPnz5wOoj2NhvyEzMDCABx98EN/4xjfK8ufhWJA6QuSQ22+/XRx//PGipaVFzJkzRzz33HO1rlIgCDCw1q9fL4QQYufOneKcc84REyZMEK2treLkk08W//AP/yD6+/trW3EfixcvFscee6xoaWkRxx13nFi8eLF47bXXnOV/+tOfxOc+9zlx1FFHiSOOOEL81V/9lXj77bdrWGM5jz/+uAAgduzY4Zmf5+Pw5JNPSs+hK664QgghhGEY4itf+YqYPHmyaG1tFeedd17Z9v3xj38Ul112mRg7dqxob28XS5cuFQcOHMjNdrzxxhuB18qTTz4phBCit7dXzJ07V3R0dIi2tjZxyimniH/9138Vg4ODudiGQ4cOifPPP19MnDhRNDc3ixNOOEEsX75c9PX1ecrI+7Gw+e53vyvGjBkj9u/fX5Y/D8ciT/T39wsAYuan/0XM+ptvJJ5mfvpfBIBc3HeyhD8jTgghhIRg/4z4mUv+JfXPiP/q/n9Cf3+/0q9/1gu5C20QQgghuSRth8kGfWzPVWdLQgghhNQXdCQIIYQQBTgglRwKCUIIIUQFhjakMLRBCCGEkMTQkSCEEEIUYGhDDoUEIYQQogJDG1IY2iCEEEJIYuhIEEIIIYo0angiDRQShBBCiApCmFOa/A0IhQQhhBCiADtbymEfCUIIIYQkho4EIYQQogLf2pBCIUEIIYQooBnmlCZ/I8LQBiGEEEISQ0eCEEIIUYGhDSkUEoQQQogCfGtDDkMbhBBCCEkMHQlCCCFEBQ5IJYVCghBCCFGAoQ05DG0QQgghJDF0JAghhBAV+NaGFAoJQgghRAGGNuRQSBBCCCEqsLOlFPaRIIQQQkhi6EgQQgghCjC0IYdCghBCCFGBnS2lMLRBCCGEkMTQkSCEEEIUYGhDDoUEIYQQooIhzClN/gaEoQ1CCCGEJIaOBCGEEKICO1tKoZAghBBCFNCQso9EZjXJFwxtEEIIISQxdCQIIYQQFThEthQKCUIIIUQBvv4ph6ENQgghRAWRwVQh9u3bhyVLlqC9vR3jx4/HsmXL8O6774amX7VqFd7//vdjzJgxOP744/H5z38e/f39sddNIUEIIYTUOUuWLMErr7yCTZs24dFHH8XTTz+Nq666KjD97t27sXv3btx66614+eWXcd9992Hjxo1YtmxZ7HVrQjRo0IYQQgjJgIGBAXR0dODD565BU1Nb4nJGRwfxiy03or+/H+3t7ZnV79VXX8Wpp56KF154AbNnzwYAbNy4EQsXLsSbb76JKVOmKJXz4IMP4tOf/jQOHjyIpib1ng90JAghhBAVjAwmmMLEPQ0NDaWq1tatWzF+/HhHRABAd3c3dF3H888/r1yOLXDiiAiAQoIQQgipKl1dXejo6HCmtWvXpiqvr68PkyZN8sxramrChAkT0NfXp1TGO++8g69+9auh4ZAg+NYGIYQQooAmBLQUvQHsvLt27fKENlpbW6XpV69ejZtvvjm0zFdffTVxfWwGBgZw4YUX4tRTT8UNN9wQOz+FBCGEEKJCRkNkt7e3K/WR+OIXv4grr7wyNM20adPQ2dmJvXv3euaPjo5i37596OzsDM1/4MABLFiwAOPGjcPDDz+M5ubmyHr5oZAghBBCcsjEiRMxceLEyHTz5s3D/v370dvbi1mzZgEAnnjiCRiGgblz5wbmGxgYwPz589Ha2oqf/OQnaGtL1pGUfSQIIYQQFeyRLdNMFeCUU07BggULsHz5cmzbtg3PPPMMVq5ciUsvvdR5Y+Ott97C9OnTsW3bNgCmiDj//PNx8OBB3HPPPRgYGEBfXx/6+vpQLBZjrZ+OBCGEEKJAnke2vP/++7Fy5Uqcd9550HUdixYtwre//W1n+cjICHbs2IFDhw4BALZv3+680XHyySd7ynrjjTcwdepU5XVTSBBCCCF1zoQJE7Bhw4bA5VOnToV72Khzzz0XWQ0jRSFBCCGEqMAf7ZJCIUEIIYQooBnmlCZ/I0IhQQghhKhAR0IK39oghBBCSGLoSBBCCCEqZDQgVaNBIUEIIYQokNUQ2Y0GQxuEEEIISQwdCUIIIUQFdraUQiFBCCGEqCAApHmFszF1BEMbhBBCCEkOHQlCCCFEAXa2lEMhQQghhKggkLKPRGY1yRUMbRBCCCEkMXQkCCGEEBX41oYUCglCCCFEBQOAljJ/A0IhQQghhCjAzpZy2EeCEEIIIYmhI0EIIYSowD4SUigkCCGEEBUoJKQwtEEIIYSQxNCRIIQQQlSgIyGFQoIQQghRga9/SmFogxBCCCGJoSNBCCGEKMBxJORQSBBCCCEqsI+EFIY2CCGEEJIYOhKEEEKICoYAtBSugtGYjgSFBCGEEKICQxtSKCQIIYQQJVIKCTSmkGAfCUIIIYQkho4EIYQQogJDG1IoJAghhBAVDIFU4YkG7WzJ0AYhhBBCEkNHghBCCFFBGOaUJn8DQiFBCCGEqMA+ElIY2iCEEEJIYuhIEEIIISqws6UUCglCCCFEBYY2pDC0QQghhJDE0JEghBBCVBBI6UhkVpNcQSFBCCGEqMDQhhQKCUIIIUQFwwCQYiwIozHHkWAfCUIIIYQkho4EIYQQogJDG1IoJAghhBAVKCSkMLRBCCGEkMRQSBBCCCEqGCL9VCH27duHJUuWoL29HePHj8eyZcvw7rvvhub5zGc+g5NOOgljxozBxIkT8YlPfAK//e1vY6+bQoIQQghRQAgj9VQplixZgldeeQWbNm3Co48+iqeffhpXXXVVaJ5Zs2Zh/fr1ePXVV/H4449DCIHzzz8fxWIx1ro1IRo0aEMIIYRkwMDAADo6OnDeUVegSW9JXM6oMYzN//d99Pf3o729PbP6vfrqqzj11FPxwgsvYPbs2QCAjRs3YuHChXjzzTcxZcoUpXJeeuklzJgxA6+99hpOOukk5fXTkSCEEEJUECnDGtZz+8DAgGcaGhpKVa2tW7di/PjxjogAgO7ubui6jueff16pjIMHD2L9+vU48cQT0dXVFWv9FBKEEEKICvZbG2kmAF1dXejo6HCmtWvXpqpWX18fJk2a5JnX1NSECRMmoK+vLzTvd77zHYwdOxZjx47Ff/3Xf2HTpk1oaYnnulBIEEIIIVVk165d6O/vd6brrrtOmm716tXQNC10StI50s2SJUvwq1/9Ck899RTe97734VOf+hQGBwdjlcFxJAghhBAVDAPQUnSYtDpbtre3K/WR+OIXv4grr7wyNM20adPQ2dmJvXv3euaPjo5i37596OzsDM1vuyLvfe97cfbZZ+Ooo47Cww8/jMsuuyyyfjYUEoQQQogKQiDVT3jGfLdh4sSJmDhxYmS6efPmYf/+/ejt7cWsWbMAAE888QQMw8DcuXNjVE9ACBG7zwZDG4QQQogCwjBST5XglFNOwYIFC7B8+XJs27YNzzzzDFauXIlLL73UeWPjrbfewvTp07Ft2zYAwP/8z/9g7dq16O3txc6dO/Hss8/ikksuwZgxY7Bw4cJY66eQIIQQQuqc+++/H9OnT8d5552HhQsX4kMf+hDuvvtuZ/nIyAh27NiBQ4cOAQDa2trwi1/8AgsXLsTJJ5+MxYsXY9y4cXj22WfLOm5GwXEkCCGEkBDscSQ+NmYxmrQU40iIYTzxpwcyH0ei1rCPBCGEEKKCIQCNP9rlh6ENQgghhCSGjgQhhBCighAA0rz+2ZiOBIUEIYQQooAwBESK0EajdklkaIMQQgghiaEjQQghhKggDKQLbVTuZ8RrCYUEIYQQogBDG3IY2iCEEEJIYuhIEEIIIQqMiqFU4YlRjGRYm/xAIUEIIYSE0NLSgs7OTvyy72epy+rs7ERLS/LRMfMIh8gmhBBCIhgcHMTw8HDqclpaWtDW1pZBjfIDhQQhhBBCEsPOloQQQghJDIUEIYQQQhJDIUEIIYSQxFBIEEIIISQxFBKEEEIISQyFBCGEEEISQyFBCCGEkMT8/1hfyAIkxVklAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(uvwp[:,1].reshape(50,200)/1000)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d000d1-c6fb-4074-8861-823db543fa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$y$ (mm)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_vel = np.sqrt(np.square(uvwp[:,0])+np.square(uvwp[:,1])+np.square(uvwp[:,2]))\n",
    "# r_vel = np.sqrt(np.square(uvwp[:,2]))\n",
    "# r_vel = uvwp[:,2]\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow((r_vel/1000).reshape(50,200),cmap = 'jet',extent = [-20,20,-20,20],vmax = 0.15,vmin = 0)\n",
    "fig.colorbar(im)\n",
    "ax.set_title('Resultant Velocity (m/s)',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "ax.set_ylabel('$y$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "# plt.savefig('Res_vel_xy_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1f440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$z$ (mm)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cross Section\n",
    "r_vel = np.sqrt(np.square(uvwp[:,0])+np.square(uvwp[:,1])+np.square(uvwp[:,2]))\n",
    "# r_vel = np.sqrt(np.square(uvwp[:,2]))\n",
    "# r_vel = uvwp[:,2]\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow((np.flip(r_vel)/1000).reshape(50,200),cmap = 'jet',extent = [-20,20,-3,0],vmax = 0.15,vmin = 0)\n",
    "# fig.colorbar(im)\n",
    "# ax.set_title('Resultant Velocity (m/s)',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "ax.set_ylabel('$z$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "# plt.savefig('Res_vel_xz_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef87f55-d125-4c5b-a16d-544611395158",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = xyz_test_tensor.clone()\n",
    "g.requires_grad = True\n",
    "\n",
    "out_full = model_PINN.PINN_uvw.forward(g.to(device1)).cpu() \n",
    "u = out_full[:,0:1]\n",
    "v = out_full[:,1:2]\n",
    "w = out_full[:,2:3]\n",
    "p = out_full[:,3:4]\n",
    "\n",
    "\n",
    "# print(T.shape)\n",
    "T = model_PINN.PINN_T.forward(g.to(device2)).cpu()\n",
    "\n",
    "# p_xyz = autograd.grad(p,g,torch.ones([xyz_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "u_xyz = autograd.grad(u,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "v_xyz = autograd.grad(v,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "w_xyz = autograd.grad(w,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "\n",
    "eps2_11 = torch.square(1/2*(2*u_xyz[:,0]))\n",
    "eps2_12 = torch.square(1/2*(u_xyz[:,1] + v_xyz[:,0]))\n",
    "eps2_13 = torch.square(1/2*(u_xyz[:,2] + w_xyz[:,0]))\n",
    "\n",
    "eps2_21 = eps2_12\n",
    "eps2_22 = torch.square(1/2*(2*v_xyz[:,1])) \n",
    "eps2_23 = torch.square(1/2*(v_xyz[:,2] + w_xyz[:,1]))\n",
    "\n",
    "eps2_31 = eps2_13\n",
    "eps2_32 = eps2_23 \n",
    "eps2_33 = torch.square(1/2*(2*w_xyz[:,2]))\n",
    "\n",
    "eps_e = torch.sqrt((2/3)*(eps2_11 + eps2_12 + eps2_13 + eps2_21 + eps2_22 + eps2_23 + eps2_31 + eps2_32 + eps2_33)).reshape(-1,1)\n",
    "\n",
    "\n",
    "# Z = eps_e*torch.exp(E_a/(R*T))\n",
    "# log_Z = torch.log(eps_e) + E_a/(R*T)\n",
    "log_Z = torch.log(eps_e) + E_a/(R*T) #Simplification\n",
    "\n",
    "\n",
    "W = (log_Z - log_A)/n\n",
    "\n",
    "\n",
    "\n",
    "# sigma_e =  (1/alpha_sig)*torch.asinh(W) \n",
    "sigma_e = (1/alpha_sig)*(np.log(2)/n + W) #Approximation\n",
    "\n",
    "#____________________________#\n",
    "mu_vis = sigma_e/(3*eps_e)\n",
    "\n",
    "\n",
    "eps_e = eps_e.cpu().detach().numpy()\n",
    "sigma_e = sigma_e.cpu().detach().numpy()\n",
    "mu_vis = mu_vis.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0592b72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(609.2927, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfcef78-9322-40dc-9938-90498e7cc584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$y$ (mm)')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(T.cpu().detach().numpy().reshape(50,200),cmap = 'jet',extent = [-20,20,-3,0],vmax = 800,vmin = 300)\n",
    "fig.colorbar(im)\n",
    "ax.set_title('Temperature (K)',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "ax.set_ylabel('$y$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "# plt.savefig('Temp_xy_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ff22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$z$ (mm)')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(np.flip(T.cpu().detach().numpy().reshape(50,200)),cmap = 'jet',extent = [-20,20,-3,0],vmax = 800,vmin = 300)\n",
    "# fig.colorbar(im)\n",
    "# ax.set_title('Temperature (K)',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "ax.set_ylabel('$z$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "# plt.savefig('Temp_xz_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb960cb-2ad1-4850-8cde-8fee710dc085",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 10000 into shape (200,200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fig,ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[0;32m----> 2\u001b[0m im \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mimshow(\u001b[43meps_e\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m,cmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjet\u001b[39m\u001b[38;5;124m'\u001b[39m,extent \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m],vmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m175\u001b[39m,vmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m fig\u001b[38;5;241m.\u001b[39mcolorbar(im)\n\u001b[1;32m      4\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEffective Strain Rate ($s^\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m-1}$)\u001b[39m\u001b[38;5;124m'\u001b[39m,math_fontfamily \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcm\u001b[39m\u001b[38;5;124m'\u001b[39m,fontsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m18\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10000 into shape (200,200)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(eps_e.reshape(200,200),cmap = 'jet',extent = [-20,20,-20,20],vmax = 175,vmin = 0)\n",
    "fig.colorbar(im)\n",
    "ax.set_title('Effective Strain Rate ($s^{-1}$)',math_fontfamily = 'cm',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 16)\n",
    "ax.set_ylabel('$y$ (mm)',math_fontfamily = 'cm',fontsize = 16)\n",
    "# plt.savefig('Viscosity_Feb7.svg',format = 'svg',bbox_inches = 'tight')\n",
    "# plt.savefig('Strain_Rate_xy_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846a92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(np.flip(eps_e.reshape(50,200)),cmap = 'jet',extent = [-20,20,-3,0],vmax = 175,vmin = 0)\n",
    "# fig.colorbar(im)\n",
    "# ax.set_title('$\\dot\\epsilon_e$ ($s^{-1}$)',math_fontfamily = 'cm',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 16)\n",
    "ax.set_ylabel('$z$ (mm)',math_fontfamily = 'cm',fontsize = 16)\n",
    "# plt.savefig('Viscosity_Feb7.svg',format = 'svg',bbox_inches = 'tight')\n",
    "# plt.savefig('Strain_Rate_xz_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499dc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74129033"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(eps_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba456a6-0f56-4100-a4b2-57d4afa0978c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartlab/anaconda3/envs/raghav/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:227: MatReadWarning: Duplicate variable name \"None\" in stream - replacing previous with new\n",
      "Consider mio5.varmats_from_mat to split file into single variable files\n",
      "  matfile_dict = MR.get_variables(variable_names)\n"
     ]
    }
   ],
   "source": [
    "#Testing with FVM data\n",
    "fvm_data = loadmat('/home/smartlab/Documents/jupyterNB/raghav/Projects_git_summer2024/Data/AFSD_Nikhil/Exponential_300_2mms.mat')\n",
    "\n",
    "u_fvm = fvm_data['u_star']\n",
    "v_fvm = fvm_data['v_star']\n",
    "w_fvm = fvm_data['w_star']\n",
    "\n",
    "u_fvm = (u_fvm[0:-1,:,:] + u_fvm[1:,:,:])/2\n",
    "v_fvm = (v_fvm[:,0:-1,:] + v_fvm[:,1:,:])/2\n",
    "w_fvm = (w_fvm[:,:,0:-1] + w_fvm[:,:,1:])/2\n",
    "\n",
    "\n",
    "Res_v_fvm = np.sqrt(np.square(u_fvm) + np.square(v_fvm) + np.square(w_fvm))\n",
    "T_fvm = fvm_data['T']\n",
    "sigma_e_fvm = fvm_data['effectivestress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7129b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'ABC', 'ALPHA', 'Db', 'De', 'Dn', 'Ds', 'Dt', 'Dw', 'Dx', 'Dy', 'Dz', 'FL', 'Fb', 'Fe', 'Fn', 'Fs', 'Ft', 'Fw', 'None', 'Lx', 'Ly', 'Lz', 'N', 'Nx', 'Ny', 'Nz', 'RPS', 'SZ', 'T', 'Tb', 'Te', 'Theat', 'Tn', 'Told', 'Ts', 'Tt', 'Tw', 'X', 'Xcenter', 'Y', 'Ycenter', 'Z', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'aB', 'aE', 'aN', 'aP', 'aS', 'aT', 'aW', 'alpha', 'alpha4', 'alpha5', 'alpha6', 'alphaP', 'alphaU', 'ans', 'b1', 'b2', 'ba', 'c', 'c1', 'c2', 'c3', 'd_u', 'd_v', 'd_w', 'delta', 'delta1', 'dx', 'dy', 'dz', 'eexx', 'eeyy', 'eezz', 'effectivestress', 'effstrrate', 'ep', 'ep1', 'errorheat', 'errormax', 'exp1', 'hbo', 'heat', 'hup', 'i', 'imax', 'ite', 'itera', 'iteration', 'j', 'jmax', 'k', 'k1', 'k2', 'k3', 'kmax', 'ku', 'l', 'maxRes', 'maxRes_u', 'maxRes_v', 'maxRes_w', 'mu', 'mumax', 'p', 'pB', 'pE', 'pN', 'pP', 'pRes', 'pS', 'pT', 'pW', 'p_prime', 'p_star', 'plasticheat', 'pold', 'pressure_term', 'q', 'q1', 'q2', 'q3', 'qu', 'ro', 'rrt', 'rrxy', 'rrxz', 'rryz', 'slip', 'sxx', 'syy', 'szz', 'thet', 'theta', 'theta1', 'tilte', 'tol', 'trt', 'txx', 'txy', 'txz', 'tyy', 'tyz', 'tzz', 'u', 'uRes', 'u_star', 'uavg', 'ub', 'uold', 'ur', 'ut', 'uth', 'v', 'v1', 'vRes', 'v_star', 'vavg', 'vb', 'vold', 'vt', 'w', 'wRes', 'w_star', 'wavg', 'wold', 'wt', 'x', 'x3', 'y', 'y3', 'z', 'z3', '__function_workspace__'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fvm_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79467057",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_min,y_min,z_min] = lb_xyz\n",
    "[x_max,y_max,z_max] = ub_xyz\n",
    "\n",
    "# x_min = -20.0\n",
    "# x_max = 20.0\n",
    "\n",
    "# x = np.linspace(x_min,x_max,250)\n",
    "x = np.linspace(x_min,x_max,251)\n",
    "x = (x[0:-1] + x[1:]).reshape(-1,1)/2\n",
    "y = np.linspace(y_min,y_max,101)\n",
    "y = (y[0:-1] + y[1:]).reshape(-1,1)/2\n",
    "z = np.linspace(z_min,z_max,13)\n",
    "z = (z[0:-1] + z[1:]).reshape(-1,1)/2\n",
    "\n",
    "X,Y,Z = np.meshgrid(x,y,z)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "Z = Z.flatten('F').reshape(-1,1)\n",
    "\n",
    "xyz = np.hstack((X,Y,Z))\n",
    "xyz_test_tensor = torch.from_numpy(xyz).float().to(device1)\n",
    "\n",
    "uvwp = model_PINN.PINN_uvw.forward(xyz_test_tensor).cpu().detach().numpy()\n",
    "\n",
    "Res_v_PINN = np.sqrt(np.square(uvwp[:,0])+np.square(uvwp[:,1])+np.square(uvwp[:,2])).reshape(12,250,100,order = 'C')\n",
    "\n",
    "Res_v_PINN = np.swapaxes(np.swapaxes(Res_v_PINN,0,1),1,2)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad2673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f6424ee80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Res_v_fvm[:,:,11],cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7d6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f642c3910>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Res_v_PINN[:,:,11],cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a17f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27328509046394744\n"
     ]
    }
   ],
   "source": [
    "RE = np.linalg.norm((Res_v_PINN-Res_v_fvm).reshape(-1,),2)/np.linalg.norm(Res_v_fvm.reshape(-1,),2)\n",
    "print(RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f5ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034875685104070664\n"
     ]
    }
   ],
   "source": [
    "RMSE = np.sqrt(np.mean(np.square(Res_v_fvm[:]-Res_v_PINN[:])))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb688df",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = xyz_test_tensor.clone()\n",
    "g.requires_grad = True\n",
    "\n",
    "out_full = model_PINN.PINN_uvw.forward(g.to(device1)).cpu() \n",
    "u = out_full[:,0:1]\n",
    "v = out_full[:,1:2]\n",
    "w = out_full[:,2:3]\n",
    "p = out_full[:,3:4]\n",
    "\n",
    "\n",
    "# print(T.shape)\n",
    "T = model_PINN.PINN_T.forward(g.to(device2)).cpu()\n",
    "\n",
    "# p_xyz = autograd.grad(p,g,torch.ones([xyz_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "u_xyz = autograd.grad(u,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "v_xyz = autograd.grad(v,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "w_xyz = autograd.grad(w,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "\n",
    "eps2_11 = torch.square(1/2*(2*u_xyz[:,0]))\n",
    "eps2_12 = torch.square(1/2*(u_xyz[:,1] + v_xyz[:,0]))\n",
    "eps2_13 = torch.square(1/2*(u_xyz[:,2] + w_xyz[:,0]))\n",
    "\n",
    "eps2_21 = eps2_12\n",
    "eps2_22 = torch.square(1/2*(2*v_xyz[:,1])) \n",
    "eps2_23 = torch.square(1/2*(v_xyz[:,2] + w_xyz[:,1]))\n",
    "\n",
    "eps2_31 = eps2_13\n",
    "eps2_32 = eps2_23 \n",
    "eps2_33 = torch.square(1/2*(2*w_xyz[:,2]))\n",
    "\n",
    "eps_e = torch.sqrt((2/3)*(eps2_11 + eps2_12 + eps2_13 + eps2_21 + eps2_22 + eps2_23 + eps2_31 + eps2_32 + eps2_33)).reshape(-1,1)\n",
    "\n",
    "\n",
    "# Z = eps_e*torch.exp(E_a/(R*T))\n",
    "# log_Z = torch.log(eps_e) + E_a/(R*T)\n",
    "log_Z = torch.log(eps_e) + E_a/(R*T) #Simplification\n",
    "\n",
    "\n",
    "W = (log_Z - log_A)/n\n",
    "\n",
    "\n",
    "\n",
    "# sigma_e =  (1/alpha_sig)*torch.asinh(W) \n",
    "sigma_e = (1/alpha_sig)*(np.log(2)/n + W) #Approximation\n",
    "\n",
    "#____________________________#\n",
    "mu_vis = sigma_e/(3*eps_e)\n",
    "\n",
    "\n",
    "eps_e = eps_e.cpu().detach().numpy()\n",
    "sigma_e = sigma_e.cpu().detach().numpy()\n",
    "mu_vis = mu_vis.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd34586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE:  0.08500561240854837\n",
      "RMSE:  45.964735108661316\n"
     ]
    }
   ],
   "source": [
    "T_PINN = T.cpu().detach().numpy().reshape(12,250,100,order = 'C')\n",
    "T_PINN = np.swapaxes(np.swapaxes(T_PINN,0,1),1,2)\n",
    "\n",
    "print(\"RE: \",np.linalg.norm((T_PINN-T_fvm).reshape(-1,),2)/np.linalg.norm(T_fvm.reshape(-1,),2))\n",
    "print(\"RMSE: \",np.sqrt(np.mean(np.square(T_fvm[:]-T_PINN[:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956c1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.92027801],\n",
       "       [0.92027801, 1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation between Predicted and Actual \n",
    "np.corrcoef(T_PINN.reshape(-1,),T_fvm.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1607be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.95771673],\n",
       "       [0.95771673, 1.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(Res_v_PINN.reshape(-1,),Res_v_fvm.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57bf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000000e+00, -7.1171441e-04],\n",
       "       [-7.1171441e-04,  1.0000000e+00]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_e = eps_e.reshape(12,250,100,order = 'C')\n",
    "eps_e = np.swapaxes(np.swapaxes(eps_e,0,1),1,2)\n",
    "\n",
    "eps_e_fvm = fvm_data['effstrrate']\n",
    "np.corrcoef(eps_e.reshape(-1,),eps_e_fvm.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3efdf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE:  4.834573293348854\n",
      "RMSE:  28.021321318860586\n"
     ]
    }
   ],
   "source": [
    "print(\"RE: \",np.linalg.norm((eps_e-eps_e_fvm).reshape(-1,),2)/np.linalg.norm(eps_e_fvm.reshape(-1,),2))\n",
    "print(\"RMSE: \",np.sqrt(np.mean(np.square(eps_e_fvm[:]-eps_e[:]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raghav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
