{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7e8113-fc6b-42be-9a3c-685830458daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 1:  cuda:2\n",
      "Device 2:  cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "# from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import loadmat,savemat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device1 = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "device2 = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Device 1: \",device1)\n",
    "print(\"Device 2: \",device2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e12c536f-3169-48e3-82a1-915d437b21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "R0 = 5.36 #mm 5.36\n",
    "Rs = 19 #mm\n",
    "mu_vis = 0.3 \n",
    "mu = 0.3 #Friction Coefficient (not viscosity)\n",
    "delta = 0.5\n",
    "A = 6.41 #For slip factor\n",
    "pi = np.pi\n",
    "Omega = 600 #rpm\n",
    "V = 2 #mm/s\n",
    "F = 0.67 #mm\n",
    "rho = 2700 * 1e-6 #g/mm3\n",
    "k_B = 1.380649*1e-23 #J/K\n",
    "R = 8.314 #J/(K.mol)\n",
    "E_a = 205000 #J/mol #Q\n",
    "alpha_sig = 52 #mm^2/(kN)\n",
    "# A = np.exp(27.78)\n",
    "log_A = 27.78\n",
    "n = 3.49\n",
    "\n",
    "k = 0.167 #Thermal Conductivity #W/(mmK)\n",
    "c_p = 0.897 #J/gK \n",
    "alpha_m = k/(rho*c_p)\n",
    "T_a = 298.0\n",
    "\n",
    "\n",
    "k_t = 0.0176 #W/(mmK)\n",
    "c_p_t = 0.46 #J/gk\n",
    "rho_t = 7750 * 1e-6 #g/mm3\n",
    "alpha_t = k_t/(rho_t*c_p_t)\n",
    "\n",
    "h_sides = 5*1e-6 #W/mm^2K\n",
    "C_bot = 0.15*1e-6 #W/mm^2K^3\n",
    "\n",
    "eeta = alpha_m/(alpha_m+alpha_t)\n",
    "\n",
    "lb_xyz_uvw = np.array([-50.0,-20.0,-3.0])\n",
    "ub_xyz_uvw = np.array([50.0,20.0,0.0])\n",
    "\n",
    "\n",
    "lb_xyz = np.array([-50.0,-20.0,-3.0])\n",
    "ub_xyz = np.array([50.0,20.0,0.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb877af0-8a4e-4628-b94d-de92a0d130bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat,uvw_true_top,r_fr_ph_out):\n",
    "    # def closure():\n",
    "    optimizer.zero_grad()\n",
    "    #model_PINN.zero_grad()\n",
    "    loss_uvw,loss_T = model_PINN.loss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat,uvw_true_top,r_fr_ph_out)\n",
    "    # loss_uvw.backward()\n",
    "    loss_T.backward()\n",
    "\n",
    "        # return loss\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5478b554-59b5-4825-95bb-acf6c27211d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep,n_batches):\n",
    "    print(rep)\n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot, uvw_true_top,r_fr_ph_out = trainingdata_uvw(N_B,N_f,lb_xyz,ub_xyz,rep*123)\n",
    "    xyz_coll = torch.from_numpy(xyz_coll).float()#.to(device)\n",
    "    xyz_1 = torch.from_numpy(xyz_1).float()#.to(device)\n",
    "    xyz_2 = torch.from_numpy(xyz_2).float()#.to(device)\n",
    "    xyz_3 = torch.from_numpy(xyz_3).float()#.to(device)\n",
    "    xyz_4 = torch.from_numpy(xyz_4).float()#.to(device)\n",
    "    r_fr_ph_out = torch.from_numpy(r_fr_ph_out).float()\n",
    "    \n",
    "    xyz_top = torch.from_numpy(xyz_top).float()#.to(device)\n",
    "    xyz_bot = torch.from_numpy(xyz_bot).float()#.to(device)\n",
    "   \n",
    "    uvw_true_top = torch.from_numpy(uvw_true_top).float().to(device1)\n",
    "    f_hat = torch.zeros(xyz_coll.shape[0],1)#.to(device1)\n",
    "    N_hat = torch.zeros(xyz_top.shape[0],1).to(device2)\n",
    "    \n",
    "\n",
    "    #pretrain\n",
    "    # for i in range(50):\n",
    "    #     optimizer.zero_grad()\n",
    "    #     loss_pretrain = model_PINN.pretrain_T_loss(xyz_coll)\n",
    "    #     loss_pretrain.backward()\n",
    "    #     optimizer.step()\n",
    "        \n",
    "    # print(\"Pretrained with T = 300.0\")\n",
    "    \n",
    "    #Batching only Collocation and f_hat for now\n",
    "    \n",
    "    # batch_size_coll = int(xyz_coll.shape[0]/n_batches)\n",
    "    # batch_size_top = int(xyz_top.shape[0]/n_batches)\n",
    "\n",
    "    # batch_size_sides = int(xyz_1.shape[0]/n_batches)\n",
    "    # batch_size_bot = int(xyz_bot.shape[0]/n_batches)\n",
    "\n",
    "    # xyz_coll_batches = torch.split(xyz_coll,batch_size_coll)\n",
    "    # f_hat_batches = torch.split(f_hat,batch_size_coll)\n",
    "    \n",
    "    # xyz_top_batches = torch.split(xyz_top,batch_size_top)\n",
    "    # N_hat_batches = torch.split(N_hat,batch_size_top)\n",
    "\n",
    "    # xyz_1_batches = torch.split(xyz_1,batch_size_sides)\n",
    "    # xyz_2_batches = torch.split(xyz_2,batch_size_sides)\n",
    "    # xyz_3_batches = torch.split(xyz_3,batch_size_sides)\n",
    "    # xyz_4_batches = torch.split(xyz_4,batch_size_sides)\n",
    "    \n",
    "    # xyz_bot_batches = torch.split(xyz_4,batch_size_bot)\n",
    "\n",
    "    # uvw_true_top_batches = torch.split(uvw_true_top,batch_size_top)\n",
    "    # r_fr_ph_out_batches = torch.split(r_fr_ph_out,batch_size_top)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "#         if(i>0 and i%50==0):\n",
    "#             _,_,_,_,_,xyz_top,xyz_bot = trainingdata(N_B,N_f,i*123)\n",
    "#             # xyz_coll = torch.from_numpy(xyz_coll).float().to(device)\n",
    "#             # xyz_1 = torch.from_numpy(xyz_1).float().to(device)\n",
    "#             # xyz_2 = torch.from_numpy(xyz_2).float().to(device)\n",
    "#             # xyz_3 = torch.from_numpy(xyz_3).float().to(device)\n",
    "#             # xyz_4 = torch.from_numpy(xyz_4).float().to(device)\n",
    "\n",
    "#             xyz_top = torch.from_numpy(xyz_top).float().to(device)\n",
    "#             xyz_bot = torch.from_numpy(xyz_bot).float().to(device)\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        # for b in range(n_batches):\n",
    "        #     loss_uvw,loss_T = model_PINN.loss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat,uvw_true_top,r_fr_ph_out)\n",
    "        #     loss_uvw.backward()\n",
    "        #     loss_T.backward()\n",
    "\n",
    "        # optimizer.step()\n",
    "        \n",
    "        # train_step(xyz_coll_batches[b],xyz_1_batches[b], xyz_2_batches[b], xyz_3_batches[b], xyz_4_batches[b],xyz_top_batches[b],xyz_bot_batches[b],f_hat_batches[b],N_hat_batches[b],uvw_true_top_batches[b],r_fr_ph_out_batches[b])\n",
    "            \n",
    "\n",
    "        train_step(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat,uvw_true_top,r_fr_ph_out)\n",
    "        # loss_np = PINN.loss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat).cpu().detach().numpy()\n",
    "        # print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "        loss_np1,loss_np2 = model_PINN.loss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat,uvw_true_top,r_fr_ph_out)\n",
    "        loss_np = loss_np1.cpu().detach().numpy() + loss_np2.cpu().detach().numpy()\n",
    "        print(i,\"Train Loss\",loss_np)\n",
    "\n",
    "        # if(i>0 and i%25 ==0):\n",
    "        #   pretrain(xyt_DBC,p_iters)\n",
    "\n",
    "        if(loss_np<10):\n",
    "            print(\"Loss Less than 7.5...\")\n",
    "            break\n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b5a6e4a-7ebc-437a-a707-0b7256025237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "Loss  2570.0947 C_bot  0.15 k_c 0.0\n",
      "Loss  45980.42 C_bot  0.15 k_c 0.0\n",
      "0 Train Loss 46061.637\n",
      "Loss  45980.42 C_bot  0.15 k_c 0.0\n",
      "Loss  6904.718 C_bot  0.15 k_c 0.0\n",
      "1 Train Loss 6944.9644\n",
      "Loss  6904.718 C_bot  0.15 k_c 0.0\n",
      "Loss  5283.6064 C_bot  0.15 k_c 0.0\n",
      "2 Train Loss 5304.0894\n",
      "Loss  5283.6064 C_bot  0.15 k_c 0.0\n",
      "Loss  13769.212 C_bot  0.15 k_c 0.0\n",
      "3 Train Loss 13801.522\n",
      "Loss  13769.212 C_bot  0.15 k_c 0.0\n",
      "Loss  8726.015 C_bot  0.15 k_c 0.0\n",
      "4 Train Loss 8775.491\n",
      "Loss  8726.015 C_bot  0.15 k_c 0.0\n",
      "Loss  1922.8195 C_bot  0.15 k_c 0.0\n",
      "5 Train Loss 1993.4539\n",
      "Loss  1922.8195 C_bot  0.15 k_c 0.0\n",
      "Loss  2407.0073 C_bot  0.15 k_c 0.0\n",
      "6 Train Loss 2507.9548\n",
      "Loss  2407.0073 C_bot  0.15 k_c 0.0\n",
      "Loss  5724.567 C_bot  0.15 k_c 0.0\n",
      "7 Train Loss 5849.1367\n",
      "Loss  5724.567 C_bot  0.15 k_c 0.0\n",
      "Loss  5468.9385 C_bot  0.15 k_c 0.0\n",
      "8 Train Loss 5596.5005\n",
      "Loss  5468.9385 C_bot  0.15 k_c 0.0\n",
      "Loss  2397.962 C_bot  0.15 k_c 0.0\n",
      "9 Train Loss 2513.4956\n",
      "Loss  2397.962 C_bot  0.15 k_c 0.0\n",
      "Loss  486.18842 C_bot  0.15 k_c 0.0\n",
      "10 Train Loss 589.9684\n",
      "Loss  486.18842 C_bot  0.15 k_c 0.0\n",
      "Loss  1756.6958 C_bot  0.15 k_c 0.0\n",
      "11 Train Loss 1858.3163\n",
      "Loss  1756.6958 C_bot  0.15 k_c 0.0\n",
      "Loss  3751.576 C_bot  0.15 k_c 0.0\n",
      "12 Train Loss 3855.0222\n",
      "Loss  3751.576 C_bot  0.15 k_c 0.0\n",
      "Loss  3230.056 C_bot  0.15 k_c 0.0\n",
      "13 Train Loss 3332.3384\n",
      "Loss  3230.056 C_bot  0.15 k_c 0.0\n",
      "Loss  1116.6752 C_bot  0.15 k_c 0.0\n",
      "14 Train Loss 1217.7019\n",
      "Loss  1116.6752 C_bot  0.15 k_c 0.0\n",
      "Loss  174.6512 C_bot  0.15 k_c 0.0\n",
      "15 Train Loss 279.47662\n",
      "Loss  174.6512 C_bot  0.15 k_c 0.0\n",
      "Loss  1017.7831 C_bot  0.15 k_c 0.0\n",
      "16 Train Loss 1131.2319\n",
      "Loss  1017.7831 C_bot  0.15 k_c 0.0\n",
      "Loss  1970.8164 C_bot  0.15 k_c 0.0\n",
      "17 Train Loss 2090.2593\n",
      "Loss  1970.8164 C_bot  0.15 k_c 0.0\n",
      "Loss  1687.0754 C_bot  0.15 k_c 0.0\n",
      "18 Train Loss 1803.8052\n",
      "Loss  1687.0754 C_bot  0.15 k_c 0.0\n",
      "Loss  621.90027 C_bot  0.15 k_c 0.0\n",
      "19 Train Loss 728.8197\n",
      "Loss  621.90027 C_bot  0.15 k_c 0.0\n",
      "Loss  116.29916 C_bot  0.15 k_c 0.0\n",
      "20 Train Loss 212.63965\n",
      "Loss  116.29916 C_bot  0.15 k_c 0.0\n",
      "Loss  662.91064 C_bot  0.15 k_c 0.0\n",
      "21 Train Loss 752.3675\n",
      "Loss  662.91064 C_bot  0.15 k_c 0.0\n",
      "Loss  1339.8732 C_bot  0.15 k_c 0.0\n",
      "22 Train Loss 1426.0325\n",
      "Loss  1339.8732 C_bot  0.15 k_c 0.0\n",
      "Loss  1168.0835 C_bot  0.15 k_c 0.0\n",
      "23 Train Loss 1253.0953\n",
      "Loss  1168.0835 C_bot  0.15 k_c 0.0\n",
      "Loss  429.7839 C_bot  0.15 k_c 0.0\n",
      "24 Train Loss 516.26\n",
      "Loss  429.7839 C_bot  0.15 k_c 0.0\n",
      "Loss  69.542915 C_bot  0.15 k_c 0.0\n",
      "25 Train Loss 160.88596\n",
      "Loss  69.542915 C_bot  0.15 k_c 0.0\n",
      "Loss  365.0591 C_bot  0.15 k_c 0.0\n",
      "26 Train Loss 462.67996\n",
      "Loss  365.0591 C_bot  0.15 k_c 0.0\n",
      "Loss  727.80005 C_bot  0.15 k_c 0.0\n",
      "27 Train Loss 828.75146\n",
      "Loss  727.80005 C_bot  0.15 k_c 0.0\n",
      "Loss  619.1685 C_bot  0.15 k_c 0.0\n",
      "28 Train Loss 717.61945\n",
      "Loss  619.1685 C_bot  0.15 k_c 0.0\n",
      "Loss  209.20326 C_bot  0.15 k_c 0.0\n",
      "29 Train Loss 300.5472\n",
      "Loss  209.20326 C_bot  0.15 k_c 0.0\n",
      "Loss  41.514202 C_bot  0.15 k_c 0.0\n",
      "30 Train Loss 124.910095\n",
      "Loss  41.514202 C_bot  0.15 k_c 0.0\n",
      "Loss  276.766 C_bot  0.15 k_c 0.0\n",
      "31 Train Loss 354.27902\n",
      "Loss  276.766 C_bot  0.15 k_c 0.0\n",
      "Loss  512.959 C_bot  0.15 k_c 0.0\n",
      "32 Train Loss 587.2912\n",
      "Loss  512.959 C_bot  0.15 k_c 0.0\n",
      "Loss  401.42618 C_bot  0.15 k_c 0.0\n",
      "33 Train Loss 474.82068\n",
      "Loss  401.42618 C_bot  0.15 k_c 0.0\n",
      "Loss  121.80568 C_bot  0.15 k_c 0.0\n",
      "34 Train Loss 196.19902\n",
      "Loss  121.80568 C_bot  0.15 k_c 0.0\n",
      "Loss  44.34091 C_bot  0.15 k_c 0.0\n",
      "35 Train Loss 121.05722\n",
      "Loss  44.34091 C_bot  0.15 k_c 0.0\n",
      "Loss  192.54202 C_bot  0.15 k_c 0.0\n",
      "36 Train Loss 271.1869\n",
      "Loss  192.54202 C_bot  0.15 k_c 0.0\n",
      "Loss  283.3789 C_bot  0.15 k_c 0.0\n",
      "37 Train Loss 361.58865\n",
      "Loss  283.3789 C_bot  0.15 k_c 0.0\n",
      "Loss  172.36618 C_bot  0.15 k_c 0.0\n",
      "38 Train Loss 247.33044\n",
      "Loss  172.36618 C_bot  0.15 k_c 0.0\n",
      "Loss  27.21038 C_bot  0.15 k_c 0.0\n",
      "39 Train Loss 97.563484\n",
      "Loss  27.21038 C_bot  0.15 k_c 0.0\n",
      "Loss  45.551937 C_bot  0.15 k_c 0.0\n",
      "40 Train Loss 111.82344\n",
      "Loss  45.551937 C_bot  0.15 k_c 0.0\n",
      "Loss  167.44263 C_bot  0.15 k_c 0.0\n",
      "41 Train Loss 231.07025\n",
      "Loss  167.44263 C_bot  0.15 k_c 0.0\n",
      "Loss  192.54443 C_bot  0.15 k_c 0.0\n",
      "42 Train Loss 254.86523\n",
      "Loss  192.54443 C_bot  0.15 k_c 0.0\n",
      "Loss  91.73909 C_bot  0.15 k_c 0.0\n",
      "43 Train Loss 153.77301\n",
      "Loss  91.73909 C_bot  0.15 k_c 0.0\n",
      "Loss  21.726843 C_bot  0.15 k_c 0.0\n",
      "44 Train Loss 84.20068\n",
      "Loss  21.726843 C_bot  0.15 k_c 0.0\n",
      "Loss  62.988518 C_bot  0.15 k_c 0.0\n",
      "45 Train Loss 125.99867\n",
      "Loss  62.988518 C_bot  0.15 k_c 0.0\n",
      "Loss  117.32722 C_bot  0.15 k_c 0.0\n",
      "46 Train Loss 180.07669\n",
      "Loss  117.32722 C_bot  0.15 k_c 0.0\n",
      "Loss  86.56247 C_bot  0.15 k_c 0.0\n",
      "47 Train Loss 147.83122\n",
      "Loss  86.56247 C_bot  0.15 k_c 0.0\n",
      "Loss  19.390118 C_bot  0.15 k_c 0.0\n",
      "48 Train Loss 78.42426\n",
      "Loss  19.390118 C_bot  0.15 k_c 0.0\n",
      "Loss  15.515859 C_bot  0.15 k_c 0.0\n",
      "49 Train Loss 72.423935\n",
      "Loss  15.515859 C_bot  0.15 k_c 0.0\n",
      "Loss  65.560135 C_bot  0.15 k_c 0.0\n",
      "50 Train Loss 120.96036\n",
      "Loss  65.560135 C_bot  0.15 k_c 0.0\n",
      "Loss  79.89745 C_bot  0.15 k_c 0.0\n",
      "51 Train Loss 134.42056\n",
      "Loss  79.89745 C_bot  0.15 k_c 0.0\n",
      "Loss  39.47181 C_bot  0.15 k_c 0.0\n",
      "52 Train Loss 93.60641\n",
      "Loss  39.47181 C_bot  0.15 k_c 0.0\n",
      "Loss  13.231441 C_bot  0.15 k_c 0.0\n",
      "53 Train Loss 67.3097\n",
      "Loss  13.231441 C_bot  0.15 k_c 0.0\n",
      "Loss  33.936886 C_bot  0.15 k_c 0.0\n",
      "54 Train Loss 87.97588\n",
      "Loss  33.936886 C_bot  0.15 k_c 0.0\n",
      "Loss  53.296173 C_bot  0.15 k_c 0.0\n",
      "55 Train Loss 106.91149\n",
      "Loss  53.296173 C_bot  0.15 k_c 0.0\n",
      "Loss  33.733482 C_bot  0.15 k_c 0.0\n",
      "56 Train Loss 86.41101\n",
      "Loss  33.733482 C_bot  0.15 k_c 0.0\n",
      "Loss  7.5474753 C_bot  0.15 k_c 0.0\n",
      "57 Train Loss 59.048573\n",
      "Loss  7.5474753 C_bot  0.15 k_c 0.0\n",
      "Loss  14.087399 C_bot  0.15 k_c 0.0\n",
      "58 Train Loss 64.549866\n",
      "Loss  14.087399 C_bot  0.15 k_c 0.0\n",
      "Loss  34.39787 C_bot  0.15 k_c 0.0\n",
      "59 Train Loss 84.11604\n",
      "Loss  34.39787 C_bot  0.15 k_c 0.0\n",
      "Loss  31.065226 C_bot  0.15 k_c 0.0\n",
      "60 Train Loss 80.2951\n",
      "Loss  31.065226 C_bot  0.15 k_c 0.0\n",
      "Loss  12.663079 C_bot  0.15 k_c 0.0\n",
      "61 Train Loss 61.597088\n",
      "Loss  12.663079 C_bot  0.15 k_c 0.0\n",
      "Loss  11.030891 C_bot  0.15 k_c 0.0\n",
      "62 Train Loss 59.774517\n",
      "Loss  11.030891 C_bot  0.15 k_c 0.0\n",
      "Loss  23.558977 C_bot  0.15 k_c 0.0\n",
      "63 Train Loss 72.04501\n",
      "Loss  23.558977 C_bot  0.15 k_c 0.0\n",
      "Loss  23.720453 C_bot  0.15 k_c 0.0\n",
      "64 Train Loss 71.72874\n",
      "Loss  23.720453 C_bot  0.15 k_c 0.0\n",
      "Loss  10.469757 C_bot  0.15 k_c 0.0\n",
      "65 Train Loss 57.80674\n",
      "Loss  10.469757 C_bot  0.15 k_c 0.0\n",
      "Loss  6.2459216 C_bot  0.15 k_c 0.0\n",
      "66 Train Loss 52.887917\n",
      "Loss  6.2459216 C_bot  0.15 k_c 0.0\n",
      "Loss  14.88325 C_bot  0.15 k_c 0.0\n",
      "67 Train Loss 60.941154\n",
      "Loss  14.88325 C_bot  0.15 k_c 0.0\n",
      "Loss  17.97712 C_bot  0.15 k_c 0.0\n",
      "68 Train Loss 63.58773\n",
      "Loss  17.97712 C_bot  0.15 k_c 0.0\n",
      "Loss  10.452289 C_bot  0.15 k_c 0.0\n",
      "69 Train Loss 55.73186\n",
      "Loss  10.452289 C_bot  0.15 k_c 0.0\n",
      "Loss  6.8817697 C_bot  0.15 k_c 0.0\n",
      "70 Train Loss 51.909256\n",
      "Loss  6.8817697 C_bot  0.15 k_c 0.0\n",
      "Loss  12.096124 C_bot  0.15 k_c 0.0\n",
      "71 Train Loss 56.86692\n",
      "Loss  12.096124 C_bot  0.15 k_c 0.0\n",
      "Loss  14.212476 C_bot  0.15 k_c 0.0\n",
      "72 Train Loss 58.62725\n",
      "Loss  14.212476 C_bot  0.15 k_c 0.0\n",
      "Loss  8.744583 C_bot  0.15 k_c 0.0\n",
      "73 Train Loss 52.690845\n",
      "Loss  8.744583 C_bot  0.15 k_c 0.0\n",
      "Loss  5.567411 C_bot  0.15 k_c 0.0\n",
      "74 Train Loss 49.011417\n",
      "Loss  5.567411 C_bot  0.15 k_c 0.0\n",
      "Loss  8.921097 C_bot  0.15 k_c 0.0\n",
      "75 Train Loss 51.911407\n",
      "Loss  8.921097 C_bot  0.15 k_c 0.0\n",
      "Loss  10.759294 C_bot  0.15 k_c 0.0\n",
      "76 Train Loss 53.3726\n",
      "Loss  10.759294 C_bot  0.15 k_c 0.0\n",
      "Loss  7.488506 C_bot  0.15 k_c 0.0\n",
      "77 Train Loss 49.794853\n",
      "Loss  7.488506 C_bot  0.15 k_c 0.0\n",
      "Loss  5.6871147 C_bot  0.15 k_c 0.0\n",
      "78 Train Loss 47.733345\n",
      "Loss  5.6871147 C_bot  0.15 k_c 0.0\n",
      "Loss  8.076359 C_bot  0.15 k_c 0.0\n",
      "79 Train Loss 49.859753\n",
      "Loss  8.076359 C_bot  0.15 k_c 0.0\n",
      "Loss  9.059088 C_bot  0.15 k_c 0.0\n",
      "80 Train Loss 50.522263\n",
      "Loss  9.059088 C_bot  0.15 k_c 0.0\n",
      "Loss  6.5498414 C_bot  0.15 k_c 0.0\n",
      "81 Train Loss 47.626686\n",
      "Loss  6.5498414 C_bot  0.15 k_c 0.0\n",
      "Loss  5.3183303 C_bot  0.15 k_c 0.0\n",
      "82 Train Loss 45.986935\n",
      "Loss  5.3183303 C_bot  0.15 k_c 0.0\n",
      "Loss  6.938238 C_bot  0.15 k_c 0.0\n",
      "83 Train Loss 47.22708\n",
      "Loss  6.938238 C_bot  0.15 k_c 0.0\n",
      "Loss  7.4107857 C_bot  0.15 k_c 0.0\n",
      "84 Train Loss 47.371258\n",
      "Loss  7.4107857 C_bot  0.15 k_c 0.0\n",
      "Loss  5.735725 C_bot  0.15 k_c 0.0\n",
      "85 Train Loss 45.41822\n",
      "Loss  5.735725 C_bot  0.15 k_c 0.0\n",
      "Loss  5.2784324 C_bot  0.15 k_c 0.0\n",
      "86 Train Loss 44.71337\n",
      "Loss  5.2784324 C_bot  0.15 k_c 0.0\n",
      "Loss  6.5084043 C_bot  0.15 k_c 0.0\n",
      "87 Train Loss 45.688007\n",
      "Loss  6.5084043 C_bot  0.15 k_c 0.0\n",
      "Loss  6.5595694 C_bot  0.15 k_c 0.0\n",
      "88 Train Loss 45.443054\n",
      "Loss  6.5595694 C_bot  0.15 k_c 0.0\n",
      "Loss  5.3337245 C_bot  0.15 k_c 0.0\n",
      "89 Train Loss 43.8823\n",
      "Loss  5.3337245 C_bot  0.15 k_c 0.0\n",
      "Loss  5.2135134 C_bot  0.15 k_c 0.0\n",
      "90 Train Loss 43.420975\n",
      "Loss  5.2135134 C_bot  0.15 k_c 0.0\n",
      "Loss  5.995562 C_bot  0.15 k_c 0.0\n",
      "91 Train Loss 43.887817\n",
      "Loss  5.995562 C_bot  0.15 k_c 0.0\n",
      "Loss  5.751953 C_bot  0.15 k_c 0.0\n",
      "92 Train Loss 43.368065\n",
      "Loss  5.751953 C_bot  0.15 k_c 0.0\n",
      "Loss  4.9491434 C_bot  0.15 k_c 0.0\n",
      "93 Train Loss 42.322308\n",
      "Loss  4.9491434 C_bot  0.15 k_c 0.0\n",
      "Loss  5.1138067 C_bot  0.15 k_c 0.0\n",
      "94 Train Loss 42.255135\n",
      "Loss  5.1138067 C_bot  0.15 k_c 0.0\n",
      "Loss  5.609725 C_bot  0.15 k_c 0.0\n",
      "95 Train Loss 42.501534\n",
      "Loss  5.609725 C_bot  0.15 k_c 0.0\n",
      "Loss  5.278886 C_bot  0.15 k_c 0.0\n",
      "96 Train Loss 41.8892\n",
      "Loss  5.278886 C_bot  0.15 k_c 0.0\n",
      "Loss  4.8387046 C_bot  0.15 k_c 0.0\n",
      "97 Train Loss 41.147633\n",
      "Loss  4.8387046 C_bot  0.15 k_c 0.0\n",
      "Loss  5.0951757 C_bot  0.15 k_c 0.0\n",
      "98 Train Loss 41.108807\n",
      "Loss  5.0951757 C_bot  0.15 k_c 0.0\n",
      "Loss  5.286135 C_bot  0.15 k_c 0.0\n",
      "99 Train Loss 41.03008\n",
      "Loss  5.286135 C_bot  0.15 k_c 0.0\n",
      "Loss  4.904553 C_bot  0.15 k_c 0.0\n",
      "100 Train Loss 40.40836\n",
      "Loss  4.904553 C_bot  0.15 k_c 0.0\n",
      "Loss  4.7024264 C_bot  0.15 k_c 0.0\n",
      "101 Train Loss 39.98421\n",
      "Loss  4.7024264 C_bot  0.15 k_c 0.0\n",
      "Loss  4.9468746 C_bot  0.15 k_c 0.0\n",
      "102 Train Loss 40.003746\n",
      "Loss  4.9468746 C_bot  0.15 k_c 0.0\n",
      "Loss  4.968495 C_bot  0.15 k_c 0.0\n",
      "103 Train Loss 39.780724\n",
      "Loss  4.968495 C_bot  0.15 k_c 0.0\n",
      "Loss  4.706173 C_bot  0.15 k_c 0.0\n",
      "104 Train Loss 39.2548\n",
      "Loss  4.706173 C_bot  0.15 k_c 0.0\n",
      "Loss  4.710271 C_bot  0.15 k_c 0.0\n",
      "105 Train Loss 38.9927\n",
      "Loss  4.710271 C_bot  0.15 k_c 0.0\n",
      "Loss  4.8695803 C_bot  0.15 k_c 0.0\n",
      "106 Train Loss 38.900936\n",
      "Loss  4.8695803 C_bot  0.15 k_c 0.0\n",
      "Loss  4.7465773 C_bot  0.15 k_c 0.0\n",
      "107 Train Loss 38.549496\n",
      "Loss  4.7465773 C_bot  0.15 k_c 0.0\n",
      "Loss  4.556307 C_bot  0.15 k_c 0.0\n",
      "108 Train Loss 38.148083\n",
      "Loss  4.556307 C_bot  0.15 k_c 0.0\n",
      "Loss  4.615995 C_bot  0.15 k_c 0.0\n",
      "109 Train Loss 37.99955\n",
      "Loss  4.615995 C_bot  0.15 k_c 0.0\n",
      "Loss  4.675662 C_bot  0.15 k_c 0.0\n",
      "110 Train Loss 37.839966\n",
      "Loss  4.675662 C_bot  0.15 k_c 0.0\n",
      "Loss  4.5575423 C_bot  0.15 k_c 0.0\n",
      "111 Train Loss 37.48845\n",
      "Loss  4.5575423 C_bot  0.15 k_c 0.0\n",
      "Loss  4.5145335 C_bot  0.15 k_c 0.0\n",
      "112 Train Loss 37.207397\n",
      "Loss  4.5145335 C_bot  0.15 k_c 0.0\n",
      "Loss  4.594943 C_bot  0.15 k_c 0.0\n",
      "113 Train Loss 37.058567\n",
      "Loss  4.594943 C_bot  0.15 k_c 0.0\n",
      "Loss  4.5583386 C_bot  0.15 k_c 0.0\n",
      "114 Train Loss 36.809196\n",
      "Loss  4.5583386 C_bot  0.15 k_c 0.0\n",
      "Loss  4.439886 C_bot  0.15 k_c 0.0\n",
      "115 Train Loss 36.492493\n",
      "Loss  4.439886 C_bot  0.15 k_c 0.0\n",
      "Loss  4.4358926 C_bot  0.15 k_c 0.0\n",
      "116 Train Loss 36.295193\n",
      "Loss  4.4358926 C_bot  0.15 k_c 0.0\n",
      "Loss  4.4671507 C_bot  0.15 k_c 0.0\n",
      "117 Train Loss 36.1276\n",
      "Loss  4.4671507 C_bot  0.15 k_c 0.0\n",
      "Loss  4.411958 C_bot  0.15 k_c 0.0\n",
      "118 Train Loss 35.864403\n",
      "Loss  4.411958 C_bot  0.15 k_c 0.0\n",
      "Loss  4.378383 C_bot  0.15 k_c 0.0\n",
      "119 Train Loss 35.61928\n",
      "Loss  4.378383 C_bot  0.15 k_c 0.0\n",
      "Loss  4.413638 C_bot  0.15 k_c 0.0\n",
      "120 Train Loss 35.448986\n",
      "Loss  4.413638 C_bot  0.15 k_c 0.0\n",
      "Loss  4.396273 C_bot  0.15 k_c 0.0\n",
      "121 Train Loss 35.23821\n",
      "Loss  4.396273 C_bot  0.15 k_c 0.0\n",
      "Loss  4.3274503 C_bot  0.15 k_c 0.0\n",
      "122 Train Loss 34.987236\n",
      "Loss  4.3274503 C_bot  0.15 k_c 0.0\n",
      "Loss  4.3120823 C_bot  0.15 k_c 0.0\n",
      "123 Train Loss 34.794365\n",
      "Loss  4.3120823 C_bot  0.15 k_c 0.0\n",
      "Loss  4.3204784 C_bot  0.15 k_c 0.0\n",
      "124 Train Loss 34.622417\n",
      "Loss  4.3204784 C_bot  0.15 k_c 0.0\n",
      "Loss  4.2889023 C_bot  0.15 k_c 0.0\n",
      "125 Train Loss 34.40497\n",
      "Loss  4.2889023 C_bot  0.15 k_c 0.0\n",
      "Loss  4.2692337 C_bot  0.15 k_c 0.0\n",
      "126 Train Loss 34.197674\n",
      "Loss  4.2692337 C_bot  0.15 k_c 0.0\n",
      "Loss  4.2831335 C_bot  0.15 k_c 0.0\n",
      "127 Train Loss 34.028893\n",
      "Loss  4.2831335 C_bot  0.15 k_c 0.0\n",
      "Loss  4.267279 C_bot  0.15 k_c 0.0\n",
      "128 Train Loss 33.839607\n",
      "Loss  4.267279 C_bot  0.15 k_c 0.0\n",
      "Loss  4.2258115 C_bot  0.15 k_c 0.0\n",
      "129 Train Loss 33.633167\n",
      "Loss  4.2258115 C_bot  0.15 k_c 0.0\n",
      "Loss  4.212498 C_bot  0.15 k_c 0.0\n",
      "130 Train Loss 33.458466\n",
      "Loss  4.212498 C_bot  0.15 k_c 0.0\n",
      "Loss  4.2089376 C_bot  0.15 k_c 0.0\n",
      "131 Train Loss 33.291874\n",
      "Loss  4.2089376 C_bot  0.15 k_c 0.0\n",
      "Loss  4.187719 C_bot  0.15 k_c 0.0\n",
      "132 Train Loss 33.10441\n",
      "Loss  4.187719 C_bot  0.15 k_c 0.0\n",
      "Loss  4.17731 C_bot  0.15 k_c 0.0\n",
      "133 Train Loss 32.927494\n",
      "Loss  4.17731 C_bot  0.15 k_c 0.0\n",
      "Loss  4.180601 C_bot  0.15 k_c 0.0\n",
      "134 Train Loss 32.768726\n",
      "Loss  4.180601 C_bot  0.15 k_c 0.0\n",
      "Loss  4.164616 C_bot  0.15 k_c 0.0\n",
      "135 Train Loss 32.597828\n",
      "Loss  4.164616 C_bot  0.15 k_c 0.0\n",
      "Loss  4.13896 C_bot  0.15 k_c 0.0\n",
      "136 Train Loss 32.423294\n",
      "Loss  4.13896 C_bot  0.15 k_c 0.0\n",
      "Loss  4.128842 C_bot  0.15 k_c 0.0\n",
      "137 Train Loss 32.26657\n",
      "Loss  4.128842 C_bot  0.15 k_c 0.0\n",
      "Loss  4.1206264 C_bot  0.15 k_c 0.0\n",
      "138 Train Loss 32.110565\n",
      "Loss  4.1206264 C_bot  0.15 k_c 0.0\n",
      "Loss  4.105987 C_bot  0.15 k_c 0.0\n",
      "139 Train Loss 31.946484\n",
      "Loss  4.105987 C_bot  0.15 k_c 0.0\n",
      "Loss  4.1003695 C_bot  0.15 k_c 0.0\n",
      "140 Train Loss 31.792332\n",
      "Loss  4.1003695 C_bot  0.15 k_c 0.0\n",
      "Loss  4.0974393 C_bot  0.15 k_c 0.0\n",
      "141 Train Loss 31.645042\n",
      "Loss  4.0974393 C_bot  0.15 k_c 0.0\n",
      "Loss  4.082197 C_bot  0.15 k_c 0.0\n",
      "142 Train Loss 31.490957\n",
      "Loss  4.082197 C_bot  0.15 k_c 0.0\n",
      "Loss  4.0657086 C_bot  0.15 k_c 0.0\n",
      "143 Train Loss 31.3397\n",
      "Loss  4.0657086 C_bot  0.15 k_c 0.0\n",
      "Loss  4.057095 C_bot  0.15 k_c 0.0\n",
      "144 Train Loss 31.197485\n",
      "Loss  4.057095 C_bot  0.15 k_c 0.0\n",
      "Loss  4.0478296 C_bot  0.15 k_c 0.0\n",
      "145 Train Loss 31.053738\n",
      "Loss  4.0478296 C_bot  0.15 k_c 0.0\n",
      "Loss  4.037776 C_bot  0.15 k_c 0.0\n",
      "146 Train Loss 30.908676\n",
      "Loss  4.037776 C_bot  0.15 k_c 0.0\n",
      "Loss  4.033391 C_bot  0.15 k_c 0.0\n",
      "147 Train Loss 30.770983\n",
      "Loss  4.033391 C_bot  0.15 k_c 0.0\n",
      "Loss  4.0266967 C_bot  0.15 k_c 0.0\n",
      "148 Train Loss 30.63476\n",
      "Loss  4.0266967 C_bot  0.15 k_c 0.0\n",
      "Loss  4.01367 C_bot  0.15 k_c 0.0\n",
      "149 Train Loss 30.496292\n",
      "Loss  4.01367 C_bot  0.15 k_c 0.0\n",
      "Loss  4.002706 C_bot  0.15 k_c 0.0\n",
      "150 Train Loss 30.362387\n",
      "Loss  4.002706 C_bot  0.15 k_c 0.0\n",
      "Loss  3.99482 C_bot  0.15 k_c 0.0\n",
      "151 Train Loss 30.231995\n",
      "Loss  3.99482 C_bot  0.15 k_c 0.0\n",
      "Loss  3.986175 C_bot  0.15 k_c 0.0\n",
      "152 Train Loss 30.100391\n",
      "Loss  3.986175 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9794788 C_bot  0.15 k_c 0.0\n",
      "153 Train Loss 29.971199\n",
      "Loss  3.9794788 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9745035 C_bot  0.15 k_c 0.0\n",
      "154 Train Loss 29.845963\n",
      "Loss  3.9745035 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9659195 C_bot  0.15 k_c 0.0\n",
      "155 Train Loss 29.720425\n",
      "Loss  3.9659195 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9555 C_bot  0.15 k_c 0.0\n",
      "156 Train Loss 29.595917\n",
      "Loss  3.9555 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9471571 C_bot  0.15 k_c 0.0\n",
      "157 Train Loss 29.474882\n",
      "Loss  3.9471571 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9396331 C_bot  0.15 k_c 0.0\n",
      "158 Train Loss 29.35479\n",
      "Loss  3.9396331 C_bot  0.15 k_c 0.0\n",
      "Loss  3.932732 C_bot  0.15 k_c 0.0\n",
      "159 Train Loss 29.235424\n",
      "Loss  3.932732 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9272587 C_bot  0.15 k_c 0.0\n",
      "160 Train Loss 29.118687\n",
      "Loss  3.9272587 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9210596 C_bot  0.15 k_c 0.0\n",
      "161 Train Loss 29.00356\n",
      "Loss  3.9210596 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9126043 C_bot  0.15 k_c 0.0\n",
      "162 Train Loss 28.888765\n",
      "Loss  3.9126043 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9042969 C_bot  0.15 k_c 0.0\n",
      "163 Train Loss 28.775898\n",
      "Loss  3.9042969 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8973079 C_bot  0.15 k_c 0.0\n",
      "164 Train Loss 28.664999\n",
      "Loss  3.8973079 C_bot  0.15 k_c 0.0\n",
      "Loss  3.890652 C_bot  0.15 k_c 0.0\n",
      "165 Train Loss 28.55459\n",
      "Loss  3.890652 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8848975 C_bot  0.15 k_c 0.0\n",
      "166 Train Loss 28.445728\n",
      "Loss  3.8848975 C_bot  0.15 k_c 0.0\n",
      "Loss  3.879627 C_bot  0.15 k_c 0.0\n",
      "167 Train Loss 28.338926\n",
      "Loss  3.879627 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8727171 C_bot  0.15 k_c 0.0\n",
      "168 Train Loss 28.232573\n",
      "Loss  3.8727171 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8652298 C_bot  0.15 k_c 0.0\n",
      "169 Train Loss 28.127413\n",
      "Loss  3.8652298 C_bot  0.15 k_c 0.0\n",
      "Loss  3.85849 C_bot  0.15 k_c 0.0\n",
      "170 Train Loss 28.023937\n",
      "Loss  3.85849 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8524039 C_bot  0.15 k_c 0.0\n",
      "171 Train Loss 27.921457\n",
      "Loss  3.8524039 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8466425 C_bot  0.15 k_c 0.0\n",
      "172 Train Loss 27.819744\n",
      "Loss  3.8466425 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8414311 C_bot  0.15 k_c 0.0\n",
      "173 Train Loss 27.719658\n",
      "Loss  3.8414311 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8357625 C_bot  0.15 k_c 0.0\n",
      "174 Train Loss 27.620754\n",
      "Loss  3.8357625 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8291967 C_bot  0.15 k_c 0.0\n",
      "175 Train Loss 27.522568\n",
      "Loss  3.8291967 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8227906 C_bot  0.15 k_c 0.0\n",
      "176 Train Loss 27.425653\n",
      "Loss  3.8227906 C_bot  0.15 k_c 0.0\n",
      "Loss  3.817073 C_bot  0.15 k_c 0.0\n",
      "177 Train Loss 27.329998\n",
      "Loss  3.817073 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8116176 C_bot  0.15 k_c 0.0\n",
      "178 Train Loss 27.235113\n",
      "Loss  3.8116176 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8067877 C_bot  0.15 k_c 0.0\n",
      "179 Train Loss 27.141766\n",
      "Loss  3.8067877 C_bot  0.15 k_c 0.0\n",
      "Loss  3.801451 C_bot  0.15 k_c 0.0\n",
      "180 Train Loss 27.049322\n",
      "Loss  3.801451 C_bot  0.15 k_c 0.0\n",
      "Loss  3.795809 C_bot  0.15 k_c 0.0\n",
      "181 Train Loss 26.958122\n",
      "Loss  3.795809 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7900333 C_bot  0.15 k_c 0.0\n",
      "182 Train Loss 26.868055\n",
      "Loss  3.7900333 C_bot  0.15 k_c 0.0\n",
      "Loss  3.784614 C_bot  0.15 k_c 0.0\n",
      "183 Train Loss 26.779205\n",
      "Loss  3.784614 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7794743 C_bot  0.15 k_c 0.0\n",
      "184 Train Loss 26.691372\n",
      "Loss  3.7794743 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7748134 C_bot  0.15 k_c 0.0\n",
      "185 Train Loss 26.604996\n",
      "Loss  3.7748134 C_bot  0.15 k_c 0.0\n",
      "Loss  3.769919 C_bot  0.15 k_c 0.0\n",
      "186 Train Loss 26.519753\n",
      "Loss  3.769919 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7647867 C_bot  0.15 k_c 0.0\n",
      "187 Train Loss 26.435814\n",
      "Loss  3.7647867 C_bot  0.15 k_c 0.0\n",
      "Loss  3.759505 C_bot  0.15 k_c 0.0\n",
      "188 Train Loss 26.353104\n",
      "Loss  3.759505 C_bot  0.15 k_c 0.0\n",
      "Loss  3.754365 C_bot  0.15 k_c 0.0\n",
      "189 Train Loss 26.271606\n",
      "Loss  3.754365 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7496605 C_bot  0.15 k_c 0.0\n",
      "190 Train Loss 26.191452\n",
      "Loss  3.7496605 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7451134 C_bot  0.15 k_c 0.0\n",
      "191 Train Loss 26.112492\n",
      "Loss  3.7451134 C_bot  0.15 k_c 0.0\n",
      "Loss  3.740571 C_bot  0.15 k_c 0.0\n",
      "192 Train Loss 26.034824\n",
      "Loss  3.740571 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7357712 C_bot  0.15 k_c 0.0\n",
      "193 Train Loss 25.958326\n",
      "Loss  3.7357712 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7308393 C_bot  0.15 k_c 0.0\n",
      "194 Train Loss 25.883015\n",
      "Loss  3.7308393 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7260535 C_bot  0.15 k_c 0.0\n",
      "195 Train Loss 25.80891\n",
      "Loss  3.7260535 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7216585 C_bot  0.15 k_c 0.0\n",
      "196 Train Loss 25.736097\n",
      "Loss  3.7216585 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7170694 C_bot  0.15 k_c 0.0\n",
      "197 Train Loss 25.664038\n",
      "Loss  3.7170694 C_bot  0.15 k_c 0.0\n",
      "Loss  3.712767 C_bot  0.15 k_c 0.0\n",
      "198 Train Loss 25.593372\n",
      "Loss  3.712767 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7083821 C_bot  0.15 k_c 0.0\n",
      "199 Train Loss 25.523844\n",
      "Loss  3.7083821 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7037117 C_bot  0.15 k_c 0.0\n",
      "200 Train Loss 25.455153\n",
      "Loss  3.7037117 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6992772 C_bot  0.15 k_c 0.0\n",
      "201 Train Loss 25.387627\n",
      "Loss  3.6992772 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6948466 C_bot  0.15 k_c 0.0\n",
      "202 Train Loss 25.320894\n",
      "Loss  3.6948466 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6907575 C_bot  0.15 k_c 0.0\n",
      "203 Train Loss 25.255308\n",
      "Loss  3.6907575 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6866517 C_bot  0.15 k_c 0.0\n",
      "204 Train Loss 25.190619\n",
      "Loss  3.6866517 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6823542 C_bot  0.15 k_c 0.0\n",
      "205 Train Loss 25.126719\n",
      "Loss  3.6823542 C_bot  0.15 k_c 0.0\n",
      "Loss  3.67816 C_bot  0.15 k_c 0.0\n",
      "206 Train Loss 25.063848\n",
      "Loss  3.67816 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6739893 C_bot  0.15 k_c 0.0\n",
      "207 Train Loss 25.001778\n",
      "Loss  3.6739893 C_bot  0.15 k_c 0.0\n",
      "Loss  3.669975 C_bot  0.15 k_c 0.0\n",
      "208 Train Loss 24.94052\n",
      "Loss  3.669975 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6660938 C_bot  0.15 k_c 0.0\n",
      "209 Train Loss 24.880066\n",
      "Loss  3.6660938 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6621606 C_bot  0.15 k_c 0.0\n",
      "210 Train Loss 24.820312\n",
      "Loss  3.6621606 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6581254 C_bot  0.15 k_c 0.0\n",
      "211 Train Loss 24.761263\n",
      "Loss  3.6581254 C_bot  0.15 k_c 0.0\n",
      "Loss  3.654188 C_bot  0.15 k_c 0.0\n",
      "212 Train Loss 24.703066\n",
      "Loss  3.654188 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6502926 C_bot  0.15 k_c 0.0\n",
      "213 Train Loss 24.645555\n",
      "Loss  3.6502926 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6466002 C_bot  0.15 k_c 0.0\n",
      "214 Train Loss 24.58881\n",
      "Loss  3.6466002 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6428485 C_bot  0.15 k_c 0.0\n",
      "215 Train Loss 24.532578\n",
      "Loss  3.6428485 C_bot  0.15 k_c 0.0\n",
      "Loss  3.639063 C_bot  0.15 k_c 0.0\n",
      "216 Train Loss 24.476955\n",
      "Loss  3.639063 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6353552 C_bot  0.15 k_c 0.0\n",
      "217 Train Loss 24.42208\n",
      "Loss  3.6353552 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6316984 C_bot  0.15 k_c 0.0\n",
      "218 Train Loss 24.367878\n",
      "Loss  3.6316984 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6280384 C_bot  0.15 k_c 0.0\n",
      "219 Train Loss 24.314213\n",
      "Loss  3.6280384 C_bot  0.15 k_c 0.0\n",
      "Loss  3.624425 C_bot  0.15 k_c 0.0\n",
      "220 Train Loss 24.26108\n",
      "Loss  3.624425 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6209583 C_bot  0.15 k_c 0.0\n",
      "221 Train Loss 24.208603\n",
      "Loss  3.6209583 C_bot  0.15 k_c 0.0\n",
      "Loss  3.617511 C_bot  0.15 k_c 0.0\n",
      "222 Train Loss 24.156698\n",
      "Loss  3.617511 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6139185 C_bot  0.15 k_c 0.0\n",
      "223 Train Loss 24.105217\n",
      "Loss  3.6139185 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6104841 C_bot  0.15 k_c 0.0\n",
      "224 Train Loss 24.054417\n",
      "Loss  3.6104841 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6070688 C_bot  0.15 k_c 0.0\n",
      "225 Train Loss 24.004097\n",
      "Loss  3.6070688 C_bot  0.15 k_c 0.0\n",
      "Loss  3.603658 C_bot  0.15 k_c 0.0\n",
      "226 Train Loss 23.95422\n",
      "Loss  3.603658 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6003435 C_bot  0.15 k_c 0.0\n",
      "227 Train Loss 23.904894\n",
      "Loss  3.6003435 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5970383 C_bot  0.15 k_c 0.0\n",
      "228 Train Loss 23.856064\n",
      "Loss  3.5970383 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5937703 C_bot  0.15 k_c 0.0\n",
      "229 Train Loss 23.807758\n",
      "Loss  3.5937703 C_bot  0.15 k_c 0.0\n",
      "Loss  3.590502 C_bot  0.15 k_c 0.0\n",
      "230 Train Loss 23.759901\n",
      "Loss  3.590502 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5872526 C_bot  0.15 k_c 0.0\n",
      "231 Train Loss 23.71247\n",
      "Loss  3.5872526 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5840516 C_bot  0.15 k_c 0.0\n",
      "232 Train Loss 23.665478\n",
      "Loss  3.5840516 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5808985 C_bot  0.15 k_c 0.0\n",
      "233 Train Loss 23.618942\n",
      "Loss  3.5808985 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5777738 C_bot  0.15 k_c 0.0\n",
      "234 Train Loss 23.572865\n",
      "Loss  3.5777738 C_bot  0.15 k_c 0.0\n",
      "Loss  3.574522 C_bot  0.15 k_c 0.0\n",
      "235 Train Loss 23.527084\n",
      "Loss  3.574522 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5715263 C_bot  0.15 k_c 0.0\n",
      "236 Train Loss 23.481956\n",
      "Loss  3.5715263 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5683262 C_bot  0.15 k_c 0.0\n",
      "237 Train Loss 23.43698\n",
      "Loss  3.5683262 C_bot  0.15 k_c 0.0\n",
      "Loss  3.565293 C_bot  0.15 k_c 0.0\n",
      "238 Train Loss 23.392527\n",
      "Loss  3.565293 C_bot  0.15 k_c 0.0\n",
      "Loss  3.562321 C_bot  0.15 k_c 0.0\n",
      "239 Train Loss 23.348509\n",
      "Loss  3.562321 C_bot  0.15 k_c 0.0\n",
      "Loss  3.55921 C_bot  0.15 k_c 0.0\n",
      "240 Train Loss 23.304737\n",
      "Loss  3.55921 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5561438 C_bot  0.15 k_c 0.0\n",
      "241 Train Loss 23.261383\n",
      "Loss  3.5561438 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5532436 C_bot  0.15 k_c 0.0\n",
      "242 Train Loss 23.21853\n",
      "Loss  3.5532436 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5504725 C_bot  0.15 k_c 0.0\n",
      "243 Train Loss 23.176136\n",
      "Loss  3.5504725 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5475907 C_bot  0.15 k_c 0.0\n",
      "244 Train Loss 23.13396\n",
      "Loss  3.5475907 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5446208 C_bot  0.15 k_c 0.0\n",
      "245 Train Loss 23.092037\n",
      "Loss  3.5446208 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5416493 C_bot  0.15 k_c 0.0\n",
      "246 Train Loss 23.050453\n",
      "Loss  3.5416493 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5386605 C_bot  0.15 k_c 0.0\n",
      "247 Train Loss 23.009178\n",
      "Loss  3.5386605 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5358865 C_bot  0.15 k_c 0.0\n",
      "248 Train Loss 22.968431\n",
      "Loss  3.5358865 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5330718 C_bot  0.15 k_c 0.0\n",
      "249 Train Loss 22.927937\n",
      "Loss  3.5330718 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5302165 C_bot  0.15 k_c 0.0\n",
      "250 Train Loss 22.887703\n",
      "Loss  3.5302165 C_bot  0.15 k_c 0.0\n",
      "Loss  3.527368 C_bot  0.15 k_c 0.0\n",
      "251 Train Loss 22.847784\n",
      "Loss  3.527368 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5246687 C_bot  0.15 k_c 0.0\n",
      "252 Train Loss 22.808327\n",
      "Loss  3.5246687 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5218246 C_bot  0.15 k_c 0.0\n",
      "253 Train Loss 22.769016\n",
      "Loss  3.5218246 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5189612 C_bot  0.15 k_c 0.0\n",
      "254 Train Loss 22.729965\n",
      "Loss  3.5189612 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5162866 C_bot  0.15 k_c 0.0\n",
      "255 Train Loss 22.691372\n",
      "Loss  3.5162866 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5134332 C_bot  0.15 k_c 0.0\n",
      "256 Train Loss 22.652885\n",
      "Loss  3.5134332 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5106556 C_bot  0.15 k_c 0.0\n",
      "257 Train Loss 22.614761\n",
      "Loss  3.5106556 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5079665 C_bot  0.15 k_c 0.0\n",
      "258 Train Loss 22.577013\n",
      "Loss  3.5079665 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5051494 C_bot  0.15 k_c 0.0\n",
      "259 Train Loss 22.539408\n",
      "Loss  3.5051494 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5025232 C_bot  0.15 k_c 0.0\n",
      "260 Train Loss 22.502254\n",
      "Loss  3.5025232 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4997654 C_bot  0.15 k_c 0.0\n",
      "261 Train Loss 22.46524\n",
      "Loss  3.4997654 C_bot  0.15 k_c 0.0\n",
      "Loss  3.497025 C_bot  0.15 k_c 0.0\n",
      "262 Train Loss 22.428532\n",
      "Loss  3.497025 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4941847 C_bot  0.15 k_c 0.0\n",
      "263 Train Loss 22.392014\n",
      "Loss  3.4941847 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4916468 C_bot  0.15 k_c 0.0\n",
      "264 Train Loss 22.356087\n",
      "Loss  3.4916468 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4888897 C_bot  0.15 k_c 0.0\n",
      "265 Train Loss 22.320223\n",
      "Loss  3.4888897 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4862301 C_bot  0.15 k_c 0.0\n",
      "266 Train Loss 22.284748\n",
      "Loss  3.4862301 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4834151 C_bot  0.15 k_c 0.0\n",
      "267 Train Loss 22.249426\n",
      "Loss  3.4834151 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4808044 C_bot  0.15 k_c 0.0\n",
      "268 Train Loss 22.214624\n",
      "Loss  3.4808044 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4780612 C_bot  0.15 k_c 0.0\n",
      "269 Train Loss 22.180025\n",
      "Loss  3.4780612 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4753408 C_bot  0.15 k_c 0.0\n",
      "270 Train Loss 22.145773\n",
      "Loss  3.4753408 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4727585 C_bot  0.15 k_c 0.0\n",
      "271 Train Loss 22.111984\n",
      "Loss  3.4727585 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4700246 C_bot  0.15 k_c 0.0\n",
      "272 Train Loss 22.078382\n",
      "Loss  3.4700246 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4672232 C_bot  0.15 k_c 0.0\n",
      "273 Train Loss 22.045061\n",
      "Loss  3.4672232 C_bot  0.15 k_c 0.0\n",
      "Loss  3.464594 C_bot  0.15 k_c 0.0\n",
      "274 Train Loss 22.012276\n",
      "Loss  3.464594 C_bot  0.15 k_c 0.0\n",
      "Loss  3.461818 C_bot  0.15 k_c 0.0\n",
      "275 Train Loss 21.979683\n",
      "Loss  3.461818 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4591007 C_bot  0.15 k_c 0.0\n",
      "276 Train Loss 21.94749\n",
      "Loss  3.4591007 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4564185 C_bot  0.15 k_c 0.0\n",
      "277 Train Loss 21.915678\n",
      "Loss  3.4564185 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4536514 C_bot  0.15 k_c 0.0\n",
      "278 Train Loss 21.884123\n",
      "Loss  3.4536514 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4507883 C_bot  0.15 k_c 0.0\n",
      "279 Train Loss 21.85282\n",
      "Loss  3.4507883 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4483438 C_bot  0.15 k_c 0.0\n",
      "280 Train Loss 21.822254\n",
      "Loss  3.4483438 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4455473 C_bot  0.15 k_c 0.0\n",
      "281 Train Loss 21.791658\n",
      "Loss  3.4455473 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4427996 C_bot  0.15 k_c 0.0\n",
      "282 Train Loss 21.761425\n",
      "Loss  3.4427996 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4400916 C_bot  0.15 k_c 0.0\n",
      "283 Train Loss 21.731537\n",
      "Loss  3.4400916 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4372609 C_bot  0.15 k_c 0.0\n",
      "284 Train Loss 21.701832\n",
      "Loss  3.4372609 C_bot  0.15 k_c 0.0\n",
      "Loss  3.434617 C_bot  0.15 k_c 0.0\n",
      "285 Train Loss 21.672604\n",
      "Loss  3.434617 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4318233 C_bot  0.15 k_c 0.0\n",
      "286 Train Loss 21.643503\n",
      "Loss  3.4318233 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4290051 C_bot  0.15 k_c 0.0\n",
      "287 Train Loss 21.614645\n",
      "Loss  3.4290051 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4263194 C_bot  0.15 k_c 0.0\n",
      "288 Train Loss 21.58619\n",
      "Loss  3.4263194 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4235907 C_bot  0.15 k_c 0.0\n",
      "289 Train Loss 21.557953\n",
      "Loss  3.4235907 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4207659 C_bot  0.15 k_c 0.0\n",
      "290 Train Loss 21.529873\n",
      "Loss  3.4207659 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4180307 C_bot  0.15 k_c 0.0\n",
      "291 Train Loss 21.502129\n",
      "Loss  3.4180307 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4154131 C_bot  0.15 k_c 0.0\n",
      "292 Train Loss 21.474728\n",
      "Loss  3.4154131 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4126036 C_bot  0.15 k_c 0.0\n",
      "293 Train Loss 21.447365\n",
      "Loss  3.4126036 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4096742 C_bot  0.15 k_c 0.0\n",
      "294 Train Loss 21.420116\n",
      "Loss  3.4096742 C_bot  0.15 k_c 0.0\n",
      "Loss  3.407042 C_bot  0.15 k_c 0.0\n",
      "295 Train Loss 21.393394\n",
      "Loss  3.407042 C_bot  0.15 k_c 0.0\n",
      "Loss  3.404213 C_bot  0.15 k_c 0.0\n",
      "296 Train Loss 21.366688\n",
      "Loss  3.404213 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4015388 C_bot  0.15 k_c 0.0\n",
      "297 Train Loss 21.340336\n",
      "Loss  3.4015388 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3987772 C_bot  0.15 k_c 0.0\n",
      "298 Train Loss 21.3141\n",
      "Loss  3.3987772 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3957965 C_bot  0.15 k_c 0.0\n",
      "299 Train Loss 21.287853\n",
      "Loss  3.3957965 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3930318 C_bot  0.15 k_c 0.0\n",
      "300 Train Loss 21.26202\n",
      "Loss  3.3930318 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3904047 C_bot  0.15 k_c 0.0\n",
      "301 Train Loss 21.236517\n",
      "Loss  3.3904047 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3873866 C_bot  0.15 k_c 0.0\n",
      "302 Train Loss 21.210808\n",
      "Loss  3.3873866 C_bot  0.15 k_c 0.0\n",
      "Loss  3.384696 C_bot  0.15 k_c 0.0\n",
      "303 Train Loss 21.185608\n",
      "Loss  3.384696 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3819366 C_bot  0.15 k_c 0.0\n",
      "304 Train Loss 21.16052\n",
      "Loss  3.3819366 C_bot  0.15 k_c 0.0\n",
      "Loss  3.378923 C_bot  0.15 k_c 0.0\n",
      "305 Train Loss 21.13536\n",
      "Loss  3.378923 C_bot  0.15 k_c 0.0\n",
      "Loss  3.376256 C_bot  0.15 k_c 0.0\n",
      "306 Train Loss 21.110718\n",
      "Loss  3.376256 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3734221 C_bot  0.15 k_c 0.0\n",
      "307 Train Loss 21.086075\n",
      "Loss  3.3734221 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3705127 C_bot  0.15 k_c 0.0\n",
      "308 Train Loss 21.061525\n",
      "Loss  3.3705127 C_bot  0.15 k_c 0.0\n",
      "Loss  3.367737 C_bot  0.15 k_c 0.0\n",
      "309 Train Loss 21.037266\n",
      "Loss  3.367737 C_bot  0.15 k_c 0.0\n",
      "Loss  3.364832 C_bot  0.15 k_c 0.0\n",
      "310 Train Loss 21.013046\n",
      "Loss  3.364832 C_bot  0.15 k_c 0.0\n",
      "Loss  3.362077 C_bot  0.15 k_c 0.0\n",
      "311 Train Loss 20.989132\n",
      "Loss  3.362077 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3592005 C_bot  0.15 k_c 0.0\n",
      "312 Train Loss 20.965252\n",
      "Loss  3.3592005 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3563254 C_bot  0.15 k_c 0.0\n",
      "313 Train Loss 20.941515\n",
      "Loss  3.3563254 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3533604 C_bot  0.15 k_c 0.0\n",
      "314 Train Loss 20.917843\n",
      "Loss  3.3533604 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3504376 C_bot  0.15 k_c 0.0\n",
      "315 Train Loss 20.894358\n",
      "Loss  3.3504376 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3476458 C_bot  0.15 k_c 0.0\n",
      "316 Train Loss 20.871143\n",
      "Loss  3.3476458 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3448124 C_bot  0.15 k_c 0.0\n",
      "317 Train Loss 20.848028\n",
      "Loss  3.3448124 C_bot  0.15 k_c 0.0\n",
      "Loss  3.341818 C_bot  0.15 k_c 0.0\n",
      "318 Train Loss 20.82489\n",
      "Loss  3.341818 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3389833 C_bot  0.15 k_c 0.0\n",
      "319 Train Loss 20.802048\n",
      "Loss  3.3389833 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3359694 C_bot  0.15 k_c 0.0\n",
      "320 Train Loss 20.779158\n",
      "Loss  3.3359694 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3331633 C_bot  0.15 k_c 0.0\n",
      "321 Train Loss 20.756601\n",
      "Loss  3.3331633 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3301096 C_bot  0.15 k_c 0.0\n",
      "322 Train Loss 20.733927\n",
      "Loss  3.3301096 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3271992 C_bot  0.15 k_c 0.0\n",
      "323 Train Loss 20.711517\n",
      "Loss  3.3271992 C_bot  0.15 k_c 0.0\n",
      "Loss  3.324237 C_bot  0.15 k_c 0.0\n",
      "324 Train Loss 20.689182\n",
      "Loss  3.324237 C_bot  0.15 k_c 0.0\n",
      "Loss  3.321285 C_bot  0.15 k_c 0.0\n",
      "325 Train Loss 20.66698\n",
      "Loss  3.321285 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3181722 C_bot  0.15 k_c 0.0\n",
      "326 Train Loss 20.644733\n",
      "Loss  3.3181722 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3153088 C_bot  0.15 k_c 0.0\n",
      "327 Train Loss 20.622849\n",
      "Loss  3.3153088 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3122747 C_bot  0.15 k_c 0.0\n",
      "328 Train Loss 20.60091\n",
      "Loss  3.3122747 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3092904 C_bot  0.15 k_c 0.0\n",
      "329 Train Loss 20.579132\n",
      "Loss  3.3092904 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3062153 C_bot  0.15 k_c 0.0\n",
      "330 Train Loss 20.557375\n",
      "Loss  3.3062153 C_bot  0.15 k_c 0.0\n",
      "Loss  3.303191 C_bot  0.15 k_c 0.0\n",
      "331 Train Loss 20.535778\n",
      "Loss  3.303191 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3000357 C_bot  0.15 k_c 0.0\n",
      "332 Train Loss 20.514153\n",
      "Loss  3.3000357 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2970414 C_bot  0.15 k_c 0.0\n",
      "333 Train Loss 20.492794\n",
      "Loss  3.2970414 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2940416 C_bot  0.15 k_c 0.0\n",
      "334 Train Loss 20.471533\n",
      "Loss  3.2940416 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2909124 C_bot  0.15 k_c 0.0\n",
      "335 Train Loss 20.450249\n",
      "Loss  3.2909124 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2879024 C_bot  0.15 k_c 0.0\n",
      "336 Train Loss 20.42918\n",
      "Loss  3.2879024 C_bot  0.15 k_c 0.0\n",
      "Loss  3.284801 C_bot  0.15 k_c 0.0\n",
      "337 Train Loss 20.408112\n",
      "Loss  3.284801 C_bot  0.15 k_c 0.0\n",
      "Loss  3.281579 C_bot  0.15 k_c 0.0\n",
      "338 Train Loss 20.387022\n",
      "Loss  3.281579 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2784805 C_bot  0.15 k_c 0.0\n",
      "339 Train Loss 20.366154\n",
      "Loss  3.2784805 C_bot  0.15 k_c 0.0\n",
      "Loss  3.275349 C_bot  0.15 k_c 0.0\n",
      "340 Train Loss 20.345356\n",
      "Loss  3.275349 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2721884 C_bot  0.15 k_c 0.0\n",
      "341 Train Loss 20.324615\n",
      "Loss  3.2721884 C_bot  0.15 k_c 0.0\n",
      "Loss  3.269048 C_bot  0.15 k_c 0.0\n",
      "342 Train Loss 20.303976\n",
      "Loss  3.269048 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2658315 C_bot  0.15 k_c 0.0\n",
      "343 Train Loss 20.283356\n",
      "Loss  3.2658315 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2626154 C_bot  0.15 k_c 0.0\n",
      "344 Train Loss 20.262833\n",
      "Loss  3.2626154 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2593615 C_bot  0.15 k_c 0.0\n",
      "345 Train Loss 20.24236\n",
      "Loss  3.2593615 C_bot  0.15 k_c 0.0\n",
      "Loss  3.256002 C_bot  0.15 k_c 0.0\n",
      "346 Train Loss 20.221863\n",
      "Loss  3.256002 C_bot  0.15 k_c 0.0\n",
      "Loss  3.252856 C_bot  0.15 k_c 0.0\n",
      "347 Train Loss 20.201662\n",
      "Loss  3.252856 C_bot  0.15 k_c 0.0\n",
      "Loss  3.249544 C_bot  0.15 k_c 0.0\n",
      "348 Train Loss 20.181381\n",
      "Loss  3.249544 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2462795 C_bot  0.15 k_c 0.0\n",
      "349 Train Loss 20.161242\n",
      "Loss  3.2462795 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2429326 C_bot  0.15 k_c 0.0\n",
      "350 Train Loss 20.141104\n",
      "Loss  3.2429326 C_bot  0.15 k_c 0.0\n",
      "Loss  3.239593 C_bot  0.15 k_c 0.0\n",
      "351 Train Loss 20.121048\n",
      "Loss  3.239593 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2363234 C_bot  0.15 k_c 0.0\n",
      "352 Train Loss 20.101141\n",
      "Loss  3.2363234 C_bot  0.15 k_c 0.0\n",
      "Loss  3.232885 C_bot  0.15 k_c 0.0\n",
      "353 Train Loss 20.08115\n",
      "Loss  3.232885 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2295554 C_bot  0.15 k_c 0.0\n",
      "354 Train Loss 20.06136\n",
      "Loss  3.2295554 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2261612 C_bot  0.15 k_c 0.0\n",
      "355 Train Loss 20.04158\n",
      "Loss  3.2261612 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2227802 C_bot  0.15 k_c 0.0\n",
      "356 Train Loss 20.021893\n",
      "Loss  3.2227802 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2192717 C_bot  0.15 k_c 0.0\n",
      "357 Train Loss 20.002151\n",
      "Loss  3.2192717 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2158363 C_bot  0.15 k_c 0.0\n",
      "358 Train Loss 19.982563\n",
      "Loss  3.2158363 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2125037 C_bot  0.15 k_c 0.0\n",
      "359 Train Loss 19.963161\n",
      "Loss  3.2125037 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2089827 C_bot  0.15 k_c 0.0\n",
      "360 Train Loss 19.943651\n",
      "Loss  3.2089827 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2053683 C_bot  0.15 k_c 0.0\n",
      "361 Train Loss 19.92413\n",
      "Loss  3.2053683 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2018209 C_bot  0.15 k_c 0.0\n",
      "362 Train Loss 19.904737\n",
      "Loss  3.2018209 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1983397 C_bot  0.15 k_c 0.0\n",
      "363 Train Loss 19.885496\n",
      "Loss  3.1983397 C_bot  0.15 k_c 0.0\n",
      "Loss  3.194811 C_bot  0.15 k_c 0.0\n",
      "364 Train Loss 19.866287\n",
      "Loss  3.194811 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1911013 C_bot  0.15 k_c 0.0\n",
      "365 Train Loss 19.846977\n",
      "Loss  3.1911013 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1875489 C_bot  0.15 k_c 0.0\n",
      "366 Train Loss 19.827896\n",
      "Loss  3.1875489 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1839716 C_bot  0.15 k_c 0.0\n",
      "367 Train Loss 19.808865\n",
      "Loss  3.1839716 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1802058 C_bot  0.15 k_c 0.0\n",
      "368 Train Loss 19.78972\n",
      "Loss  3.1802058 C_bot  0.15 k_c 0.0\n",
      "Loss  3.17664 C_bot  0.15 k_c 0.0\n",
      "369 Train Loss 19.770855\n",
      "Loss  3.17664 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1730063 C_bot  0.15 k_c 0.0\n",
      "370 Train Loss 19.752003\n",
      "Loss  3.1730063 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1692357 C_bot  0.15 k_c 0.0\n",
      "371 Train Loss 19.733084\n",
      "Loss  3.1692357 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1655512 C_bot  0.15 k_c 0.0\n",
      "372 Train Loss 19.71432\n",
      "Loss  3.1655512 C_bot  0.15 k_c 0.0\n",
      "Loss  3.161801 C_bot  0.15 k_c 0.0\n",
      "373 Train Loss 19.69557\n",
      "Loss  3.161801 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1580255 C_bot  0.15 k_c 0.0\n",
      "374 Train Loss 19.676874\n",
      "Loss  3.1580255 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1540964 C_bot  0.15 k_c 0.0\n",
      "375 Train Loss 19.658096\n",
      "Loss  3.1540964 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1503854 C_bot  0.15 k_c 0.0\n",
      "376 Train Loss 19.639606\n",
      "Loss  3.1503854 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1465678 C_bot  0.15 k_c 0.0\n",
      "377 Train Loss 19.621084\n",
      "Loss  3.1465678 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1427717 C_bot  0.15 k_c 0.0\n",
      "378 Train Loss 19.602657\n",
      "Loss  3.1427717 C_bot  0.15 k_c 0.0\n",
      "Loss  3.138895 C_bot  0.15 k_c 0.0\n",
      "379 Train Loss 19.584225\n",
      "Loss  3.138895 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1349354 C_bot  0.15 k_c 0.0\n",
      "380 Train Loss 19.565784\n",
      "Loss  3.1349354 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1311052 C_bot  0.15 k_c 0.0\n",
      "381 Train Loss 19.547543\n",
      "Loss  3.1311052 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1271865 C_bot  0.15 k_c 0.0\n",
      "382 Train Loss 19.529282\n",
      "Loss  3.1271865 C_bot  0.15 k_c 0.0\n",
      "Loss  3.123351 C_bot  0.15 k_c 0.0\n",
      "383 Train Loss 19.51117\n",
      "Loss  3.123351 C_bot  0.15 k_c 0.0\n",
      "Loss  3.119365 C_bot  0.15 k_c 0.0\n",
      "384 Train Loss 19.492989\n",
      "Loss  3.119365 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1154075 C_bot  0.15 k_c 0.0\n",
      "385 Train Loss 19.474907\n",
      "Loss  3.1154075 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1115727 C_bot  0.15 k_c 0.0\n",
      "386 Train Loss 19.457012\n",
      "Loss  3.1115727 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1075776 C_bot  0.15 k_c 0.0\n",
      "387 Train Loss 19.439024\n",
      "Loss  3.1075776 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1035752 C_bot  0.15 k_c 0.0\n",
      "388 Train Loss 19.421093\n",
      "Loss  3.1035752 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0995047 C_bot  0.15 k_c 0.0\n",
      "389 Train Loss 19.403173\n",
      "Loss  3.0995047 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0954595 C_bot  0.15 k_c 0.0\n",
      "390 Train Loss 19.385345\n",
      "Loss  3.0954595 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0915313 C_bot  0.15 k_c 0.0\n",
      "391 Train Loss 19.367695\n",
      "Loss  3.0915313 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0874283 C_bot  0.15 k_c 0.0\n",
      "392 Train Loss 19.34993\n",
      "Loss  3.0874283 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0835052 C_bot  0.15 k_c 0.0\n",
      "393 Train Loss 19.33241\n",
      "Loss  3.0835052 C_bot  0.15 k_c 0.0\n",
      "Loss  3.079404 C_bot  0.15 k_c 0.0\n",
      "394 Train Loss 19.314787\n",
      "Loss  3.079404 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0754187 C_bot  0.15 k_c 0.0\n",
      "395 Train Loss 19.297337\n",
      "Loss  3.0754187 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0715246 C_bot  0.15 k_c 0.0\n",
      "396 Train Loss 19.280037\n",
      "Loss  3.0715246 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0674326 C_bot  0.15 k_c 0.0\n",
      "397 Train Loss 19.262596\n",
      "Loss  3.0674326 C_bot  0.15 k_c 0.0\n",
      "Loss  3.063262 C_bot  0.15 k_c 0.0\n",
      "398 Train Loss 19.245146\n",
      "Loss  3.063262 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0592597 C_bot  0.15 k_c 0.0\n",
      "399 Train Loss 19.227924\n",
      "Loss  3.0592597 C_bot  0.15 k_c 0.0\n",
      "Loss  3.055345 C_bot  0.15 k_c 0.0\n",
      "400 Train Loss 19.210846\n",
      "Loss  3.055345 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0512064 C_bot  0.15 k_c 0.0\n",
      "401 Train Loss 19.193592\n",
      "Loss  3.0512064 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0472398 C_bot  0.15 k_c 0.0\n",
      "402 Train Loss 19.176575\n",
      "Loss  3.0472398 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0430882 C_bot  0.15 k_c 0.0\n",
      "403 Train Loss 19.159428\n",
      "Loss  3.0430882 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0390942 C_bot  0.15 k_c 0.0\n",
      "404 Train Loss 19.142492\n",
      "Loss  3.0390942 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0349965 C_bot  0.15 k_c 0.0\n",
      "405 Train Loss 19.125505\n",
      "Loss  3.0349965 C_bot  0.15 k_c 0.0\n",
      "Loss  3.031083 C_bot  0.15 k_c 0.0\n",
      "406 Train Loss 19.108753\n",
      "Loss  3.031083 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0269983 C_bot  0.15 k_c 0.0\n",
      "407 Train Loss 19.091888\n",
      "Loss  3.0269983 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0229938 C_bot  0.15 k_c 0.0\n",
      "408 Train Loss 19.075153\n",
      "Loss  3.0229938 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0190303 C_bot  0.15 k_c 0.0\n",
      "409 Train Loss 19.058506\n",
      "Loss  3.0190303 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0149279 C_bot  0.15 k_c 0.0\n",
      "410 Train Loss 19.04177\n",
      "Loss  3.0149279 C_bot  0.15 k_c 0.0\n",
      "Loss  3.011011 C_bot  0.15 k_c 0.0\n",
      "411 Train Loss 19.025267\n",
      "Loss  3.011011 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0070603 C_bot  0.15 k_c 0.0\n",
      "412 Train Loss 19.008783\n",
      "Loss  3.0070603 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0029988 C_bot  0.15 k_c 0.0\n",
      "413 Train Loss 18.992237\n",
      "Loss  3.0029988 C_bot  0.15 k_c 0.0\n",
      "Loss  2.998937 C_bot  0.15 k_c 0.0\n",
      "414 Train Loss 18.975729\n",
      "Loss  2.998937 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9951415 C_bot  0.15 k_c 0.0\n",
      "415 Train Loss 18.959534\n",
      "Loss  2.9951415 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9911337 C_bot  0.15 k_c 0.0\n",
      "416 Train Loss 18.943176\n",
      "Loss  2.9911337 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9871113 C_bot  0.15 k_c 0.0\n",
      "417 Train Loss 18.926857\n",
      "Loss  2.9871113 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9831245 C_bot  0.15 k_c 0.0\n",
      "418 Train Loss 18.910608\n",
      "Loss  2.9831245 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9790578 C_bot  0.15 k_c 0.0\n",
      "419 Train Loss 18.894325\n",
      "Loss  2.9790578 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9752173 C_bot  0.15 k_c 0.0\n",
      "420 Train Loss 18.878311\n",
      "Loss  2.9752173 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9713025 C_bot  0.15 k_c 0.0\n",
      "421 Train Loss 18.86227\n",
      "Loss  2.9713025 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9673705 C_bot  0.15 k_c 0.0\n",
      "422 Train Loss 18.846249\n",
      "Loss  2.9673705 C_bot  0.15 k_c 0.0\n",
      "Loss  2.963497 C_bot  0.15 k_c 0.0\n",
      "423 Train Loss 18.830332\n",
      "Loss  2.963497 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9595647 C_bot  0.15 k_c 0.0\n",
      "424 Train Loss 18.8144\n",
      "Loss  2.9595647 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9557266 C_bot  0.15 k_c 0.0\n",
      "425 Train Loss 18.798603\n",
      "Loss  2.9557266 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9516728 C_bot  0.15 k_c 0.0\n",
      "426 Train Loss 18.782629\n",
      "Loss  2.9516728 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9478576 C_bot  0.15 k_c 0.0\n",
      "427 Train Loss 18.766933\n",
      "Loss  2.9478576 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9439118 C_bot  0.15 k_c 0.0\n",
      "428 Train Loss 18.751152\n",
      "Loss  2.9439118 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9401057 C_bot  0.15 k_c 0.0\n",
      "429 Train Loss 18.73555\n",
      "Loss  2.9401057 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9361498 C_bot  0.15 k_c 0.0\n",
      "430 Train Loss 18.719835\n",
      "Loss  2.9361498 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9322789 C_bot  0.15 k_c 0.0\n",
      "431 Train Loss 18.704243\n",
      "Loss  2.9322789 C_bot  0.15 k_c 0.0\n",
      "Loss  2.928448 C_bot  0.15 k_c 0.0\n",
      "432 Train Loss 18.688732\n",
      "Loss  2.928448 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9245398 C_bot  0.15 k_c 0.0\n",
      "433 Train Loss 18.673182\n",
      "Loss  2.9245398 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9206755 C_bot  0.15 k_c 0.0\n",
      "434 Train Loss 18.657713\n",
      "Loss  2.9206755 C_bot  0.15 k_c 0.0\n",
      "Loss  2.916906 C_bot  0.15 k_c 0.0\n",
      "435 Train Loss 18.642382\n",
      "Loss  2.916906 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9130294 C_bot  0.15 k_c 0.0\n",
      "436 Train Loss 18.626976\n",
      "Loss  2.9130294 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9091818 C_bot  0.15 k_c 0.0\n",
      "437 Train Loss 18.611637\n",
      "Loss  2.9091818 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9053853 C_bot  0.15 k_c 0.0\n",
      "438 Train Loss 18.596394\n",
      "Loss  2.9053853 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9014874 C_bot  0.15 k_c 0.0\n",
      "439 Train Loss 18.58108\n",
      "Loss  2.9014874 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8977866 C_bot  0.15 k_c 0.0\n",
      "440 Train Loss 18.565998\n",
      "Loss  2.8977866 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8939342 C_bot  0.15 k_c 0.0\n",
      "441 Train Loss 18.5508\n",
      "Loss  2.8939342 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8900683 C_bot  0.15 k_c 0.0\n",
      "442 Train Loss 18.53563\n",
      "Loss  2.8900683 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8863935 C_bot  0.15 k_c 0.0\n",
      "443 Train Loss 18.520687\n",
      "Loss  2.8863935 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8825836 C_bot  0.15 k_c 0.0\n",
      "444 Train Loss 18.505638\n",
      "Loss  2.8825836 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8786905 C_bot  0.15 k_c 0.0\n",
      "445 Train Loss 18.490545\n",
      "Loss  2.8786905 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8749774 C_bot  0.15 k_c 0.0\n",
      "446 Train Loss 18.47567\n",
      "Loss  2.8749774 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8711038 C_bot  0.15 k_c 0.0\n",
      "447 Train Loss 18.460669\n",
      "Loss  2.8711038 C_bot  0.15 k_c 0.0\n",
      "Loss  2.867488 C_bot  0.15 k_c 0.0\n",
      "448 Train Loss 18.445953\n",
      "Loss  2.867488 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8637204 C_bot  0.15 k_c 0.0\n",
      "449 Train Loss 18.431122\n",
      "Loss  2.8637204 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8598032 C_bot  0.15 k_c 0.0\n",
      "450 Train Loss 18.416183\n",
      "Loss  2.8598032 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8561227 C_bot  0.15 k_c 0.0\n",
      "451 Train Loss 18.40151\n",
      "Loss  2.8561227 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8524213 C_bot  0.15 k_c 0.0\n",
      "452 Train Loss 18.386845\n",
      "Loss  2.8524213 C_bot  0.15 k_c 0.0\n",
      "Loss  2.84872 C_bot  0.15 k_c 0.0\n",
      "453 Train Loss 18.372217\n",
      "Loss  2.84872 C_bot  0.15 k_c 0.0\n",
      "Loss  2.844863 C_bot  0.15 k_c 0.0\n",
      "454 Train Loss 18.357468\n",
      "Loss  2.844863 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8411589 C_bot  0.15 k_c 0.0\n",
      "455 Train Loss 18.342905\n",
      "Loss  2.8411589 C_bot  0.15 k_c 0.0\n",
      "Loss  2.837458 C_bot  0.15 k_c 0.0\n",
      "456 Train Loss 18.328373\n",
      "Loss  2.837458 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8337479 C_bot  0.15 k_c 0.0\n",
      "457 Train Loss 18.313866\n",
      "Loss  2.8337479 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8300755 C_bot  0.15 k_c 0.0\n",
      "458 Train Loss 18.299427\n",
      "Loss  2.8300755 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8262217 C_bot  0.15 k_c 0.0\n",
      "459 Train Loss 18.284845\n",
      "Loss  2.8262217 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8226824 C_bot  0.15 k_c 0.0\n",
      "460 Train Loss 18.270607\n",
      "Loss  2.8226824 C_bot  0.15 k_c 0.0\n",
      "Loss  2.818956 C_bot  0.15 k_c 0.0\n",
      "461 Train Loss 18.256207\n",
      "Loss  2.818956 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8153076 C_bot  0.15 k_c 0.0\n",
      "462 Train Loss 18.241922\n",
      "Loss  2.8153076 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8115385 C_bot  0.15 k_c 0.0\n",
      "463 Train Loss 18.227547\n",
      "Loss  2.8115385 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8079295 C_bot  0.15 k_c 0.0\n",
      "464 Train Loss 18.21336\n",
      "Loss  2.8079295 C_bot  0.15 k_c 0.0\n",
      "Loss  2.804241 C_bot  0.15 k_c 0.0\n",
      "465 Train Loss 18.199123\n",
      "Loss  2.804241 C_bot  0.15 k_c 0.0\n",
      "Loss  2.8005528 C_bot  0.15 k_c 0.0\n",
      "466 Train Loss 18.184921\n",
      "Loss  2.8005528 C_bot  0.15 k_c 0.0\n",
      "Loss  2.796816 C_bot  0.15 k_c 0.0\n",
      "467 Train Loss 18.170696\n",
      "Loss  2.796816 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7932546 C_bot  0.15 k_c 0.0\n",
      "468 Train Loss 18.156681\n",
      "Loss  2.7932546 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7896817 C_bot  0.15 k_c 0.0\n",
      "469 Train Loss 18.142681\n",
      "Loss  2.7896817 C_bot  0.15 k_c 0.0\n",
      "Loss  2.785892 C_bot  0.15 k_c 0.0\n",
      "470 Train Loss 18.128494\n",
      "Loss  2.785892 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7823393 C_bot  0.15 k_c 0.0\n",
      "471 Train Loss 18.11457\n",
      "Loss  2.7823393 C_bot  0.15 k_c 0.0\n",
      "Loss  2.778797 C_bot  0.15 k_c 0.0\n",
      "472 Train Loss 18.100695\n",
      "Loss  2.778797 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7751133 C_bot  0.15 k_c 0.0\n",
      "473 Train Loss 18.0867\n",
      "Loss  2.7751133 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7713888 C_bot  0.15 k_c 0.0\n",
      "474 Train Loss 18.072697\n",
      "Loss  2.7713888 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7677827 C_bot  0.15 k_c 0.0\n",
      "475 Train Loss 18.058834\n",
      "Loss  2.7677827 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7641768 C_bot  0.15 k_c 0.0\n",
      "476 Train Loss 18.045006\n",
      "Loss  2.7641768 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7605722 C_bot  0.15 k_c 0.0\n",
      "477 Train Loss 18.031206\n",
      "Loss  2.7605722 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7569559 C_bot  0.15 k_c 0.0\n",
      "478 Train Loss 18.017422\n",
      "Loss  2.7569559 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7533731 C_bot  0.15 k_c 0.0\n",
      "479 Train Loss 18.003693\n",
      "Loss  2.7533731 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7498016 C_bot  0.15 k_c 0.0\n",
      "480 Train Loss 17.990017\n",
      "Loss  2.7498016 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7460349 C_bot  0.15 k_c 0.0\n",
      "481 Train Loss 17.976164\n",
      "Loss  2.7460349 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7425551 C_bot  0.15 k_c 0.0\n",
      "482 Train Loss 17.96262\n",
      "Loss  2.7425551 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7390199 C_bot  0.15 k_c 0.0\n",
      "483 Train Loss 17.94905\n",
      "Loss  2.7390199 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7354608 C_bot  0.15 k_c 0.0\n",
      "484 Train Loss 17.935493\n",
      "Loss  2.7354608 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7318785 C_bot  0.15 k_c 0.0\n",
      "485 Train Loss 17.921932\n",
      "Loss  2.7318785 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7281768 C_bot  0.15 k_c 0.0\n",
      "486 Train Loss 17.90828\n",
      "Loss  2.7281768 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7246914 C_bot  0.15 k_c 0.0\n",
      "487 Train Loss 17.894865\n",
      "Loss  2.7246914 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7211773 C_bot  0.15 k_c 0.0\n",
      "488 Train Loss 17.881453\n",
      "Loss  2.7211773 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7175274 C_bot  0.15 k_c 0.0\n",
      "489 Train Loss 17.867935\n",
      "Loss  2.7175274 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7140174 C_bot  0.15 k_c 0.0\n",
      "490 Train Loss 17.854576\n",
      "Loss  2.7140174 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7104297 C_bot  0.15 k_c 0.0\n",
      "491 Train Loss 17.841166\n",
      "Loss  2.7104297 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7069561 C_bot  0.15 k_c 0.0\n",
      "492 Train Loss 17.827896\n",
      "Loss  2.7069561 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7032876 C_bot  0.15 k_c 0.0\n",
      "493 Train Loss 17.81446\n",
      "Loss  2.7032876 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6999545 C_bot  0.15 k_c 0.0\n",
      "494 Train Loss 17.801384\n",
      "Loss  2.6999545 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6963272 C_bot  0.15 k_c 0.0\n",
      "495 Train Loss 17.788036\n",
      "Loss  2.6963272 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6927602 C_bot  0.15 k_c 0.0\n",
      "496 Train Loss 17.774773\n",
      "Loss  2.6927602 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6893072 C_bot  0.15 k_c 0.0\n",
      "497 Train Loss 17.76165\n",
      "Loss  2.6893072 C_bot  0.15 k_c 0.0\n",
      "Loss  2.685837 C_bot  0.15 k_c 0.0\n",
      "498 Train Loss 17.748537\n",
      "Loss  2.685837 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6822188 C_bot  0.15 k_c 0.0\n",
      "499 Train Loss 17.735298\n",
      "Loss  2.6822188 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6787255 C_bot  0.15 k_c 0.0\n",
      "500 Train Loss 17.722206\n",
      "Loss  2.6787255 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6752462 C_bot  0.15 k_c 0.0\n",
      "501 Train Loss 17.709154\n",
      "Loss  2.6752462 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6717134 C_bot  0.15 k_c 0.0\n",
      "502 Train Loss 17.696075\n",
      "Loss  2.6717134 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6682427 C_bot  0.15 k_c 0.0\n",
      "503 Train Loss 17.683084\n",
      "Loss  2.6682427 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6647992 C_bot  0.15 k_c 0.0\n",
      "504 Train Loss 17.670137\n",
      "Loss  2.6647992 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6613295 C_bot  0.15 k_c 0.0\n",
      "505 Train Loss 17.657192\n",
      "Loss  2.6613295 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6579015 C_bot  0.15 k_c 0.0\n",
      "506 Train Loss 17.644312\n",
      "Loss  2.6579015 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6544015 C_bot  0.15 k_c 0.0\n",
      "507 Train Loss 17.631384\n",
      "Loss  2.6544015 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6508698 C_bot  0.15 k_c 0.0\n",
      "508 Train Loss 17.618448\n",
      "Loss  2.6508698 C_bot  0.15 k_c 0.0\n",
      "Loss  2.647263 C_bot  0.15 k_c 0.0\n",
      "509 Train Loss 17.60546\n",
      "Loss  2.647263 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6438391 C_bot  0.15 k_c 0.0\n",
      "510 Train Loss 17.592674\n",
      "Loss  2.6438391 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6403565 C_bot  0.15 k_c 0.0\n",
      "511 Train Loss 17.579853\n",
      "Loss  2.6403565 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6369889 C_bot  0.15 k_c 0.0\n",
      "512 Train Loss 17.567177\n",
      "Loss  2.6369889 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6335046 C_bot  0.15 k_c 0.0\n",
      "513 Train Loss 17.554405\n",
      "Loss  2.6335046 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6301112 C_bot  0.15 k_c 0.0\n",
      "514 Train Loss 17.54174\n",
      "Loss  2.6301112 C_bot  0.15 k_c 0.0\n",
      "Loss  2.626692 C_bot  0.15 k_c 0.0\n",
      "515 Train Loss 17.529072\n",
      "Loss  2.626692 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6231577 C_bot  0.15 k_c 0.0\n",
      "516 Train Loss 17.51632\n",
      "Loss  2.6231577 C_bot  0.15 k_c 0.0\n",
      "Loss  2.619693 C_bot  0.15 k_c 0.0\n",
      "517 Train Loss 17.503656\n",
      "Loss  2.619693 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6163447 C_bot  0.15 k_c 0.0\n",
      "518 Train Loss 17.49113\n",
      "Loss  2.6163447 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6128666 C_bot  0.15 k_c 0.0\n",
      "519 Train Loss 17.478495\n",
      "Loss  2.6128666 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6094415 C_bot  0.15 k_c 0.0\n",
      "520 Train Loss 17.465935\n",
      "Loss  2.6094415 C_bot  0.15 k_c 0.0\n",
      "Loss  2.605956 C_bot  0.15 k_c 0.0\n",
      "521 Train Loss 17.45334\n",
      "Loss  2.605956 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6025531 C_bot  0.15 k_c 0.0\n",
      "522 Train Loss 17.440845\n",
      "Loss  2.6025531 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5991948 C_bot  0.15 k_c 0.0\n",
      "523 Train Loss 17.42842\n",
      "Loss  2.5991948 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5958378 C_bot  0.15 k_c 0.0\n",
      "524 Train Loss 17.416016\n",
      "Loss  2.5958378 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5923758 C_bot  0.15 k_c 0.0\n",
      "525 Train Loss 17.403534\n",
      "Loss  2.5923758 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5890033 C_bot  0.15 k_c 0.0\n",
      "526 Train Loss 17.391157\n",
      "Loss  2.5890033 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5855641 C_bot  0.15 k_c 0.0\n",
      "527 Train Loss 17.37873\n",
      "Loss  2.5855641 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5821629 C_bot  0.15 k_c 0.0\n",
      "528 Train Loss 17.366371\n",
      "Loss  2.5821629 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5788112 C_bot  0.15 k_c 0.0\n",
      "529 Train Loss 17.354088\n",
      "Loss  2.5788112 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5753465 C_bot  0.15 k_c 0.0\n",
      "530 Train Loss 17.341702\n",
      "Loss  2.5753465 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5718963 C_bot  0.15 k_c 0.0\n",
      "531 Train Loss 17.329351\n",
      "Loss  2.5718963 C_bot  0.15 k_c 0.0\n",
      "Loss  2.568534 C_bot  0.15 k_c 0.0\n",
      "532 Train Loss 17.317112\n",
      "Loss  2.568534 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5651402 C_bot  0.15 k_c 0.0\n",
      "533 Train Loss 17.304869\n",
      "Loss  2.5651402 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5618775 C_bot  0.15 k_c 0.0\n",
      "534 Train Loss 17.29277\n",
      "Loss  2.5618775 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5583868 C_bot  0.15 k_c 0.0\n",
      "535 Train Loss 17.280466\n",
      "Loss  2.5583868 C_bot  0.15 k_c 0.0\n",
      "Loss  2.554932 C_bot  0.15 k_c 0.0\n",
      "536 Train Loss 17.268215\n",
      "Loss  2.554932 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5516558 C_bot  0.15 k_c 0.0\n",
      "537 Train Loss 17.256174\n",
      "Loss  2.5516558 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5481877 C_bot  0.15 k_c 0.0\n",
      "538 Train Loss 17.243954\n",
      "Loss  2.5481877 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5448396 C_bot  0.15 k_c 0.0\n",
      "539 Train Loss 17.231869\n",
      "Loss  2.5448396 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5416584 C_bot  0.15 k_c 0.0\n",
      "540 Train Loss 17.219978\n",
      "Loss  2.5416584 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5382285 C_bot  0.15 k_c 0.0\n",
      "541 Train Loss 17.207863\n",
      "Loss  2.5382285 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5348158 C_bot  0.15 k_c 0.0\n",
      "542 Train Loss 17.19578\n",
      "Loss  2.5348158 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5313907 C_bot  0.15 k_c 0.0\n",
      "543 Train Loss 17.183697\n",
      "Loss  2.5313907 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5281115 C_bot  0.15 k_c 0.0\n",
      "544 Train Loss 17.171791\n",
      "Loss  2.5281115 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5247614 C_bot  0.15 k_c 0.0\n",
      "545 Train Loss 17.159836\n",
      "Loss  2.5247614 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5214548 C_bot  0.15 k_c 0.0\n",
      "546 Train Loss 17.14794\n",
      "Loss  2.5214548 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5181627 C_bot  0.15 k_c 0.0\n",
      "547 Train Loss 17.13607\n",
      "Loss  2.5181627 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5147417 C_bot  0.15 k_c 0.0\n",
      "548 Train Loss 17.124098\n",
      "Loss  2.5147417 C_bot  0.15 k_c 0.0\n",
      "Loss  2.511423 C_bot  0.15 k_c 0.0\n",
      "549 Train Loss 17.112251\n",
      "Loss  2.511423 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5080454 C_bot  0.15 k_c 0.0\n",
      "550 Train Loss 17.100363\n",
      "Loss  2.5080454 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5047357 C_bot  0.15 k_c 0.0\n",
      "551 Train Loss 17.088558\n",
      "Loss  2.5047357 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5014868 C_bot  0.15 k_c 0.0\n",
      "552 Train Loss 17.076834\n",
      "Loss  2.5014868 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4982135 C_bot  0.15 k_c 0.0\n",
      "553 Train Loss 17.065113\n",
      "Loss  2.4982135 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4947143 C_bot  0.15 k_c 0.0\n",
      "554 Train Loss 17.053177\n",
      "Loss  2.4947143 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4914756 C_bot  0.15 k_c 0.0\n",
      "555 Train Loss 17.04152\n",
      "Loss  2.4914756 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4882116 C_bot  0.15 k_c 0.0\n",
      "556 Train Loss 17.029858\n",
      "Loss  2.4882116 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4849432 C_bot  0.15 k_c 0.0\n",
      "557 Train Loss 17.018215\n",
      "Loss  2.4849432 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4816048 C_bot  0.15 k_c 0.0\n",
      "558 Train Loss 17.006517\n",
      "Loss  2.4816048 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4782562 C_bot  0.15 k_c 0.0\n",
      "559 Train Loss 16.994825\n",
      "Loss  2.4782562 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4749303 C_bot  0.15 k_c 0.0\n",
      "560 Train Loss 16.983177\n",
      "Loss  2.4749303 C_bot  0.15 k_c 0.0\n",
      "Loss  2.471729 C_bot  0.15 k_c 0.0\n",
      "561 Train Loss 16.971676\n",
      "Loss  2.471729 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4684143 C_bot  0.15 k_c 0.0\n",
      "562 Train Loss 16.960075\n",
      "Loss  2.4684143 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4650955 C_bot  0.15 k_c 0.0\n",
      "563 Train Loss 16.948484\n",
      "Loss  2.4650955 C_bot  0.15 k_c 0.0\n",
      "Loss  2.461766 C_bot  0.15 k_c 0.0\n",
      "564 Train Loss 16.936909\n",
      "Loss  2.461766 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4584537 C_bot  0.15 k_c 0.0\n",
      "565 Train Loss 16.925367\n",
      "Loss  2.4584537 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4551494 C_bot  0.15 k_c 0.0\n",
      "566 Train Loss 16.91385\n",
      "Loss  2.4551494 C_bot  0.15 k_c 0.0\n",
      "Loss  2.451947 C_bot  0.15 k_c 0.0\n",
      "567 Train Loss 16.902447\n",
      "Loss  2.451947 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4487185 C_bot  0.15 k_c 0.0\n",
      "568 Train Loss 16.89104\n",
      "Loss  2.4487185 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4454 C_bot  0.15 k_c 0.0\n",
      "569 Train Loss 16.879562\n",
      "Loss  2.4454 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4422297 C_bot  0.15 k_c 0.0\n",
      "570 Train Loss 16.86825\n",
      "Loss  2.4422297 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4388297 C_bot  0.15 k_c 0.0\n",
      "571 Train Loss 16.856722\n",
      "Loss  2.4388297 C_bot  0.15 k_c 0.0\n",
      "Loss  2.435613 C_bot  0.15 k_c 0.0\n",
      "572 Train Loss 16.845398\n",
      "Loss  2.435613 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4323254 C_bot  0.15 k_c 0.0\n",
      "573 Train Loss 16.834019\n",
      "Loss  2.4323254 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4291275 C_bot  0.15 k_c 0.0\n",
      "574 Train Loss 16.822746\n",
      "Loss  2.4291275 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4258761 C_bot  0.15 k_c 0.0\n",
      "575 Train Loss 16.811432\n",
      "Loss  2.4258761 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4225733 C_bot  0.15 k_c 0.0\n",
      "576 Train Loss 16.80009\n",
      "Loss  2.4225733 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4192703 C_bot  0.15 k_c 0.0\n",
      "577 Train Loss 16.788765\n",
      "Loss  2.4192703 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4160805 C_bot  0.15 k_c 0.0\n",
      "578 Train Loss 16.777561\n",
      "Loss  2.4160805 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4129026 C_bot  0.15 k_c 0.0\n",
      "579 Train Loss 16.766384\n",
      "Loss  2.4129026 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4096284 C_bot  0.15 k_c 0.0\n",
      "580 Train Loss 16.755136\n",
      "Loss  2.4096284 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4063766 C_bot  0.15 k_c 0.0\n",
      "581 Train Loss 16.743923\n",
      "Loss  2.4063766 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4031107 C_bot  0.15 k_c 0.0\n",
      "582 Train Loss 16.732712\n",
      "Loss  2.4031107 C_bot  0.15 k_c 0.0\n",
      "Loss  2.399983 C_bot  0.15 k_c 0.0\n",
      "583 Train Loss 16.72165\n",
      "Loss  2.399983 C_bot  0.15 k_c 0.0\n",
      "Loss  2.396601 C_bot  0.15 k_c 0.0\n",
      "584 Train Loss 16.710356\n",
      "Loss  2.396601 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3935242 C_bot  0.15 k_c 0.0\n",
      "585 Train Loss 16.699383\n",
      "Loss  2.3935242 C_bot  0.15 k_c 0.0\n",
      "Loss  2.390171 C_bot  0.15 k_c 0.0\n",
      "586 Train Loss 16.688137\n",
      "Loss  2.390171 C_bot  0.15 k_c 0.0\n",
      "Loss  2.38709 C_bot  0.15 k_c 0.0\n",
      "587 Train Loss 16.677183\n",
      "Loss  2.38709 C_bot  0.15 k_c 0.0\n",
      "Loss  2.383758 C_bot  0.15 k_c 0.0\n",
      "588 Train Loss 16.666\n",
      "Loss  2.383758 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3805063 C_bot  0.15 k_c 0.0\n",
      "589 Train Loss 16.654907\n",
      "Loss  2.3805063 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3773825 C_bot  0.15 k_c 0.0\n",
      "590 Train Loss 16.643955\n",
      "Loss  2.3773825 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3741388 C_bot  0.15 k_c 0.0\n",
      "591 Train Loss 16.6329\n",
      "Loss  2.3741388 C_bot  0.15 k_c 0.0\n",
      "Loss  2.370925 C_bot  0.15 k_c 0.0\n",
      "592 Train Loss 16.621891\n",
      "Loss  2.370925 C_bot  0.15 k_c 0.0\n",
      "Loss  2.367725 C_bot  0.15 k_c 0.0\n",
      "593 Train Loss 16.610903\n",
      "Loss  2.367725 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3645895 C_bot  0.15 k_c 0.0\n",
      "594 Train Loss 16.599995\n",
      "Loss  2.3645895 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3613577 C_bot  0.15 k_c 0.0\n",
      "595 Train Loss 16.589008\n",
      "Loss  2.3613577 C_bot  0.15 k_c 0.0\n",
      "Loss  2.35824 C_bot  0.15 k_c 0.0\n",
      "596 Train Loss 16.578152\n",
      "Loss  2.35824 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3549535 C_bot  0.15 k_c 0.0\n",
      "597 Train Loss 16.567131\n",
      "Loss  2.3549535 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3517072 C_bot  0.15 k_c 0.0\n",
      "598 Train Loss 16.556168\n",
      "Loss  2.3517072 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3486557 C_bot  0.15 k_c 0.0\n",
      "599 Train Loss 16.545414\n",
      "Loss  2.3486557 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3454406 C_bot  0.15 k_c 0.0\n",
      "600 Train Loss 16.534512\n",
      "Loss  2.3454406 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3422303 C_bot  0.15 k_c 0.0\n",
      "601 Train Loss 16.52362\n",
      "Loss  2.3422303 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3390777 C_bot  0.15 k_c 0.0\n",
      "602 Train Loss 16.512804\n",
      "Loss  2.3390777 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3358464 C_bot  0.15 k_c 0.0\n",
      "603 Train Loss 16.501923\n",
      "Loss  2.3358464 C_bot  0.15 k_c 0.0\n",
      "Loss  2.332712 C_bot  0.15 k_c 0.0\n",
      "604 Train Loss 16.491154\n",
      "Loss  2.332712 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3296602 C_bot  0.15 k_c 0.0\n",
      "605 Train Loss 16.480473\n",
      "Loss  2.3296602 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3263223 C_bot  0.15 k_c 0.0\n",
      "606 Train Loss 16.46952\n",
      "Loss  2.3263223 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3232436 C_bot  0.15 k_c 0.0\n",
      "607 Train Loss 16.458843\n",
      "Loss  2.3232436 C_bot  0.15 k_c 0.0\n",
      "Loss  2.320143 C_bot  0.15 k_c 0.0\n",
      "608 Train Loss 16.448162\n",
      "Loss  2.320143 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3169677 C_bot  0.15 k_c 0.0\n",
      "609 Train Loss 16.437405\n",
      "Loss  2.3169677 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3137953 C_bot  0.15 k_c 0.0\n",
      "610 Train Loss 16.426668\n",
      "Loss  2.3137953 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3106556 C_bot  0.15 k_c 0.0\n",
      "611 Train Loss 16.415985\n",
      "Loss  2.3106556 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3074436 C_bot  0.15 k_c 0.0\n",
      "612 Train Loss 16.405243\n",
      "Loss  2.3074436 C_bot  0.15 k_c 0.0\n",
      "Loss  2.304333 C_bot  0.15 k_c 0.0\n",
      "613 Train Loss 16.394602\n",
      "Loss  2.304333 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3011343 C_bot  0.15 k_c 0.0\n",
      "614 Train Loss 16.38389\n",
      "Loss  2.3011343 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2981048 C_bot  0.15 k_c 0.0\n",
      "615 Train Loss 16.37337\n",
      "Loss  2.2981048 C_bot  0.15 k_c 0.0\n",
      "Loss  2.294835 C_bot  0.15 k_c 0.0\n",
      "616 Train Loss 16.36262\n",
      "Loss  2.294835 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2918248 C_bot  0.15 k_c 0.0\n",
      "617 Train Loss 16.352135\n",
      "Loss  2.2918248 C_bot  0.15 k_c 0.0\n",
      "Loss  2.288681 C_bot  0.15 k_c 0.0\n",
      "618 Train Loss 16.341534\n",
      "Loss  2.288681 C_bot  0.15 k_c 0.0\n",
      "Loss  2.285536 C_bot  0.15 k_c 0.0\n",
      "619 Train Loss 16.330954\n",
      "Loss  2.285536 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2824137 C_bot  0.15 k_c 0.0\n",
      "620 Train Loss 16.320404\n",
      "Loss  2.2824137 C_bot  0.15 k_c 0.0\n",
      "Loss  2.279253 C_bot  0.15 k_c 0.0\n",
      "621 Train Loss 16.309826\n",
      "Loss  2.279253 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2761557 C_bot  0.15 k_c 0.0\n",
      "622 Train Loss 16.299328\n",
      "Loss  2.2761557 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2729976 C_bot  0.15 k_c 0.0\n",
      "623 Train Loss 16.288792\n",
      "Loss  2.2729976 C_bot  0.15 k_c 0.0\n",
      "Loss  2.269919 C_bot  0.15 k_c 0.0\n",
      "624 Train Loss 16.278347\n",
      "Loss  2.269919 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2668529 C_bot  0.15 k_c 0.0\n",
      "625 Train Loss 16.267925\n",
      "Loss  2.2668529 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2637513 C_bot  0.15 k_c 0.0\n",
      "626 Train Loss 16.257483\n",
      "Loss  2.2637513 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2605686 C_bot  0.15 k_c 0.0\n",
      "627 Train Loss 16.246986\n",
      "Loss  2.2605686 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2575858 C_bot  0.15 k_c 0.0\n",
      "628 Train Loss 16.236698\n",
      "Loss  2.2575858 C_bot  0.15 k_c 0.0\n",
      "Loss  2.254439 C_bot  0.15 k_c 0.0\n",
      "629 Train Loss 16.22626\n",
      "Loss  2.254439 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2513194 C_bot  0.15 k_c 0.0\n",
      "630 Train Loss 16.21587\n",
      "Loss  2.2513194 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2482061 C_bot  0.15 k_c 0.0\n",
      "631 Train Loss 16.20551\n",
      "Loss  2.2482061 C_bot  0.15 k_c 0.0\n",
      "Loss  2.245118 C_bot  0.15 k_c 0.0\n",
      "632 Train Loss 16.195183\n",
      "Loss  2.245118 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2420764 C_bot  0.15 k_c 0.0\n",
      "633 Train Loss 16.184921\n",
      "Loss  2.2420764 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2389295 C_bot  0.15 k_c 0.0\n",
      "634 Train Loss 16.174582\n",
      "Loss  2.2389295 C_bot  0.15 k_c 0.0\n",
      "Loss  2.235817 C_bot  0.15 k_c 0.0\n",
      "635 Train Loss 16.164295\n",
      "Loss  2.235817 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2328017 C_bot  0.15 k_c 0.0\n",
      "636 Train Loss 16.154116\n",
      "Loss  2.2328017 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2297602 C_bot  0.15 k_c 0.0\n",
      "637 Train Loss 16.143929\n",
      "Loss  2.2297602 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2266693 C_bot  0.15 k_c 0.0\n",
      "638 Train Loss 16.133722\n",
      "Loss  2.2266693 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2235503 C_bot  0.15 k_c 0.0\n",
      "639 Train Loss 16.123505\n",
      "Loss  2.2235503 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2205195 C_bot  0.15 k_c 0.0\n",
      "640 Train Loss 16.113396\n",
      "Loss  2.2205195 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2175345 C_bot  0.15 k_c 0.0\n",
      "641 Train Loss 16.103348\n",
      "Loss  2.2175345 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2144592 C_bot  0.15 k_c 0.0\n",
      "642 Train Loss 16.093237\n",
      "Loss  2.2144592 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2113738 C_bot  0.15 k_c 0.0\n",
      "643 Train Loss 16.08314\n",
      "Loss  2.2113738 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2083201 C_bot  0.15 k_c 0.0\n",
      "644 Train Loss 16.07309\n",
      "Loss  2.2083201 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2052953 C_bot  0.15 k_c 0.0\n",
      "645 Train Loss 16.06309\n",
      "Loss  2.2052953 C_bot  0.15 k_c 0.0\n",
      "Loss  2.202065 C_bot  0.15 k_c 0.0\n",
      "646 Train Loss 16.052914\n",
      "Loss  2.202065 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1991632 C_bot  0.15 k_c 0.0\n",
      "647 Train Loss 16.043083\n",
      "Loss  2.1991632 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1960397 C_bot  0.15 k_c 0.0\n",
      "648 Train Loss 16.033054\n",
      "Loss  2.1960397 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1930022 C_bot  0.15 k_c 0.0\n",
      "649 Train Loss 16.023132\n",
      "Loss  2.1930022 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1900399 C_bot  0.15 k_c 0.0\n",
      "650 Train Loss 16.01331\n",
      "Loss  2.1900399 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1869252 C_bot  0.15 k_c 0.0\n",
      "651 Train Loss 16.003359\n",
      "Loss  2.1869252 C_bot  0.15 k_c 0.0\n",
      "Loss  2.183877 C_bot  0.15 k_c 0.0\n",
      "652 Train Loss 15.993494\n",
      "Loss  2.183877 C_bot  0.15 k_c 0.0\n",
      "Loss  2.180838 C_bot  0.15 k_c 0.0\n",
      "653 Train Loss 15.98366\n",
      "Loss  2.180838 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1777709 C_bot  0.15 k_c 0.0\n",
      "654 Train Loss 15.973831\n",
      "Loss  2.1777709 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1748884 C_bot  0.15 k_c 0.0\n",
      "655 Train Loss 15.9642\n",
      "Loss  2.1748884 C_bot  0.15 k_c 0.0\n",
      "Loss  2.171813 C_bot  0.15 k_c 0.0\n",
      "656 Train Loss 15.954399\n",
      "Loss  2.171813 C_bot  0.15 k_c 0.0\n",
      "Loss  2.168778 C_bot  0.15 k_c 0.0\n",
      "657 Train Loss 15.944658\n",
      "Loss  2.168778 C_bot  0.15 k_c 0.0\n",
      "Loss  2.16564 C_bot  0.15 k_c 0.0\n",
      "658 Train Loss 15.93485\n",
      "Loss  2.16564 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1627746 C_bot  0.15 k_c 0.0\n",
      "659 Train Loss 15.92533\n",
      "Loss  2.1627746 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1597192 C_bot  0.15 k_c 0.0\n",
      "660 Train Loss 15.915637\n",
      "Loss  2.1597192 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1566613 C_bot  0.15 k_c 0.0\n",
      "661 Train Loss 15.90597\n",
      "Loss  2.1566613 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1536884 C_bot  0.15 k_c 0.0\n",
      "662 Train Loss 15.896417\n",
      "Loss  2.1536884 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1506953 C_bot  0.15 k_c 0.0\n",
      "663 Train Loss 15.88686\n",
      "Loss  2.1506953 C_bot  0.15 k_c 0.0\n",
      "Loss  2.147608 C_bot  0.15 k_c 0.0\n",
      "664 Train Loss 15.877224\n",
      "Loss  2.147608 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1446552 C_bot  0.15 k_c 0.0\n",
      "665 Train Loss 15.867754\n",
      "Loss  2.1446552 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1416757 C_bot  0.15 k_c 0.0\n",
      "666 Train Loss 15.858286\n",
      "Loss  2.1416757 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1385841 C_bot  0.15 k_c 0.0\n",
      "667 Train Loss 15.848715\n",
      "Loss  2.1385841 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1356828 C_bot  0.15 k_c 0.0\n",
      "668 Train Loss 15.8393545\n",
      "Loss  2.1356828 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1326625 C_bot  0.15 k_c 0.0\n",
      "669 Train Loss 15.82991\n",
      "Loss  2.1326625 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1296751 C_bot  0.15 k_c 0.0\n",
      "670 Train Loss 15.82052\n",
      "Loss  2.1296751 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1266494 C_bot  0.15 k_c 0.0\n",
      "671 Train Loss 15.811101\n",
      "Loss  2.1266494 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1236756 C_bot  0.15 k_c 0.0\n",
      "672 Train Loss 15.80176\n",
      "Loss  2.1236756 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1205368 C_bot  0.15 k_c 0.0\n",
      "673 Train Loss 15.792282\n",
      "Loss  2.1205368 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1176474 C_bot  0.15 k_c 0.0\n",
      "674 Train Loss 15.783075\n",
      "Loss  2.1176474 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1147492 C_bot  0.15 k_c 0.0\n",
      "675 Train Loss 15.773872\n",
      "Loss  2.1147492 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1117213 C_bot  0.15 k_c 0.0\n",
      "676 Train Loss 15.764563\n",
      "Loss  2.1117213 C_bot  0.15 k_c 0.0\n",
      "Loss  2.108587 C_bot  0.15 k_c 0.0\n",
      "677 Train Loss 15.755175\n",
      "Loss  2.108587 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1056533 C_bot  0.15 k_c 0.0\n",
      "678 Train Loss 15.746006\n",
      "Loss  2.1056533 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1027005 C_bot  0.15 k_c 0.0\n",
      "679 Train Loss 15.736836\n",
      "Loss  2.1027005 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0996783 C_bot  0.15 k_c 0.0\n",
      "680 Train Loss 15.727614\n",
      "Loss  2.0996783 C_bot  0.15 k_c 0.0\n",
      "Loss  2.096756 C_bot  0.15 k_c 0.0\n",
      "681 Train Loss 15.71852\n",
      "Loss  2.096756 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0937285 C_bot  0.15 k_c 0.0\n",
      "682 Train Loss 15.709341\n",
      "Loss  2.0937285 C_bot  0.15 k_c 0.0\n",
      "Loss  2.090824 C_bot  0.15 k_c 0.0\n",
      "683 Train Loss 15.700304\n",
      "Loss  2.090824 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0877879 C_bot  0.15 k_c 0.0\n",
      "684 Train Loss 15.691149\n",
      "Loss  2.0877879 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0848536 C_bot  0.15 k_c 0.0\n",
      "685 Train Loss 15.682122\n",
      "Loss  2.0848536 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0818717 C_bot  0.15 k_c 0.0\n",
      "686 Train Loss 15.673073\n",
      "Loss  2.0818717 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0789773 C_bot  0.15 k_c 0.0\n",
      "687 Train Loss 15.66412\n",
      "Loss  2.0789773 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0759757 C_bot  0.15 k_c 0.0\n",
      "688 Train Loss 15.655082\n",
      "Loss  2.0759757 C_bot  0.15 k_c 0.0\n",
      "Loss  2.073042 C_bot  0.15 k_c 0.0\n",
      "689 Train Loss 15.646138\n",
      "Loss  2.073042 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0699627 C_bot  0.15 k_c 0.0\n",
      "690 Train Loss 15.637067\n",
      "Loss  2.0699627 C_bot  0.15 k_c 0.0\n",
      "Loss  2.067057 C_bot  0.15 k_c 0.0\n",
      "691 Train Loss 15.628179\n",
      "Loss  2.067057 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0640855 C_bot  0.15 k_c 0.0\n",
      "692 Train Loss 15.619252\n",
      "Loss  2.0640855 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0610952 C_bot  0.15 k_c 0.0\n",
      "693 Train Loss 15.610326\n",
      "Loss  2.0610952 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0582724 C_bot  0.15 k_c 0.0\n",
      "694 Train Loss 15.601584\n",
      "Loss  2.0582724 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0552053 C_bot  0.15 k_c 0.0\n",
      "695 Train Loss 15.592617\n",
      "Loss  2.0552053 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0522559 C_bot  0.15 k_c 0.0\n",
      "696 Train Loss 15.583784\n",
      "Loss  2.0522559 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0493412 C_bot  0.15 k_c 0.0\n",
      "697 Train Loss 15.57501\n",
      "Loss  2.0493412 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0464368 C_bot  0.15 k_c 0.0\n",
      "698 Train Loss 15.566261\n",
      "Loss  2.0464368 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0434127 C_bot  0.15 k_c 0.0\n",
      "699 Train Loss 15.557409\n",
      "Loss  2.0434127 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0404809 C_bot  0.15 k_c 0.0\n",
      "700 Train Loss 15.548664\n",
      "Loss  2.0404809 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0374954 C_bot  0.15 k_c 0.0\n",
      "701 Train Loss 15.539891\n",
      "Loss  2.0374954 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0344248 C_bot  0.15 k_c 0.0\n",
      "702 Train Loss 15.53105\n",
      "Loss  2.0344248 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0315113 C_bot  0.15 k_c 0.0\n",
      "703 Train Loss 15.522376\n",
      "Loss  2.0315113 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0287116 C_bot  0.15 k_c 0.0\n",
      "704 Train Loss 15.513838\n",
      "Loss  2.0287116 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0256963 C_bot  0.15 k_c 0.0\n",
      "705 Train Loss 15.505106\n",
      "Loss  2.0256963 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0227416 C_bot  0.15 k_c 0.0\n",
      "706 Train Loss 15.496445\n",
      "Loss  2.0227416 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0197902 C_bot  0.15 k_c 0.0\n",
      "707 Train Loss 15.4878025\n",
      "Loss  2.0197902 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0168443 C_bot  0.15 k_c 0.0\n",
      "708 Train Loss 15.479187\n",
      "Loss  2.0168443 C_bot  0.15 k_c 0.0\n",
      "Loss  2.013973 C_bot  0.15 k_c 0.0\n",
      "709 Train Loss 15.470666\n",
      "Loss  2.013973 C_bot  0.15 k_c 0.0\n",
      "Loss  2.010974 C_bot  0.15 k_c 0.0\n",
      "710 Train Loss 15.462027\n",
      "Loss  2.010974 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0081115 C_bot  0.15 k_c 0.0\n",
      "711 Train Loss 15.453542\n",
      "Loss  2.0081115 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0051544 C_bot  0.15 k_c 0.0\n",
      "712 Train Loss 15.444983\n",
      "Loss  2.0051544 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0021799 C_bot  0.15 k_c 0.0\n",
      "713 Train Loss 15.436419\n",
      "Loss  2.0021799 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9992362 C_bot  0.15 k_c 0.0\n",
      "714 Train Loss 15.4279\n",
      "Loss  1.9992362 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9964119 C_bot  0.15 k_c 0.0\n",
      "715 Train Loss 15.4195175\n",
      "Loss  1.9964119 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9934894 C_bot  0.15 k_c 0.0\n",
      "716 Train Loss 15.411055\n",
      "Loss  1.9934894 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9904965 C_bot  0.15 k_c 0.0\n",
      "717 Train Loss 15.402533\n",
      "Loss  1.9904965 C_bot  0.15 k_c 0.0\n",
      "Loss  1.987569 C_bot  0.15 k_c 0.0\n",
      "718 Train Loss 15.394094\n",
      "Loss  1.987569 C_bot  0.15 k_c 0.0\n",
      "Loss  1.984611 C_bot  0.15 k_c 0.0\n",
      "719 Train Loss 15.38564\n",
      "Loss  1.984611 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9817911 C_bot  0.15 k_c 0.0\n",
      "720 Train Loss 15.377341\n",
      "Loss  1.9817911 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9788437 C_bot  0.15 k_c 0.0\n",
      "721 Train Loss 15.368919\n",
      "Loss  1.9788437 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9759324 C_bot  0.15 k_c 0.0\n",
      "722 Train Loss 15.360558\n",
      "Loss  1.9759324 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9729581 C_bot  0.15 k_c 0.0\n",
      "723 Train Loss 15.352149\n",
      "Loss  1.9729581 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9700109 C_bot  0.15 k_c 0.0\n",
      "724 Train Loss 15.343777\n",
      "Loss  1.9700109 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9672544 C_bot  0.15 k_c 0.0\n",
      "725 Train Loss 15.335605\n",
      "Loss  1.9672544 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9642934 C_bot  0.15 k_c 0.0\n",
      "726 Train Loss 15.3272505\n",
      "Loss  1.9642934 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9613755 C_bot  0.15 k_c 0.0\n",
      "727 Train Loss 15.318956\n",
      "Loss  1.9613755 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9585508 C_bot  0.15 k_c 0.0\n",
      "728 Train Loss 15.310757\n",
      "Loss  1.9585508 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9556727 C_bot  0.15 k_c 0.0\n",
      "729 Train Loss 15.302523\n",
      "Loss  1.9556727 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9527252 C_bot  0.15 k_c 0.0\n",
      "730 Train Loss 15.294241\n",
      "Loss  1.9527252 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9498401 C_bot  0.15 k_c 0.0\n",
      "731 Train Loss 15.286027\n",
      "Loss  1.9498401 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9469396 C_bot  0.15 k_c 0.0\n",
      "732 Train Loss 15.277804\n",
      "Loss  1.9469396 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9440808 C_bot  0.15 k_c 0.0\n",
      "733 Train Loss 15.269649\n",
      "Loss  1.9440808 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9411384 C_bot  0.15 k_c 0.0\n",
      "734 Train Loss 15.261419\n",
      "Loss  1.9411384 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9383689 C_bot  0.15 k_c 0.0\n",
      "735 Train Loss 15.253367\n",
      "Loss  1.9383689 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9353114 C_bot  0.15 k_c 0.0\n",
      "736 Train Loss 15.245049\n",
      "Loss  1.9353114 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9324956 C_bot  0.15 k_c 0.0\n",
      "737 Train Loss 15.236983\n",
      "Loss  1.9324956 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9296278 C_bot  0.15 k_c 0.0\n",
      "738 Train Loss 15.228872\n",
      "Loss  1.9296278 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9267507 C_bot  0.15 k_c 0.0\n",
      "739 Train Loss 15.220771\n",
      "Loss  1.9267507 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9237931 C_bot  0.15 k_c 0.0\n",
      "740 Train Loss 15.212603\n",
      "Loss  1.9237931 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9209108 C_bot  0.15 k_c 0.0\n",
      "741 Train Loss 15.204513\n",
      "Loss  1.9209108 C_bot  0.15 k_c 0.0\n",
      "Loss  1.918045 C_bot  0.15 k_c 0.0\n",
      "742 Train Loss 15.196456\n",
      "Loss  1.918045 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9151782 C_bot  0.15 k_c 0.0\n",
      "743 Train Loss 15.188414\n",
      "Loss  1.9151782 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9122688 C_bot  0.15 k_c 0.0\n",
      "744 Train Loss 15.180334\n",
      "Loss  1.9122688 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9095352 C_bot  0.15 k_c 0.0\n",
      "745 Train Loss 15.172442\n",
      "Loss  1.9095352 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9065996 C_bot  0.15 k_c 0.0\n",
      "746 Train Loss 15.164368\n",
      "Loss  1.9065996 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9038025 C_bot  0.15 k_c 0.0\n",
      "747 Train Loss 15.156436\n",
      "Loss  1.9038025 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9007878 C_bot  0.15 k_c 0.0\n",
      "748 Train Loss 15.1482935\n",
      "Loss  1.9007878 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8979963 C_bot  0.15 k_c 0.0\n",
      "749 Train Loss 15.140396\n",
      "Loss  1.8979963 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8951485 C_bot  0.15 k_c 0.0\n",
      "750 Train Loss 15.13245\n",
      "Loss  1.8951485 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8922307 C_bot  0.15 k_c 0.0\n",
      "751 Train Loss 15.124437\n",
      "Loss  1.8922307 C_bot  0.15 k_c 0.0\n",
      "Loss  1.889458 C_bot  0.15 k_c 0.0\n",
      "752 Train Loss 15.116587\n",
      "Loss  1.889458 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8866173 C_bot  0.15 k_c 0.0\n",
      "753 Train Loss 15.108685\n",
      "Loss  1.8866173 C_bot  0.15 k_c 0.0\n",
      "Loss  1.883761 C_bot  0.15 k_c 0.0\n",
      "754 Train Loss 15.10077\n",
      "Loss  1.883761 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8808446 C_bot  0.15 k_c 0.0\n",
      "755 Train Loss 15.092806\n",
      "Loss  1.8808446 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8781357 C_bot  0.15 k_c 0.0\n",
      "756 Train Loss 15.085066\n",
      "Loss  1.8781357 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8752949 C_bot  0.15 k_c 0.0\n",
      "757 Train Loss 15.077198\n",
      "Loss  1.8752949 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8724674 C_bot  0.15 k_c 0.0\n",
      "758 Train Loss 15.069356\n",
      "Loss  1.8724674 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8695853 C_bot  0.15 k_c 0.0\n",
      "759 Train Loss 15.061474\n",
      "Loss  1.8695853 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8668437 C_bot  0.15 k_c 0.0\n",
      "760 Train Loss 15.05374\n",
      "Loss  1.8668437 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8638746 C_bot  0.15 k_c 0.0\n",
      "761 Train Loss 15.045785\n",
      "Loss  1.8638746 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8610795 C_bot  0.15 k_c 0.0\n",
      "762 Train Loss 15.038019\n",
      "Loss  1.8610795 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8582393 C_bot  0.15 k_c 0.0\n",
      "763 Train Loss 15.030219\n",
      "Loss  1.8582393 C_bot  0.15 k_c 0.0\n",
      "Loss  1.855368 C_bot  0.15 k_c 0.0\n",
      "764 Train Loss 15.022394\n",
      "Loss  1.855368 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8525993 C_bot  0.15 k_c 0.0\n",
      "765 Train Loss 15.014687\n",
      "Loss  1.8525993 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8498021 C_bot  0.15 k_c 0.0\n",
      "766 Train Loss 15.006961\n",
      "Loss  1.8498021 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8470023 C_bot  0.15 k_c 0.0\n",
      "767 Train Loss 14.999234\n",
      "Loss  1.8470023 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8441135 C_bot  0.15 k_c 0.0\n",
      "768 Train Loss 14.99144\n",
      "Loss  1.8441135 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8414273 C_bot  0.15 k_c 0.0\n",
      "769 Train Loss 14.983859\n",
      "Loss  1.8414273 C_bot  0.15 k_c 0.0\n",
      "Loss  1.838575 C_bot  0.15 k_c 0.0\n",
      "770 Train Loss 14.9761095\n",
      "Loss  1.838575 C_bot  0.15 k_c 0.0\n",
      "Loss  1.835734 C_bot  0.15 k_c 0.0\n",
      "771 Train Loss 14.968391\n",
      "Loss  1.835734 C_bot  0.15 k_c 0.0\n",
      "Loss  1.832923 C_bot  0.15 k_c 0.0\n",
      "772 Train Loss 14.960718\n",
      "Loss  1.832923 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8301082 C_bot  0.15 k_c 0.0\n",
      "773 Train Loss 14.953039\n",
      "Loss  1.8301082 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8273809 C_bot  0.15 k_c 0.0\n",
      "774 Train Loss 14.945463\n",
      "Loss  1.8273809 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8246106 C_bot  0.15 k_c 0.0\n",
      "775 Train Loss 14.9378605\n",
      "Loss  1.8246106 C_bot  0.15 k_c 0.0\n",
      "Loss  1.821791 C_bot  0.15 k_c 0.0\n",
      "776 Train Loss 14.93021\n",
      "Loss  1.821791 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8190374 C_bot  0.15 k_c 0.0\n",
      "777 Train Loss 14.922637\n",
      "Loss  1.8190374 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8161783 C_bot  0.15 k_c 0.0\n",
      "778 Train Loss 14.914977\n",
      "Loss  1.8161783 C_bot  0.15 k_c 0.0\n",
      "Loss  1.813525 C_bot  0.15 k_c 0.0\n",
      "779 Train Loss 14.907522\n",
      "Loss  1.813525 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8107712 C_bot  0.15 k_c 0.0\n",
      "780 Train Loss 14.8999815\n",
      "Loss  1.8107712 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8078465 C_bot  0.15 k_c 0.0\n",
      "781 Train Loss 14.892288\n",
      "Loss  1.8078465 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8051587 C_bot  0.15 k_c 0.0\n",
      "782 Train Loss 14.884834\n",
      "Loss  1.8051587 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8023617 C_bot  0.15 k_c 0.0\n",
      "783 Train Loss 14.877278\n",
      "Loss  1.8023617 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7995735 C_bot  0.15 k_c 0.0\n",
      "784 Train Loss 14.869753\n",
      "Loss  1.7995735 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7968297 C_bot  0.15 k_c 0.0\n",
      "785 Train Loss 14.862274\n",
      "Loss  1.7968297 C_bot  0.15 k_c 0.0\n",
      "Loss  1.794104 C_bot  0.15 k_c 0.0\n",
      "786 Train Loss 14.854819\n",
      "Loss  1.794104 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7912866 C_bot  0.15 k_c 0.0\n",
      "787 Train Loss 14.847296\n",
      "Loss  1.7912866 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7886231 C_bot  0.15 k_c 0.0\n",
      "788 Train Loss 14.839933\n",
      "Loss  1.7886231 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7858523 C_bot  0.15 k_c 0.0\n",
      "789 Train Loss 14.832462\n",
      "Loss  1.7858523 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7830455 C_bot  0.15 k_c 0.0\n",
      "790 Train Loss 14.824978\n",
      "Loss  1.7830455 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7802805 C_bot  0.15 k_c 0.0\n",
      "791 Train Loss 14.817551\n",
      "Loss  1.7802805 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7774814 C_bot  0.15 k_c 0.0\n",
      "792 Train Loss 14.810086\n",
      "Loss  1.7774814 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7747636 C_bot  0.15 k_c 0.0\n",
      "793 Train Loss 14.802715\n",
      "Loss  1.7747636 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7720604 C_bot  0.15 k_c 0.0\n",
      "794 Train Loss 14.79538\n",
      "Loss  1.7720604 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7693317 C_bot  0.15 k_c 0.0\n",
      "795 Train Loss 14.788024\n",
      "Loss  1.7693317 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7665722 C_bot  0.15 k_c 0.0\n",
      "796 Train Loss 14.780643\n",
      "Loss  1.7665722 C_bot  0.15 k_c 0.0\n",
      "Loss  1.763918 C_bot  0.15 k_c 0.0\n",
      "797 Train Loss 14.773384\n",
      "Loss  1.763918 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7611359 C_bot  0.15 k_c 0.0\n",
      "798 Train Loss 14.766008\n",
      "Loss  1.7611359 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7583517 C_bot  0.15 k_c 0.0\n",
      "799 Train Loss 14.758639\n",
      "Loss  1.7583517 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7557259 C_bot  0.15 k_c 0.0\n",
      "800 Train Loss 14.751439\n",
      "Loss  1.7557259 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7530056 C_bot  0.15 k_c 0.0\n",
      "801 Train Loss 14.744154\n",
      "Loss  1.7530056 C_bot  0.15 k_c 0.0\n",
      "Loss  1.750245 C_bot  0.15 k_c 0.0\n",
      "802 Train Loss 14.73684\n",
      "Loss  1.750245 C_bot  0.15 k_c 0.0\n",
      "Loss  1.747552 C_bot  0.15 k_c 0.0\n",
      "803 Train Loss 14.729608\n",
      "Loss  1.747552 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7447176 C_bot  0.15 k_c 0.0\n",
      "804 Train Loss 14.722243\n",
      "Loss  1.7447176 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7420827 C_bot  0.15 k_c 0.0\n",
      "805 Train Loss 14.715085\n",
      "Loss  1.7420827 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7393794 C_bot  0.15 k_c 0.0\n",
      "806 Train Loss 14.70787\n",
      "Loss  1.7393794 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7367051 C_bot  0.15 k_c 0.0\n",
      "807 Train Loss 14.700699\n",
      "Loss  1.7367051 C_bot  0.15 k_c 0.0\n",
      "Loss  1.733974 C_bot  0.15 k_c 0.0\n",
      "808 Train Loss 14.693478\n",
      "Loss  1.733974 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7312884 C_bot  0.15 k_c 0.0\n",
      "809 Train Loss 14.686314\n",
      "Loss  1.7312884 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7285504 C_bot  0.15 k_c 0.0\n",
      "810 Train Loss 14.6791115\n",
      "Loss  1.7285504 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7258658 C_bot  0.15 k_c 0.0\n",
      "811 Train Loss 14.671969\n",
      "Loss  1.7258658 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7232538 C_bot  0.15 k_c 0.0\n",
      "812 Train Loss 14.664908\n",
      "Loss  1.7232538 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7205554 C_bot  0.15 k_c 0.0\n",
      "813 Train Loss 14.657778\n",
      "Loss  1.7205554 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7177745 C_bot  0.15 k_c 0.0\n",
      "814 Train Loss 14.65057\n",
      "Loss  1.7177745 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7150385 C_bot  0.15 k_c 0.0\n",
      "815 Train Loss 14.64342\n",
      "Loss  1.7150385 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7124835 C_bot  0.15 k_c 0.0\n",
      "816 Train Loss 14.636459\n",
      "Loss  1.7124835 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7097783 C_bot  0.15 k_c 0.0\n",
      "817 Train Loss 14.629363\n",
      "Loss  1.7097783 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7071229 C_bot  0.15 k_c 0.0\n",
      "818 Train Loss 14.622322\n",
      "Loss  1.7071229 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7043736 C_bot  0.15 k_c 0.0\n",
      "819 Train Loss 14.615201\n",
      "Loss  1.7043736 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7018069 C_bot  0.15 k_c 0.0\n",
      "820 Train Loss 14.608274\n",
      "Loss  1.7018069 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6991754 C_bot  0.15 k_c 0.0\n",
      "821 Train Loss 14.601285\n",
      "Loss  1.6991754 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6964675 C_bot  0.15 k_c 0.0\n",
      "822 Train Loss 14.594236\n",
      "Loss  1.6964675 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6936488 C_bot  0.15 k_c 0.0\n",
      "823 Train Loss 14.587091\n",
      "Loss  1.6936488 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6911491 C_bot  0.15 k_c 0.0\n",
      "824 Train Loss 14.580267\n",
      "Loss  1.6911491 C_bot  0.15 k_c 0.0\n",
      "Loss  1.688497 C_bot  0.15 k_c 0.0\n",
      "825 Train Loss 14.573302\n",
      "Loss  1.688497 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6858256 C_bot  0.15 k_c 0.0\n",
      "826 Train Loss 14.5663395\n",
      "Loss  1.6858256 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6832134 C_bot  0.15 k_c 0.0\n",
      "827 Train Loss 14.559436\n",
      "Loss  1.6832134 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6805439 C_bot  0.15 k_c 0.0\n",
      "828 Train Loss 14.55248\n",
      "Loss  1.6805439 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6778518 C_bot  0.15 k_c 0.0\n",
      "829 Train Loss 14.545525\n",
      "Loss  1.6778518 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6752876 C_bot  0.15 k_c 0.0\n",
      "830 Train Loss 14.538702\n",
      "Loss  1.6752876 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6726573 C_bot  0.15 k_c 0.0\n",
      "831 Train Loss 14.531815\n",
      "Loss  1.6726573 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6699677 C_bot  0.15 k_c 0.0\n",
      "832 Train Loss 14.524894\n",
      "Loss  1.6699677 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6673322 C_bot  0.15 k_c 0.0\n",
      "833 Train Loss 14.51803\n",
      "Loss  1.6673322 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6647273 C_bot  0.15 k_c 0.0\n",
      "834 Train Loss 14.511198\n",
      "Loss  1.6647273 C_bot  0.15 k_c 0.0\n",
      "Loss  1.662073 C_bot  0.15 k_c 0.0\n",
      "835 Train Loss 14.504341\n",
      "Loss  1.662073 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6594424 C_bot  0.15 k_c 0.0\n",
      "836 Train Loss 14.497513\n",
      "Loss  1.6594424 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6567976 C_bot  0.15 k_c 0.0\n",
      "837 Train Loss 14.49067\n",
      "Loss  1.6567976 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6541685 C_bot  0.15 k_c 0.0\n",
      "838 Train Loss 14.48387\n",
      "Loss  1.6541685 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6516205 C_bot  0.15 k_c 0.0\n",
      "839 Train Loss 14.477151\n",
      "Loss  1.6516205 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6489995 C_bot  0.15 k_c 0.0\n",
      "840 Train Loss 14.470366\n",
      "Loss  1.6489995 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6463612 C_bot  0.15 k_c 0.0\n",
      "841 Train Loss 14.463578\n",
      "Loss  1.6463612 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6438342 C_bot  0.15 k_c 0.0\n",
      "842 Train Loss 14.456915\n",
      "Loss  1.6438342 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6412094 C_bot  0.15 k_c 0.0\n",
      "843 Train Loss 14.450155\n",
      "Loss  1.6412094 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6386298 C_bot  0.15 k_c 0.0\n",
      "844 Train Loss 14.443454\n",
      "Loss  1.6386298 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6359894 C_bot  0.15 k_c 0.0\n",
      "845 Train Loss 14.436706\n",
      "Loss  1.6359894 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6334251 C_bot  0.15 k_c 0.0\n",
      "846 Train Loss 14.430035\n",
      "Loss  1.6334251 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6308637 C_bot  0.15 k_c 0.0\n",
      "847 Train Loss 14.423379\n",
      "Loss  1.6308637 C_bot  0.15 k_c 0.0\n",
      "Loss  1.628259 C_bot  0.15 k_c 0.0\n",
      "848 Train Loss 14.416698\n",
      "Loss  1.628259 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6256559 C_bot  0.15 k_c 0.0\n",
      "849 Train Loss 14.410013\n",
      "Loss  1.6256559 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6230702 C_bot  0.15 k_c 0.0\n",
      "850 Train Loss 14.40336\n",
      "Loss  1.6230702 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6205157 C_bot  0.15 k_c 0.0\n",
      "851 Train Loss 14.396753\n",
      "Loss  1.6205157 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6178986 C_bot  0.15 k_c 0.0\n",
      "852 Train Loss 14.390087\n",
      "Loss  1.6178986 C_bot  0.15 k_c 0.0\n",
      "Loss  1.615432 C_bot  0.15 k_c 0.0\n",
      "853 Train Loss 14.383575\n",
      "Loss  1.615432 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6128348 C_bot  0.15 k_c 0.0\n",
      "854 Train Loss 14.376955\n",
      "Loss  1.6128348 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6101621 C_bot  0.15 k_c 0.0\n",
      "855 Train Loss 14.37026\n",
      "Loss  1.6101621 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6076528 C_bot  0.15 k_c 0.0\n",
      "856 Train Loss 14.363734\n",
      "Loss  1.6076528 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6051308 C_bot  0.15 k_c 0.0\n",
      "857 Train Loss 14.357212\n",
      "Loss  1.6051308 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6025739 C_bot  0.15 k_c 0.0\n",
      "858 Train Loss 14.350661\n",
      "Loss  1.6025739 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6000229 C_bot  0.15 k_c 0.0\n",
      "859 Train Loss 14.344118\n",
      "Loss  1.6000229 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5975329 C_bot  0.15 k_c 0.0\n",
      "860 Train Loss 14.337652\n",
      "Loss  1.5975329 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5950012 C_bot  0.15 k_c 0.0\n",
      "861 Train Loss 14.331152\n",
      "Loss  1.5950012 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5923873 C_bot  0.15 k_c 0.0\n",
      "862 Train Loss 14.32457\n",
      "Loss  1.5923873 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5898834 C_bot  0.15 k_c 0.0\n",
      "863 Train Loss 14.318111\n",
      "Loss  1.5898834 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5873858 C_bot  0.15 k_c 0.0\n",
      "864 Train Loss 14.311678\n",
      "Loss  1.5873858 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5847901 C_bot  0.15 k_c 0.0\n",
      "865 Train Loss 14.305134\n",
      "Loss  1.5847901 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5823194 C_bot  0.15 k_c 0.0\n",
      "866 Train Loss 14.298729\n",
      "Loss  1.5823194 C_bot  0.15 k_c 0.0\n",
      "Loss  1.579751 C_bot  0.15 k_c 0.0\n",
      "867 Train Loss 14.29225\n",
      "Loss  1.579751 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5772125 C_bot  0.15 k_c 0.0\n",
      "868 Train Loss 14.2857895\n",
      "Loss  1.5772125 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5747149 C_bot  0.15 k_c 0.0\n",
      "869 Train Loss 14.279379\n",
      "Loss  1.5747149 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5721805 C_bot  0.15 k_c 0.0\n",
      "870 Train Loss 14.272952\n",
      "Loss  1.5721805 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5697376 C_bot  0.15 k_c 0.0\n",
      "871 Train Loss 14.266616\n",
      "Loss  1.5697376 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5672251 C_bot  0.15 k_c 0.0\n",
      "872 Train Loss 14.26021\n",
      "Loss  1.5672251 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5647254 C_bot  0.15 k_c 0.0\n",
      "873 Train Loss 14.2538395\n",
      "Loss  1.5647254 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5621648 C_bot  0.15 k_c 0.0\n",
      "874 Train Loss 14.247412\n",
      "Loss  1.5621648 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5596722 C_bot  0.15 k_c 0.0\n",
      "875 Train Loss 14.241047\n",
      "Loss  1.5596722 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5572451 C_bot  0.15 k_c 0.0\n",
      "876 Train Loss 14.234764\n",
      "Loss  1.5572451 C_bot  0.15 k_c 0.0\n",
      "Loss  1.554703 C_bot  0.15 k_c 0.0\n",
      "877 Train Loss 14.22838\n",
      "Loss  1.554703 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5522987 C_bot  0.15 k_c 0.0\n",
      "878 Train Loss 14.222124\n",
      "Loss  1.5522987 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5497352 C_bot  0.15 k_c 0.0\n",
      "879 Train Loss 14.215725\n",
      "Loss  1.5497352 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5473007 C_bot  0.15 k_c 0.0\n",
      "880 Train Loss 14.209467\n",
      "Loss  1.5473007 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5448335 C_bot  0.15 k_c 0.0\n",
      "881 Train Loss 14.203176\n",
      "Loss  1.5448335 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5422872 C_bot  0.15 k_c 0.0\n",
      "882 Train Loss 14.196812\n",
      "Loss  1.5422872 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5398005 C_bot  0.15 k_c 0.0\n",
      "883 Train Loss 14.190519\n",
      "Loss  1.5398005 C_bot  0.15 k_c 0.0\n",
      "Loss  1.537463 C_bot  0.15 k_c 0.0\n",
      "884 Train Loss 14.18438\n",
      "Loss  1.537463 C_bot  0.15 k_c 0.0\n",
      "Loss  1.534994 C_bot  0.15 k_c 0.0\n",
      "885 Train Loss 14.17811\n",
      "Loss  1.534994 C_bot  0.15 k_c 0.0\n",
      "Loss  1.532492 C_bot  0.15 k_c 0.0\n",
      "886 Train Loss 14.171823\n",
      "Loss  1.532492 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5300059 C_bot  0.15 k_c 0.0\n",
      "887 Train Loss 14.165553\n",
      "Loss  1.5300059 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5275772 C_bot  0.15 k_c 0.0\n",
      "888 Train Loss 14.159348\n",
      "Loss  1.5275772 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5251178 C_bot  0.15 k_c 0.0\n",
      "889 Train Loss 14.153116\n",
      "Loss  1.5251178 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5226637 C_bot  0.15 k_c 0.0\n",
      "890 Train Loss 14.146902\n",
      "Loss  1.5226637 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5202324 C_bot  0.15 k_c 0.0\n",
      "891 Train Loss 14.140714\n",
      "Loss  1.5202324 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5178387 C_bot  0.15 k_c 0.0\n",
      "892 Train Loss 14.134563\n",
      "Loss  1.5178387 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5153642 C_bot  0.15 k_c 0.0\n",
      "893 Train Loss 14.1283455\n",
      "Loss  1.5153642 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5129182 C_bot  0.15 k_c 0.0\n",
      "894 Train Loss 14.122162\n",
      "Loss  1.5129182 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5105101 C_bot  0.15 k_c 0.0\n",
      "895 Train Loss 14.11602\n",
      "Loss  1.5105101 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5081244 C_bot  0.15 k_c 0.0\n",
      "896 Train Loss 14.109907\n",
      "Loss  1.5081244 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5056432 C_bot  0.15 k_c 0.0\n",
      "897 Train Loss 14.103709\n",
      "Loss  1.5056432 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5032653 C_bot  0.15 k_c 0.0\n",
      "898 Train Loss 14.097618\n",
      "Loss  1.5032653 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5008014 C_bot  0.15 k_c 0.0\n",
      "899 Train Loss 14.091444\n",
      "Loss  1.5008014 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4983745 C_bot  0.15 k_c 0.0\n",
      "900 Train Loss 14.085317\n",
      "Loss  1.4983745 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4959111 C_bot  0.15 k_c 0.0\n",
      "901 Train Loss 14.079161\n",
      "Loss  1.4959111 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4935516 C_bot  0.15 k_c 0.0\n",
      "902 Train Loss 14.073111\n",
      "Loss  1.4935516 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4912109 C_bot  0.15 k_c 0.0\n",
      "903 Train Loss 14.067087\n",
      "Loss  1.4912109 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4887922 C_bot  0.15 k_c 0.0\n",
      "904 Train Loss 14.060993\n",
      "Loss  1.4887922 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4863764 C_bot  0.15 k_c 0.0\n",
      "905 Train Loss 14.054908\n",
      "Loss  1.4863764 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4839303 C_bot  0.15 k_c 0.0\n",
      "906 Train Loss 14.048797\n",
      "Loss  1.4839303 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4814944 C_bot  0.15 k_c 0.0\n",
      "907 Train Loss 14.042706\n",
      "Loss  1.4814944 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4792275 C_bot  0.15 k_c 0.0\n",
      "908 Train Loss 14.036789\n",
      "Loss  1.4792275 C_bot  0.15 k_c 0.0\n",
      "Loss  1.476797 C_bot  0.15 k_c 0.0\n",
      "909 Train Loss 14.030713\n",
      "Loss  1.476797 C_bot  0.15 k_c 0.0\n",
      "Loss  1.474363 C_bot  0.15 k_c 0.0\n",
      "910 Train Loss 14.024645\n",
      "Loss  1.474363 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4719732 C_bot  0.15 k_c 0.0\n",
      "911 Train Loss 14.018622\n",
      "Loss  1.4719732 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4696007 C_bot  0.15 k_c 0.0\n",
      "912 Train Loss 14.012625\n",
      "Loss  1.4696007 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4672438 C_bot  0.15 k_c 0.0\n",
      "913 Train Loss 14.006653\n",
      "Loss  1.4672438 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4649175 C_bot  0.15 k_c 0.0\n",
      "914 Train Loss 14.000711\n",
      "Loss  1.4649175 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4625069 C_bot  0.15 k_c 0.0\n",
      "915 Train Loss 13.9946995\n",
      "Loss  1.4625069 C_bot  0.15 k_c 0.0\n",
      "Loss  1.460122 C_bot  0.15 k_c 0.0\n",
      "916 Train Loss 13.98872\n",
      "Loss  1.460122 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4578624 C_bot  0.15 k_c 0.0\n",
      "917 Train Loss 13.982868\n",
      "Loss  1.4578624 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4554513 C_bot  0.15 k_c 0.0\n",
      "918 Train Loss 13.976872\n",
      "Loss  1.4554513 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4530842 C_bot  0.15 k_c 0.0\n",
      "919 Train Loss 13.970932\n",
      "Loss  1.4530842 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4506389 C_bot  0.15 k_c 0.0\n",
      "920 Train Loss 13.964916\n",
      "Loss  1.4506389 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4483457 C_bot  0.15 k_c 0.0\n",
      "921 Train Loss 13.959059\n",
      "Loss  1.4483457 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4460775 C_bot  0.15 k_c 0.0\n",
      "922 Train Loss 13.953239\n",
      "Loss  1.4460775 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4436955 C_bot  0.15 k_c 0.0\n",
      "923 Train Loss 13.9473095\n",
      "Loss  1.4436955 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4413046 C_bot  0.15 k_c 0.0\n",
      "924 Train Loss 13.941376\n",
      "Loss  1.4413046 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4390528 C_bot  0.15 k_c 0.0\n",
      "925 Train Loss 13.935595\n",
      "Loss  1.4390528 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4365703 C_bot  0.15 k_c 0.0\n",
      "926 Train Loss 13.929583\n",
      "Loss  1.4365703 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4343697 C_bot  0.15 k_c 0.0\n",
      "927 Train Loss 13.923862\n",
      "Loss  1.4343697 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4319587 C_bot  0.15 k_c 0.0\n",
      "928 Train Loss 13.917946\n",
      "Loss  1.4319587 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4296542 C_bot  0.15 k_c 0.0\n",
      "929 Train Loss 13.912136\n",
      "Loss  1.4296542 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4273796 C_bot  0.15 k_c 0.0\n",
      "930 Train Loss 13.906366\n",
      "Loss  1.4273796 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4250551 C_bot  0.15 k_c 0.0\n",
      "931 Train Loss 13.900554\n",
      "Loss  1.4250551 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4226761 C_bot  0.15 k_c 0.0\n",
      "932 Train Loss 13.894695\n",
      "Loss  1.4226761 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4203498 C_bot  0.15 k_c 0.0\n",
      "933 Train Loss 13.888896\n",
      "Loss  1.4203498 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4180255 C_bot  0.15 k_c 0.0\n",
      "934 Train Loss 13.88311\n",
      "Loss  1.4180255 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4157923 C_bot  0.15 k_c 0.0\n",
      "935 Train Loss 13.8774185\n",
      "Loss  1.4157923 C_bot  0.15 k_c 0.0\n",
      "Loss  1.41341 C_bot  0.15 k_c 0.0\n",
      "936 Train Loss 13.871588\n",
      "Loss  1.41341 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4111512 C_bot  0.15 k_c 0.0\n",
      "937 Train Loss 13.865892\n",
      "Loss  1.4111512 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4088616 C_bot  0.15 k_c 0.0\n",
      "938 Train Loss 13.860165\n",
      "Loss  1.4088616 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4066001 C_bot  0.15 k_c 0.0\n",
      "939 Train Loss 13.854483\n",
      "Loss  1.4066001 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4042401 C_bot  0.15 k_c 0.0\n",
      "940 Train Loss 13.848707\n",
      "Loss  1.4042401 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4020492 C_bot  0.15 k_c 0.0\n",
      "941 Train Loss 13.843098\n",
      "Loss  1.4020492 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3997141 C_bot  0.15 k_c 0.0\n",
      "942 Train Loss 13.837371\n",
      "Loss  1.3997141 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3974121 C_bot  0.15 k_c 0.0\n",
      "943 Train Loss 13.831678\n",
      "Loss  1.3974121 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3951218 C_bot  0.15 k_c 0.0\n",
      "944 Train Loss 13.825992\n",
      "Loss  1.3951218 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3928515 C_bot  0.15 k_c 0.0\n",
      "945 Train Loss 13.820354\n",
      "Loss  1.3928515 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3905166 C_bot  0.15 k_c 0.0\n",
      "946 Train Loss 13.814653\n",
      "Loss  1.3905166 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3883029 C_bot  0.15 k_c 0.0\n",
      "947 Train Loss 13.809067\n",
      "Loss  1.3883029 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3860719 C_bot  0.15 k_c 0.0\n",
      "948 Train Loss 13.803493\n",
      "Loss  1.3860719 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3837907 C_bot  0.15 k_c 0.0\n",
      "949 Train Loss 13.79787\n",
      "Loss  1.3837907 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3815451 C_bot  0.15 k_c 0.0\n",
      "950 Train Loss 13.792273\n",
      "Loss  1.3815451 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3792235 C_bot  0.15 k_c 0.0\n",
      "951 Train Loss 13.786636\n",
      "Loss  1.3792235 C_bot  0.15 k_c 0.0\n",
      "Loss  1.376987 C_bot  0.15 k_c 0.0\n",
      "952 Train Loss 13.781077\n",
      "Loss  1.376987 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3747077 C_bot  0.15 k_c 0.0\n",
      "953 Train Loss 13.775476\n",
      "Loss  1.3747077 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3724829 C_bot  0.15 k_c 0.0\n",
      "954 Train Loss 13.769954\n",
      "Loss  1.3724829 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3702074 C_bot  0.15 k_c 0.0\n",
      "955 Train Loss 13.764383\n",
      "Loss  1.3702074 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3679955 C_bot  0.15 k_c 0.0\n",
      "956 Train Loss 13.758869\n",
      "Loss  1.3679955 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3657265 C_bot  0.15 k_c 0.0\n",
      "957 Train Loss 13.753331\n",
      "Loss  1.3657265 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3635409 C_bot  0.15 k_c 0.0\n",
      "958 Train Loss 13.747873\n",
      "Loss  1.3635409 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3613229 C_bot  0.15 k_c 0.0\n",
      "959 Train Loss 13.742376\n",
      "Loss  1.3613229 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3590914 C_bot  0.15 k_c 0.0\n",
      "960 Train Loss 13.736898\n",
      "Loss  1.3590914 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3568769 C_bot  0.15 k_c 0.0\n",
      "961 Train Loss 13.731434\n",
      "Loss  1.3568769 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3547285 C_bot  0.15 k_c 0.0\n",
      "962 Train Loss 13.726028\n",
      "Loss  1.3547285 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3524065 C_bot  0.15 k_c 0.0\n",
      "963 Train Loss 13.720488\n",
      "Loss  1.3524065 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3501395 C_bot  0.15 k_c 0.0\n",
      "964 Train Loss 13.714991\n",
      "Loss  1.3501395 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3479816 C_bot  0.15 k_c 0.0\n",
      "965 Train Loss 13.709594\n",
      "Loss  1.3479816 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3456783 C_bot  0.15 k_c 0.0\n",
      "966 Train Loss 13.704101\n",
      "Loss  1.3456783 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3434925 C_bot  0.15 k_c 0.0\n",
      "967 Train Loss 13.698704\n",
      "Loss  1.3434925 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3413436 C_bot  0.15 k_c 0.0\n",
      "968 Train Loss 13.69334\n",
      "Loss  1.3413436 C_bot  0.15 k_c 0.0\n",
      "Loss  1.339166 C_bot  0.15 k_c 0.0\n",
      "969 Train Loss 13.687996\n",
      "Loss  1.339166 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3369857 C_bot  0.15 k_c 0.0\n",
      "970 Train Loss 13.68262\n",
      "Loss  1.3369857 C_bot  0.15 k_c 0.0\n",
      "Loss  1.334766 C_bot  0.15 k_c 0.0\n",
      "971 Train Loss 13.677216\n",
      "Loss  1.334766 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3325129 C_bot  0.15 k_c 0.0\n",
      "972 Train Loss 13.671811\n",
      "Loss  1.3325129 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3303972 C_bot  0.15 k_c 0.0\n",
      "973 Train Loss 13.666521\n",
      "Loss  1.3303972 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3282224 C_bot  0.15 k_c 0.0\n",
      "974 Train Loss 13.661186\n",
      "Loss  1.3282224 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3259857 C_bot  0.15 k_c 0.0\n",
      "975 Train Loss 13.655816\n",
      "Loss  1.3259857 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3238612 C_bot  0.15 k_c 0.0\n",
      "976 Train Loss 13.650538\n",
      "Loss  1.3238612 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3216519 C_bot  0.15 k_c 0.0\n",
      "977 Train Loss 13.645192\n",
      "Loss  1.3216519 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3194435 C_bot  0.15 k_c 0.0\n",
      "978 Train Loss 13.639869\n",
      "Loss  1.3194435 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3173765 C_bot  0.15 k_c 0.0\n",
      "979 Train Loss 13.634668\n",
      "Loss  1.3173765 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3152066 C_bot  0.15 k_c 0.0\n",
      "980 Train Loss 13.629381\n",
      "Loss  1.3152066 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3130172 C_bot  0.15 k_c 0.0\n",
      "981 Train Loss 13.6241\n",
      "Loss  1.3130172 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3108262 C_bot  0.15 k_c 0.0\n",
      "982 Train Loss 13.61879\n",
      "Loss  1.3108262 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3087047 C_bot  0.15 k_c 0.0\n",
      "983 Train Loss 13.613579\n",
      "Loss  1.3087047 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3065346 C_bot  0.15 k_c 0.0\n",
      "984 Train Loss 13.60833\n",
      "Loss  1.3065346 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3043319 C_bot  0.15 k_c 0.0\n",
      "985 Train Loss 13.603031\n",
      "Loss  1.3043319 C_bot  0.15 k_c 0.0\n",
      "Loss  1.30228 C_bot  0.15 k_c 0.0\n",
      "986 Train Loss 13.597912\n",
      "Loss  1.30228 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3001035 C_bot  0.15 k_c 0.0\n",
      "987 Train Loss 13.5926695\n",
      "Loss  1.3001035 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2980547 C_bot  0.15 k_c 0.0\n",
      "988 Train Loss 13.587547\n",
      "Loss  1.2980547 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2957786 C_bot  0.15 k_c 0.0\n",
      "989 Train Loss 13.582222\n",
      "Loss  1.2957786 C_bot  0.15 k_c 0.0\n",
      "Loss  1.293732 C_bot  0.15 k_c 0.0\n",
      "990 Train Loss 13.577125\n",
      "Loss  1.293732 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2916548 C_bot  0.15 k_c 0.0\n",
      "991 Train Loss 13.571995\n",
      "Loss  1.2916548 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2894728 C_bot  0.15 k_c 0.0\n",
      "992 Train Loss 13.566783\n",
      "Loss  1.2894728 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2873802 C_bot  0.15 k_c 0.0\n",
      "993 Train Loss 13.561657\n",
      "Loss  1.2873802 C_bot  0.15 k_c 0.0\n",
      "Loss  1.285187 C_bot  0.15 k_c 0.0\n",
      "994 Train Loss 13.556429\n",
      "Loss  1.285187 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2831374 C_bot  0.15 k_c 0.0\n",
      "995 Train Loss 13.551367\n",
      "Loss  1.2831374 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2809917 C_bot  0.15 k_c 0.0\n",
      "996 Train Loss 13.5462055\n",
      "Loss  1.2809917 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2789469 C_bot  0.15 k_c 0.0\n",
      "997 Train Loss 13.541145\n",
      "Loss  1.2789469 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2768272 C_bot  0.15 k_c 0.0\n",
      "998 Train Loss 13.536033\n",
      "Loss  1.2768272 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2748065 C_bot  0.15 k_c 0.0\n",
      "999 Train Loss 13.53101\n",
      "Loss  1.2748065 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2726665 C_bot  0.15 k_c 0.0\n",
      "1000 Train Loss 13.525877\n",
      "Loss  1.2726665 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2705821 C_bot  0.15 k_c 0.0\n",
      "1001 Train Loss 13.520811\n",
      "Loss  1.2705821 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2684364 C_bot  0.15 k_c 0.0\n",
      "1002 Train Loss 13.51568\n",
      "Loss  1.2684364 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2663676 C_bot  0.15 k_c 0.0\n",
      "1003 Train Loss 13.51064\n",
      "Loss  1.2663676 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2642916 C_bot  0.15 k_c 0.0\n",
      "1004 Train Loss 13.505596\n",
      "Loss  1.2642916 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2621955 C_bot  0.15 k_c 0.0\n",
      "1005 Train Loss 13.500534\n",
      "Loss  1.2621955 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2601348 C_bot  0.15 k_c 0.0\n",
      "1006 Train Loss 13.495516\n",
      "Loss  1.2601348 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2580173 C_bot  0.15 k_c 0.0\n",
      "1007 Train Loss 13.490448\n",
      "Loss  1.2580173 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2559762 C_bot  0.15 k_c 0.0\n",
      "1008 Train Loss 13.485455\n",
      "Loss  1.2559762 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2538929 C_bot  0.15 k_c 0.0\n",
      "1009 Train Loss 13.4804325\n",
      "Loss  1.2538929 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2518699 C_bot  0.15 k_c 0.0\n",
      "1010 Train Loss 13.475474\n",
      "Loss  1.2518699 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2498301 C_bot  0.15 k_c 0.0\n",
      "1011 Train Loss 13.470501\n",
      "Loss  1.2498301 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2477424 C_bot  0.15 k_c 0.0\n",
      "1012 Train Loss 13.465488\n",
      "Loss  1.2477424 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2457165 C_bot  0.15 k_c 0.0\n",
      "1013 Train Loss 13.4605465\n",
      "Loss  1.2457165 C_bot  0.15 k_c 0.0\n",
      "Loss  1.243662 C_bot  0.15 k_c 0.0\n",
      "1014 Train Loss 13.45557\n",
      "Loss  1.243662 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2415805 C_bot  0.15 k_c 0.0\n",
      "1015 Train Loss 13.450582\n",
      "Loss  1.2415805 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2396278 C_bot  0.15 k_c 0.0\n",
      "1016 Train Loss 13.445723\n",
      "Loss  1.2396278 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2375478 C_bot  0.15 k_c 0.0\n",
      "1017 Train Loss 13.440744\n",
      "Loss  1.2375478 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2355528 C_bot  0.15 k_c 0.0\n",
      "1018 Train Loss 13.435852\n",
      "Loss  1.2355528 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2334715 C_bot  0.15 k_c 0.0\n",
      "1019 Train Loss 13.430886\n",
      "Loss  1.2334715 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2314326 C_bot  0.15 k_c 0.0\n",
      "1020 Train Loss 13.425961\n",
      "Loss  1.2314326 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2294354 C_bot  0.15 k_c 0.0\n",
      "1021 Train Loss 13.421081\n",
      "Loss  1.2294354 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2274094 C_bot  0.15 k_c 0.0\n",
      "1022 Train Loss 13.416187\n",
      "Loss  1.2274094 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2254206 C_bot  0.15 k_c 0.0\n",
      "1023 Train Loss 13.411325\n",
      "Loss  1.2254206 C_bot  0.15 k_c 0.0\n",
      "Loss  1.223382 C_bot  0.15 k_c 0.0\n",
      "1024 Train Loss 13.406418\n",
      "Loss  1.223382 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2212974 C_bot  0.15 k_c 0.0\n",
      "1025 Train Loss 13.401482\n",
      "Loss  1.2212974 C_bot  0.15 k_c 0.0\n",
      "Loss  1.21931 C_bot  0.15 k_c 0.0\n",
      "1026 Train Loss 13.396637\n",
      "Loss  1.21931 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2173175 C_bot  0.15 k_c 0.0\n",
      "1027 Train Loss 13.391793\n",
      "Loss  1.2173175 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2153534 C_bot  0.15 k_c 0.0\n",
      "1028 Train Loss 13.38699\n",
      "Loss  1.2153534 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2134595 C_bot  0.15 k_c 0.0\n",
      "1029 Train Loss 13.382248\n",
      "Loss  1.2134595 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2113563 C_bot  0.15 k_c 0.0\n",
      "1030 Train Loss 13.377312\n",
      "Loss  1.2113563 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2094094 C_bot  0.15 k_c 0.0\n",
      "1031 Train Loss 13.3725395\n",
      "Loss  1.2094094 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2073133 C_bot  0.15 k_c 0.0\n",
      "1032 Train Loss 13.367614\n",
      "Loss  1.2073133 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2054015 C_bot  0.15 k_c 0.0\n",
      "1033 Train Loss 13.362881\n",
      "Loss  1.2054015 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2034103 C_bot  0.15 k_c 0.0\n",
      "1034 Train Loss 13.358082\n",
      "Loss  1.2034103 C_bot  0.15 k_c 0.0\n",
      "Loss  1.201442 C_bot  0.15 k_c 0.0\n",
      "1035 Train Loss 13.353291\n",
      "Loss  1.201442 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1994938 C_bot  0.15 k_c 0.0\n",
      "1036 Train Loss 13.348543\n",
      "Loss  1.1994938 C_bot  0.15 k_c 0.0\n",
      "Loss  1.19748 C_bot  0.15 k_c 0.0\n",
      "1037 Train Loss 13.343731\n",
      "Loss  1.19748 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1955901 C_bot  0.15 k_c 0.0\n",
      "1038 Train Loss 13.339031\n",
      "Loss  1.1955901 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1935676 C_bot  0.15 k_c 0.0\n",
      "1039 Train Loss 13.33423\n",
      "Loss  1.1935676 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1915694 C_bot  0.15 k_c 0.0\n",
      "1040 Train Loss 13.329444\n",
      "Loss  1.1915694 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1897008 C_bot  0.15 k_c 0.0\n",
      "1041 Train Loss 13.324781\n",
      "Loss  1.1897008 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1876593 C_bot  0.15 k_c 0.0\n",
      "1042 Train Loss 13.319974\n",
      "Loss  1.1876593 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1857197 C_bot  0.15 k_c 0.0\n",
      "1043 Train Loss 13.315256\n",
      "Loss  1.1857197 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1837822 C_bot  0.15 k_c 0.0\n",
      "1044 Train Loss 13.310545\n",
      "Loss  1.1837822 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1818817 C_bot  0.15 k_c 0.0\n",
      "1045 Train Loss 13.305892\n",
      "Loss  1.1818817 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1799582 C_bot  0.15 k_c 0.0\n",
      "1046 Train Loss 13.301201\n",
      "Loss  1.1799582 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1779848 C_bot  0.15 k_c 0.0\n",
      "1047 Train Loss 13.296474\n",
      "Loss  1.1779848 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1759382 C_bot  0.15 k_c 0.0\n",
      "1048 Train Loss 13.291681\n",
      "Loss  1.1759382 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1741155 C_bot  0.15 k_c 0.0\n",
      "1049 Train Loss 13.287106\n",
      "Loss  1.1741155 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1720992 C_bot  0.15 k_c 0.0\n",
      "1050 Train Loss 13.282354\n",
      "Loss  1.1720992 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1702362 C_bot  0.15 k_c 0.0\n",
      "1051 Train Loss 13.277757\n",
      "Loss  1.1702362 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1683215 C_bot  0.15 k_c 0.0\n",
      "1052 Train Loss 13.273104\n",
      "Loss  1.1683215 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1663648 C_bot  0.15 k_c 0.0\n",
      "1053 Train Loss 13.268427\n",
      "Loss  1.1663648 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1645234 C_bot  0.15 k_c 0.0\n",
      "1054 Train Loss 13.263861\n",
      "Loss  1.1645234 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1625824 C_bot  0.15 k_c 0.0\n",
      "1055 Train Loss 13.259197\n",
      "Loss  1.1625824 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1606373 C_bot  0.15 k_c 0.0\n",
      "1056 Train Loss 13.254549\n",
      "Loss  1.1606373 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1587621 C_bot  0.15 k_c 0.0\n",
      "1057 Train Loss 13.249956\n",
      "Loss  1.1587621 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1568525 C_bot  0.15 k_c 0.0\n",
      "1058 Train Loss 13.245344\n",
      "Loss  1.1568525 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1549299 C_bot  0.15 k_c 0.0\n",
      "1059 Train Loss 13.240727\n",
      "Loss  1.1549299 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1529363 C_bot  0.15 k_c 0.0\n",
      "1060 Train Loss 13.236033\n",
      "Loss  1.1529363 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1510793 C_bot  0.15 k_c 0.0\n",
      "1061 Train Loss 13.231488\n",
      "Loss  1.1510793 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1491915 C_bot  0.15 k_c 0.0\n",
      "1062 Train Loss 13.226915\n",
      "Loss  1.1491915 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1473215 C_bot  0.15 k_c 0.0\n",
      "1063 Train Loss 13.22236\n",
      "Loss  1.1473215 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1454145 C_bot  0.15 k_c 0.0\n",
      "1064 Train Loss 13.217781\n",
      "Loss  1.1454145 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1435577 C_bot  0.15 k_c 0.0\n",
      "1065 Train Loss 13.213251\n",
      "Loss  1.1435577 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1416612 C_bot  0.15 k_c 0.0\n",
      "1066 Train Loss 13.208685\n",
      "Loss  1.1416612 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1398313 C_bot  0.15 k_c 0.0\n",
      "1067 Train Loss 13.204194\n",
      "Loss  1.1398313 C_bot  0.15 k_c 0.0\n",
      "Loss  1.137963 C_bot  0.15 k_c 0.0\n",
      "1068 Train Loss 13.199668\n",
      "Loss  1.137963 C_bot  0.15 k_c 0.0\n",
      "Loss  1.136088 C_bot  0.15 k_c 0.0\n",
      "1069 Train Loss 13.195135\n",
      "Loss  1.136088 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1342046 C_bot  0.15 k_c 0.0\n",
      "1070 Train Loss 13.190605\n",
      "Loss  1.1342046 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1323067 C_bot  0.15 k_c 0.0\n",
      "1071 Train Loss 13.186062\n",
      "Loss  1.1323067 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1304573 C_bot  0.15 k_c 0.0\n",
      "1072 Train Loss 13.181571\n",
      "Loss  1.1304573 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1285499 C_bot  0.15 k_c 0.0\n",
      "1073 Train Loss 13.177029\n",
      "Loss  1.1285499 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1266518 C_bot  0.15 k_c 0.0\n",
      "1074 Train Loss 13.172501\n",
      "Loss  1.1266518 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1248618 C_bot  0.15 k_c 0.0\n",
      "1075 Train Loss 13.168083\n",
      "Loss  1.1248618 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1229991 C_bot  0.15 k_c 0.0\n",
      "1076 Train Loss 13.163597\n",
      "Loss  1.1229991 C_bot  0.15 k_c 0.0\n",
      "Loss  1.121151 C_bot  0.15 k_c 0.0\n",
      "1077 Train Loss 13.159132\n",
      "Loss  1.121151 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1193483 C_bot  0.15 k_c 0.0\n",
      "1078 Train Loss 13.154718\n",
      "Loss  1.1193483 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1174229 C_bot  0.15 k_c 0.0\n",
      "1079 Train Loss 13.150181\n",
      "Loss  1.1174229 C_bot  0.15 k_c 0.0\n",
      "Loss  1.115601 C_bot  0.15 k_c 0.0\n",
      "1080 Train Loss 13.145759\n",
      "Loss  1.115601 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1138157 C_bot  0.15 k_c 0.0\n",
      "1081 Train Loss 13.141373\n",
      "Loss  1.1138157 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1118969 C_bot  0.15 k_c 0.0\n",
      "1082 Train Loss 13.136858\n",
      "Loss  1.1118969 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1100565 C_bot  0.15 k_c 0.0\n",
      "1083 Train Loss 13.132427\n",
      "Loss  1.1100565 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1082845 C_bot  0.15 k_c 0.0\n",
      "1084 Train Loss 13.128072\n",
      "Loss  1.1082845 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1064576 C_bot  0.15 k_c 0.0\n",
      "1085 Train Loss 13.123663\n",
      "Loss  1.1064576 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1046823 C_bot  0.15 k_c 0.0\n",
      "1086 Train Loss 13.11931\n",
      "Loss  1.1046823 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1027821 C_bot  0.15 k_c 0.0\n",
      "1087 Train Loss 13.114845\n",
      "Loss  1.1027821 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1009766 C_bot  0.15 k_c 0.0\n",
      "1088 Train Loss 13.110464\n",
      "Loss  1.1009766 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0990916 C_bot  0.15 k_c 0.0\n",
      "1089 Train Loss 13.106018\n",
      "Loss  1.0990916 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0973132 C_bot  0.15 k_c 0.0\n",
      "1090 Train Loss 13.101686\n",
      "Loss  1.0973132 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0955375 C_bot  0.15 k_c 0.0\n",
      "1091 Train Loss 13.09735\n",
      "Loss  1.0955375 C_bot  0.15 k_c 0.0\n",
      "Loss  1.093709 C_bot  0.15 k_c 0.0\n",
      "1092 Train Loss 13.092978\n",
      "Loss  1.093709 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0918785 C_bot  0.15 k_c 0.0\n",
      "1093 Train Loss 13.088603\n",
      "Loss  1.0918785 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0900879 C_bot  0.15 k_c 0.0\n",
      "1094 Train Loss 13.08427\n",
      "Loss  1.0900879 C_bot  0.15 k_c 0.0\n",
      "Loss  1.08828 C_bot  0.15 k_c 0.0\n",
      "1095 Train Loss 13.079931\n",
      "Loss  1.08828 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0864741 C_bot  0.15 k_c 0.0\n",
      "1096 Train Loss 13.075588\n",
      "Loss  1.0864741 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0846317 C_bot  0.15 k_c 0.0\n",
      "1097 Train Loss 13.071224\n",
      "Loss  1.0846317 C_bot  0.15 k_c 0.0\n",
      "Loss  1.082885 C_bot  0.15 k_c 0.0\n",
      "1098 Train Loss 13.066957\n",
      "Loss  1.082885 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0810707 C_bot  0.15 k_c 0.0\n",
      "1099 Train Loss 13.062622\n",
      "Loss  1.0810707 C_bot  0.15 k_c 0.0\n",
      "Loss  1.079294 C_bot  0.15 k_c 0.0\n",
      "1100 Train Loss 13.058338\n",
      "Loss  1.079294 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0774503 C_bot  0.15 k_c 0.0\n",
      "1101 Train Loss 13.053984\n",
      "Loss  1.0774503 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0757239 C_bot  0.15 k_c 0.0\n",
      "1102 Train Loss 13.049751\n",
      "Loss  1.0757239 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0738987 C_bot  0.15 k_c 0.0\n",
      "1103 Train Loss 13.045435\n",
      "Loss  1.0738987 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0721341 C_bot  0.15 k_c 0.0\n",
      "1104 Train Loss 13.041167\n",
      "Loss  1.0721341 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0703214 C_bot  0.15 k_c 0.0\n",
      "1105 Train Loss 13.036875\n",
      "Loss  1.0703214 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0685163 C_bot  0.15 k_c 0.0\n",
      "1106 Train Loss 13.03258\n",
      "Loss  1.0685163 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0668025 C_bot  0.15 k_c 0.0\n",
      "1107 Train Loss 13.028383\n",
      "Loss  1.0668025 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0649688 C_bot  0.15 k_c 0.0\n",
      "1108 Train Loss 13.024083\n",
      "Loss  1.0649688 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0632204 C_bot  0.15 k_c 0.0\n",
      "1109 Train Loss 13.019852\n",
      "Loss  1.0632204 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0614518 C_bot  0.15 k_c 0.0\n",
      "1110 Train Loss 13.015626\n",
      "Loss  1.0614518 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0597118 C_bot  0.15 k_c 0.0\n",
      "1111 Train Loss 13.011421\n",
      "Loss  1.0597118 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0578289 C_bot  0.15 k_c 0.0\n",
      "1112 Train Loss 13.007076\n",
      "Loss  1.0578289 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0560738 C_bot  0.15 k_c 0.0\n",
      "1113 Train Loss 13.002876\n",
      "Loss  1.0560738 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0543054 C_bot  0.15 k_c 0.0\n",
      "1114 Train Loss 12.99865\n",
      "Loss  1.0543054 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0526551 C_bot  0.15 k_c 0.0\n",
      "1115 Train Loss 12.994564\n",
      "Loss  1.0526551 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0508373 C_bot  0.15 k_c 0.0\n",
      "1116 Train Loss 12.990304\n",
      "Loss  1.0508373 C_bot  0.15 k_c 0.0\n",
      "Loss  1.049042 C_bot  0.15 k_c 0.0\n",
      "1117 Train Loss 12.986067\n",
      "Loss  1.049042 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0472655 C_bot  0.15 k_c 0.0\n",
      "1118 Train Loss 12.981871\n",
      "Loss  1.0472655 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0455409 C_bot  0.15 k_c 0.0\n",
      "1119 Train Loss 12.977713\n",
      "Loss  1.0455409 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0437788 C_bot  0.15 k_c 0.0\n",
      "1120 Train Loss 12.97353\n",
      "Loss  1.0437788 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0420517 C_bot  0.15 k_c 0.0\n",
      "1121 Train Loss 12.969392\n",
      "Loss  1.0420517 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0402695 C_bot  0.15 k_c 0.0\n",
      "1122 Train Loss 12.965189\n",
      "Loss  1.0402695 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0384933 C_bot  0.15 k_c 0.0\n",
      "1123 Train Loss 12.96101\n",
      "Loss  1.0384933 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0366912 C_bot  0.15 k_c 0.0\n",
      "1124 Train Loss 12.95681\n",
      "Loss  1.0366912 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0350003 C_bot  0.15 k_c 0.0\n",
      "1125 Train Loss 12.952707\n",
      "Loss  1.0350003 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0332043 C_bot  0.15 k_c 0.0\n",
      "1126 Train Loss 12.94853\n",
      "Loss  1.0332043 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0314463 C_bot  0.15 k_c 0.0\n",
      "1127 Train Loss 12.944378\n",
      "Loss  1.0314463 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0297706 C_bot  0.15 k_c 0.0\n",
      "1128 Train Loss 12.940311\n",
      "Loss  1.0297706 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0280609 C_bot  0.15 k_c 0.0\n",
      "1129 Train Loss 12.936232\n",
      "Loss  1.0280609 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0262474 C_bot  0.15 k_c 0.0\n",
      "1130 Train Loss 12.93203\n",
      "Loss  1.0262474 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0245371 C_bot  0.15 k_c 0.0\n",
      "1131 Train Loss 12.927954\n",
      "Loss  1.0245371 C_bot  0.15 k_c 0.0\n",
      "Loss  1.022832 C_bot  0.15 k_c 0.0\n",
      "1132 Train Loss 12.923883\n",
      "Loss  1.022832 C_bot  0.15 k_c 0.0\n",
      "Loss  1.021001 C_bot  0.15 k_c 0.0\n",
      "1133 Train Loss 12.919682\n",
      "Loss  1.021001 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0192453 C_bot  0.15 k_c 0.0\n",
      "1134 Train Loss 12.915579\n",
      "Loss  1.0192453 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0175905 C_bot  0.15 k_c 0.0\n",
      "1135 Train Loss 12.911558\n",
      "Loss  1.0175905 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0157444 C_bot  0.15 k_c 0.0\n",
      "1136 Train Loss 12.907368\n",
      "Loss  1.0157444 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0140083 C_bot  0.15 k_c 0.0\n",
      "1137 Train Loss 12.903293\n",
      "Loss  1.0140083 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0123407 C_bot  0.15 k_c 0.0\n",
      "1138 Train Loss 12.89927\n",
      "Loss  1.0123407 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0105482 C_bot  0.15 k_c 0.0\n",
      "1139 Train Loss 12.895154\n",
      "Loss  1.0105482 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0088104 C_bot  0.15 k_c 0.0\n",
      "1140 Train Loss 12.891078\n",
      "Loss  1.0088104 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0070523 C_bot  0.15 k_c 0.0\n",
      "1141 Train Loss 12.886989\n",
      "Loss  1.0070523 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0053343 C_bot  0.15 k_c 0.0\n",
      "1142 Train Loss 12.882957\n",
      "Loss  1.0053343 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0035629 C_bot  0.15 k_c 0.0\n",
      "1143 Train Loss 12.878857\n",
      "Loss  1.0035629 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0018473 C_bot  0.15 k_c 0.0\n",
      "1144 Train Loss 12.874832\n",
      "Loss  1.0018473 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0000966 C_bot  0.15 k_c 0.0\n",
      "1145 Train Loss 12.870771\n",
      "Loss  1.0000966 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99841857 C_bot  0.15 k_c 0.0\n",
      "1146 Train Loss 12.866783\n",
      "Loss  0.99841857 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9965881 C_bot  0.15 k_c 0.0\n",
      "1147 Train Loss 12.862655\n",
      "Loss  0.9965881 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99488586 C_bot  0.15 k_c 0.0\n",
      "1148 Train Loss 12.858655\n",
      "Loss  0.99488586 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99311584 C_bot  0.15 k_c 0.0\n",
      "1149 Train Loss 12.854587\n",
      "Loss  0.99311584 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99145555 C_bot  0.15 k_c 0.0\n",
      "1150 Train Loss 12.850643\n",
      "Loss  0.99145555 C_bot  0.15 k_c 0.0\n",
      "Loss  0.98971456 C_bot  0.15 k_c 0.0\n",
      "1151 Train Loss 12.846613\n",
      "Loss  0.98971456 C_bot  0.15 k_c 0.0\n",
      "Loss  0.98792213 C_bot  0.15 k_c 0.0\n",
      "1152 Train Loss 12.842543\n",
      "Loss  0.98792213 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9861117 C_bot  0.15 k_c 0.0\n",
      "1153 Train Loss 12.838457\n",
      "Loss  0.9861117 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9844681 C_bot  0.15 k_c 0.0\n",
      "1154 Train Loss 12.834537\n",
      "Loss  0.9844681 C_bot  0.15 k_c 0.0\n",
      "Loss  0.982651 C_bot  0.15 k_c 0.0\n",
      "1155 Train Loss 12.830456\n",
      "Loss  0.982651 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9809532 C_bot  0.15 k_c 0.0\n",
      "1156 Train Loss 12.826494\n",
      "Loss  0.9809532 C_bot  0.15 k_c 0.0\n",
      "Loss  0.979158 C_bot  0.15 k_c 0.0\n",
      "1157 Train Loss 12.822435\n",
      "Loss  0.979158 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97747177 C_bot  0.15 k_c 0.0\n",
      "1158 Train Loss 12.818499\n",
      "Loss  0.97747177 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97566897 C_bot  0.15 k_c 0.0\n",
      "1159 Train Loss 12.8144455\n",
      "Loss  0.97566897 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9739043 C_bot  0.15 k_c 0.0\n",
      "1160 Train Loss 12.810431\n",
      "Loss  0.9739043 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9720669 C_bot  0.15 k_c 0.0\n",
      "1161 Train Loss 12.8063545\n",
      "Loss  0.9720669 C_bot  0.15 k_c 0.0\n",
      "Loss  0.97034353 C_bot  0.15 k_c 0.0\n",
      "1162 Train Loss 12.802391\n",
      "Loss  0.97034353 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9686113 C_bot  0.15 k_c 0.0\n",
      "1163 Train Loss 12.798426\n",
      "Loss  0.9686113 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9668321 C_bot  0.15 k_c 0.0\n",
      "1164 Train Loss 12.794418\n",
      "Loss  0.9668321 C_bot  0.15 k_c 0.0\n",
      "Loss  0.965064 C_bot  0.15 k_c 0.0\n",
      "1165 Train Loss 12.790417\n",
      "Loss  0.965064 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9632914 C_bot  0.15 k_c 0.0\n",
      "1166 Train Loss 12.786432\n",
      "Loss  0.9632914 C_bot  0.15 k_c 0.0\n",
      "Loss  0.96146303 C_bot  0.15 k_c 0.0\n",
      "1167 Train Loss 12.782378\n",
      "Loss  0.96146303 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9597037 C_bot  0.15 k_c 0.0\n",
      "1168 Train Loss 12.778408\n",
      "Loss  0.9597037 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95792806 C_bot  0.15 k_c 0.0\n",
      "1169 Train Loss 12.774426\n",
      "Loss  0.95792806 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9561086 C_bot  0.15 k_c 0.0\n",
      "1170 Train Loss 12.770391\n",
      "Loss  0.9561086 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9543105 C_bot  0.15 k_c 0.0\n",
      "1171 Train Loss 12.766401\n",
      "Loss  0.9543105 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9525369 C_bot  0.15 k_c 0.0\n",
      "1172 Train Loss 12.762426\n",
      "Loss  0.9525369 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95078593 C_bot  0.15 k_c 0.0\n",
      "1173 Train Loss 12.758481\n",
      "Loss  0.95078593 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9488853 C_bot  0.15 k_c 0.0\n",
      "1174 Train Loss 12.7544\n",
      "Loss  0.9488853 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9471125 C_bot  0.15 k_c 0.0\n",
      "1175 Train Loss 12.750429\n",
      "Loss  0.9471125 C_bot  0.15 k_c 0.0\n",
      "Loss  0.94537693 C_bot  0.15 k_c 0.0\n",
      "1176 Train Loss 12.746523\n",
      "Loss  0.94537693 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9434228 C_bot  0.15 k_c 0.0\n",
      "1177 Train Loss 12.742388\n",
      "Loss  0.9434228 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9416597 C_bot  0.15 k_c 0.0\n",
      "1178 Train Loss 12.738447\n",
      "Loss  0.9416597 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9398435 C_bot  0.15 k_c 0.0\n",
      "1179 Train Loss 12.73447\n",
      "Loss  0.9398435 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9379975 C_bot  0.15 k_c 0.0\n",
      "1180 Train Loss 12.730452\n",
      "Loss  0.9379975 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9361571 C_bot  0.15 k_c 0.0\n",
      "1181 Train Loss 12.726454\n",
      "Loss  0.9361571 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93429834 C_bot  0.15 k_c 0.0\n",
      "1182 Train Loss 12.722439\n",
      "Loss  0.93429834 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93242353 C_bot  0.15 k_c 0.0\n",
      "1183 Train Loss 12.718409\n",
      "Loss  0.93242353 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9305342 C_bot  0.15 k_c 0.0\n",
      "1184 Train Loss 12.714373\n",
      "Loss  0.9305342 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92867047 C_bot  0.15 k_c 0.0\n",
      "1185 Train Loss 12.710363\n",
      "Loss  0.92867047 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9268092 C_bot  0.15 k_c 0.0\n",
      "1186 Train Loss 12.706358\n",
      "Loss  0.9268092 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92491233 C_bot  0.15 k_c 0.0\n",
      "1187 Train Loss 12.702328\n",
      "Loss  0.92491233 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9230154 C_bot  0.15 k_c 0.0\n",
      "1188 Train Loss 12.698299\n",
      "Loss  0.9230154 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9210858 C_bot  0.15 k_c 0.0\n",
      "1189 Train Loss 12.694235\n",
      "Loss  0.9210858 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9191617 C_bot  0.15 k_c 0.0\n",
      "1190 Train Loss 12.690195\n",
      "Loss  0.9191617 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9172073 C_bot  0.15 k_c 0.0\n",
      "1191 Train Loss 12.68611\n",
      "Loss  0.9172073 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9152943 C_bot  0.15 k_c 0.0\n",
      "1192 Train Loss 12.682091\n",
      "Loss  0.9152943 C_bot  0.15 k_c 0.0\n",
      "Loss  0.913303 C_bot  0.15 k_c 0.0\n",
      "1193 Train Loss 12.677977\n",
      "Loss  0.913303 C_bot  0.15 k_c 0.0\n",
      "Loss  0.91133344 C_bot  0.15 k_c 0.0\n",
      "1194 Train Loss 12.673905\n",
      "Loss  0.91133344 C_bot  0.15 k_c 0.0\n",
      "Loss  0.909417 C_bot  0.15 k_c 0.0\n",
      "1195 Train Loss 12.669879\n",
      "Loss  0.909417 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9073998 C_bot  0.15 k_c 0.0\n",
      "1196 Train Loss 12.665767\n",
      "Loss  0.9073998 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90542585 C_bot  0.15 k_c 0.0\n",
      "1197 Train Loss 12.661692\n",
      "Loss  0.90542585 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9034038 C_bot  0.15 k_c 0.0\n",
      "1198 Train Loss 12.657579\n",
      "Loss  0.9034038 C_bot  0.15 k_c 0.0\n",
      "Loss  0.90133655 C_bot  0.15 k_c 0.0\n",
      "1199 Train Loss 12.653429\n",
      "Loss  0.90133655 C_bot  0.15 k_c 0.0\n",
      "Loss  0.899382 C_bot  0.15 k_c 0.0\n",
      "1200 Train Loss 12.649383\n",
      "Loss  0.899382 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89726 C_bot  0.15 k_c 0.0\n",
      "1201 Train Loss 12.645191\n",
      "Loss  0.89726 C_bot  0.15 k_c 0.0\n",
      "Loss  0.895229 C_bot  0.15 k_c 0.0\n",
      "1202 Train Loss 12.641076\n",
      "Loss  0.895229 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8931194 C_bot  0.15 k_c 0.0\n",
      "1203 Train Loss 12.636902\n",
      "Loss  0.8931194 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89107144 C_bot  0.15 k_c 0.0\n",
      "1204 Train Loss 12.632786\n",
      "Loss  0.89107144 C_bot  0.15 k_c 0.0\n",
      "Loss  0.88891274 C_bot  0.15 k_c 0.0\n",
      "1205 Train Loss 12.628561\n",
      "Loss  0.88891274 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8868175 C_bot  0.15 k_c 0.0\n",
      "1206 Train Loss 12.624415\n",
      "Loss  0.8868175 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8846799 C_bot  0.15 k_c 0.0\n",
      "1207 Train Loss 12.620216\n",
      "Loss  0.8846799 C_bot  0.15 k_c 0.0\n",
      "Loss  0.88246685 C_bot  0.15 k_c 0.0\n",
      "1208 Train Loss 12.615964\n",
      "Loss  0.88246685 C_bot  0.15 k_c 0.0\n",
      "Loss  0.88029534 C_bot  0.15 k_c 0.0\n",
      "1209 Train Loss 12.61174\n",
      "Loss  0.88029534 C_bot  0.15 k_c 0.0\n",
      "Loss  0.87814254 C_bot  0.15 k_c 0.0\n",
      "1210 Train Loss 12.607554\n",
      "Loss  0.87814254 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8758453 C_bot  0.15 k_c 0.0\n",
      "1211 Train Loss 12.603216\n",
      "Loss  0.8758453 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8736057 C_bot  0.15 k_c 0.0\n",
      "1212 Train Loss 12.598946\n",
      "Loss  0.8736057 C_bot  0.15 k_c 0.0\n",
      "Loss  0.87134993 C_bot  0.15 k_c 0.0\n",
      "1213 Train Loss 12.594669\n",
      "Loss  0.87134993 C_bot  0.15 k_c 0.0\n",
      "Loss  0.869132 C_bot  0.15 k_c 0.0\n",
      "1214 Train Loss 12.590418\n",
      "Loss  0.869132 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8667967 C_bot  0.15 k_c 0.0\n",
      "1215 Train Loss 12.586082\n",
      "Loss  0.8667967 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8645484 C_bot  0.15 k_c 0.0\n",
      "1216 Train Loss 12.581806\n",
      "Loss  0.8645484 C_bot  0.15 k_c 0.0\n",
      "Loss  0.862141 C_bot  0.15 k_c 0.0\n",
      "1217 Train Loss 12.577402\n",
      "Loss  0.862141 C_bot  0.15 k_c 0.0\n",
      "Loss  0.85979706 C_bot  0.15 k_c 0.0\n",
      "1218 Train Loss 12.573051\n",
      "Loss  0.85979706 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8574219 C_bot  0.15 k_c 0.0\n",
      "1219 Train Loss 12.568676\n",
      "Loss  0.8574219 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8550293 C_bot  0.15 k_c 0.0\n",
      "1220 Train Loss 12.564298\n",
      "Loss  0.8550293 C_bot  0.15 k_c 0.0\n",
      "Loss  0.852638 C_bot  0.15 k_c 0.0\n",
      "1221 Train Loss 12.559911\n",
      "Loss  0.852638 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8501964 C_bot  0.15 k_c 0.0\n",
      "1222 Train Loss 12.555494\n",
      "Loss  0.8501964 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8477977 C_bot  0.15 k_c 0.0\n",
      "1223 Train Loss 12.551108\n",
      "Loss  0.8477977 C_bot  0.15 k_c 0.0\n",
      "Loss  0.84528834 C_bot  0.15 k_c 0.0\n",
      "1224 Train Loss 12.546632\n",
      "Loss  0.84528834 C_bot  0.15 k_c 0.0\n",
      "Loss  0.84275806 C_bot  0.15 k_c 0.0\n",
      "1225 Train Loss 12.5421295\n",
      "Loss  0.84275806 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8402561 C_bot  0.15 k_c 0.0\n",
      "1226 Train Loss 12.537661\n",
      "Loss  0.8402561 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8377038 C_bot  0.15 k_c 0.0\n",
      "1227 Train Loss 12.533162\n",
      "Loss  0.8377038 C_bot  0.15 k_c 0.0\n",
      "Loss  0.83519596 C_bot  0.15 k_c 0.0\n",
      "1228 Train Loss 12.528685\n",
      "Loss  0.83519596 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8326463 C_bot  0.15 k_c 0.0\n",
      "1229 Train Loss 12.524203\n",
      "Loss  0.8326463 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8300277 C_bot  0.15 k_c 0.0\n",
      "1230 Train Loss 12.519624\n",
      "Loss  0.8300277 C_bot  0.15 k_c 0.0\n",
      "Loss  0.82747525 C_bot  0.15 k_c 0.0\n",
      "1231 Train Loss 12.515144\n",
      "Loss  0.82747525 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8248482 C_bot  0.15 k_c 0.0\n",
      "1232 Train Loss 12.510577\n",
      "Loss  0.8248482 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8221897 C_bot  0.15 k_c 0.0\n",
      "1233 Train Loss 12.505988\n",
      "Loss  0.8221897 C_bot  0.15 k_c 0.0\n",
      "Loss  0.81956166 C_bot  0.15 k_c 0.0\n",
      "1234 Train Loss 12.501443\n",
      "Loss  0.81956166 C_bot  0.15 k_c 0.0\n",
      "Loss  0.81690943 C_bot  0.15 k_c 0.0\n",
      "1235 Train Loss 12.496857\n",
      "Loss  0.81690943 C_bot  0.15 k_c 0.0\n",
      "Loss  0.81425786 C_bot  0.15 k_c 0.0\n",
      "1236 Train Loss 12.492304\n",
      "Loss  0.81425786 C_bot  0.15 k_c 0.0\n",
      "Loss  0.81160516 C_bot  0.15 k_c 0.0\n",
      "1237 Train Loss 12.487727\n",
      "Loss  0.81160516 C_bot  0.15 k_c 0.0\n",
      "Loss  0.80889547 C_bot  0.15 k_c 0.0\n",
      "1238 Train Loss 12.483114\n",
      "Loss  0.80889547 C_bot  0.15 k_c 0.0\n",
      "Loss  0.80622643 C_bot  0.15 k_c 0.0\n",
      "1239 Train Loss 12.478546\n",
      "Loss  0.80622643 C_bot  0.15 k_c 0.0\n",
      "Loss  0.80355746 C_bot  0.15 k_c 0.0\n",
      "1240 Train Loss 12.473967\n",
      "Loss  0.80355746 C_bot  0.15 k_c 0.0\n",
      "Loss  0.800882 C_bot  0.15 k_c 0.0\n",
      "1241 Train Loss 12.46941\n",
      "Loss  0.800882 C_bot  0.15 k_c 0.0\n",
      "Loss  0.798222 C_bot  0.15 k_c 0.0\n",
      "1242 Train Loss 12.464841\n",
      "Loss  0.798222 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7955126 C_bot  0.15 k_c 0.0\n",
      "1243 Train Loss 12.460259\n",
      "Loss  0.7955126 C_bot  0.15 k_c 0.0\n",
      "Loss  0.792777 C_bot  0.15 k_c 0.0\n",
      "1244 Train Loss 12.455621\n",
      "Loss  0.792777 C_bot  0.15 k_c 0.0\n",
      "Loss  0.79014915 C_bot  0.15 k_c 0.0\n",
      "1245 Train Loss 12.45113\n",
      "Loss  0.79014915 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7875618 C_bot  0.15 k_c 0.0\n",
      "1246 Train Loss 12.446644\n",
      "Loss  0.7875618 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7848822 C_bot  0.15 k_c 0.0\n",
      "1247 Train Loss 12.442108\n",
      "Loss  0.7848822 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7821514 C_bot  0.15 k_c 0.0\n",
      "1248 Train Loss 12.437484\n",
      "Loss  0.7821514 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7795148 C_bot  0.15 k_c 0.0\n",
      "1249 Train Loss 12.432994\n",
      "Loss  0.7795148 C_bot  0.15 k_c 0.0\n",
      "Loss  0.77691996 C_bot  0.15 k_c 0.0\n",
      "1250 Train Loss 12.428515\n",
      "Loss  0.77691996 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7742326 C_bot  0.15 k_c 0.0\n",
      "1251 Train Loss 12.423972\n",
      "Loss  0.7742326 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7716301 C_bot  0.15 k_c 0.0\n",
      "1252 Train Loss 12.419504\n",
      "Loss  0.7716301 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7691305 C_bot  0.15 k_c 0.0\n",
      "1253 Train Loss 12.415135\n",
      "Loss  0.7691305 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7664992 C_bot  0.15 k_c 0.0\n",
      "1254 Train Loss 12.410658\n",
      "Loss  0.7664992 C_bot  0.15 k_c 0.0\n",
      "Loss  0.76403755 C_bot  0.15 k_c 0.0\n",
      "1255 Train Loss 12.406317\n",
      "Loss  0.76403755 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7614412 C_bot  0.15 k_c 0.0\n",
      "1256 Train Loss 12.40189\n",
      "Loss  0.7614412 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7590133 C_bot  0.15 k_c 0.0\n",
      "1257 Train Loss 12.397579\n",
      "Loss  0.7590133 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7564824 C_bot  0.15 k_c 0.0\n",
      "1258 Train Loss 12.393224\n",
      "Loss  0.7564824 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7540404 C_bot  0.15 k_c 0.0\n",
      "1259 Train Loss 12.388903\n",
      "Loss  0.7540404 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7515153 C_bot  0.15 k_c 0.0\n",
      "1260 Train Loss 12.384552\n",
      "Loss  0.7515153 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7490967 C_bot  0.15 k_c 0.0\n",
      "1261 Train Loss 12.380265\n",
      "Loss  0.7490967 C_bot  0.15 k_c 0.0\n",
      "Loss  0.74669695 C_bot  0.15 k_c 0.0\n",
      "1262 Train Loss 12.376032\n",
      "Loss  0.74669695 C_bot  0.15 k_c 0.0\n",
      "Loss  0.74431026 C_bot  0.15 k_c 0.0\n",
      "1263 Train Loss 12.371795\n",
      "Loss  0.74431026 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7419677 C_bot  0.15 k_c 0.0\n",
      "1264 Train Loss 12.367608\n",
      "Loss  0.7419677 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73961294 C_bot  0.15 k_c 0.0\n",
      "1265 Train Loss 12.363414\n",
      "Loss  0.73961294 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73731 C_bot  0.15 k_c 0.0\n",
      "1266 Train Loss 12.35927\n",
      "Loss  0.73731 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7349973 C_bot  0.15 k_c 0.0\n",
      "1267 Train Loss 12.355119\n",
      "Loss  0.7349973 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7327414 C_bot  0.15 k_c 0.0\n",
      "1268 Train Loss 12.351027\n",
      "Loss  0.7327414 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73045677 C_bot  0.15 k_c 0.0\n",
      "1269 Train Loss 12.34691\n",
      "Loss  0.73045677 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7282026 C_bot  0.15 k_c 0.0\n",
      "1270 Train Loss 12.34282\n",
      "Loss  0.7282026 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72601086 C_bot  0.15 k_c 0.0\n",
      "1271 Train Loss 12.338802\n",
      "Loss  0.72601086 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72378355 C_bot  0.15 k_c 0.0\n",
      "1272 Train Loss 12.334741\n",
      "Loss  0.72378355 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72166294 C_bot  0.15 k_c 0.0\n",
      "1273 Train Loss 12.330803\n",
      "Loss  0.72166294 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7194953 C_bot  0.15 k_c 0.0\n",
      "1274 Train Loss 12.326803\n",
      "Loss  0.7194953 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7173072 C_bot  0.15 k_c 0.0\n",
      "1275 Train Loss 12.322802\n",
      "Loss  0.7173072 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7151506 C_bot  0.15 k_c 0.0\n",
      "1276 Train Loss 12.318821\n",
      "Loss  0.7151506 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71309364 C_bot  0.15 k_c 0.0\n",
      "1277 Train Loss 12.314954\n",
      "Loss  0.71309364 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7110205 C_bot  0.15 k_c 0.0\n",
      "1278 Train Loss 12.311066\n",
      "Loss  0.7110205 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70888287 C_bot  0.15 k_c 0.0\n",
      "1279 Train Loss 12.307117\n",
      "Loss  0.70888287 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7068378 C_bot  0.15 k_c 0.0\n",
      "1280 Train Loss 12.3032675\n",
      "Loss  0.7068378 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7048059 C_bot  0.15 k_c 0.0\n",
      "1281 Train Loss 12.299427\n",
      "Loss  0.7048059 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70271134 C_bot  0.15 k_c 0.0\n",
      "1282 Train Loss 12.295541\n",
      "Loss  0.70271134 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7007938 C_bot  0.15 k_c 0.0\n",
      "1283 Train Loss 12.29181\n",
      "Loss  0.7007938 C_bot  0.15 k_c 0.0\n",
      "Loss  0.698739 C_bot  0.15 k_c 0.0\n",
      "1284 Train Loss 12.287977\n",
      "Loss  0.698739 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69673085 C_bot  0.15 k_c 0.0\n",
      "1285 Train Loss 12.284162\n",
      "Loss  0.69673085 C_bot  0.15 k_c 0.0\n",
      "Loss  0.694777 C_bot  0.15 k_c 0.0\n",
      "1286 Train Loss 12.280434\n",
      "Loss  0.694777 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6927986 C_bot  0.15 k_c 0.0\n",
      "1287 Train Loss 12.276654\n",
      "Loss  0.6927986 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69082034 C_bot  0.15 k_c 0.0\n",
      "1288 Train Loss 12.272908\n",
      "Loss  0.69082034 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6888691 C_bot  0.15 k_c 0.0\n",
      "1289 Train Loss 12.269163\n",
      "Loss  0.6888691 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6869393 C_bot  0.15 k_c 0.0\n",
      "1290 Train Loss 12.265472\n",
      "Loss  0.6869393 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6850286 C_bot  0.15 k_c 0.0\n",
      "1291 Train Loss 12.261774\n",
      "Loss  0.6850286 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68311024 C_bot  0.15 k_c 0.0\n",
      "1292 Train Loss 12.258097\n",
      "Loss  0.68311024 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6812121 C_bot  0.15 k_c 0.0\n",
      "1293 Train Loss 12.254429\n",
      "Loss  0.6812121 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67939085 C_bot  0.15 k_c 0.0\n",
      "1294 Train Loss 12.250843\n",
      "Loss  0.67939085 C_bot  0.15 k_c 0.0\n",
      "Loss  0.677454 C_bot  0.15 k_c 0.0\n",
      "1295 Train Loss 12.24715\n",
      "Loss  0.677454 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6755801 C_bot  0.15 k_c 0.0\n",
      "1296 Train Loss 12.243513\n",
      "Loss  0.6755801 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67376214 C_bot  0.15 k_c 0.0\n",
      "1297 Train Loss 12.23995\n",
      "Loss  0.67376214 C_bot  0.15 k_c 0.0\n",
      "Loss  0.67184055 C_bot  0.15 k_c 0.0\n",
      "1298 Train Loss 12.236265\n",
      "Loss  0.67184055 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6700451 C_bot  0.15 k_c 0.0\n",
      "1299 Train Loss 12.23274\n",
      "Loss  0.6700451 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66822726 C_bot  0.15 k_c 0.0\n",
      "1300 Train Loss 12.229154\n",
      "Loss  0.66822726 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66639745 C_bot  0.15 k_c 0.0\n",
      "1301 Train Loss 12.225608\n",
      "Loss  0.66639745 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66464895 C_bot  0.15 k_c 0.0\n",
      "1302 Train Loss 12.222093\n",
      "Loss  0.66464895 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66276205 C_bot  0.15 k_c 0.0\n",
      "1303 Train Loss 12.218497\n",
      "Loss  0.66276205 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6610318 C_bot  0.15 k_c 0.0\n",
      "1304 Train Loss 12.215005\n",
      "Loss  0.6610318 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65921426 C_bot  0.15 k_c 0.0\n",
      "1305 Train Loss 12.211483\n",
      "Loss  0.65921426 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65745956 C_bot  0.15 k_c 0.0\n",
      "1306 Train Loss 12.2079735\n",
      "Loss  0.65745956 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65567183 C_bot  0.15 k_c 0.0\n",
      "1307 Train Loss 12.204491\n",
      "Loss  0.65567183 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65397424 C_bot  0.15 k_c 0.0\n",
      "1308 Train Loss 12.201036\n",
      "Loss  0.65397424 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65213686 C_bot  0.15 k_c 0.0\n",
      "1309 Train Loss 12.197518\n",
      "Loss  0.65213686 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6504823 C_bot  0.15 k_c 0.0\n",
      "1310 Train Loss 12.194097\n",
      "Loss  0.6504823 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64871556 C_bot  0.15 k_c 0.0\n",
      "1311 Train Loss 12.190676\n",
      "Loss  0.64871556 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64704686 C_bot  0.15 k_c 0.0\n",
      "1312 Train Loss 12.187218\n",
      "Loss  0.64704686 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6452562 C_bot  0.15 k_c 0.0\n",
      "1313 Train Loss 12.183811\n",
      "Loss  0.6452562 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64371777 C_bot  0.15 k_c 0.0\n",
      "1314 Train Loss 12.180444\n",
      "Loss  0.64371777 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64188987 C_bot  0.15 k_c 0.0\n",
      "1315 Train Loss 12.177061\n",
      "Loss  0.64188987 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64040744 C_bot  0.15 k_c 0.0\n",
      "1316 Train Loss 12.173682\n",
      "Loss  0.64040744 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6385227 C_bot  0.15 k_c 0.0\n",
      "1317 Train Loss 12.170343\n",
      "Loss  0.6385227 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6372436 C_bot  0.15 k_c 0.0\n",
      "1318 Train Loss 12.1670475\n",
      "Loss  0.6372436 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6352502 C_bot  0.15 k_c 0.0\n",
      "1319 Train Loss 12.163766\n",
      "Loss  0.6352502 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63434815 C_bot  0.15 k_c 0.0\n",
      "1320 Train Loss 12.160637\n",
      "Loss  0.63434815 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6323896 C_bot  0.15 k_c 0.0\n",
      "1321 Train Loss 12.157677\n",
      "Loss  0.6323896 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6322275 C_bot  0.15 k_c 0.0\n",
      "1322 Train Loss 12.1549225\n",
      "Loss  0.6322275 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63051504 C_bot  0.15 k_c 0.0\n",
      "1323 Train Loss 12.152706\n",
      "Loss  0.63051504 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6321532 C_bot  0.15 k_c 0.0\n",
      "1324 Train Loss 12.151093\n",
      "Loss  0.6321532 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6318568 C_bot  0.15 k_c 0.0\n",
      "1325 Train Loss 12.151193\n",
      "Loss  0.6318568 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6386954 C_bot  0.15 k_c 0.0\n",
      "1326 Train Loss 12.153587\n",
      "Loss  0.6386954 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64435863 C_bot  0.15 k_c 0.0\n",
      "1327 Train Loss 12.161291\n",
      "Loss  0.64435863 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6674238 C_bot  0.15 k_c 0.0\n",
      "1328 Train Loss 12.17771\n",
      "Loss  0.6674238 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6963003 C_bot  0.15 k_c 0.0\n",
      "1329 Train Loss 12.211715\n",
      "Loss  0.6963003 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7726197 C_bot  0.15 k_c 0.0\n",
      "1330 Train Loss 12.277266\n",
      "Loss  0.7726197 C_bot  0.15 k_c 0.0\n",
      "Loss  0.88989514 C_bot  0.15 k_c 0.0\n",
      "1331 Train Loss 12.405577\n",
      "Loss  0.88989514 C_bot  0.15 k_c 0.0\n",
      "Loss  1.152241 C_bot  0.15 k_c 0.0\n",
      "1332 Train Loss 12.649403\n",
      "Loss  1.152241 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6066558 C_bot  0.15 k_c 0.0\n",
      "1333 Train Loss 13.126429\n",
      "Loss  1.6066558 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5501032 C_bot  0.15 k_c 0.0\n",
      "1334 Train Loss 14.036758\n",
      "Loss  2.5501032 C_bot  0.15 k_c 0.0\n",
      "Loss  4.3095493 C_bot  0.15 k_c 0.0\n",
      "1335 Train Loss 15.842287\n",
      "Loss  4.3095493 C_bot  0.15 k_c 0.0\n",
      "Loss  7.819391 C_bot  0.15 k_c 0.0\n",
      "1336 Train Loss 19.2919\n",
      "Loss  7.819391 C_bot  0.15 k_c 0.0\n",
      "Loss  14.702588 C_bot  0.15 k_c 0.0\n",
      "1337 Train Loss 26.2712\n",
      "Loss  14.702588 C_bot  0.15 k_c 0.0\n",
      "Loss  27.903877 C_bot  0.15 k_c 0.0\n",
      "1338 Train Loss 39.364044\n",
      "Loss  27.903877 C_bot  0.15 k_c 0.0\n",
      "Loss  54.58998 C_bot  0.15 k_c 0.0\n",
      "1339 Train Loss 66.26065\n",
      "Loss  54.58998 C_bot  0.15 k_c 0.0\n",
      "Loss  101.38042 C_bot  0.15 k_c 0.0\n",
      "1340 Train Loss 112.8629\n",
      "Loss  101.38042 C_bot  0.15 k_c 0.0\n",
      "Loss  193.77536 C_bot  0.15 k_c 0.0\n",
      "1341 Train Loss 205.74513\n",
      "Loss  193.77536 C_bot  0.15 k_c 0.0\n",
      "Loss  313.63727 C_bot  0.15 k_c 0.0\n",
      "1342 Train Loss 325.2678\n",
      "Loss  313.63727 C_bot  0.15 k_c 0.0\n",
      "Loss  496.8722 C_bot  0.15 k_c 0.0\n",
      "1343 Train Loss 509.5312\n",
      "Loss  496.8722 C_bot  0.15 k_c 0.0\n",
      "Loss  517.65094 C_bot  0.15 k_c 0.0\n",
      "1344 Train Loss 529.4734\n",
      "Loss  517.65094 C_bot  0.15 k_c 0.0\n",
      "Loss  399.27014 C_bot  0.15 k_c 0.0\n",
      "1345 Train Loss 412.12018\n",
      "Loss  399.27014 C_bot  0.15 k_c 0.0\n",
      "Loss  104.25191 C_bot  0.15 k_c 0.0\n",
      "1346 Train Loss 116.04321\n",
      "Loss  104.25191 C_bot  0.15 k_c 0.0\n",
      "Loss  10.375364 C_bot  0.15 k_c 0.0\n",
      "1347 Train Loss 22.450066\n",
      "Loss  10.375364 C_bot  0.15 k_c 0.0\n",
      "Loss  163.52605 C_bot  0.15 k_c 0.0\n",
      "1348 Train Loss 176.63654\n",
      "Loss  163.52605 C_bot  0.15 k_c 0.0\n",
      "Loss  201.83173 C_bot  0.15 k_c 0.0\n",
      "1349 Train Loss 214.32018\n",
      "Loss  201.83173 C_bot  0.15 k_c 0.0\n",
      "Loss  52.27928 C_bot  0.15 k_c 0.0\n",
      "1350 Train Loss 65.660545\n",
      "Loss  52.27928 C_bot  0.15 k_c 0.0\n",
      "Loss  17.591875 C_bot  0.15 k_c 0.0\n",
      "1351 Train Loss 31.099712\n",
      "Loss  17.591875 C_bot  0.15 k_c 0.0\n",
      "Loss  123.92946 C_bot  0.15 k_c 0.0\n",
      "1352 Train Loss 137.181\n",
      "Loss  123.92946 C_bot  0.15 k_c 0.0\n",
      "Loss  99.09956 C_bot  0.15 k_c 0.0\n",
      "1353 Train Loss 113.46179\n",
      "Loss  99.09956 C_bot  0.15 k_c 0.0\n",
      "Loss  5.4033484 C_bot  0.15 k_c 0.0\n",
      "1354 Train Loss 19.248978\n",
      "Loss  5.4033484 C_bot  0.15 k_c 0.0\n",
      "Loss  54.601048 C_bot  0.15 k_c 0.0\n",
      "1355 Train Loss 68.35476\n",
      "Loss  54.601048 C_bot  0.15 k_c 0.0\n",
      "Loss  94.42072 C_bot  0.15 k_c 0.0\n",
      "1356 Train Loss 109.113556\n",
      "Loss  94.42072 C_bot  0.15 k_c 0.0\n",
      "Loss  21.26448 C_bot  0.15 k_c 0.0\n",
      "1357 Train Loss 35.230095\n",
      "Loss  21.26448 C_bot  0.15 k_c 0.0\n",
      "Loss  17.221924 C_bot  0.15 k_c 0.0\n",
      "1358 Train Loss 31.222572\n",
      "Loss  17.221924 C_bot  0.15 k_c 0.0\n",
      "Loss  67.59332 C_bot  0.15 k_c 0.0\n",
      "1359 Train Loss 82.16846\n",
      "Loss  67.59332 C_bot  0.15 k_c 0.0\n",
      "Loss  32.23489 C_bot  0.15 k_c 0.0\n",
      "1360 Train Loss 46.192192\n",
      "Loss  32.23489 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5350983 C_bot  0.15 k_c 0.0\n",
      "1361 Train Loss 17.580336\n",
      "Loss  3.5350983 C_bot  0.15 k_c 0.0\n",
      "Loss  40.132812 C_bot  0.15 k_c 0.0\n",
      "1362 Train Loss 54.442852\n",
      "Loss  40.132812 C_bot  0.15 k_c 0.0\n",
      "Loss  34.322357 C_bot  0.15 k_c 0.0\n",
      "1363 Train Loss 48.192604\n",
      "Loss  34.322357 C_bot  0.15 k_c 0.0\n",
      "Loss  2.105298 C_bot  0.15 k_c 0.0\n",
      "1364 Train Loss 16.069023\n",
      "Loss  2.105298 C_bot  0.15 k_c 0.0\n",
      "Loss  19.67232 C_bot  0.15 k_c 0.0\n",
      "1365 Train Loss 33.69733\n",
      "Loss  19.67232 C_bot  0.15 k_c 0.0\n",
      "Loss  30.322252 C_bot  0.15 k_c 0.0\n",
      "1366 Train Loss 44.05001\n",
      "Loss  30.322252 C_bot  0.15 k_c 0.0\n",
      "Loss  5.7766175 C_bot  0.15 k_c 0.0\n",
      "1367 Train Loss 19.58117\n",
      "Loss  5.7766175 C_bot  0.15 k_c 0.0\n",
      "Loss  7.504494 C_bot  0.15 k_c 0.0\n",
      "1368 Train Loss 21.243845\n",
      "Loss  7.504494 C_bot  0.15 k_c 0.0\n",
      "Loss  23.01497 C_bot  0.15 k_c 0.0\n",
      "1369 Train Loss 36.55229\n",
      "Loss  23.01497 C_bot  0.15 k_c 0.0\n",
      "Loss  9.742391 C_bot  0.15 k_c 0.0\n",
      "1370 Train Loss 23.336063\n",
      "Loss  9.742391 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1526458 C_bot  0.15 k_c 0.0\n",
      "1371 Train Loss 15.614357\n",
      "Loss  2.1526458 C_bot  0.15 k_c 0.0\n",
      "Loss  15.099003 C_bot  0.15 k_c 0.0\n",
      "1372 Train Loss 28.407608\n",
      "Loss  15.099003 C_bot  0.15 k_c 0.0\n",
      "Loss  11.765271 C_bot  0.15 k_c 0.0\n",
      "1373 Train Loss 25.129177\n",
      "Loss  11.765271 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2752441 C_bot  0.15 k_c 0.0\n",
      "1374 Train Loss 14.474344\n",
      "Loss  1.2752441 C_bot  0.15 k_c 0.0\n",
      "Loss  8.429922 C_bot  0.15 k_c 0.0\n",
      "1375 Train Loss 21.515303\n",
      "Loss  8.429922 C_bot  0.15 k_c 0.0\n",
      "Loss  11.314616 C_bot  0.15 k_c 0.0\n",
      "1376 Train Loss 24.475286\n",
      "Loss  11.314616 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4473174 C_bot  0.15 k_c 0.0\n",
      "1377 Train Loss 15.433568\n",
      "Loss  2.4473174 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9146576 C_bot  0.15 k_c 0.0\n",
      "1378 Train Loss 16.836323\n",
      "Loss  3.9146576 C_bot  0.15 k_c 0.0\n",
      "Loss  9.053186 C_bot  0.15 k_c 0.0\n",
      "1379 Train Loss 22.050966\n",
      "Loss  9.053186 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8582168 C_bot  0.15 k_c 0.0\n",
      "1380 Train Loss 16.686134\n",
      "Loss  3.8582168 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6114978 C_bot  0.15 k_c 0.0\n",
      "1381 Train Loss 14.420377\n",
      "Loss  1.6114978 C_bot  0.15 k_c 0.0\n",
      "Loss  6.166869 C_bot  0.15 k_c 0.0\n",
      "1382 Train Loss 19.02809\n",
      "Loss  6.166869 C_bot  0.15 k_c 0.0\n",
      "Loss  4.6565046 C_bot  0.15 k_c 0.0\n",
      "1383 Train Loss 17.362167\n",
      "Loss  4.6565046 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0256828 C_bot  0.15 k_c 0.0\n",
      "1384 Train Loss 13.746717\n",
      "Loss  1.0256828 C_bot  0.15 k_c 0.0\n",
      "Loss  3.580192 C_bot  0.15 k_c 0.0\n",
      "1385 Train Loss 16.317122\n",
      "Loss  3.580192 C_bot  0.15 k_c 0.0\n",
      "Loss  4.5426674 C_bot  0.15 k_c 0.0\n",
      "1386 Train Loss 17.149345\n",
      "Loss  4.5426674 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3732587 C_bot  0.15 k_c 0.0\n",
      "1387 Train Loss 14.0177765\n",
      "Loss  1.3732587 C_bot  0.15 k_c 0.0\n",
      "Loss  1.844739 C_bot  0.15 k_c 0.0\n",
      "1388 Train Loss 14.47019\n",
      "Loss  1.844739 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7420776 C_bot  0.15 k_c 0.0\n",
      "1389 Train Loss 16.271301\n",
      "Loss  3.7420776 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9372305 C_bot  0.15 k_c 0.0\n",
      "1390 Train Loss 14.510742\n",
      "Loss  1.9372305 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0459794 C_bot  0.15 k_c 0.0\n",
      "1391 Train Loss 13.575514\n",
      "Loss  1.0459794 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6776288 C_bot  0.15 k_c 0.0\n",
      "1392 Train Loss 15.144222\n",
      "Loss  2.6776288 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2650132 C_bot  0.15 k_c 0.0\n",
      "1393 Train Loss 14.769916\n",
      "Loss  2.2650132 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9351964 C_bot  0.15 k_c 0.0\n",
      "1394 Train Loss 13.383848\n",
      "Loss  0.9351964 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7116663 C_bot  0.15 k_c 0.0\n",
      "1395 Train Loss 14.123261\n",
      "Loss  1.7116663 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1876333 C_bot  0.15 k_c 0.0\n",
      "1396 Train Loss 14.625126\n",
      "Loss  2.1876333 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1587183 C_bot  0.15 k_c 0.0\n",
      "1397 Train Loss 13.537371\n",
      "Loss  1.1587183 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0932871 C_bot  0.15 k_c 0.0\n",
      "1398 Train Loss 13.453356\n",
      "Loss  1.0932871 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8061692 C_bot  0.15 k_c 0.0\n",
      "1399 Train Loss 14.177349\n",
      "Loss  1.8061692 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3916453 C_bot  0.15 k_c 0.0\n",
      "1400 Train Loss 13.708218\n",
      "Loss  1.3916453 C_bot  0.15 k_c 0.0\n",
      "Loss  0.85723066 C_bot  0.15 k_c 0.0\n",
      "1401 Train Loss 13.167442\n",
      "Loss  0.85723066 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3265926 C_bot  0.15 k_c 0.0\n",
      "1402 Train Loss 13.6336565\n",
      "Loss  1.3265926 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4430332 C_bot  0.15 k_c 0.0\n",
      "1403 Train Loss 13.70345\n",
      "Loss  1.4430332 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8886585 C_bot  0.15 k_c 0.0\n",
      "1404 Train Loss 13.15057\n",
      "Loss  0.8886585 C_bot  0.15 k_c 0.0\n",
      "Loss  0.95594364 C_bot  0.15 k_c 0.0\n",
      "1405 Train Loss 13.203335\n",
      "Loss  0.95594364 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2922356 C_bot  0.15 k_c 0.0\n",
      "1406 Train Loss 13.503151\n",
      "Loss  1.2922356 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9978851 C_bot  0.15 k_c 0.0\n",
      "1407 Train Loss 13.215191\n",
      "Loss  0.9978851 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7880568 C_bot  0.15 k_c 0.0\n",
      "1408 Train Loss 12.982937\n",
      "Loss  0.7880568 C_bot  0.15 k_c 0.0\n",
      "Loss  1.041072 C_bot  0.15 k_c 0.0\n",
      "1409 Train Loss 13.210993\n",
      "Loss  1.041072 C_bot  0.15 k_c 0.0\n",
      "Loss  1.032993 C_bot  0.15 k_c 0.0\n",
      "1410 Train Loss 13.210215\n",
      "Loss  1.032993 C_bot  0.15 k_c 0.0\n",
      "Loss  0.78207606 C_bot  0.15 k_c 0.0\n",
      "1411 Train Loss 12.932613\n",
      "Loss  0.78207606 C_bot  0.15 k_c 0.0\n",
      "Loss  0.82048225 C_bot  0.15 k_c 0.0\n",
      "1412 Train Loss 12.957113\n",
      "Loss  0.82048225 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9516065 C_bot  0.15 k_c 0.0\n",
      "1413 Train Loss 13.092177\n",
      "Loss  0.9516065 C_bot  0.15 k_c 0.0\n",
      "Loss  0.83032507 C_bot  0.15 k_c 0.0\n",
      "1414 Train Loss 12.943554\n",
      "Loss  0.83032507 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70834595 C_bot  0.15 k_c 0.0\n",
      "1415 Train Loss 12.816462\n",
      "Loss  0.70834595 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8073532 C_bot  0.15 k_c 0.0\n",
      "1416 Train Loss 12.913141\n",
      "Loss  0.8073532 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8332315 C_bot  0.15 k_c 0.0\n",
      "1417 Train Loss 12.914444\n",
      "Loss  0.8332315 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6899868 C_bot  0.15 k_c 0.0\n",
      "1418 Train Loss 12.771767\n",
      "Loss  0.6899868 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68481255 C_bot  0.15 k_c 0.0\n",
      "1419 Train Loss 12.757482\n",
      "Loss  0.68481255 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7652359 C_bot  0.15 k_c 0.0\n",
      "1420 Train Loss 12.818794\n",
      "Loss  0.7652359 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6976397 C_bot  0.15 k_c 0.0\n",
      "1421 Train Loss 12.753635\n",
      "Loss  0.6976397 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6272849 C_bot  0.15 k_c 0.0\n",
      "1422 Train Loss 12.6689625\n",
      "Loss  0.6272849 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6663226 C_bot  0.15 k_c 0.0\n",
      "1423 Train Loss 12.695329\n",
      "Loss  0.6663226 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6752831 C_bot  0.15 k_c 0.0\n",
      "1424 Train Loss 12.705126\n",
      "Loss  0.6752831 C_bot  0.15 k_c 0.0\n",
      "Loss  0.61766964 C_bot  0.15 k_c 0.0\n",
      "1425 Train Loss 12.630932\n",
      "Loss  0.61766964 C_bot  0.15 k_c 0.0\n",
      "Loss  0.59044236 C_bot  0.15 k_c 0.0\n",
      "1426 Train Loss 12.596684\n",
      "Loss  0.59044236 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6168914 C_bot  0.15 k_c 0.0\n",
      "1427 Train Loss 12.620265\n",
      "Loss  0.6168914 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6094055 C_bot  0.15 k_c 0.0\n",
      "1428 Train Loss 12.596804\n",
      "Loss  0.6094055 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5571933 C_bot  0.15 k_c 0.0\n",
      "1429 Train Loss 12.541216\n",
      "Loss  0.5571933 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5560565 C_bot  0.15 k_c 0.0\n",
      "1430 Train Loss 12.532964\n",
      "Loss  0.5560565 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5765027 C_bot  0.15 k_c 0.0\n",
      "1431 Train Loss 12.540003\n",
      "Loss  0.5765027 C_bot  0.15 k_c 0.0\n",
      "Loss  0.54509234 C_bot  0.15 k_c 0.0\n",
      "1432 Train Loss 12.5064535\n",
      "Loss  0.54509234 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5198814 C_bot  0.15 k_c 0.0\n",
      "1433 Train Loss 12.470741\n",
      "Loss  0.5198814 C_bot  0.15 k_c 0.0\n",
      "Loss  0.52900565 C_bot  0.15 k_c 0.0\n",
      "1434 Train Loss 12.469837\n",
      "Loss  0.52900565 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5261755 C_bot  0.15 k_c 0.0\n",
      "1435 Train Loss 12.463971\n",
      "Loss  0.5261755 C_bot  0.15 k_c 0.0\n",
      "Loss  0.50614965 C_bot  0.15 k_c 0.0\n",
      "1436 Train Loss 12.431761\n",
      "Loss  0.50614965 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49142405 C_bot  0.15 k_c 0.0\n",
      "1437 Train Loss 12.410163\n",
      "Loss  0.49142405 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49508393 C_bot  0.15 k_c 0.0\n",
      "1438 Train Loss 12.408569\n",
      "Loss  0.49508393 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49393076 C_bot  0.15 k_c 0.0\n",
      "1439 Train Loss 12.395494\n",
      "Loss  0.49393076 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4725041 C_bot  0.15 k_c 0.0\n",
      "1440 Train Loss 12.369339\n",
      "Loss  0.4725041 C_bot  0.15 k_c 0.0\n",
      "Loss  0.46607375 C_bot  0.15 k_c 0.0\n",
      "1441 Train Loss 12.355155\n",
      "Loss  0.46607375 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47169888 C_bot  0.15 k_c 0.0\n",
      "1442 Train Loss 12.350641\n",
      "Loss  0.47169888 C_bot  0.15 k_c 0.0\n",
      "Loss  0.46100023 C_bot  0.15 k_c 0.0\n",
      "1443 Train Loss 12.335844\n",
      "Loss  0.46100023 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44993475 C_bot  0.15 k_c 0.0\n",
      "1444 Train Loss 12.315256\n",
      "Loss  0.44993475 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44705668 C_bot  0.15 k_c 0.0\n",
      "1445 Train Loss 12.304659\n",
      "Loss  0.44705668 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44544888 C_bot  0.15 k_c 0.0\n",
      "1446 Train Loss 12.298189\n",
      "Loss  0.44544888 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44083813 C_bot  0.15 k_c 0.0\n",
      "1447 Train Loss 12.283657\n",
      "Loss  0.44083813 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43028894 C_bot  0.15 k_c 0.0\n",
      "1448 Train Loss 12.267506\n",
      "Loss  0.43028894 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42764446 C_bot  0.15 k_c 0.0\n",
      "1449 Train Loss 12.258491\n",
      "Loss  0.42764446 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42890942 C_bot  0.15 k_c 0.0\n",
      "1450 Train Loss 12.25083\n",
      "Loss  0.42890942 C_bot  0.15 k_c 0.0\n",
      "Loss  0.420533 C_bot  0.15 k_c 0.0\n",
      "1451 Train Loss 12.237916\n",
      "Loss  0.420533 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4149819 C_bot  0.15 k_c 0.0\n",
      "1452 Train Loss 12.224678\n",
      "Loss  0.4149819 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41380316 C_bot  0.15 k_c 0.0\n",
      "1453 Train Loss 12.216351\n",
      "Loss  0.41380316 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4105828 C_bot  0.15 k_c 0.0\n",
      "1454 Train Loss 12.208455\n",
      "Loss  0.4105828 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40726277 C_bot  0.15 k_c 0.0\n",
      "1455 Train Loss 12.197033\n",
      "Loss  0.40726277 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40146446 C_bot  0.15 k_c 0.0\n",
      "1456 Train Loss 12.185787\n",
      "Loss  0.40146446 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39910695 C_bot  0.15 k_c 0.0\n",
      "1457 Train Loss 12.177839\n",
      "Loss  0.39910695 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3987161 C_bot  0.15 k_c 0.0\n",
      "1458 Train Loss 12.169979\n",
      "Loss  0.3987161 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39324585 C_bot  0.15 k_c 0.0\n",
      "1459 Train Loss 12.159972\n",
      "Loss  0.39324585 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3899038 C_bot  0.15 k_c 0.0\n",
      "1460 Train Loss 12.150122\n",
      "Loss  0.3899038 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38838476 C_bot  0.15 k_c 0.0\n",
      "1461 Train Loss 12.142374\n",
      "Loss  0.38838476 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38552287 C_bot  0.15 k_c 0.0\n",
      "1462 Train Loss 12.134948\n",
      "Loss  0.38552287 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38333985 C_bot  0.15 k_c 0.0\n",
      "1463 Train Loss 12.125942\n",
      "Loss  0.38333985 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37949288 C_bot  0.15 k_c 0.0\n",
      "1464 Train Loss 12.117076\n",
      "Loss  0.37949288 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3772765 C_bot  0.15 k_c 0.0\n",
      "1465 Train Loss 12.109642\n",
      "Loss  0.3772765 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37645593 C_bot  0.15 k_c 0.0\n",
      "1466 Train Loss 12.102472\n",
      "Loss  0.37645593 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37281516 C_bot  0.15 k_c 0.0\n",
      "1467 Train Loss 12.094418\n",
      "Loss  0.37281516 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37054044 C_bot  0.15 k_c 0.0\n",
      "1468 Train Loss 12.086285\n",
      "Loss  0.37054044 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36880594 C_bot  0.15 k_c 0.0\n",
      "1469 Train Loss 12.079116\n",
      "Loss  0.36880594 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36651358 C_bot  0.15 k_c 0.0\n",
      "1470 Train Loss 12.0722885\n",
      "Loss  0.36651358 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36515054 C_bot  0.15 k_c 0.0\n",
      "1471 Train Loss 12.064938\n",
      "Loss  0.36515054 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36229035 C_bot  0.15 k_c 0.0\n",
      "1472 Train Loss 12.057448\n",
      "Loss  0.36229035 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36046484 C_bot  0.15 k_c 0.0\n",
      "1473 Train Loss 12.050575\n",
      "Loss  0.36046484 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35942644 C_bot  0.15 k_c 0.0\n",
      "1474 Train Loss 12.043998\n",
      "Loss  0.35942644 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3570109 C_bot  0.15 k_c 0.0\n",
      "1475 Train Loss 12.037249\n",
      "Loss  0.3570109 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35546806 C_bot  0.15 k_c 0.0\n",
      "1476 Train Loss 12.030265\n",
      "Loss  0.35546806 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35369185 C_bot  0.15 k_c 0.0\n",
      "1477 Train Loss 12.02365\n",
      "Loss  0.35369185 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35196456 C_bot  0.15 k_c 0.0\n",
      "1478 Train Loss 12.01737\n",
      "Loss  0.35196456 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35092822 C_bot  0.15 k_c 0.0\n",
      "1479 Train Loss 12.010973\n",
      "Loss  0.35092822 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34883335 C_bot  0.15 k_c 0.0\n",
      "1480 Train Loss 12.004529\n",
      "Loss  0.34883335 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3473623 C_bot  0.15 k_c 0.0\n",
      "1481 Train Loss 11.998149\n",
      "Loss  0.3473623 C_bot  0.15 k_c 0.0\n",
      "Loss  0.346213 C_bot  0.15 k_c 0.0\n",
      "1482 Train Loss 11.9921055\n",
      "Loss  0.346213 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34450257 C_bot  0.15 k_c 0.0\n",
      "1483 Train Loss 11.986122\n",
      "Loss  0.34450257 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3434179 C_bot  0.15 k_c 0.0\n",
      "1484 Train Loss 11.980002\n",
      "Loss  0.3434179 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34171796 C_bot  0.15 k_c 0.0\n",
      "1485 Train Loss 11.973928\n",
      "Loss  0.34171796 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3403845 C_bot  0.15 k_c 0.0\n",
      "1486 Train Loss 11.968086\n",
      "Loss  0.3403845 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33946818 C_bot  0.15 k_c 0.0\n",
      "1487 Train Loss 11.962389\n",
      "Loss  0.33946818 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3378333 C_bot  0.15 k_c 0.0\n",
      "1488 Train Loss 11.956612\n",
      "Loss  0.3378333 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3367548 C_bot  0.15 k_c 0.0\n",
      "1489 Train Loss 11.950846\n",
      "Loss  0.3367548 C_bot  0.15 k_c 0.0\n",
      "Loss  0.335503 C_bot  0.15 k_c 0.0\n",
      "1490 Train Loss 11.945241\n",
      "Loss  0.335503 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3342128 C_bot  0.15 k_c 0.0\n",
      "1491 Train Loss 11.939726\n",
      "Loss  0.3342128 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3332712 C_bot  0.15 k_c 0.0\n",
      "1492 Train Loss 11.934195\n",
      "Loss  0.3332712 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3318699 C_bot  0.15 k_c 0.0\n",
      "1493 Train Loss 11.928734\n",
      "Loss  0.3318699 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3308249 C_bot  0.15 k_c 0.0\n",
      "1494 Train Loss 11.923314\n",
      "Loss  0.3308249 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32978848 C_bot  0.15 k_c 0.0\n",
      "1495 Train Loss 11.917997\n",
      "Loss  0.32978848 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32858744 C_bot  0.15 k_c 0.0\n",
      "1496 Train Loss 11.912784\n",
      "Loss  0.32858744 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3276628 C_bot  0.15 k_c 0.0\n",
      "1497 Train Loss 11.907487\n",
      "Loss  0.3276628 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3264741 C_bot  0.15 k_c 0.0\n",
      "1498 Train Loss 11.90232\n",
      "Loss  0.3264741 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32540983 C_bot  0.15 k_c 0.0\n",
      "1499 Train Loss 11.897142\n",
      "Loss  0.32540983 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32451817 C_bot  0.15 k_c 0.0\n",
      "1500 Train Loss 11.892092\n",
      "Loss  0.32451817 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32336235 C_bot  0.15 k_c 0.0\n",
      "1501 Train Loss 11.887077\n",
      "Loss  0.32336235 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3225101 C_bot  0.15 k_c 0.0\n",
      "1502 Train Loss 11.882071\n",
      "Loss  0.3225101 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32141614 C_bot  0.15 k_c 0.0\n",
      "1503 Train Loss 11.877092\n",
      "Loss  0.32141614 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3204675 C_bot  0.15 k_c 0.0\n",
      "1504 Train Loss 11.872231\n",
      "Loss  0.3204675 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31962293 C_bot  0.15 k_c 0.0\n",
      "1505 Train Loss 11.867372\n",
      "Loss  0.31962293 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31856516 C_bot  0.15 k_c 0.0\n",
      "1506 Train Loss 11.862578\n",
      "Loss  0.31856516 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31771952 C_bot  0.15 k_c 0.0\n",
      "1507 Train Loss 11.857771\n",
      "Loss  0.31771952 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3167788 C_bot  0.15 k_c 0.0\n",
      "1508 Train Loss 11.853048\n",
      "Loss  0.3167788 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31583658 C_bot  0.15 k_c 0.0\n",
      "1509 Train Loss 11.84836\n",
      "Loss  0.31583658 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31507888 C_bot  0.15 k_c 0.0\n",
      "1510 Train Loss 11.843731\n",
      "Loss  0.31507888 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3140912 C_bot  0.15 k_c 0.0\n",
      "1511 Train Loss 11.839124\n",
      "Loss  0.3140912 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31328183 C_bot  0.15 k_c 0.0\n",
      "1512 Train Loss 11.834524\n",
      "Loss  0.31328183 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3124087 C_bot  0.15 k_c 0.0\n",
      "1513 Train Loss 11.829976\n",
      "Loss  0.3124087 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31149888 C_bot  0.15 k_c 0.0\n",
      "1514 Train Loss 11.825467\n",
      "Loss  0.31149888 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31077316 C_bot  0.15 k_c 0.0\n",
      "1515 Train Loss 11.821011\n",
      "Loss  0.31077316 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30982655 C_bot  0.15 k_c 0.0\n",
      "1516 Train Loss 11.816553\n",
      "Loss  0.30982655 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30907238 C_bot  0.15 k_c 0.0\n",
      "1517 Train Loss 11.812162\n",
      "Loss  0.30907238 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30830416 C_bot  0.15 k_c 0.0\n",
      "1518 Train Loss 11.807832\n",
      "Loss  0.30830416 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30741727 C_bot  0.15 k_c 0.0\n",
      "1519 Train Loss 11.803473\n",
      "Loss  0.30741727 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30675715 C_bot  0.15 k_c 0.0\n",
      "1520 Train Loss 11.7992115\n",
      "Loss  0.30675715 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3058669 C_bot  0.15 k_c 0.0\n",
      "1521 Train Loss 11.794921\n",
      "Loss  0.3058669 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30510843 C_bot  0.15 k_c 0.0\n",
      "1522 Train Loss 11.790655\n",
      "Loss  0.30510843 C_bot  0.15 k_c 0.0\n",
      "Loss  0.304387 C_bot  0.15 k_c 0.0\n",
      "1523 Train Loss 11.786486\n",
      "Loss  0.304387 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30357602 C_bot  0.15 k_c 0.0\n",
      "1524 Train Loss 11.782314\n",
      "Loss  0.30357602 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30287227 C_bot  0.15 k_c 0.0\n",
      "1525 Train Loss 11.778137\n",
      "Loss  0.30287227 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3020838 C_bot  0.15 k_c 0.0\n",
      "1526 Train Loss 11.774054\n",
      "Loss  0.3020838 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30135515 C_bot  0.15 k_c 0.0\n",
      "1527 Train Loss 11.769937\n",
      "Loss  0.30135515 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3006506 C_bot  0.15 k_c 0.0\n",
      "1528 Train Loss 11.765896\n",
      "Loss  0.3006506 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29986268 C_bot  0.15 k_c 0.0\n",
      "1529 Train Loss 11.761857\n",
      "Loss  0.29986268 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29920304 C_bot  0.15 k_c 0.0\n",
      "1530 Train Loss 11.7578335\n",
      "Loss  0.29920304 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29845312 C_bot  0.15 k_c 0.0\n",
      "1531 Train Loss 11.753899\n",
      "Loss  0.29845312 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29775384 C_bot  0.15 k_c 0.0\n",
      "1532 Train Loss 11.749908\n",
      "Loss  0.29775384 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2970579 C_bot  0.15 k_c 0.0\n",
      "1533 Train Loss 11.7459955\n",
      "Loss  0.2970579 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29635793 C_bot  0.15 k_c 0.0\n",
      "1534 Train Loss 11.742128\n",
      "Loss  0.29635793 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29568973 C_bot  0.15 k_c 0.0\n",
      "1535 Train Loss 11.738222\n",
      "Loss  0.29568973 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29495633 C_bot  0.15 k_c 0.0\n",
      "1536 Train Loss 11.734384\n",
      "Loss  0.29495633 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2943162 C_bot  0.15 k_c 0.0\n",
      "1537 Train Loss 11.7305565\n",
      "Loss  0.2943162 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29361472 C_bot  0.15 k_c 0.0\n",
      "1538 Train Loss 11.726751\n",
      "Loss  0.29361472 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29292202 C_bot  0.15 k_c 0.0\n",
      "1539 Train Loss 11.7229595\n",
      "Loss  0.29292202 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29227996 C_bot  0.15 k_c 0.0\n",
      "1540 Train Loss 11.719204\n",
      "Loss  0.29227996 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2915692 C_bot  0.15 k_c 0.0\n",
      "1541 Train Loss 11.71546\n",
      "Loss  0.2915692 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2909621 C_bot  0.15 k_c 0.0\n",
      "1542 Train Loss 11.711771\n",
      "Loss  0.2909621 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29026285 C_bot  0.15 k_c 0.0\n",
      "1543 Train Loss 11.708057\n",
      "Loss  0.29026285 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28963324 C_bot  0.15 k_c 0.0\n",
      "1544 Train Loss 11.704409\n",
      "Loss  0.28963324 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2890033 C_bot  0.15 k_c 0.0\n",
      "1545 Train Loss 11.700771\n",
      "Loss  0.2890033 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2883446 C_bot  0.15 k_c 0.0\n",
      "1546 Train Loss 11.697148\n",
      "Loss  0.2883446 C_bot  0.15 k_c 0.0\n",
      "Loss  0.287718 C_bot  0.15 k_c 0.0\n",
      "1547 Train Loss 11.693538\n",
      "Loss  0.287718 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28703392 C_bot  0.15 k_c 0.0\n",
      "1548 Train Loss 11.689923\n",
      "Loss  0.28703392 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28642595 C_bot  0.15 k_c 0.0\n",
      "1549 Train Loss 11.686369\n",
      "Loss  0.28642595 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28580183 C_bot  0.15 k_c 0.0\n",
      "1550 Train Loss 11.682838\n",
      "Loss  0.28580183 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28518704 C_bot  0.15 k_c 0.0\n",
      "1551 Train Loss 11.679325\n",
      "Loss  0.28518704 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28455606 C_bot  0.15 k_c 0.0\n",
      "1552 Train Loss 11.6758\n",
      "Loss  0.28455606 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28397533 C_bot  0.15 k_c 0.0\n",
      "1553 Train Loss 11.672371\n",
      "Loss  0.28397533 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2833245 C_bot  0.15 k_c 0.0\n",
      "1554 Train Loss 11.668842\n",
      "Loss  0.2833245 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28266925 C_bot  0.15 k_c 0.0\n",
      "1555 Train Loss 11.665371\n",
      "Loss  0.28266925 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28207672 C_bot  0.15 k_c 0.0\n",
      "1556 Train Loss 11.661946\n",
      "Loss  0.28207672 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28148612 C_bot  0.15 k_c 0.0\n",
      "1557 Train Loss 11.658543\n",
      "Loss  0.28148612 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2808998 C_bot  0.15 k_c 0.0\n",
      "1558 Train Loss 11.655176\n",
      "Loss  0.2808998 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2803149 C_bot  0.15 k_c 0.0\n",
      "1559 Train Loss 11.651794\n",
      "Loss  0.2803149 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27968776 C_bot  0.15 k_c 0.0\n",
      "1560 Train Loss 11.64842\n",
      "Loss  0.27968776 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27914053 C_bot  0.15 k_c 0.0\n",
      "1561 Train Loss 11.645107\n",
      "Loss  0.27914053 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27849814 C_bot  0.15 k_c 0.0\n",
      "1562 Train Loss 11.641737\n",
      "Loss  0.27849814 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27794933 C_bot  0.15 k_c 0.0\n",
      "1563 Train Loss 11.638462\n",
      "Loss  0.27794933 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27734548 C_bot  0.15 k_c 0.0\n",
      "1564 Train Loss 11.635145\n",
      "Loss  0.27734548 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27677855 C_bot  0.15 k_c 0.0\n",
      "1565 Train Loss 11.631889\n",
      "Loss  0.27677855 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27620926 C_bot  0.15 k_c 0.0\n",
      "1566 Train Loss 11.628625\n",
      "Loss  0.27620926 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2755921 C_bot  0.15 k_c 0.0\n",
      "1567 Train Loss 11.625352\n",
      "Loss  0.2755921 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2750261 C_bot  0.15 k_c 0.0\n",
      "1568 Train Loss 11.622116\n",
      "Loss  0.2750261 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27440828 C_bot  0.15 k_c 0.0\n",
      "1569 Train Loss 11.61886\n",
      "Loss  0.27440828 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27383867 C_bot  0.15 k_c 0.0\n",
      "1570 Train Loss 11.615658\n",
      "Loss  0.27383867 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27331376 C_bot  0.15 k_c 0.0\n",
      "1571 Train Loss 11.612507\n",
      "Loss  0.27331376 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2727516 C_bot  0.15 k_c 0.0\n",
      "1572 Train Loss 11.6093445\n",
      "Loss  0.2727516 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27215394 C_bot  0.15 k_c 0.0\n",
      "1573 Train Loss 11.606149\n",
      "Loss  0.27215394 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27162614 C_bot  0.15 k_c 0.0\n",
      "1574 Train Loss 11.603035\n",
      "Loss  0.27162614 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2710241 C_bot  0.15 k_c 0.0\n",
      "1575 Train Loss 11.599869\n",
      "Loss  0.2710241 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27049926 C_bot  0.15 k_c 0.0\n",
      "1576 Train Loss 11.596774\n",
      "Loss  0.27049926 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2699036 C_bot  0.15 k_c 0.0\n",
      "1577 Train Loss 11.593637\n",
      "Loss  0.2699036 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26936996 C_bot  0.15 k_c 0.0\n",
      "1578 Train Loss 11.590563\n",
      "Loss  0.26936996 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26880673 C_bot  0.15 k_c 0.0\n",
      "1579 Train Loss 11.587477\n",
      "Loss  0.26880673 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26828045 C_bot  0.15 k_c 0.0\n",
      "1580 Train Loss 11.5844345\n",
      "Loss  0.26828045 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26773614 C_bot  0.15 k_c 0.0\n",
      "1581 Train Loss 11.581388\n",
      "Loss  0.26773614 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2671578 C_bot  0.15 k_c 0.0\n",
      "1582 Train Loss 11.578316\n",
      "Loss  0.2671578 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2666096 C_bot  0.15 k_c 0.0\n",
      "1583 Train Loss 11.575288\n",
      "Loss  0.2666096 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2660689 C_bot  0.15 k_c 0.0\n",
      "1584 Train Loss 11.572277\n",
      "Loss  0.2660689 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2655317 C_bot  0.15 k_c 0.0\n",
      "1585 Train Loss 11.569278\n",
      "Loss  0.2655317 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26500484 C_bot  0.15 k_c 0.0\n",
      "1586 Train Loss 11.566303\n",
      "Loss  0.26500484 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26442543 C_bot  0.15 k_c 0.0\n",
      "1587 Train Loss 11.56328\n",
      "Loss  0.26442543 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2639014 C_bot  0.15 k_c 0.0\n",
      "1588 Train Loss 11.560333\n",
      "Loss  0.2639014 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26337382 C_bot  0.15 k_c 0.0\n",
      "1589 Train Loss 11.557381\n",
      "Loss  0.26337382 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26282176 C_bot  0.15 k_c 0.0\n",
      "1590 Train Loss 11.554428\n",
      "Loss  0.26282176 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26226977 C_bot  0.15 k_c 0.0\n",
      "1591 Train Loss 11.551471\n",
      "Loss  0.26226977 C_bot  0.15 k_c 0.0\n",
      "Loss  0.261784 C_bot  0.15 k_c 0.0\n",
      "1592 Train Loss 11.548601\n",
      "Loss  0.261784 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26123393 C_bot  0.15 k_c 0.0\n",
      "1593 Train Loss 11.545673\n",
      "Loss  0.26123393 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26071772 C_bot  0.15 k_c 0.0\n",
      "1594 Train Loss 11.542786\n",
      "Loss  0.26071772 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26016673 C_bot  0.15 k_c 0.0\n",
      "1595 Train Loss 11.539877\n",
      "Loss  0.26016673 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25965735 C_bot  0.15 k_c 0.0\n",
      "1596 Train Loss 11.537016\n",
      "Loss  0.25965735 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2591296 C_bot  0.15 k_c 0.0\n",
      "1597 Train Loss 11.534151\n",
      "Loss  0.2591296 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25860426 C_bot  0.15 k_c 0.0\n",
      "1598 Train Loss 11.531288\n",
      "Loss  0.25860426 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25812754 C_bot  0.15 k_c 0.0\n",
      "1599 Train Loss 11.5285\n",
      "Loss  0.25812754 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25756496 C_bot  0.15 k_c 0.0\n",
      "1600 Train Loss 11.525618\n",
      "Loss  0.25756496 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25704435 C_bot  0.15 k_c 0.0\n",
      "1601 Train Loss 11.522799\n",
      "Loss  0.25704435 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2564805 C_bot  0.15 k_c 0.0\n",
      "1602 Train Loss 11.519939\n",
      "Loss  0.2564805 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25601223 C_bot  0.15 k_c 0.0\n",
      "1603 Train Loss 11.517185\n",
      "Loss  0.25601223 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25550812 C_bot  0.15 k_c 0.0\n",
      "1604 Train Loss 11.514406\n",
      "Loss  0.25550812 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2549852 C_bot  0.15 k_c 0.0\n",
      "1605 Train Loss 11.511616\n",
      "Loss  0.2549852 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25446582 C_bot  0.15 k_c 0.0\n",
      "1606 Train Loss 11.508835\n",
      "Loss  0.25446582 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25395697 C_bot  0.15 k_c 0.0\n",
      "1607 Train Loss 11.506078\n",
      "Loss  0.25395697 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25346115 C_bot  0.15 k_c 0.0\n",
      "1608 Train Loss 11.503342\n",
      "Loss  0.25346115 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25291303 C_bot  0.15 k_c 0.0\n",
      "1609 Train Loss 11.500557\n",
      "Loss  0.25291303 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25240803 C_bot  0.15 k_c 0.0\n",
      "1610 Train Loss 11.497833\n",
      "Loss  0.25240803 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25195292 C_bot  0.15 k_c 0.0\n",
      "1611 Train Loss 11.49515\n",
      "Loss  0.25195292 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25141028 C_bot  0.15 k_c 0.0\n",
      "1612 Train Loss 11.492418\n",
      "Loss  0.25141028 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25092664 C_bot  0.15 k_c 0.0\n",
      "1613 Train Loss 11.489708\n",
      "Loss  0.25092664 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25040346 C_bot  0.15 k_c 0.0\n",
      "1614 Train Loss 11.487021\n",
      "Loss  0.25040346 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24991871 C_bot  0.15 k_c 0.0\n",
      "1615 Train Loss 11.4843235\n",
      "Loss  0.24991871 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24935849 C_bot  0.15 k_c 0.0\n",
      "1616 Train Loss 11.481617\n",
      "Loss  0.24935849 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24892308 C_bot  0.15 k_c 0.0\n",
      "1617 Train Loss 11.478987\n",
      "Loss  0.24892308 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24841292 C_bot  0.15 k_c 0.0\n",
      "1618 Train Loss 11.476339\n",
      "Loss  0.24841292 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24794613 C_bot  0.15 k_c 0.0\n",
      "1619 Train Loss 11.4737\n",
      "Loss  0.24794613 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2474266 C_bot  0.15 k_c 0.0\n",
      "1620 Train Loss 11.471048\n",
      "Loss  0.2474266 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24694875 C_bot  0.15 k_c 0.0\n",
      "1621 Train Loss 11.468424\n",
      "Loss  0.24694875 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24644695 C_bot  0.15 k_c 0.0\n",
      "1622 Train Loss 11.465799\n",
      "Loss  0.24644695 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24593808 C_bot  0.15 k_c 0.0\n",
      "1623 Train Loss 11.463167\n",
      "Loss  0.24593808 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2454742 C_bot  0.15 k_c 0.0\n",
      "1624 Train Loss 11.460583\n",
      "Loss  0.2454742 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24492897 C_bot  0.15 k_c 0.0\n",
      "1625 Train Loss 11.457941\n",
      "Loss  0.24492897 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24450903 C_bot  0.15 k_c 0.0\n",
      "1626 Train Loss 11.455404\n",
      "Loss  0.24450903 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24400336 C_bot  0.15 k_c 0.0\n",
      "1627 Train Loss 11.452826\n",
      "Loss  0.24400336 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24353518 C_bot  0.15 k_c 0.0\n",
      "1628 Train Loss 11.450245\n",
      "Loss  0.24353518 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24302381 C_bot  0.15 k_c 0.0\n",
      "1629 Train Loss 11.447688\n",
      "Loss  0.24302381 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24255612 C_bot  0.15 k_c 0.0\n",
      "1630 Train Loss 11.445109\n",
      "Loss  0.24255612 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24204798 C_bot  0.15 k_c 0.0\n",
      "1631 Train Loss 11.442577\n",
      "Loss  0.24204798 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24161221 C_bot  0.15 k_c 0.0\n",
      "1632 Train Loss 11.440046\n",
      "Loss  0.24161221 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24109332 C_bot  0.15 k_c 0.0\n",
      "1633 Train Loss 11.437505\n",
      "Loss  0.24109332 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24064535 C_bot  0.15 k_c 0.0\n",
      "1634 Train Loss 11.434987\n",
      "Loss  0.24064535 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2401527 C_bot  0.15 k_c 0.0\n",
      "1635 Train Loss 11.432481\n",
      "Loss  0.2401527 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23970789 C_bot  0.15 k_c 0.0\n",
      "1636 Train Loss 11.429981\n",
      "Loss  0.23970789 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23919967 C_bot  0.15 k_c 0.0\n",
      "1637 Train Loss 11.427473\n",
      "Loss  0.23919967 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23873924 C_bot  0.15 k_c 0.0\n",
      "1638 Train Loss 11.424968\n",
      "Loss  0.23873924 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23825713 C_bot  0.15 k_c 0.0\n",
      "1639 Train Loss 11.4225025\n",
      "Loss  0.23825713 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2378041 C_bot  0.15 k_c 0.0\n",
      "1640 Train Loss 11.420013\n",
      "Loss  0.2378041 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23732065 C_bot  0.15 k_c 0.0\n",
      "1641 Train Loss 11.417564\n",
      "Loss  0.23732065 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2368845 C_bot  0.15 k_c 0.0\n",
      "1642 Train Loss 11.415101\n",
      "Loss  0.2368845 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23636067 C_bot  0.15 k_c 0.0\n",
      "1643 Train Loss 11.412625\n",
      "Loss  0.23636067 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23592004 C_bot  0.15 k_c 0.0\n",
      "1644 Train Loss 11.410177\n",
      "Loss  0.23592004 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23542163 C_bot  0.15 k_c 0.0\n",
      "1645 Train Loss 11.407729\n",
      "Loss  0.23542163 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23500001 C_bot  0.15 k_c 0.0\n",
      "1646 Train Loss 11.405319\n",
      "Loss  0.23500001 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23454286 C_bot  0.15 k_c 0.0\n",
      "1647 Train Loss 11.402924\n",
      "Loss  0.23454286 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23406042 C_bot  0.15 k_c 0.0\n",
      "1648 Train Loss 11.400458\n",
      "Loss  0.23406042 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23358564 C_bot  0.15 k_c 0.0\n",
      "1649 Train Loss 11.398066\n",
      "Loss  0.23358564 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23315324 C_bot  0.15 k_c 0.0\n",
      "1650 Train Loss 11.395655\n",
      "Loss  0.23315324 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23268263 C_bot  0.15 k_c 0.0\n",
      "1651 Train Loss 11.393286\n",
      "Loss  0.23268263 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23226145 C_bot  0.15 k_c 0.0\n",
      "1652 Train Loss 11.390888\n",
      "Loss  0.23226145 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23174995 C_bot  0.15 k_c 0.0\n",
      "1653 Train Loss 11.388504\n",
      "Loss  0.23174995 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23138537 C_bot  0.15 k_c 0.0\n",
      "1654 Train Loss 11.386158\n",
      "Loss  0.23138537 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23087086 C_bot  0.15 k_c 0.0\n",
      "1655 Train Loss 11.3838005\n",
      "Loss  0.23087086 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2304916 C_bot  0.15 k_c 0.0\n",
      "1656 Train Loss 11.38143\n",
      "Loss  0.2304916 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22996789 C_bot  0.15 k_c 0.0\n",
      "1657 Train Loss 11.379101\n",
      "Loss  0.22996789 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2296093 C_bot  0.15 k_c 0.0\n",
      "1658 Train Loss 11.376727\n",
      "Loss  0.2296093 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22905062 C_bot  0.15 k_c 0.0\n",
      "1659 Train Loss 11.374418\n",
      "Loss  0.22905062 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22878656 C_bot  0.15 k_c 0.0\n",
      "1660 Train Loss 11.372092\n",
      "Loss  0.22878656 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2281337 C_bot  0.15 k_c 0.0\n",
      "1661 Train Loss 11.369783\n",
      "Loss  0.2281337 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22804455 C_bot  0.15 k_c 0.0\n",
      "1662 Train Loss 11.367531\n",
      "Loss  0.22804455 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22734708 C_bot  0.15 k_c 0.0\n",
      "1663 Train Loss 11.365332\n",
      "Loss  0.22734708 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22747019 C_bot  0.15 k_c 0.0\n",
      "1664 Train Loss 11.363115\n",
      "Loss  0.22747019 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22667886 C_bot  0.15 k_c 0.0\n",
      "1665 Train Loss 11.361076\n",
      "Loss  0.22667886 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22739923 C_bot  0.15 k_c 0.0\n",
      "1666 Train Loss 11.359149\n",
      "Loss  0.22739923 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22670898 C_bot  0.15 k_c 0.0\n",
      "1667 Train Loss 11.357645\n",
      "Loss  0.22670898 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22874235 C_bot  0.15 k_c 0.0\n",
      "1668 Train Loss 11.356487\n",
      "Loss  0.22874235 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22870812 C_bot  0.15 k_c 0.0\n",
      "1669 Train Loss 11.356386\n",
      "Loss  0.22870812 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23428778 C_bot  0.15 k_c 0.0\n",
      "1670 Train Loss 11.357807\n",
      "Loss  0.23428778 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2375872 C_bot  0.15 k_c 0.0\n",
      "1671 Train Loss 11.362379\n",
      "Loss  0.2375872 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25314525 C_bot  0.15 k_c 0.0\n",
      "1672 Train Loss 11.372015\n",
      "Loss  0.25314525 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2695594 C_bot  0.15 k_c 0.0\n",
      "1673 Train Loss 11.392157\n",
      "Loss  0.2695594 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31679487 C_bot  0.15 k_c 0.0\n",
      "1674 Train Loss 11.430223\n",
      "Loss  0.31679487 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38244507 C_bot  0.15 k_c 0.0\n",
      "1675 Train Loss 11.5042095\n",
      "Loss  0.38244507 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5363003 C_bot  0.15 k_c 0.0\n",
      "1676 Train Loss 11.6428585\n",
      "Loss  0.5363003 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7866442 C_bot  0.15 k_c 0.0\n",
      "1677 Train Loss 11.910403\n",
      "Loss  0.7866442 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3197721 C_bot  0.15 k_c 0.0\n",
      "1678 Train Loss 12.417034\n",
      "Loss  1.3197721 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2740705 C_bot  0.15 k_c 0.0\n",
      "1679 Train Loss 13.406172\n",
      "Loss  2.2740705 C_bot  0.15 k_c 0.0\n",
      "Loss  4.212872 C_bot  0.15 k_c 0.0\n",
      "1680 Train Loss 15.297486\n",
      "Loss  4.212872 C_bot  0.15 k_c 0.0\n",
      "Loss  7.900349 C_bot  0.15 k_c 0.0\n",
      "1681 Train Loss 19.05655\n",
      "Loss  7.900349 C_bot  0.15 k_c 0.0\n",
      "Loss  15.184869 C_bot  0.15 k_c 0.0\n",
      "1682 Train Loss 26.255762\n",
      "Loss  15.184869 C_bot  0.15 k_c 0.0\n",
      "Loss  29.619028 C_bot  0.15 k_c 0.0\n",
      "1683 Train Loss 40.8436\n",
      "Loss  29.619028 C_bot  0.15 k_c 0.0\n",
      "Loss  57.04299 C_bot  0.15 k_c 0.0\n",
      "1684 Train Loss 68.118935\n",
      "Loss  57.04299 C_bot  0.15 k_c 0.0\n",
      "Loss  112.27033 C_bot  0.15 k_c 0.0\n",
      "1685 Train Loss 123.701675\n",
      "Loss  112.27033 C_bot  0.15 k_c 0.0\n",
      "Loss  205.98619 C_bot  0.15 k_c 0.0\n",
      "1686 Train Loss 217.16841\n",
      "Loss  205.98619 C_bot  0.15 k_c 0.0\n",
      "Loss  382.11768 C_bot  0.15 k_c 0.0\n",
      "1687 Train Loss 394.17255\n",
      "Loss  382.11768 C_bot  0.15 k_c 0.0\n",
      "Loss  576.22644 C_bot  0.15 k_c 0.0\n",
      "1688 Train Loss 587.7521\n",
      "Loss  576.22644 C_bot  0.15 k_c 0.0\n",
      "Loss  799.847 C_bot  0.15 k_c 0.0\n",
      "1689 Train Loss 813.0989\n",
      "Loss  799.847 C_bot  0.15 k_c 0.0\n",
      "Loss  665.3089 C_bot  0.15 k_c 0.0\n",
      "1690 Train Loss 676.9966\n",
      "Loss  665.3089 C_bot  0.15 k_c 0.0\n",
      "Loss  319.87576 C_bot  0.15 k_c 0.0\n",
      "1691 Train Loss 332.77817\n",
      "Loss  319.87576 C_bot  0.15 k_c 0.0\n",
      "Loss  18.128971 C_bot  0.15 k_c 0.0\n",
      "1692 Train Loss 30.160524\n",
      "Loss  18.128971 C_bot  0.15 k_c 0.0\n",
      "Loss  112.70006 C_bot  0.15 k_c 0.0\n",
      "1693 Train Loss 124.92483\n",
      "Loss  112.70006 C_bot  0.15 k_c 0.0\n",
      "Loss  344.21857 C_bot  0.15 k_c 0.0\n",
      "1694 Train Loss 358.52942\n",
      "Loss  344.21857 C_bot  0.15 k_c 0.0\n",
      "Loss  257.46576 C_bot  0.15 k_c 0.0\n",
      "1695 Train Loss 270.17026\n",
      "Loss  257.46576 C_bot  0.15 k_c 0.0\n",
      "Loss  36.28243 C_bot  0.15 k_c 0.0\n",
      "1696 Train Loss 50.006115\n",
      "Loss  36.28243 C_bot  0.15 k_c 0.0\n",
      "Loss  47.14997 C_bot  0.15 k_c 0.0\n",
      "1697 Train Loss 61.10783\n",
      "Loss  47.14997 C_bot  0.15 k_c 0.0\n",
      "Loss  197.83563 C_bot  0.15 k_c 0.0\n",
      "1698 Train Loss 210.9116\n",
      "Loss  197.83563 C_bot  0.15 k_c 0.0\n",
      "Loss  170.66823 C_bot  0.15 k_c 0.0\n",
      "1699 Train Loss 185.27933\n",
      "Loss  170.66823 C_bot  0.15 k_c 0.0\n",
      "Loss  21.332218 C_bot  0.15 k_c 0.0\n",
      "1700 Train Loss 34.686314\n",
      "Loss  21.332218 C_bot  0.15 k_c 0.0\n",
      "Loss  41.63256 C_bot  0.15 k_c 0.0\n",
      "1701 Train Loss 54.870556\n",
      "Loss  41.63256 C_bot  0.15 k_c 0.0\n",
      "Loss  139.40788 C_bot  0.15 k_c 0.0\n",
      "1702 Train Loss 153.61\n",
      "Loss  139.40788 C_bot  0.15 k_c 0.0\n",
      "Loss  83.20028 C_bot  0.15 k_c 0.0\n",
      "1703 Train Loss 96.274956\n",
      "Loss  83.20028 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5922987 C_bot  0.15 k_c 0.0\n",
      "1704 Train Loss 15.880383\n",
      "Loss  2.5922987 C_bot  0.15 k_c 0.0\n",
      "Loss  49.16017 C_bot  0.15 k_c 0.0\n",
      "1705 Train Loss 62.6574\n",
      "Loss  49.16017 C_bot  0.15 k_c 0.0\n",
      "Loss  87.306915 C_bot  0.15 k_c 0.0\n",
      "1706 Train Loss 100.24046\n",
      "Loss  87.306915 C_bot  0.15 k_c 0.0\n",
      "Loss  29.60379 C_bot  0.15 k_c 0.0\n",
      "1707 Train Loss 42.832317\n",
      "Loss  29.60379 C_bot  0.15 k_c 0.0\n",
      "Loss  4.4148326 C_bot  0.15 k_c 0.0\n",
      "1708 Train Loss 17.4231\n",
      "Loss  4.4148326 C_bot  0.15 k_c 0.0\n",
      "Loss  51.12763 C_bot  0.15 k_c 0.0\n",
      "1709 Train Loss 63.933487\n",
      "Loss  51.12763 C_bot  0.15 k_c 0.0\n",
      "Loss  50.36089 C_bot  0.15 k_c 0.0\n",
      "1710 Train Loss 63.439625\n",
      "Loss  50.36089 C_bot  0.15 k_c 0.0\n",
      "Loss  5.325988 C_bot  0.15 k_c 0.0\n",
      "1711 Train Loss 18.07919\n",
      "Loss  5.325988 C_bot  0.15 k_c 0.0\n",
      "Loss  16.222807 C_bot  0.15 k_c 0.0\n",
      "1712 Train Loss 28.907047\n",
      "Loss  16.222807 C_bot  0.15 k_c 0.0\n",
      "Loss  43.603386 C_bot  0.15 k_c 0.0\n",
      "1713 Train Loss 56.498325\n",
      "Loss  43.603386 C_bot  0.15 k_c 0.0\n",
      "Loss  19.555742 C_bot  0.15 k_c 0.0\n",
      "1714 Train Loss 32.11956\n",
      "Loss  19.555742 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7999277 C_bot  0.15 k_c 0.0\n",
      "1715 Train Loss 14.3539\n",
      "Loss  1.7999277 C_bot  0.15 k_c 0.0\n",
      "Loss  23.068785 C_bot  0.15 k_c 0.0\n",
      "1716 Train Loss 35.734657\n",
      "Loss  23.068785 C_bot  0.15 k_c 0.0\n",
      "Loss  25.634697 C_bot  0.15 k_c 0.0\n",
      "1717 Train Loss 38.013294\n",
      "Loss  25.634697 C_bot  0.15 k_c 0.0\n",
      "Loss  4.2388086 C_bot  0.15 k_c 0.0\n",
      "1718 Train Loss 16.719486\n",
      "Loss  4.2388086 C_bot  0.15 k_c 0.0\n",
      "Loss  6.7010736 C_bot  0.15 k_c 0.0\n",
      "1719 Train Loss 19.170433\n",
      "Loss  6.7010736 C_bot  0.15 k_c 0.0\n",
      "Loss  20.36987 C_bot  0.15 k_c 0.0\n",
      "1720 Train Loss 32.63182\n",
      "Loss  20.36987 C_bot  0.15 k_c 0.0\n",
      "Loss  10.905742 C_bot  0.15 k_c 0.0\n",
      "1721 Train Loss 23.354263\n",
      "Loss  10.905742 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1231616 C_bot  0.15 k_c 0.0\n",
      "1722 Train Loss 13.443079\n",
      "Loss  1.1231616 C_bot  0.15 k_c 0.0\n",
      "Loss  10.586474 C_bot  0.15 k_c 0.0\n",
      "1723 Train Loss 22.796234\n",
      "Loss  10.586474 C_bot  0.15 k_c 0.0\n",
      "Loss  13.172383 C_bot  0.15 k_c 0.0\n",
      "1724 Train Loss 25.575474\n",
      "Loss  13.172383 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9258552 C_bot  0.15 k_c 0.0\n",
      "1725 Train Loss 15.131596\n",
      "Loss  2.9258552 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2403195 C_bot  0.15 k_c 0.0\n",
      "1726 Train Loss 15.420023\n",
      "Loss  3.2403195 C_bot  0.15 k_c 0.0\n",
      "Loss  10.061733 C_bot  0.15 k_c 0.0\n",
      "1727 Train Loss 22.374174\n",
      "Loss  10.061733 C_bot  0.15 k_c 0.0\n",
      "Loss  6.0387945 C_bot  0.15 k_c 0.0\n",
      "1728 Train Loss 18.15904\n",
      "Loss  6.0387945 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8804298 C_bot  0.15 k_c 0.0\n",
      "1729 Train Loss 13.039911\n",
      "Loss  0.8804298 C_bot  0.15 k_c 0.0\n",
      "Loss  5.0846415 C_bot  0.15 k_c 0.0\n",
      "1730 Train Loss 17.290302\n",
      "Loss  5.0846415 C_bot  0.15 k_c 0.0\n",
      "Loss  6.8072453 C_bot  0.15 k_c 0.0\n",
      "1731 Train Loss 18.871077\n",
      "Loss  6.8072453 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9137472 C_bot  0.15 k_c 0.0\n",
      "1732 Train Loss 14.041903\n",
      "Loss  1.9137472 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6545299 C_bot  0.15 k_c 0.0\n",
      "1733 Train Loss 13.758402\n",
      "Loss  1.6545299 C_bot  0.15 k_c 0.0\n",
      "Loss  5.0901365 C_bot  0.15 k_c 0.0\n",
      "1734 Train Loss 17.111221\n",
      "Loss  5.0901365 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4590902 C_bot  0.15 k_c 0.0\n",
      "1735 Train Loss 15.54084\n",
      "Loss  3.4590902 C_bot  0.15 k_c 0.0\n",
      "Loss  0.78983754 C_bot  0.15 k_c 0.0\n",
      "1736 Train Loss 12.809214\n",
      "Loss  0.78983754 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5962803 C_bot  0.15 k_c 0.0\n",
      "1737 Train Loss 14.574069\n",
      "Loss  2.5962803 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7037306 C_bot  0.15 k_c 0.0\n",
      "1738 Train Loss 15.72391\n",
      "Loss  3.7037306 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5076611 C_bot  0.15 k_c 0.0\n",
      "1739 Train Loss 13.454786\n",
      "Loss  1.5076611 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9892312 C_bot  0.15 k_c 0.0\n",
      "1740 Train Loss 12.923181\n",
      "Loss  0.9892312 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6291468 C_bot  0.15 k_c 0.0\n",
      "1741 Train Loss 14.581475\n",
      "Loss  2.6291468 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2419713 C_bot  0.15 k_c 0.0\n",
      "1742 Train Loss 14.125557\n",
      "Loss  2.2419713 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7507891 C_bot  0.15 k_c 0.0\n",
      "1743 Train Loss 12.639803\n",
      "Loss  0.7507891 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3261017 C_bot  0.15 k_c 0.0\n",
      "1744 Train Loss 13.207504\n",
      "Loss  1.3261017 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1635804 C_bot  0.15 k_c 0.0\n",
      "1745 Train Loss 13.989553\n",
      "Loss  2.1635804 C_bot  0.15 k_c 0.0\n",
      "Loss  1.231286 C_bot  0.15 k_c 0.0\n",
      "1746 Train Loss 13.075644\n",
      "Loss  1.231286 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6952611 C_bot  0.15 k_c 0.0\n",
      "1747 Train Loss 12.5099125\n",
      "Loss  0.6952611 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4635935 C_bot  0.15 k_c 0.0\n",
      "1748 Train Loss 13.2418995\n",
      "Loss  1.4635935 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5352813 C_bot  0.15 k_c 0.0\n",
      "1749 Train Loss 13.335035\n",
      "Loss  1.5352813 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8072434 C_bot  0.15 k_c 0.0\n",
      "1750 Train Loss 12.564178\n",
      "Loss  0.8072434 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8244682 C_bot  0.15 k_c 0.0\n",
      "1751 Train Loss 12.566905\n",
      "Loss  0.8244682 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3140483 C_bot  0.15 k_c 0.0\n",
      "1752 Train Loss 13.069189\n",
      "Loss  1.3140483 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1113261 C_bot  0.15 k_c 0.0\n",
      "1753 Train Loss 12.822054\n",
      "Loss  1.1113261 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6615398 C_bot  0.15 k_c 0.0\n",
      "1754 Train Loss 12.374584\n",
      "Loss  0.6615398 C_bot  0.15 k_c 0.0\n",
      "Loss  0.877097 C_bot  0.15 k_c 0.0\n",
      "1755 Train Loss 12.586269\n",
      "Loss  0.877097 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1347888 C_bot  0.15 k_c 0.0\n",
      "1756 Train Loss 12.807689\n",
      "Loss  1.1347888 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8181198 C_bot  0.15 k_c 0.0\n",
      "1757 Train Loss 12.50192\n",
      "Loss  0.8181198 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6456724 C_bot  0.15 k_c 0.0\n",
      "1758 Train Loss 12.310398\n",
      "Loss  0.6456724 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8848124 C_bot  0.15 k_c 0.0\n",
      "1759 Train Loss 12.526947\n",
      "Loss  0.8848124 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9166374 C_bot  0.15 k_c 0.0\n",
      "1760 Train Loss 12.568599\n",
      "Loss  0.9166374 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69304997 C_bot  0.15 k_c 0.0\n",
      "1761 Train Loss 12.318152\n",
      "Loss  0.69304997 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65720975 C_bot  0.15 k_c 0.0\n",
      "1762 Train Loss 12.273303\n",
      "Loss  0.65720975 C_bot  0.15 k_c 0.0\n",
      "Loss  0.81011707 C_bot  0.15 k_c 0.0\n",
      "1763 Train Loss 12.42813\n",
      "Loss  0.81011707 C_bot  0.15 k_c 0.0\n",
      "Loss  0.79040617 C_bot  0.15 k_c 0.0\n",
      "1764 Train Loss 12.382277\n",
      "Loss  0.79040617 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62397027 C_bot  0.15 k_c 0.0\n",
      "1765 Train Loss 12.215577\n",
      "Loss  0.62397027 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6502504 C_bot  0.15 k_c 0.0\n",
      "1766 Train Loss 12.233919\n",
      "Loss  0.6502504 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7586347 C_bot  0.15 k_c 0.0\n",
      "1767 Train Loss 12.322458\n",
      "Loss  0.7586347 C_bot  0.15 k_c 0.0\n",
      "Loss  0.686998 C_bot  0.15 k_c 0.0\n",
      "1768 Train Loss 12.253686\n",
      "Loss  0.686998 C_bot  0.15 k_c 0.0\n",
      "Loss  0.60154814 C_bot  0.15 k_c 0.0\n",
      "1769 Train Loss 12.15319\n",
      "Loss  0.60154814 C_bot  0.15 k_c 0.0\n",
      "Loss  0.64729166 C_bot  0.15 k_c 0.0\n",
      "1770 Train Loss 12.18722\n",
      "Loss  0.64729166 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68961495 C_bot  0.15 k_c 0.0\n",
      "1771 Train Loss 12.230198\n",
      "Loss  0.68961495 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6412993 C_bot  0.15 k_c 0.0\n",
      "1772 Train Loss 12.164257\n",
      "Loss  0.6412993 C_bot  0.15 k_c 0.0\n",
      "Loss  0.588677 C_bot  0.15 k_c 0.0\n",
      "1773 Train Loss 12.10685\n",
      "Loss  0.588677 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62386614 C_bot  0.15 k_c 0.0\n",
      "1774 Train Loss 12.13747\n",
      "Loss  0.62386614 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65491325 C_bot  0.15 k_c 0.0\n",
      "1775 Train Loss 12.152681\n",
      "Loss  0.65491325 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6031821 C_bot  0.15 k_c 0.0\n",
      "1776 Train Loss 12.099926\n",
      "Loss  0.6031821 C_bot  0.15 k_c 0.0\n",
      "Loss  0.57971764 C_bot  0.15 k_c 0.0\n",
      "1777 Train Loss 12.066431\n",
      "Loss  0.57971764 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6120165 C_bot  0.15 k_c 0.0\n",
      "1778 Train Loss 12.087584\n",
      "Loss  0.6120165 C_bot  0.15 k_c 0.0\n",
      "Loss  0.61519486 C_bot  0.15 k_c 0.0\n",
      "1779 Train Loss 12.089898\n",
      "Loss  0.61519486 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5879859 C_bot  0.15 k_c 0.0\n",
      "1780 Train Loss 12.049767\n",
      "Loss  0.5879859 C_bot  0.15 k_c 0.0\n",
      "Loss  0.57285595 C_bot  0.15 k_c 0.0\n",
      "1781 Train Loss 12.028749\n",
      "Loss  0.57285595 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5893494 C_bot  0.15 k_c 0.0\n",
      "1782 Train Loss 12.041437\n",
      "Loss  0.5893494 C_bot  0.15 k_c 0.0\n",
      "Loss  0.59811705 C_bot  0.15 k_c 0.0\n",
      "1783 Train Loss 12.0377865\n",
      "Loss  0.59811705 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5711801 C_bot  0.15 k_c 0.0\n",
      "1784 Train Loss 12.008436\n",
      "Loss  0.5711801 C_bot  0.15 k_c 0.0\n",
      "Loss  0.56368244 C_bot  0.15 k_c 0.0\n",
      "1785 Train Loss 11.993378\n",
      "Loss  0.56368244 C_bot  0.15 k_c 0.0\n",
      "Loss  0.57889634 C_bot  0.15 k_c 0.0\n",
      "1786 Train Loss 11.9993515\n",
      "Loss  0.57889634 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5756188 C_bot  0.15 k_c 0.0\n",
      "1787 Train Loss 11.994184\n",
      "Loss  0.5756188 C_bot  0.15 k_c 0.0\n",
      "Loss  0.56341577 C_bot  0.15 k_c 0.0\n",
      "1788 Train Loss 11.972155\n",
      "Loss  0.56341577 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5567001 C_bot  0.15 k_c 0.0\n",
      "1789 Train Loss 11.960045\n",
      "Loss  0.5567001 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5620914 C_bot  0.15 k_c 0.0\n",
      "1790 Train Loss 11.961676\n",
      "Loss  0.5620914 C_bot  0.15 k_c 0.0\n",
      "Loss  0.56580037 C_bot  0.15 k_c 0.0\n",
      "1791 Train Loss 11.955913\n",
      "Loss  0.56580037 C_bot  0.15 k_c 0.0\n",
      "Loss  0.55213976 C_bot  0.15 k_c 0.0\n",
      "1792 Train Loss 11.939369\n",
      "Loss  0.55213976 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5477325 C_bot  0.15 k_c 0.0\n",
      "1793 Train Loss 11.928587\n",
      "Loss  0.5477325 C_bot  0.15 k_c 0.0\n",
      "Loss  0.55340016 C_bot  0.15 k_c 0.0\n",
      "1794 Train Loss 11.927025\n",
      "Loss  0.55340016 C_bot  0.15 k_c 0.0\n",
      "Loss  0.55077016 C_bot  0.15 k_c 0.0\n",
      "1795 Train Loss 11.921764\n",
      "Loss  0.55077016 C_bot  0.15 k_c 0.0\n",
      "Loss  0.54558975 C_bot  0.15 k_c 0.0\n",
      "1796 Train Loss 11.908751\n",
      "Loss  0.54558975 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5402643 C_bot  0.15 k_c 0.0\n",
      "1797 Train Loss 11.898817\n",
      "Loss  0.5402643 C_bot  0.15 k_c 0.0\n",
      "Loss  0.54101396 C_bot  0.15 k_c 0.0\n",
      "1798 Train Loss 11.89548\n",
      "Loss  0.54101396 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5433609 C_bot  0.15 k_c 0.0\n",
      "1799 Train Loss 11.8903885\n",
      "Loss  0.5433609 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5362256 C_bot  0.15 k_c 0.0\n",
      "1800 Train Loss 11.880188\n",
      "Loss  0.5362256 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5327728 C_bot  0.15 k_c 0.0\n",
      "1801 Train Loss 11.870892\n",
      "Loss  0.5327728 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5337522 C_bot  0.15 k_c 0.0\n",
      "1802 Train Loss 11.866159\n",
      "Loss  0.5337522 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5321594 C_bot  0.15 k_c 0.0\n",
      "1803 Train Loss 11.86138\n",
      "Loss  0.5321594 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5303514 C_bot  0.15 k_c 0.0\n",
      "1804 Train Loss 11.852945\n",
      "Loss  0.5303514 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5258054 C_bot  0.15 k_c 0.0\n",
      "1805 Train Loss 11.844427\n",
      "Loss  0.5258054 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5246721 C_bot  0.15 k_c 0.0\n",
      "1806 Train Loss 11.838881\n",
      "Loss  0.5246721 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5258352 C_bot  0.15 k_c 0.0\n",
      "1807 Train Loss 11.834028\n",
      "Loss  0.5258352 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5221484 C_bot  0.15 k_c 0.0\n",
      "1808 Train Loss 11.827127\n",
      "Loss  0.5221484 C_bot  0.15 k_c 0.0\n",
      "Loss  0.51988125 C_bot  0.15 k_c 0.0\n",
      "1809 Train Loss 11.8193\n",
      "Loss  0.51988125 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5184655 C_bot  0.15 k_c 0.0\n",
      "1810 Train Loss 11.813232\n",
      "Loss  0.5184655 C_bot  0.15 k_c 0.0\n",
      "Loss  0.51717615 C_bot  0.15 k_c 0.0\n",
      "1811 Train Loss 11.8082695\n",
      "Loss  0.51717615 C_bot  0.15 k_c 0.0\n",
      "Loss  0.51682335 C_bot  0.15 k_c 0.0\n",
      "1812 Train Loss 11.802193\n",
      "Loss  0.51682335 C_bot  0.15 k_c 0.0\n",
      "Loss  0.51336634 C_bot  0.15 k_c 0.0\n",
      "1813 Train Loss 11.795176\n",
      "Loss  0.51336634 C_bot  0.15 k_c 0.0\n",
      "Loss  0.511802 C_bot  0.15 k_c 0.0\n",
      "1814 Train Loss 11.788963\n",
      "Loss  0.511802 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5115085 C_bot  0.15 k_c 0.0\n",
      "1815 Train Loss 11.783749\n",
      "Loss  0.5115085 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5094542 C_bot  0.15 k_c 0.0\n",
      "1816 Train Loss 11.778286\n",
      "Loss  0.5094542 C_bot  0.15 k_c 0.0\n",
      "Loss  0.50831836 C_bot  0.15 k_c 0.0\n",
      "1817 Train Loss 11.771977\n",
      "Loss  0.50831836 C_bot  0.15 k_c 0.0\n",
      "Loss  0.50602764 C_bot  0.15 k_c 0.0\n",
      "1818 Train Loss 11.765827\n",
      "Loss  0.50602764 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5046673 C_bot  0.15 k_c 0.0\n",
      "1819 Train Loss 11.760471\n",
      "Loss  0.5046673 C_bot  0.15 k_c 0.0\n",
      "Loss  0.50433457 C_bot  0.15 k_c 0.0\n",
      "1820 Train Loss 11.755302\n",
      "Loss  0.50433457 C_bot  0.15 k_c 0.0\n",
      "Loss  0.50201005 C_bot  0.15 k_c 0.0\n",
      "1821 Train Loss 11.749623\n",
      "Loss  0.50201005 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5006838 C_bot  0.15 k_c 0.0\n",
      "1822 Train Loss 11.743703\n",
      "Loss  0.5006838 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4992197 C_bot  0.15 k_c 0.0\n",
      "1823 Train Loss 11.738251\n",
      "Loss  0.4992197 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49770266 C_bot  0.15 k_c 0.0\n",
      "1824 Train Loss 11.733128\n",
      "Loss  0.49770266 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49702352 C_bot  0.15 k_c 0.0\n",
      "1825 Train Loss 11.727879\n",
      "Loss  0.49702352 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4948614 C_bot  0.15 k_c 0.0\n",
      "1826 Train Loss 11.722331\n",
      "Loss  0.4948614 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49356017 C_bot  0.15 k_c 0.0\n",
      "1827 Train Loss 11.716921\n",
      "Loss  0.49356017 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49246183 C_bot  0.15 k_c 0.0\n",
      "1828 Train Loss 11.71183\n",
      "Loss  0.49246183 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49084625 C_bot  0.15 k_c 0.0\n",
      "1829 Train Loss 11.706833\n",
      "Loss  0.49084625 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48991612 C_bot  0.15 k_c 0.0\n",
      "1830 Train Loss 11.701647\n",
      "Loss  0.48991612 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48806018 C_bot  0.15 k_c 0.0\n",
      "1831 Train Loss 11.696389\n",
      "Loss  0.48806018 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4867887 C_bot  0.15 k_c 0.0\n",
      "1832 Train Loss 11.691362\n",
      "Loss  0.4867887 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48572573 C_bot  0.15 k_c 0.0\n",
      "1833 Train Loss 11.686409\n",
      "Loss  0.48572573 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4841037 C_bot  0.15 k_c 0.0\n",
      "1834 Train Loss 11.681524\n",
      "Loss  0.4841037 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48302573 C_bot  0.15 k_c 0.0\n",
      "1835 Train Loss 11.676481\n",
      "Loss  0.48302573 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4814733 C_bot  0.15 k_c 0.0\n",
      "1836 Train Loss 11.671545\n",
      "Loss  0.4814733 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48017883 C_bot  0.15 k_c 0.0\n",
      "1837 Train Loss 11.666733\n",
      "Loss  0.48017883 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47913143 C_bot  0.15 k_c 0.0\n",
      "1838 Train Loss 11.66194\n",
      "Loss  0.47913143 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47760397 C_bot  0.15 k_c 0.0\n",
      "1839 Train Loss 11.657228\n",
      "Loss  0.47760397 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47652963 C_bot  0.15 k_c 0.0\n",
      "1840 Train Loss 11.652426\n",
      "Loss  0.47652963 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4750958 C_bot  0.15 k_c 0.0\n",
      "1841 Train Loss 11.647664\n",
      "Loss  0.4750958 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4738276 C_bot  0.15 k_c 0.0\n",
      "1842 Train Loss 11.643044\n",
      "Loss  0.4738276 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47275028 C_bot  0.15 k_c 0.0\n",
      "1843 Train Loss 11.638377\n",
      "Loss  0.47275028 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47135347 C_bot  0.15 k_c 0.0\n",
      "1844 Train Loss 11.633852\n",
      "Loss  0.47135347 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47023967 C_bot  0.15 k_c 0.0\n",
      "1845 Train Loss 11.629211\n",
      "Loss  0.47023967 C_bot  0.15 k_c 0.0\n",
      "Loss  0.46891224 C_bot  0.15 k_c 0.0\n",
      "1846 Train Loss 11.624623\n",
      "Loss  0.46891224 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4676235 C_bot  0.15 k_c 0.0\n",
      "1847 Train Loss 11.6201105\n",
      "Loss  0.4676235 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4666102 C_bot  0.15 k_c 0.0\n",
      "1848 Train Loss 11.615657\n",
      "Loss  0.4666102 C_bot  0.15 k_c 0.0\n",
      "Loss  0.46520352 C_bot  0.15 k_c 0.0\n",
      "1849 Train Loss 11.611183\n",
      "Loss  0.46520352 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4641644 C_bot  0.15 k_c 0.0\n",
      "1850 Train Loss 11.60678\n",
      "Loss  0.4641644 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4628968 C_bot  0.15 k_c 0.0\n",
      "1851 Train Loss 11.602343\n",
      "Loss  0.4628968 C_bot  0.15 k_c 0.0\n",
      "Loss  0.46173558 C_bot  0.15 k_c 0.0\n",
      "1852 Train Loss 11.598061\n",
      "Loss  0.46173558 C_bot  0.15 k_c 0.0\n",
      "Loss  0.46069303 C_bot  0.15 k_c 0.0\n",
      "1853 Train Loss 11.593716\n",
      "Loss  0.46069303 C_bot  0.15 k_c 0.0\n",
      "Loss  0.45934156 C_bot  0.15 k_c 0.0\n",
      "1854 Train Loss 11.589369\n",
      "Loss  0.45934156 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4582822 C_bot  0.15 k_c 0.0\n",
      "1855 Train Loss 11.585075\n",
      "Loss  0.4582822 C_bot  0.15 k_c 0.0\n",
      "Loss  0.45711538 C_bot  0.15 k_c 0.0\n",
      "1856 Train Loss 11.580842\n",
      "Loss  0.45711538 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4559464 C_bot  0.15 k_c 0.0\n",
      "1857 Train Loss 11.576633\n",
      "Loss  0.4559464 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4547792 C_bot  0.15 k_c 0.0\n",
      "1858 Train Loss 11.572304\n",
      "Loss  0.4547792 C_bot  0.15 k_c 0.0\n",
      "Loss  0.45364836 C_bot  0.15 k_c 0.0\n",
      "1859 Train Loss 11.568242\n",
      "Loss  0.45364836 C_bot  0.15 k_c 0.0\n",
      "Loss  0.45259246 C_bot  0.15 k_c 0.0\n",
      "1860 Train Loss 11.564074\n",
      "Loss  0.45259246 C_bot  0.15 k_c 0.0\n",
      "Loss  0.45142573 C_bot  0.15 k_c 0.0\n",
      "1861 Train Loss 11.55994\n",
      "Loss  0.45142573 C_bot  0.15 k_c 0.0\n",
      "Loss  0.45029932 C_bot  0.15 k_c 0.0\n",
      "1862 Train Loss 11.555843\n",
      "Loss  0.45029932 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44924608 C_bot  0.15 k_c 0.0\n",
      "1863 Train Loss 11.551763\n",
      "Loss  0.44924608 C_bot  0.15 k_c 0.0\n",
      "Loss  0.448066 C_bot  0.15 k_c 0.0\n",
      "1864 Train Loss 11.547712\n",
      "Loss  0.448066 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44704467 C_bot  0.15 k_c 0.0\n",
      "1865 Train Loss 11.543686\n",
      "Loss  0.44704467 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44591534 C_bot  0.15 k_c 0.0\n",
      "1866 Train Loss 11.539682\n",
      "Loss  0.44591534 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44484404 C_bot  0.15 k_c 0.0\n",
      "1867 Train Loss 11.535715\n",
      "Loss  0.44484404 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44380197 C_bot  0.15 k_c 0.0\n",
      "1868 Train Loss 11.531757\n",
      "Loss  0.44380197 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44267064 C_bot  0.15 k_c 0.0\n",
      "1869 Train Loss 11.527817\n",
      "Loss  0.44267064 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44165683 C_bot  0.15 k_c 0.0\n",
      "1870 Train Loss 11.523908\n",
      "Loss  0.44165683 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44057316 C_bot  0.15 k_c 0.0\n",
      "1871 Train Loss 11.520024\n",
      "Loss  0.44057316 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4395273 C_bot  0.15 k_c 0.0\n",
      "1872 Train Loss 11.516166\n",
      "Loss  0.4395273 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43848324 C_bot  0.15 k_c 0.0\n",
      "1873 Train Loss 11.512298\n",
      "Loss  0.43848324 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43740013 C_bot  0.15 k_c 0.0\n",
      "1874 Train Loss 11.508476\n",
      "Loss  0.43740013 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4363595 C_bot  0.15 k_c 0.0\n",
      "1875 Train Loss 11.504623\n",
      "Loss  0.4363595 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4352949 C_bot  0.15 k_c 0.0\n",
      "1876 Train Loss 11.500847\n",
      "Loss  0.4352949 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4343138 C_bot  0.15 k_c 0.0\n",
      "1877 Train Loss 11.497112\n",
      "Loss  0.4343138 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4332829 C_bot  0.15 k_c 0.0\n",
      "1878 Train Loss 11.493351\n",
      "Loss  0.4332829 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4322622 C_bot  0.15 k_c 0.0\n",
      "1879 Train Loss 11.489658\n",
      "Loss  0.4322622 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43129477 C_bot  0.15 k_c 0.0\n",
      "1880 Train Loss 11.485954\n",
      "Loss  0.43129477 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43023723 C_bot  0.15 k_c 0.0\n",
      "1881 Train Loss 11.482267\n",
      "Loss  0.43023723 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42924002 C_bot  0.15 k_c 0.0\n",
      "1882 Train Loss 11.478575\n",
      "Loss  0.42924002 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42822084 C_bot  0.15 k_c 0.0\n",
      "1883 Train Loss 11.474917\n",
      "Loss  0.42822084 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42725325 C_bot  0.15 k_c 0.0\n",
      "1884 Train Loss 11.471333\n",
      "Loss  0.42725325 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42627683 C_bot  0.15 k_c 0.0\n",
      "1885 Train Loss 11.467703\n",
      "Loss  0.42627683 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42524248 C_bot  0.15 k_c 0.0\n",
      "1886 Train Loss 11.464105\n",
      "Loss  0.42524248 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42430335 C_bot  0.15 k_c 0.0\n",
      "1887 Train Loss 11.460531\n",
      "Loss  0.42430335 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42329946 C_bot  0.15 k_c 0.0\n",
      "1888 Train Loss 11.456982\n",
      "Loss  0.42329946 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42233607 C_bot  0.15 k_c 0.0\n",
      "1889 Train Loss 11.453436\n",
      "Loss  0.42233607 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42134005 C_bot  0.15 k_c 0.0\n",
      "1890 Train Loss 11.449882\n",
      "Loss  0.42134005 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42035675 C_bot  0.15 k_c 0.0\n",
      "1891 Train Loss 11.446382\n",
      "Loss  0.42035675 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41944498 C_bot  0.15 k_c 0.0\n",
      "1892 Train Loss 11.442908\n",
      "Loss  0.41944498 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41847128 C_bot  0.15 k_c 0.0\n",
      "1893 Train Loss 11.439455\n",
      "Loss  0.41847128 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4175443 C_bot  0.15 k_c 0.0\n",
      "1894 Train Loss 11.435997\n",
      "Loss  0.4175443 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41657785 C_bot  0.15 k_c 0.0\n",
      "1895 Train Loss 11.432554\n",
      "Loss  0.41657785 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41560656 C_bot  0.15 k_c 0.0\n",
      "1896 Train Loss 11.429105\n",
      "Loss  0.41560656 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41470826 C_bot  0.15 k_c 0.0\n",
      "1897 Train Loss 11.425726\n",
      "Loss  0.41470826 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4137251 C_bot  0.15 k_c 0.0\n",
      "1898 Train Loss 11.422312\n",
      "Loss  0.4137251 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4128697 C_bot  0.15 k_c 0.0\n",
      "1899 Train Loss 11.418989\n",
      "Loss  0.4128697 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41188398 C_bot  0.15 k_c 0.0\n",
      "1900 Train Loss 11.41559\n",
      "Loss  0.41188398 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41097024 C_bot  0.15 k_c 0.0\n",
      "1901 Train Loss 11.412246\n",
      "Loss  0.41097024 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41004077 C_bot  0.15 k_c 0.0\n",
      "1902 Train Loss 11.408911\n",
      "Loss  0.41004077 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40917137 C_bot  0.15 k_c 0.0\n",
      "1903 Train Loss 11.405647\n",
      "Loss  0.40917137 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40824986 C_bot  0.15 k_c 0.0\n",
      "1904 Train Loss 11.4023285\n",
      "Loss  0.40824986 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40729186 C_bot  0.15 k_c 0.0\n",
      "1905 Train Loss 11.399012\n",
      "Loss  0.40729186 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40643743 C_bot  0.15 k_c 0.0\n",
      "1906 Train Loss 11.39577\n",
      "Loss  0.40643743 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40550905 C_bot  0.15 k_c 0.0\n",
      "1907 Train Loss 11.39251\n",
      "Loss  0.40550905 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40461904 C_bot  0.15 k_c 0.0\n",
      "1908 Train Loss 11.389259\n",
      "Loss  0.40461904 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40372226 C_bot  0.15 k_c 0.0\n",
      "1909 Train Loss 11.386042\n",
      "Loss  0.40372226 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4028474 C_bot  0.15 k_c 0.0\n",
      "1910 Train Loss 11.3828335\n",
      "Loss  0.4028474 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40192345 C_bot  0.15 k_c 0.0\n",
      "1911 Train Loss 11.379602\n",
      "Loss  0.40192345 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40106875 C_bot  0.15 k_c 0.0\n",
      "1912 Train Loss 11.376444\n",
      "Loss  0.40106875 C_bot  0.15 k_c 0.0\n",
      "Loss  0.400169 C_bot  0.15 k_c 0.0\n",
      "1913 Train Loss 11.373249\n",
      "Loss  0.400169 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39931133 C_bot  0.15 k_c 0.0\n",
      "1914 Train Loss 11.37011\n",
      "Loss  0.39931133 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39843586 C_bot  0.15 k_c 0.0\n",
      "1915 Train Loss 11.366958\n",
      "Loss  0.39843586 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39756456 C_bot  0.15 k_c 0.0\n",
      "1916 Train Loss 11.363827\n",
      "Loss  0.39756456 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3967077 C_bot  0.15 k_c 0.0\n",
      "1917 Train Loss 11.360708\n",
      "Loss  0.3967077 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39582214 C_bot  0.15 k_c 0.0\n",
      "1918 Train Loss 11.357588\n",
      "Loss  0.39582214 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3949629 C_bot  0.15 k_c 0.0\n",
      "1919 Train Loss 11.354483\n",
      "Loss  0.3949629 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39413172 C_bot  0.15 k_c 0.0\n",
      "1920 Train Loss 11.351435\n",
      "Loss  0.39413172 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3932361 C_bot  0.15 k_c 0.0\n",
      "1921 Train Loss 11.348312\n",
      "Loss  0.3932361 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3924107 C_bot  0.15 k_c 0.0\n",
      "1922 Train Loss 11.345291\n",
      "Loss  0.3924107 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39155686 C_bot  0.15 k_c 0.0\n",
      "1923 Train Loss 11.342221\n",
      "Loss  0.39155686 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3907374 C_bot  0.15 k_c 0.0\n",
      "1924 Train Loss 11.33923\n",
      "Loss  0.3907374 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38987654 C_bot  0.15 k_c 0.0\n",
      "1925 Train Loss 11.336174\n",
      "Loss  0.38987654 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38904992 C_bot  0.15 k_c 0.0\n",
      "1926 Train Loss 11.333179\n",
      "Loss  0.38904992 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38817978 C_bot  0.15 k_c 0.0\n",
      "1927 Train Loss 11.330147\n",
      "Loss  0.38817978 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38737437 C_bot  0.15 k_c 0.0\n",
      "1928 Train Loss 11.327177\n",
      "Loss  0.38737437 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38652146 C_bot  0.15 k_c 0.0\n",
      "1929 Train Loss 11.324188\n",
      "Loss  0.38652146 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3857574 C_bot  0.15 k_c 0.0\n",
      "1930 Train Loss 11.321274\n",
      "Loss  0.3857574 C_bot  0.15 k_c 0.0\n",
      "Loss  0.384912 C_bot  0.15 k_c 0.0\n",
      "1931 Train Loss 11.318302\n",
      "Loss  0.384912 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38407877 C_bot  0.15 k_c 0.0\n",
      "1932 Train Loss 11.315347\n",
      "Loss  0.38407877 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38329184 C_bot  0.15 k_c 0.0\n",
      "1933 Train Loss 11.312444\n",
      "Loss  0.38329184 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38245812 C_bot  0.15 k_c 0.0\n",
      "1934 Train Loss 11.309504\n",
      "Loss  0.38245812 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38162747 C_bot  0.15 k_c 0.0\n",
      "1935 Train Loss 11.306576\n",
      "Loss  0.38162747 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3808384 C_bot  0.15 k_c 0.0\n",
      "1936 Train Loss 11.303692\n",
      "Loss  0.3808384 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38004464 C_bot  0.15 k_c 0.0\n",
      "1937 Train Loss 11.300822\n",
      "Loss  0.38004464 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37918732 C_bot  0.15 k_c 0.0\n",
      "1938 Train Loss 11.29788\n",
      "Loss  0.37918732 C_bot  0.15 k_c 0.0\n",
      "Loss  0.378399 C_bot  0.15 k_c 0.0\n",
      "1939 Train Loss 11.295033\n",
      "Loss  0.378399 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37766674 C_bot  0.15 k_c 0.0\n",
      "1940 Train Loss 11.29223\n",
      "Loss  0.37766674 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3768362 C_bot  0.15 k_c 0.0\n",
      "1941 Train Loss 11.289357\n",
      "Loss  0.3768362 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37605503 C_bot  0.15 k_c 0.0\n",
      "1942 Train Loss 11.286522\n",
      "Loss  0.37605503 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37522355 C_bot  0.15 k_c 0.0\n",
      "1943 Train Loss 11.283659\n",
      "Loss  0.37522355 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37445518 C_bot  0.15 k_c 0.0\n",
      "1944 Train Loss 11.280855\n",
      "Loss  0.37445518 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37368444 C_bot  0.15 k_c 0.0\n",
      "1945 Train Loss 11.278061\n",
      "Loss  0.37368444 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37289634 C_bot  0.15 k_c 0.0\n",
      "1946 Train Loss 11.275259\n",
      "Loss  0.37289634 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37213877 C_bot  0.15 k_c 0.0\n",
      "1947 Train Loss 11.272486\n",
      "Loss  0.37213877 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37135056 C_bot  0.15 k_c 0.0\n",
      "1948 Train Loss 11.2697\n",
      "Loss  0.37135056 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37057418 C_bot  0.15 k_c 0.0\n",
      "1949 Train Loss 11.266926\n",
      "Loss  0.37057418 C_bot  0.15 k_c 0.0\n",
      "Loss  0.369815 C_bot  0.15 k_c 0.0\n",
      "1950 Train Loss 11.264174\n",
      "Loss  0.369815 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3690538 C_bot  0.15 k_c 0.0\n",
      "1951 Train Loss 11.261436\n",
      "Loss  0.3690538 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36826694 C_bot  0.15 k_c 0.0\n",
      "1952 Train Loss 11.258669\n",
      "Loss  0.36826694 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3675016 C_bot  0.15 k_c 0.0\n",
      "1953 Train Loss 11.255937\n",
      "Loss  0.3675016 C_bot  0.15 k_c 0.0\n",
      "Loss  0.366715 C_bot  0.15 k_c 0.0\n",
      "1954 Train Loss 11.253187\n",
      "Loss  0.366715 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36601353 C_bot  0.15 k_c 0.0\n",
      "1955 Train Loss 11.250528\n",
      "Loss  0.36601353 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36524156 C_bot  0.15 k_c 0.0\n",
      "1956 Train Loss 11.247807\n",
      "Loss  0.36524156 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3644615 C_bot  0.15 k_c 0.0\n",
      "1957 Train Loss 11.245084\n",
      "Loss  0.3644615 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36373067 C_bot  0.15 k_c 0.0\n",
      "1958 Train Loss 11.242417\n",
      "Loss  0.36373067 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36298144 C_bot  0.15 k_c 0.0\n",
      "1959 Train Loss 11.239733\n",
      "Loss  0.36298144 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3622465 C_bot  0.15 k_c 0.0\n",
      "1960 Train Loss 11.23708\n",
      "Loss  0.3622465 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3614968 C_bot  0.15 k_c 0.0\n",
      "1961 Train Loss 11.234406\n",
      "Loss  0.3614968 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36072984 C_bot  0.15 k_c 0.0\n",
      "1962 Train Loss 11.231728\n",
      "Loss  0.36072984 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36002472 C_bot  0.15 k_c 0.0\n",
      "1963 Train Loss 11.22912\n",
      "Loss  0.36002472 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3592763 C_bot  0.15 k_c 0.0\n",
      "1964 Train Loss 11.226463\n",
      "Loss  0.3592763 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35854518 C_bot  0.15 k_c 0.0\n",
      "1965 Train Loss 11.223846\n",
      "Loss  0.35854518 C_bot  0.15 k_c 0.0\n",
      "Loss  0.357837 C_bot  0.15 k_c 0.0\n",
      "1966 Train Loss 11.221239\n",
      "Loss  0.357837 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35708904 C_bot  0.15 k_c 0.0\n",
      "1967 Train Loss 11.218619\n",
      "Loss  0.35708904 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3563574 C_bot  0.15 k_c 0.0\n",
      "1968 Train Loss 11.215997\n",
      "Loss  0.3563574 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3556517 C_bot  0.15 k_c 0.0\n",
      "1969 Train Loss 11.213436\n",
      "Loss  0.3556517 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35492104 C_bot  0.15 k_c 0.0\n",
      "1970 Train Loss 11.210821\n",
      "Loss  0.35492104 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35417703 C_bot  0.15 k_c 0.0\n",
      "1971 Train Loss 11.208237\n",
      "Loss  0.35417703 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35346404 C_bot  0.15 k_c 0.0\n",
      "1972 Train Loss 11.205643\n",
      "Loss  0.35346404 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3527602 C_bot  0.15 k_c 0.0\n",
      "1973 Train Loss 11.203119\n",
      "Loss  0.3527602 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35205275 C_bot  0.15 k_c 0.0\n",
      "1974 Train Loss 11.200535\n",
      "Loss  0.35205275 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35127547 C_bot  0.15 k_c 0.0\n",
      "1975 Train Loss 11.197954\n",
      "Loss  0.35127547 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35063767 C_bot  0.15 k_c 0.0\n",
      "1976 Train Loss 11.195439\n",
      "Loss  0.35063767 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3498805 C_bot  0.15 k_c 0.0\n",
      "1977 Train Loss 11.192904\n",
      "Loss  0.3498805 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34924743 C_bot  0.15 k_c 0.0\n",
      "1978 Train Loss 11.190386\n",
      "Loss  0.34924743 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34845856 C_bot  0.15 k_c 0.0\n",
      "1979 Train Loss 11.187851\n",
      "Loss  0.34845856 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3478646 C_bot  0.15 k_c 0.0\n",
      "1980 Train Loss 11.185362\n",
      "Loss  0.3478646 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34707525 C_bot  0.15 k_c 0.0\n",
      "1981 Train Loss 11.182859\n",
      "Loss  0.34707525 C_bot  0.15 k_c 0.0\n",
      "Loss  0.346481 C_bot  0.15 k_c 0.0\n",
      "1982 Train Loss 11.180349\n",
      "Loss  0.346481 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3457089 C_bot  0.15 k_c 0.0\n",
      "1983 Train Loss 11.177914\n",
      "Loss  0.3457089 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3451428 C_bot  0.15 k_c 0.0\n",
      "1984 Train Loss 11.175392\n",
      "Loss  0.3451428 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3442857 C_bot  0.15 k_c 0.0\n",
      "1985 Train Loss 11.172941\n",
      "Loss  0.3442857 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34384665 C_bot  0.15 k_c 0.0\n",
      "1986 Train Loss 11.170483\n",
      "Loss  0.34384665 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34293035 C_bot  0.15 k_c 0.0\n",
      "1987 Train Loss 11.168072\n",
      "Loss  0.34293035 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34262747 C_bot  0.15 k_c 0.0\n",
      "1988 Train Loss 11.165648\n",
      "Loss  0.34262747 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34167895 C_bot  0.15 k_c 0.0\n",
      "1989 Train Loss 11.163353\n",
      "Loss  0.34167895 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34162334 C_bot  0.15 k_c 0.0\n",
      "1990 Train Loss 11.161013\n",
      "Loss  0.34162334 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34056416 C_bot  0.15 k_c 0.0\n",
      "1991 Train Loss 11.158834\n",
      "Loss  0.34056416 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34102002 C_bot  0.15 k_c 0.0\n",
      "1992 Train Loss 11.156734\n",
      "Loss  0.34102002 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34004435 C_bot  0.15 k_c 0.0\n",
      "1993 Train Loss 11.155014\n",
      "Loss  0.34004435 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3416017 C_bot  0.15 k_c 0.0\n",
      "1994 Train Loss 11.153555\n",
      "Loss  0.3416017 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34112358 C_bot  0.15 k_c 0.0\n",
      "1995 Train Loss 11.152952\n",
      "Loss  0.34112358 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34521657 C_bot  0.15 k_c 0.0\n",
      "1996 Train Loss 11.153248\n",
      "Loss  0.34521657 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3467907 C_bot  0.15 k_c 0.0\n",
      "1997 Train Loss 11.155739\n",
      "Loss  0.3467907 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3573315 C_bot  0.15 k_c 0.0\n",
      "1998 Train Loss 11.161158\n",
      "Loss  0.3573315 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3662478 C_bot  0.15 k_c 0.0\n",
      "1999 Train Loss 11.172781\n",
      "Loss  0.3662478 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39483097 C_bot  0.15 k_c 0.0\n",
      "2000 Train Loss 11.193939\n",
      "Loss  0.39483097 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4288039 C_bot  0.15 k_c 0.0\n",
      "2001 Train Loss 11.233786\n",
      "Loss  0.4288039 C_bot  0.15 k_c 0.0\n",
      "Loss  0.51102424 C_bot  0.15 k_c 0.0\n",
      "2002 Train Loss 11.304516\n",
      "Loss  0.51102424 C_bot  0.15 k_c 0.0\n",
      "Loss  0.629606 C_bot  0.15 k_c 0.0\n",
      "2003 Train Loss 11.434702\n",
      "Loss  0.629606 C_bot  0.15 k_c 0.0\n",
      "Loss  0.88083 C_bot  0.15 k_c 0.0\n",
      "2004 Train Loss 11.66721\n",
      "Loss  0.88083 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2892 C_bot  0.15 k_c 0.0\n",
      "2005 Train Loss 12.097849\n",
      "Loss  1.2892 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0994303 C_bot  0.15 k_c 0.0\n",
      "2006 Train Loss 12.876465\n",
      "Loss  2.0994303 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5225692 C_bot  0.15 k_c 0.0\n",
      "2007 Train Loss 14.342484\n",
      "Loss  3.5225692 C_bot  0.15 k_c 0.0\n",
      "Loss  6.248196 C_bot  0.15 k_c 0.0\n",
      "2008 Train Loss 17.013704\n",
      "Loss  6.248196 C_bot  0.15 k_c 0.0\n",
      "Loss  11.300289 C_bot  0.15 k_c 0.0\n",
      "2009 Train Loss 22.150597\n",
      "Loss  11.300289 C_bot  0.15 k_c 0.0\n",
      "Loss  20.707428 C_bot  0.15 k_c 0.0\n",
      "2010 Train Loss 31.464523\n",
      "Loss  20.707428 C_bot  0.15 k_c 0.0\n",
      "Loss  38.82941 C_bot  0.15 k_c 0.0\n",
      "2011 Train Loss 49.76315\n",
      "Loss  38.82941 C_bot  0.15 k_c 0.0\n",
      "Loss  70.848076 C_bot  0.15 k_c 0.0\n",
      "2012 Train Loss 81.626816\n",
      "Loss  70.848076 C_bot  0.15 k_c 0.0\n",
      "Loss  133.13821 C_bot  0.15 k_c 0.0\n",
      "2013 Train Loss 144.31264\n",
      "Loss  133.13821 C_bot  0.15 k_c 0.0\n",
      "Loss  227.54366 C_bot  0.15 k_c 0.0\n",
      "2014 Train Loss 238.45901\n",
      "Loss  227.54366 C_bot  0.15 k_c 0.0\n",
      "Loss  394.48358 C_bot  0.15 k_c 0.0\n",
      "2015 Train Loss 406.30618\n",
      "Loss  394.48358 C_bot  0.15 k_c 0.0\n",
      "Loss  538.1578 C_bot  0.15 k_c 0.0\n",
      "2016 Train Loss 549.3885\n",
      "Loss  538.1578 C_bot  0.15 k_c 0.0\n",
      "Loss  667.87744 C_bot  0.15 k_c 0.0\n",
      "2017 Train Loss 680.66595\n",
      "Loss  667.87744 C_bot  0.15 k_c 0.0\n",
      "Loss  497.6737 C_bot  0.15 k_c 0.0\n",
      "2018 Train Loss 508.97095\n",
      "Loss  497.6737 C_bot  0.15 k_c 0.0\n",
      "Loss  204.544 C_bot  0.15 k_c 0.0\n",
      "2019 Train Loss 216.928\n",
      "Loss  204.544 C_bot  0.15 k_c 0.0\n",
      "Loss  7.8778353 C_bot  0.15 k_c 0.0\n",
      "2020 Train Loss 19.61391\n",
      "Loss  7.8778353 C_bot  0.15 k_c 0.0\n",
      "Loss  93.27119 C_bot  0.15 k_c 0.0\n",
      "2021 Train Loss 105.05827\n",
      "Loss  93.27119 C_bot  0.15 k_c 0.0\n",
      "Loss  273.58176 C_bot  0.15 k_c 0.0\n",
      "2022 Train Loss 287.27493\n",
      "Loss  273.58176 C_bot  0.15 k_c 0.0\n",
      "Loss  246.78596 C_bot  0.15 k_c 0.0\n",
      "2023 Train Loss 258.9181\n",
      "Loss  246.78596 C_bot  0.15 k_c 0.0\n",
      "Loss  77.64745 C_bot  0.15 k_c 0.0\n",
      "2024 Train Loss 90.95899\n",
      "Loss  77.64745 C_bot  0.15 k_c 0.0\n",
      "Loss  5.7971163 C_bot  0.15 k_c 0.0\n",
      "2025 Train Loss 18.680555\n",
      "Loss  5.7971163 C_bot  0.15 k_c 0.0\n",
      "Loss  104.44704 C_bot  0.15 k_c 0.0\n",
      "2026 Train Loss 116.921265\n",
      "Loss  104.44704 C_bot  0.15 k_c 0.0\n",
      "Loss  175.79156 C_bot  0.15 k_c 0.0\n",
      "2027 Train Loss 189.50075\n",
      "Loss  175.79156 C_bot  0.15 k_c 0.0\n",
      "Loss  87.72458 C_bot  0.15 k_c 0.0\n",
      "2028 Train Loss 100.20183\n",
      "Loss  87.72458 C_bot  0.15 k_c 0.0\n",
      "Loss  3.3212998 C_bot  0.15 k_c 0.0\n",
      "2029 Train Loss 16.05673\n",
      "Loss  3.3212998 C_bot  0.15 k_c 0.0\n",
      "Loss  42.9715 C_bot  0.15 k_c 0.0\n",
      "2030 Train Loss 55.88397\n",
      "Loss  42.9715 C_bot  0.15 k_c 0.0\n",
      "Loss  101.81439 C_bot  0.15 k_c 0.0\n",
      "2031 Train Loss 114.17894\n",
      "Loss  101.81439 C_bot  0.15 k_c 0.0\n",
      "Loss  67.53771 C_bot  0.15 k_c 0.0\n",
      "2032 Train Loss 80.361015\n",
      "Loss  67.53771 C_bot  0.15 k_c 0.0\n",
      "Loss  4.7577724 C_bot  0.15 k_c 0.0\n",
      "2033 Train Loss 17.120195\n",
      "Loss  4.7577724 C_bot  0.15 k_c 0.0\n",
      "Loss  22.555096 C_bot  0.15 k_c 0.0\n",
      "2034 Train Loss 34.835888\n",
      "Loss  22.555096 C_bot  0.15 k_c 0.0\n",
      "Loss  66.74684 C_bot  0.15 k_c 0.0\n",
      "2035 Train Loss 79.35257\n",
      "Loss  66.74684 C_bot  0.15 k_c 0.0\n",
      "Loss  44.936066 C_bot  0.15 k_c 0.0\n",
      "2036 Train Loss 57.121548\n",
      "Loss  44.936066 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7699432 C_bot  0.15 k_c 0.0\n",
      "2037 Train Loss 16.01252\n",
      "Loss  3.7699432 C_bot  0.15 k_c 0.0\n",
      "Loss  14.571639 C_bot  0.15 k_c 0.0\n",
      "2038 Train Loss 26.8167\n",
      "Loss  14.571639 C_bot  0.15 k_c 0.0\n",
      "Loss  42.632404 C_bot  0.15 k_c 0.0\n",
      "2039 Train Loss 54.64687\n",
      "Loss  42.632404 C_bot  0.15 k_c 0.0\n",
      "Loss  29.83445 C_bot  0.15 k_c 0.0\n",
      "2040 Train Loss 42.033497\n",
      "Loss  29.83445 C_bot  0.15 k_c 0.0\n",
      "Loss  2.828459 C_bot  0.15 k_c 0.0\n",
      "2041 Train Loss 14.771135\n",
      "Loss  2.828459 C_bot  0.15 k_c 0.0\n",
      "Loss  10.824495 C_bot  0.15 k_c 0.0\n",
      "2042 Train Loss 22.682106\n",
      "Loss  10.824495 C_bot  0.15 k_c 0.0\n",
      "Loss  29.1446 C_bot  0.15 k_c 0.0\n",
      "2043 Train Loss 41.213684\n",
      "Loss  29.1446 C_bot  0.15 k_c 0.0\n",
      "Loss  18.622814 C_bot  0.15 k_c 0.0\n",
      "2044 Train Loss 30.376663\n",
      "Loss  18.622814 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5519732 C_bot  0.15 k_c 0.0\n",
      "2045 Train Loss 13.394241\n",
      "Loss  1.5519732 C_bot  0.15 k_c 0.0\n",
      "Loss  8.117806 C_bot  0.15 k_c 0.0\n",
      "2046 Train Loss 20.008709\n",
      "Loss  8.117806 C_bot  0.15 k_c 0.0\n",
      "Loss  19.236792 C_bot  0.15 k_c 0.0\n",
      "2047 Train Loss 30.911007\n",
      "Loss  19.236792 C_bot  0.15 k_c 0.0\n",
      "Loss  11.203727 C_bot  0.15 k_c 0.0\n",
      "2048 Train Loss 23.091518\n",
      "Loss  11.203727 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8871321 C_bot  0.15 k_c 0.0\n",
      "2049 Train Loss 12.634899\n",
      "Loss  0.8871321 C_bot  0.15 k_c 0.0\n",
      "Loss  6.471426 C_bot  0.15 k_c 0.0\n",
      "2050 Train Loss 18.158524\n",
      "Loss  6.471426 C_bot  0.15 k_c 0.0\n",
      "Loss  12.970432 C_bot  0.15 k_c 0.0\n",
      "2051 Train Loss 24.838093\n",
      "Loss  12.970432 C_bot  0.15 k_c 0.0\n",
      "Loss  6.738883 C_bot  0.15 k_c 0.0\n",
      "2052 Train Loss 18.4033\n",
      "Loss  6.738883 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6232221 C_bot  0.15 k_c 0.0\n",
      "2053 Train Loss 12.333689\n",
      "Loss  0.6232221 C_bot  0.15 k_c 0.0\n",
      "Loss  5.001939 C_bot  0.15 k_c 0.0\n",
      "2054 Train Loss 16.753845\n",
      "Loss  5.001939 C_bot  0.15 k_c 0.0\n",
      "Loss  8.700093 C_bot  0.15 k_c 0.0\n",
      "2055 Train Loss 20.317587\n",
      "Loss  8.700093 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9720445 C_bot  0.15 k_c 0.0\n",
      "2056 Train Loss 15.668921\n",
      "Loss  3.9720445 C_bot  0.15 k_c 0.0\n",
      "Loss  0.57837164 C_bot  0.15 k_c 0.0\n",
      "2057 Train Loss 12.20952\n",
      "Loss  0.57837164 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9380057 C_bot  0.15 k_c 0.0\n",
      "2058 Train Loss 15.517018\n",
      "Loss  3.9380057 C_bot  0.15 k_c 0.0\n",
      "Loss  5.854776 C_bot  0.15 k_c 0.0\n",
      "2059 Train Loss 17.492033\n",
      "Loss  5.854776 C_bot  0.15 k_c 0.0\n",
      "Loss  2.506218 C_bot  0.15 k_c 0.0\n",
      "2060 Train Loss 14.055515\n",
      "Loss  2.506218 C_bot  0.15 k_c 0.0\n",
      "Loss  0.58886147 C_bot  0.15 k_c 0.0\n",
      "2061 Train Loss 12.135627\n",
      "Loss  0.58886147 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9394343 C_bot  0.15 k_c 0.0\n",
      "2062 Train Loss 14.498901\n",
      "Loss  2.9394343 C_bot  0.15 k_c 0.0\n",
      "Loss  3.9934635 C_bot  0.15 k_c 0.0\n",
      "2063 Train Loss 15.482756\n",
      "Loss  3.9934635 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6310581 C_bot  0.15 k_c 0.0\n",
      "2064 Train Loss 13.142847\n",
      "Loss  1.6310581 C_bot  0.15 k_c 0.0\n",
      "Loss  0.55345637 C_bot  0.15 k_c 0.0\n",
      "2065 Train Loss 12.032501\n",
      "Loss  0.55345637 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2046468 C_bot  0.15 k_c 0.0\n",
      "2066 Train Loss 13.643303\n",
      "Loss  2.2046468 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7562034 C_bot  0.15 k_c 0.0\n",
      "2067 Train Loss 14.225137\n",
      "Loss  2.7562034 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2213895 C_bot  0.15 k_c 0.0\n",
      "2068 Train Loss 12.630724\n",
      "Loss  1.2213895 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5392275 C_bot  0.15 k_c 0.0\n",
      "2069 Train Loss 11.942534\n",
      "Loss  0.5392275 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5980197 C_bot  0.15 k_c 0.0\n",
      "2070 Train Loss 13.012295\n",
      "Loss  1.5980197 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0187955 C_bot  0.15 k_c 0.0\n",
      "2071 Train Loss 13.375126\n",
      "Loss  2.0187955 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9614166 C_bot  0.15 k_c 0.0\n",
      "2072 Train Loss 12.34053\n",
      "Loss  0.9614166 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5020574 C_bot  0.15 k_c 0.0\n",
      "2073 Train Loss 11.856028\n",
      "Loss  0.5020574 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2177073 C_bot  0.15 k_c 0.0\n",
      "2074 Train Loss 12.538675\n",
      "Loss  1.2177073 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4749125 C_bot  0.15 k_c 0.0\n",
      "2075 Train Loss 12.822294\n",
      "Loss  1.4749125 C_bot  0.15 k_c 0.0\n",
      "Loss  0.85122514 C_bot  0.15 k_c 0.0\n",
      "2076 Train Loss 12.150932\n",
      "Loss  0.85122514 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47938538 C_bot  0.15 k_c 0.0\n",
      "2077 Train Loss 11.777083\n",
      "Loss  0.47938538 C_bot  0.15 k_c 0.0\n",
      "Loss  0.889612 C_bot  0.15 k_c 0.0\n",
      "2078 Train Loss 12.1913595\n",
      "Loss  0.889612 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1607503 C_bot  0.15 k_c 0.0\n",
      "2079 Train Loss 12.420595\n",
      "Loss  1.1607503 C_bot  0.15 k_c 0.0\n",
      "Loss  0.73701406 C_bot  0.15 k_c 0.0\n",
      "2080 Train Loss 12.012428\n",
      "Loss  0.73701406 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4547918 C_bot  0.15 k_c 0.0\n",
      "2081 Train Loss 11.708381\n",
      "Loss  0.4547918 C_bot  0.15 k_c 0.0\n",
      "Loss  0.70453256 C_bot  0.15 k_c 0.0\n",
      "2082 Train Loss 11.938798\n",
      "Loss  0.70453256 C_bot  0.15 k_c 0.0\n",
      "Loss  0.89124924 C_bot  0.15 k_c 0.0\n",
      "2083 Train Loss 12.137312\n",
      "Loss  0.89124924 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68874145 C_bot  0.15 k_c 0.0\n",
      "2084 Train Loss 11.904194\n",
      "Loss  0.68874145 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44540355 C_bot  0.15 k_c 0.0\n",
      "2085 Train Loss 11.660864\n",
      "Loss  0.44540355 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5547612 C_bot  0.15 k_c 0.0\n",
      "2086 Train Loss 11.766261\n",
      "Loss  0.5547612 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7372868 C_bot  0.15 k_c 0.0\n",
      "2087 Train Loss 11.926594\n",
      "Loss  0.7372868 C_bot  0.15 k_c 0.0\n",
      "Loss  0.621041 C_bot  0.15 k_c 0.0\n",
      "2088 Train Loss 11.81724\n",
      "Loss  0.621041 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4491666 C_bot  0.15 k_c 0.0\n",
      "2089 Train Loss 11.628426\n",
      "Loss  0.4491666 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48113874 C_bot  0.15 k_c 0.0\n",
      "2090 Train Loss 11.651233\n",
      "Loss  0.48113874 C_bot  0.15 k_c 0.0\n",
      "Loss  0.59865344 C_bot  0.15 k_c 0.0\n",
      "2091 Train Loss 11.770758\n",
      "Loss  0.59865344 C_bot  0.15 k_c 0.0\n",
      "Loss  0.583565 C_bot  0.15 k_c 0.0\n",
      "2092 Train Loss 11.736192\n",
      "Loss  0.583565 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44836852 C_bot  0.15 k_c 0.0\n",
      "2093 Train Loss 11.601677\n",
      "Loss  0.44836852 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42907643 C_bot  0.15 k_c 0.0\n",
      "2094 Train Loss 11.574121\n",
      "Loss  0.42907643 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5175758 C_bot  0.15 k_c 0.0\n",
      "2095 Train Loss 11.649202\n",
      "Loss  0.5175758 C_bot  0.15 k_c 0.0\n",
      "Loss  0.52428555 C_bot  0.15 k_c 0.0\n",
      "2096 Train Loss 11.658703\n",
      "Loss  0.52428555 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4536197 C_bot  0.15 k_c 0.0\n",
      "2097 Train Loss 11.572691\n",
      "Loss  0.4536197 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40764394 C_bot  0.15 k_c 0.0\n",
      "2098 Train Loss 11.522641\n",
      "Loss  0.40764394 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44528756 C_bot  0.15 k_c 0.0\n",
      "2099 Train Loss 11.557308\n",
      "Loss  0.44528756 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48519775 C_bot  0.15 k_c 0.0\n",
      "2100 Train Loss 11.582895\n",
      "Loss  0.48519775 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44071344 C_bot  0.15 k_c 0.0\n",
      "2101 Train Loss 11.539915\n",
      "Loss  0.44071344 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39893615 C_bot  0.15 k_c 0.0\n",
      "2102 Train Loss 11.487581\n",
      "Loss  0.39893615 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40855515 C_bot  0.15 k_c 0.0\n",
      "2103 Train Loss 11.490065\n",
      "Loss  0.40855515 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4333176 C_bot  0.15 k_c 0.0\n",
      "2104 Train Loss 11.514414\n",
      "Loss  0.4333176 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43220514 C_bot  0.15 k_c 0.0\n",
      "2105 Train Loss 11.500593\n",
      "Loss  0.43220514 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39246356 C_bot  0.15 k_c 0.0\n",
      "2106 Train Loss 11.460148\n",
      "Loss  0.39246356 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38147938 C_bot  0.15 k_c 0.0\n",
      "2107 Train Loss 11.442595\n",
      "Loss  0.38147938 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4013161 C_bot  0.15 k_c 0.0\n",
      "2108 Train Loss 11.4540825\n",
      "Loss  0.4013161 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4036551 C_bot  0.15 k_c 0.0\n",
      "2109 Train Loss 11.45641\n",
      "Loss  0.4036551 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3894581 C_bot  0.15 k_c 0.0\n",
      "2110 Train Loss 11.432068\n",
      "Loss  0.3894581 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36789164 C_bot  0.15 k_c 0.0\n",
      "2111 Train Loss 11.407845\n",
      "Loss  0.36789164 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3690195 C_bot  0.15 k_c 0.0\n",
      "2112 Train Loss 11.404766\n",
      "Loss  0.3690195 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3816035 C_bot  0.15 k_c 0.0\n",
      "2113 Train Loss 11.40909\n",
      "Loss  0.3816035 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37274233 C_bot  0.15 k_c 0.0\n",
      "2114 Train Loss 11.399526\n",
      "Loss  0.37274233 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35980517 C_bot  0.15 k_c 0.0\n",
      "2115 Train Loss 11.3786125\n",
      "Loss  0.35980517 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35073954 C_bot  0.15 k_c 0.0\n",
      "2116 Train Loss 11.36562\n",
      "Loss  0.35073954 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35273445 C_bot  0.15 k_c 0.0\n",
      "2117 Train Loss 11.36444\n",
      "Loss  0.35273445 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35755017 C_bot  0.15 k_c 0.0\n",
      "2118 Train Loss 11.361588\n",
      "Loss  0.35755017 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3464683 C_bot  0.15 k_c 0.0\n",
      "2119 Train Loss 11.349016\n",
      "Loss  0.3464683 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3373992 C_bot  0.15 k_c 0.0\n",
      "2120 Train Loss 11.333507\n",
      "Loss  0.3373992 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33361253 C_bot  0.15 k_c 0.0\n",
      "2121 Train Loss 11.325258\n",
      "Loss  0.33361253 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33343327 C_bot  0.15 k_c 0.0\n",
      "2122 Train Loss 11.322343\n",
      "Loss  0.33343327 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33367518 C_bot  0.15 k_c 0.0\n",
      "2123 Train Loss 11.315714\n",
      "Loss  0.33367518 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32384723 C_bot  0.15 k_c 0.0\n",
      "2124 Train Loss 11.303843\n",
      "Loss  0.32384723 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31752765 C_bot  0.15 k_c 0.0\n",
      "2125 Train Loss 11.29212\n",
      "Loss  0.31752765 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3151846 C_bot  0.15 k_c 0.0\n",
      "2126 Train Loss 11.285233\n",
      "Loss  0.3151846 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3130528 C_bot  0.15 k_c 0.0\n",
      "2127 Train Loss 11.280459\n",
      "Loss  0.3130528 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3115581 C_bot  0.15 k_c 0.0\n",
      "2128 Train Loss 11.27284\n",
      "Loss  0.3115581 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30362442 C_bot  0.15 k_c 0.0\n",
      "2129 Train Loss 11.262495\n",
      "Loss  0.30362442 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29879612 C_bot  0.15 k_c 0.0\n",
      "2130 Train Loss 11.252913\n",
      "Loss  0.29879612 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29655144 C_bot  0.15 k_c 0.0\n",
      "2131 Train Loss 11.246284\n",
      "Loss  0.29655144 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29361966 C_bot  0.15 k_c 0.0\n",
      "2132 Train Loss 11.240673\n",
      "Loss  0.29361966 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29156065 C_bot  0.15 k_c 0.0\n",
      "2133 Train Loss 11.233173\n",
      "Loss  0.29156065 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2852925 C_bot  0.15 k_c 0.0\n",
      "2134 Train Loss 11.2243185\n",
      "Loss  0.2852925 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28141764 C_bot  0.15 k_c 0.0\n",
      "2135 Train Loss 11.216139\n",
      "Loss  0.28141764 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27908394 C_bot  0.15 k_c 0.0\n",
      "2136 Train Loss 11.209742\n",
      "Loss  0.27908394 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27597326 C_bot  0.15 k_c 0.0\n",
      "2137 Train Loss 11.203912\n",
      "Loss  0.27597326 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27403754 C_bot  0.15 k_c 0.0\n",
      "2138 Train Loss 11.19713\n",
      "Loss  0.27403754 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26908076 C_bot  0.15 k_c 0.0\n",
      "2139 Train Loss 11.189566\n",
      "Loss  0.26908076 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26592615 C_bot  0.15 k_c 0.0\n",
      "2140 Train Loss 11.182398\n",
      "Loss  0.26592615 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26354873 C_bot  0.15 k_c 0.0\n",
      "2141 Train Loss 11.176313\n",
      "Loss  0.26354873 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26080215 C_bot  0.15 k_c 0.0\n",
      "2142 Train Loss 11.1707735\n",
      "Loss  0.26080215 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25918138 C_bot  0.15 k_c 0.0\n",
      "2143 Train Loss 11.164779\n",
      "Loss  0.25918138 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2553597 C_bot  0.15 k_c 0.0\n",
      "2144 Train Loss 11.158352\n",
      "Loss  0.2553597 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25285146 C_bot  0.15 k_c 0.0\n",
      "2145 Train Loss 11.151997\n",
      "Loss  0.25285146 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2505702 C_bot  0.15 k_c 0.0\n",
      "2146 Train Loss 11.146332\n",
      "Loss  0.2505702 C_bot  0.15 k_c 0.0\n",
      "Loss  0.248324 C_bot  0.15 k_c 0.0\n",
      "2147 Train Loss 11.1411915\n",
      "Loss  0.248324 C_bot  0.15 k_c 0.0\n",
      "Loss  0.246987 C_bot  0.15 k_c 0.0\n",
      "2148 Train Loss 11.135868\n",
      "Loss  0.246987 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24412385 C_bot  0.15 k_c 0.0\n",
      "2149 Train Loss 11.1304\n",
      "Loss  0.24412385 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24230385 C_bot  0.15 k_c 0.0\n",
      "2150 Train Loss 11.124859\n",
      "Loss  0.24230385 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24017407 C_bot  0.15 k_c 0.0\n",
      "2151 Train Loss 11.119622\n",
      "Loss  0.24017407 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23834677 C_bot  0.15 k_c 0.0\n",
      "2152 Train Loss 11.114798\n",
      "Loss  0.23834677 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23727669 C_bot  0.15 k_c 0.0\n",
      "2153 Train Loss 11.110083\n",
      "Loss  0.23727669 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23515795 C_bot  0.15 k_c 0.0\n",
      "2154 Train Loss 11.105333\n",
      "Loss  0.23515795 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23383613 C_bot  0.15 k_c 0.0\n",
      "2155 Train Loss 11.100423\n",
      "Loss  0.23383613 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23200749 C_bot  0.15 k_c 0.0\n",
      "2156 Train Loss 11.095702\n",
      "Loss  0.23200749 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23058958 C_bot  0.15 k_c 0.0\n",
      "2157 Train Loss 11.091205\n",
      "Loss  0.23058958 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2296395 C_bot  0.15 k_c 0.0\n",
      "2158 Train Loss 11.086914\n",
      "Loss  0.2296395 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22806476 C_bot  0.15 k_c 0.0\n",
      "2159 Train Loss 11.082661\n",
      "Loss  0.22806476 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22717775 C_bot  0.15 k_c 0.0\n",
      "2160 Train Loss 11.078327\n",
      "Loss  0.22717775 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22559617 C_bot  0.15 k_c 0.0\n",
      "2161 Train Loss 11.074021\n",
      "Loss  0.22559617 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22455578 C_bot  0.15 k_c 0.0\n",
      "2162 Train Loss 11.0698395\n",
      "Loss  0.22455578 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22357778 C_bot  0.15 k_c 0.0\n",
      "2163 Train Loss 11.06582\n",
      "Loss  0.22357778 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22243617 C_bot  0.15 k_c 0.0\n",
      "2164 Train Loss 11.061921\n",
      "Loss  0.22243617 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22173725 C_bot  0.15 k_c 0.0\n",
      "2165 Train Loss 11.057983\n",
      "Loss  0.22173725 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22051658 C_bot  0.15 k_c 0.0\n",
      "2166 Train Loss 11.054134\n",
      "Loss  0.22051658 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21976437 C_bot  0.15 k_c 0.0\n",
      "2167 Train Loss 11.050251\n",
      "Loss  0.21976437 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21879789 C_bot  0.15 k_c 0.0\n",
      "2168 Train Loss 11.046503\n",
      "Loss  0.21879789 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2179369 C_bot  0.15 k_c 0.0\n",
      "2169 Train Loss 11.042812\n",
      "Loss  0.2179369 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21730372 C_bot  0.15 k_c 0.0\n",
      "2170 Train Loss 11.039192\n",
      "Loss  0.21730372 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21636249 C_bot  0.15 k_c 0.0\n",
      "2171 Train Loss 11.035641\n",
      "Loss  0.21636249 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21580003 C_bot  0.15 k_c 0.0\n",
      "2172 Train Loss 11.03206\n",
      "Loss  0.21580003 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2149148 C_bot  0.15 k_c 0.0\n",
      "2173 Train Loss 11.028568\n",
      "Loss  0.2149148 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2143077 C_bot  0.15 k_c 0.0\n",
      "2174 Train Loss 11.025114\n",
      "Loss  0.2143077 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21363772 C_bot  0.15 k_c 0.0\n",
      "2175 Train Loss 11.0217\n",
      "Loss  0.21363772 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2129138 C_bot  0.15 k_c 0.0\n",
      "2176 Train Loss 11.018349\n",
      "Loss  0.2129138 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21244024 C_bot  0.15 k_c 0.0\n",
      "2177 Train Loss 11.015032\n",
      "Loss  0.21244024 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21165006 C_bot  0.15 k_c 0.0\n",
      "2178 Train Loss 11.011732\n",
      "Loss  0.21165006 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21123514 C_bot  0.15 k_c 0.0\n",
      "2179 Train Loss 11.0085125\n",
      "Loss  0.21123514 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21050803 C_bot  0.15 k_c 0.0\n",
      "2180 Train Loss 11.005255\n",
      "Loss  0.21050803 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20999667 C_bot  0.15 k_c 0.0\n",
      "2181 Train Loss 11.002085\n",
      "Loss  0.20999667 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20946105 C_bot  0.15 k_c 0.0\n",
      "2182 Train Loss 10.998932\n",
      "Loss  0.20946105 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20888068 C_bot  0.15 k_c 0.0\n",
      "2183 Train Loss 10.995854\n",
      "Loss  0.20888068 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20847224 C_bot  0.15 k_c 0.0\n",
      "2184 Train Loss 10.992775\n",
      "Loss  0.20847224 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20784391 C_bot  0.15 k_c 0.0\n",
      "2185 Train Loss 10.989731\n",
      "Loss  0.20784391 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20744781 C_bot  0.15 k_c 0.0\n",
      "2186 Train Loss 10.9867115\n",
      "Loss  0.20744781 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20685183 C_bot  0.15 k_c 0.0\n",
      "2187 Train Loss 10.983683\n",
      "Loss  0.20685183 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20641248 C_bot  0.15 k_c 0.0\n",
      "2188 Train Loss 10.980733\n",
      "Loss  0.20641248 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20595439 C_bot  0.15 k_c 0.0\n",
      "2189 Train Loss 10.977795\n",
      "Loss  0.20595439 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2054664 C_bot  0.15 k_c 0.0\n",
      "2190 Train Loss 10.974909\n",
      "Loss  0.2054664 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20507754 C_bot  0.15 k_c 0.0\n",
      "2191 Train Loss 10.9720125\n",
      "Loss  0.20507754 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20458736 C_bot  0.15 k_c 0.0\n",
      "2192 Train Loss 10.969194\n",
      "Loss  0.20458736 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20417792 C_bot  0.15 k_c 0.0\n",
      "2193 Train Loss 10.966308\n",
      "Loss  0.20417792 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20374478 C_bot  0.15 k_c 0.0\n",
      "2194 Train Loss 10.9635515\n",
      "Loss  0.20374478 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20334615 C_bot  0.15 k_c 0.0\n",
      "2195 Train Loss 10.960757\n",
      "Loss  0.20334615 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2029231 C_bot  0.15 k_c 0.0\n",
      "2196 Train Loss 10.957987\n",
      "Loss  0.2029231 C_bot  0.15 k_c 0.0\n",
      "Loss  0.202505 C_bot  0.15 k_c 0.0\n",
      "2197 Train Loss 10.955257\n",
      "Loss  0.202505 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20214406 C_bot  0.15 k_c 0.0\n",
      "2198 Train Loss 10.952539\n",
      "Loss  0.20214406 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20166656 C_bot  0.15 k_c 0.0\n",
      "2199 Train Loss 10.949802\n",
      "Loss  0.20166656 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2013434 C_bot  0.15 k_c 0.0\n",
      "2200 Train Loss 10.947148\n",
      "Loss  0.2013434 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20090345 C_bot  0.15 k_c 0.0\n",
      "2201 Train Loss 10.944469\n",
      "Loss  0.20090345 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20057693 C_bot  0.15 k_c 0.0\n",
      "2202 Train Loss 10.941858\n",
      "Loss  0.20057693 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20015924 C_bot  0.15 k_c 0.0\n",
      "2203 Train Loss 10.939207\n",
      "Loss  0.20015924 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19977875 C_bot  0.15 k_c 0.0\n",
      "2204 Train Loss 10.936593\n",
      "Loss  0.19977875 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19943868 C_bot  0.15 k_c 0.0\n",
      "2205 Train Loss 10.934029\n",
      "Loss  0.19943868 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19903612 C_bot  0.15 k_c 0.0\n",
      "2206 Train Loss 10.931437\n",
      "Loss  0.19903612 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19871573 C_bot  0.15 k_c 0.0\n",
      "2207 Train Loss 10.9289\n",
      "Loss  0.19871573 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19832048 C_bot  0.15 k_c 0.0\n",
      "2208 Train Loss 10.926354\n",
      "Loss  0.19832048 C_bot  0.15 k_c 0.0\n",
      "Loss  0.198012 C_bot  0.15 k_c 0.0\n",
      "2209 Train Loss 10.923855\n",
      "Loss  0.198012 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19764246 C_bot  0.15 k_c 0.0\n",
      "2210 Train Loss 10.921354\n",
      "Loss  0.19764246 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19730519 C_bot  0.15 k_c 0.0\n",
      "2211 Train Loss 10.918863\n",
      "Loss  0.19730519 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19696435 C_bot  0.15 k_c 0.0\n",
      "2212 Train Loss 10.916403\n",
      "Loss  0.19696435 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19661799 C_bot  0.15 k_c 0.0\n",
      "2213 Train Loss 10.9139385\n",
      "Loss  0.19661799 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19627352 C_bot  0.15 k_c 0.0\n",
      "2214 Train Loss 10.911491\n",
      "Loss  0.19627352 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19592813 C_bot  0.15 k_c 0.0\n",
      "2215 Train Loss 10.909054\n",
      "Loss  0.19592813 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19560613 C_bot  0.15 k_c 0.0\n",
      "2216 Train Loss 10.906654\n",
      "Loss  0.19560613 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19525479 C_bot  0.15 k_c 0.0\n",
      "2217 Train Loss 10.90423\n",
      "Loss  0.19525479 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19493808 C_bot  0.15 k_c 0.0\n",
      "2218 Train Loss 10.901859\n",
      "Loss  0.19493808 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19461171 C_bot  0.15 k_c 0.0\n",
      "2219 Train Loss 10.899483\n",
      "Loss  0.19461171 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19425553 C_bot  0.15 k_c 0.0\n",
      "2220 Train Loss 10.897095\n",
      "Loss  0.19425553 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19397153 C_bot  0.15 k_c 0.0\n",
      "2221 Train Loss 10.894784\n",
      "Loss  0.19397153 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19363385 C_bot  0.15 k_c 0.0\n",
      "2222 Train Loss 10.892436\n",
      "Loss  0.19363385 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19332986 C_bot  0.15 k_c 0.0\n",
      "2223 Train Loss 10.890124\n",
      "Loss  0.19332986 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1930011 C_bot  0.15 k_c 0.0\n",
      "2224 Train Loss 10.887808\n",
      "Loss  0.1930011 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19272259 C_bot  0.15 k_c 0.0\n",
      "2225 Train Loss 10.885538\n",
      "Loss  0.19272259 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19240722 C_bot  0.15 k_c 0.0\n",
      "2226 Train Loss 10.883264\n",
      "Loss  0.19240722 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1920881 C_bot  0.15 k_c 0.0\n",
      "2227 Train Loss 10.880966\n",
      "Loss  0.1920881 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19176687 C_bot  0.15 k_c 0.0\n",
      "2228 Train Loss 10.878708\n",
      "Loss  0.19176687 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19149199 C_bot  0.15 k_c 0.0\n",
      "2229 Train Loss 10.876476\n",
      "Loss  0.19149199 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19114093 C_bot  0.15 k_c 0.0\n",
      "2230 Train Loss 10.874199\n",
      "Loss  0.19114093 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19087048 C_bot  0.15 k_c 0.0\n",
      "2231 Train Loss 10.872\n",
      "Loss  0.19087048 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19057468 C_bot  0.15 k_c 0.0\n",
      "2232 Train Loss 10.869786\n",
      "Loss  0.19057468 C_bot  0.15 k_c 0.0\n",
      "Loss  0.190246 C_bot  0.15 k_c 0.0\n",
      "2233 Train Loss 10.8675585\n",
      "Loss  0.190246 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18996659 C_bot  0.15 k_c 0.0\n",
      "2234 Train Loss 10.865368\n",
      "Loss  0.18996659 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18966112 C_bot  0.15 k_c 0.0\n",
      "2235 Train Loss 10.8631935\n",
      "Loss  0.18966112 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18939361 C_bot  0.15 k_c 0.0\n",
      "2236 Train Loss 10.86102\n",
      "Loss  0.18939361 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18908443 C_bot  0.15 k_c 0.0\n",
      "2237 Train Loss 10.858871\n",
      "Loss  0.18908443 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18884762 C_bot  0.15 k_c 0.0\n",
      "2238 Train Loss 10.856735\n",
      "Loss  0.18884762 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18851592 C_bot  0.15 k_c 0.0\n",
      "2239 Train Loss 10.854589\n",
      "Loss  0.18851592 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18827905 C_bot  0.15 k_c 0.0\n",
      "2240 Train Loss 10.852463\n",
      "Loss  0.18827905 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1879438 C_bot  0.15 k_c 0.0\n",
      "2241 Train Loss 10.850333\n",
      "Loss  0.1879438 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1877072 C_bot  0.15 k_c 0.0\n",
      "2242 Train Loss 10.848223\n",
      "Loss  0.1877072 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18741536 C_bot  0.15 k_c 0.0\n",
      "2243 Train Loss 10.84615\n",
      "Loss  0.18741536 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18713596 C_bot  0.15 k_c 0.0\n",
      "2244 Train Loss 10.844019\n",
      "Loss  0.18713596 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18682879 C_bot  0.15 k_c 0.0\n",
      "2245 Train Loss 10.841942\n",
      "Loss  0.18682879 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18659152 C_bot  0.15 k_c 0.0\n",
      "2246 Train Loss 10.839869\n",
      "Loss  0.18659152 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18626009 C_bot  0.15 k_c 0.0\n",
      "2247 Train Loss 10.837782\n",
      "Loss  0.18626009 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1860421 C_bot  0.15 k_c 0.0\n",
      "2248 Train Loss 10.835747\n",
      "Loss  0.1860421 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18577231 C_bot  0.15 k_c 0.0\n",
      "2249 Train Loss 10.833731\n",
      "Loss  0.18577231 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18548599 C_bot  0.15 k_c 0.0\n",
      "2250 Train Loss 10.83165\n",
      "Loss  0.18548599 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18523474 C_bot  0.15 k_c 0.0\n",
      "2251 Train Loss 10.829655\n",
      "Loss  0.18523474 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18495311 C_bot  0.15 k_c 0.0\n",
      "2252 Train Loss 10.827604\n",
      "Loss  0.18495311 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18470952 C_bot  0.15 k_c 0.0\n",
      "2253 Train Loss 10.825623\n",
      "Loss  0.18470952 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18444528 C_bot  0.15 k_c 0.0\n",
      "2254 Train Loss 10.823615\n",
      "Loss  0.18444528 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18419777 C_bot  0.15 k_c 0.0\n",
      "2255 Train Loss 10.8216305\n",
      "Loss  0.18419777 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18393627 C_bot  0.15 k_c 0.0\n",
      "2256 Train Loss 10.819649\n",
      "Loss  0.18393627 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18367986 C_bot  0.15 k_c 0.0\n",
      "2257 Train Loss 10.817663\n",
      "Loss  0.18367986 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18342806 C_bot  0.15 k_c 0.0\n",
      "2258 Train Loss 10.815708\n",
      "Loss  0.18342806 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18322136 C_bot  0.15 k_c 0.0\n",
      "2259 Train Loss 10.813782\n",
      "Loss  0.18322136 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18293092 C_bot  0.15 k_c 0.0\n",
      "2260 Train Loss 10.811806\n",
      "Loss  0.18293092 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18267713 C_bot  0.15 k_c 0.0\n",
      "2261 Train Loss 10.809839\n",
      "Loss  0.18267713 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18242598 C_bot  0.15 k_c 0.0\n",
      "2262 Train Loss 10.80792\n",
      "Loss  0.18242598 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18221177 C_bot  0.15 k_c 0.0\n",
      "2263 Train Loss 10.806002\n",
      "Loss  0.18221177 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18193242 C_bot  0.15 k_c 0.0\n",
      "2264 Train Loss 10.804076\n",
      "Loss  0.18193242 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18173876 C_bot  0.15 k_c 0.0\n",
      "2265 Train Loss 10.802178\n",
      "Loss  0.18173876 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18145885 C_bot  0.15 k_c 0.0\n",
      "2266 Train Loss 10.800275\n",
      "Loss  0.18145885 C_bot  0.15 k_c 0.0\n",
      "Loss  0.181266 C_bot  0.15 k_c 0.0\n",
      "2267 Train Loss 10.79838\n",
      "Loss  0.181266 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18099058 C_bot  0.15 k_c 0.0\n",
      "2268 Train Loss 10.796505\n",
      "Loss  0.18099058 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18079557 C_bot  0.15 k_c 0.0\n",
      "2269 Train Loss 10.794605\n",
      "Loss  0.18079557 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18050973 C_bot  0.15 k_c 0.0\n",
      "2270 Train Loss 10.792749\n",
      "Loss  0.18050973 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1803813 C_bot  0.15 k_c 0.0\n",
      "2271 Train Loss 10.790903\n",
      "Loss  0.1803813 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1800465 C_bot  0.15 k_c 0.0\n",
      "2272 Train Loss 10.789047\n",
      "Loss  0.1800465 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17996332 C_bot  0.15 k_c 0.0\n",
      "2273 Train Loss 10.787206\n",
      "Loss  0.17996332 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17957567 C_bot  0.15 k_c 0.0\n",
      "2274 Train Loss 10.7853775\n",
      "Loss  0.17957567 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17963287 C_bot  0.15 k_c 0.0\n",
      "2275 Train Loss 10.783597\n",
      "Loss  0.17963287 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17919579 C_bot  0.15 k_c 0.0\n",
      "2276 Train Loss 10.781847\n",
      "Loss  0.17919579 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17941974 C_bot  0.15 k_c 0.0\n",
      "2277 Train Loss 10.780093\n",
      "Loss  0.17941974 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17890863 C_bot  0.15 k_c 0.0\n",
      "2278 Train Loss 10.778479\n",
      "Loss  0.17890863 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17960796 C_bot  0.15 k_c 0.0\n",
      "2279 Train Loss 10.776949\n",
      "Loss  0.17960796 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17917553 C_bot  0.15 k_c 0.0\n",
      "2280 Train Loss 10.775776\n",
      "Loss  0.17917553 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18099947 C_bot  0.15 k_c 0.0\n",
      "2281 Train Loss 10.77491\n",
      "Loss  0.18099947 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1812259 C_bot  0.15 k_c 0.0\n",
      "2282 Train Loss 10.775044\n",
      "Loss  0.1812259 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18612547 C_bot  0.15 k_c 0.0\n",
      "2283 Train Loss 10.776405\n",
      "Loss  0.18612547 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18942693 C_bot  0.15 k_c 0.0\n",
      "2284 Train Loss 10.780802\n",
      "Loss  0.18942693 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20362121 C_bot  0.15 k_c 0.0\n",
      "2285 Train Loss 10.78989\n",
      "Loss  0.20362121 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21945289 C_bot  0.15 k_c 0.0\n",
      "2286 Train Loss 10.809029\n",
      "Loss  0.21945289 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26400757 C_bot  0.15 k_c 0.0\n",
      "2287 Train Loss 10.845539\n",
      "Loss  0.26400757 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3285876 C_bot  0.15 k_c 0.0\n",
      "2288 Train Loss 10.917654\n",
      "Loss  0.3285876 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47937602 C_bot  0.15 k_c 0.0\n",
      "2289 Train Loss 11.054841\n",
      "Loss  0.47937602 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7332807 C_bot  0.15 k_c 0.0\n",
      "2290 Train Loss 11.324589\n",
      "Loss  0.7332807 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2758003 C_bot  0.15 k_c 0.0\n",
      "2291 Train Loss 11.842979\n",
      "Loss  1.2758003 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2740247 C_bot  0.15 k_c 0.0\n",
      "2292 Train Loss 12.873956\n",
      "Loss  2.2740247 C_bot  0.15 k_c 0.0\n",
      "Loss  4.3187237 C_bot  0.15 k_c 0.0\n",
      "2293 Train Loss 14.874826\n",
      "Loss  4.3187237 C_bot  0.15 k_c 0.0\n",
      "Loss  8.304208 C_bot  0.15 k_c 0.0\n",
      "2294 Train Loss 18.929352\n",
      "Loss  8.304208 C_bot  0.15 k_c 0.0\n",
      "Loss  16.243484 C_bot  0.15 k_c 0.0\n",
      "2295 Train Loss 26.78942\n",
      "Loss  16.243484 C_bot  0.15 k_c 0.0\n",
      "Loss  32.34498 C_bot  0.15 k_c 0.0\n",
      "2296 Train Loss 43.0446\n",
      "Loss  32.34498 C_bot  0.15 k_c 0.0\n",
      "Loss  63.030445 C_bot  0.15 k_c 0.0\n",
      "2297 Train Loss 73.59271\n",
      "Loss  63.030445 C_bot  0.15 k_c 0.0\n",
      "Loss  126.195625 C_bot  0.15 k_c 0.0\n",
      "2298 Train Loss 137.13286\n",
      "Loss  126.195625 C_bot  0.15 k_c 0.0\n",
      "Loss  231.47694 C_bot  0.15 k_c 0.0\n",
      "2299 Train Loss 242.18045\n",
      "Loss  231.47694 C_bot  0.15 k_c 0.0\n",
      "Loss  430.62915 C_bot  0.15 k_c 0.0\n",
      "2300 Train Loss 442.3109\n",
      "Loss  430.62915 C_bot  0.15 k_c 0.0\n",
      "Loss  626.943 C_bot  0.15 k_c 0.0\n",
      "2301 Train Loss 638.033\n",
      "Loss  626.943 C_bot  0.15 k_c 0.0\n",
      "Loss  821.19763 C_bot  0.15 k_c 0.0\n",
      "2302 Train Loss 834.2253\n",
      "Loss  821.19763 C_bot  0.15 k_c 0.0\n",
      "Loss  609.81915 C_bot  0.15 k_c 0.0\n",
      "2303 Train Loss 621.0803\n",
      "Loss  609.81915 C_bot  0.15 k_c 0.0\n",
      "Loss  227.65094 C_bot  0.15 k_c 0.0\n",
      "2304 Train Loss 240.2386\n",
      "Loss  227.65094 C_bot  0.15 k_c 0.0\n",
      "Loss  4.8207645 C_bot  0.15 k_c 0.0\n",
      "2305 Train Loss 16.849121\n",
      "Loss  4.8207645 C_bot  0.15 k_c 0.0\n",
      "Loss  164.46962 C_bot  0.15 k_c 0.0\n",
      "2306 Train Loss 176.48611\n",
      "Loss  164.46962 C_bot  0.15 k_c 0.0\n",
      "Loss  393.48074 C_bot  0.15 k_c 0.0\n",
      "2307 Train Loss 407.93808\n",
      "Loss  393.48074 C_bot  0.15 k_c 0.0\n",
      "Loss  291.80008 C_bot  0.15 k_c 0.0\n",
      "2308 Train Loss 304.1852\n",
      "Loss  291.80008 C_bot  0.15 k_c 0.0\n",
      "Loss  60.23209 C_bot  0.15 k_c 0.0\n",
      "2309 Train Loss 73.71992\n",
      "Loss  60.23209 C_bot  0.15 k_c 0.0\n",
      "Loss  23.27891 C_bot  0.15 k_c 0.0\n",
      "2310 Train Loss 36.490067\n",
      "Loss  23.27891 C_bot  0.15 k_c 0.0\n",
      "Loss  176.17978 C_bot  0.15 k_c 0.0\n",
      "2311 Train Loss 188.57948\n",
      "Loss  176.17978 C_bot  0.15 k_c 0.0\n",
      "Loss  222.78708 C_bot  0.15 k_c 0.0\n",
      "2312 Train Loss 236.64838\n",
      "Loss  222.78708 C_bot  0.15 k_c 0.0\n",
      "Loss  70.51544 C_bot  0.15 k_c 0.0\n",
      "2313 Train Loss 82.82682\n",
      "Loss  70.51544 C_bot  0.15 k_c 0.0\n",
      "Loss  5.342521 C_bot  0.15 k_c 0.0\n",
      "2314 Train Loss 17.727955\n",
      "Loss  5.342521 C_bot  0.15 k_c 0.0\n",
      "Loss  100.22412 C_bot  0.15 k_c 0.0\n",
      "2315 Train Loss 113.0942\n",
      "Loss  100.22412 C_bot  0.15 k_c 0.0\n",
      "Loss  129.0483 C_bot  0.15 k_c 0.0\n",
      "2316 Train Loss 141.15483\n",
      "Loss  129.0483 C_bot  0.15 k_c 0.0\n",
      "Loss  39.655003 C_bot  0.15 k_c 0.0\n",
      "2317 Train Loss 52.098564\n",
      "Loss  39.655003 C_bot  0.15 k_c 0.0\n",
      "Loss  5.0562468 C_bot  0.15 k_c 0.0\n",
      "2318 Train Loss 17.270897\n",
      "Loss  5.0562468 C_bot  0.15 k_c 0.0\n",
      "Loss  70.48711 C_bot  0.15 k_c 0.0\n",
      "2319 Train Loss 82.51981\n",
      "Loss  70.48711 C_bot  0.15 k_c 0.0\n",
      "Loss  84.13869 C_bot  0.15 k_c 0.0\n",
      "2320 Train Loss 96.56471\n",
      "Loss  84.13869 C_bot  0.15 k_c 0.0\n",
      "Loss  18.448402 C_bot  0.15 k_c 0.0\n",
      "2321 Train Loss 30.415226\n",
      "Loss  18.448402 C_bot  0.15 k_c 0.0\n",
      "Loss  9.623157 C_bot  0.15 k_c 0.0\n",
      "2322 Train Loss 21.556553\n",
      "Loss  9.623157 C_bot  0.15 k_c 0.0\n",
      "Loss  55.870514 C_bot  0.15 k_c 0.0\n",
      "2323 Train Loss 68.06103\n",
      "Loss  55.870514 C_bot  0.15 k_c 0.0\n",
      "Loss  47.210846 C_bot  0.15 k_c 0.0\n",
      "2324 Train Loss 59.007385\n",
      "Loss  47.210846 C_bot  0.15 k_c 0.0\n",
      "Loss  5.6199226 C_bot  0.15 k_c 0.0\n",
      "2325 Train Loss 17.5042\n",
      "Loss  5.6199226 C_bot  0.15 k_c 0.0\n",
      "Loss  13.025524 C_bot  0.15 k_c 0.0\n",
      "2326 Train Loss 24.911541\n",
      "Loss  13.025524 C_bot  0.15 k_c 0.0\n",
      "Loss  39.843468 C_bot  0.15 k_c 0.0\n",
      "2327 Train Loss 51.45794\n",
      "Loss  39.843468 C_bot  0.15 k_c 0.0\n",
      "Loss  24.423014 C_bot  0.15 k_c 0.0\n",
      "2328 Train Loss 36.31931\n",
      "Loss  24.423014 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3553972 C_bot  0.15 k_c 0.0\n",
      "2329 Train Loss 13.028982\n",
      "Loss  1.3553972 C_bot  0.15 k_c 0.0\n",
      "Loss  15.385642 C_bot  0.15 k_c 0.0\n",
      "2330 Train Loss 26.959475\n",
      "Loss  15.385642 C_bot  0.15 k_c 0.0\n",
      "Loss  27.64158 C_bot  0.15 k_c 0.0\n",
      "2331 Train Loss 39.53887\n",
      "Loss  27.64158 C_bot  0.15 k_c 0.0\n",
      "Loss  10.148533 C_bot  0.15 k_c 0.0\n",
      "2332 Train Loss 21.727085\n",
      "Loss  10.148533 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6372194 C_bot  0.15 k_c 0.0\n",
      "2333 Train Loss 13.270603\n",
      "Loss  1.6372194 C_bot  0.15 k_c 0.0\n",
      "Loss  15.155149 C_bot  0.15 k_c 0.0\n",
      "2334 Train Loss 26.955969\n",
      "Loss  15.155149 C_bot  0.15 k_c 0.0\n",
      "Loss  16.269627 C_bot  0.15 k_c 0.0\n",
      "2335 Train Loss 27.802734\n",
      "Loss  16.269627 C_bot  0.15 k_c 0.0\n",
      "Loss  2.980601 C_bot  0.15 k_c 0.0\n",
      "2336 Train Loss 14.634394\n",
      "Loss  2.980601 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5720336 C_bot  0.15 k_c 0.0\n",
      "2337 Train Loss 15.200956\n",
      "Loss  3.5720336 C_bot  0.15 k_c 0.0\n",
      "Loss  12.589092 C_bot  0.15 k_c 0.0\n",
      "2338 Train Loss 24.068806\n",
      "Loss  12.589092 C_bot  0.15 k_c 0.0\n",
      "Loss  8.443739 C_bot  0.15 k_c 0.0\n",
      "2339 Train Loss 20.04447\n",
      "Loss  8.443739 C_bot  0.15 k_c 0.0\n",
      "Loss  0.931733 C_bot  0.15 k_c 0.0\n",
      "2340 Train Loss 12.417446\n",
      "Loss  0.931733 C_bot  0.15 k_c 0.0\n",
      "Loss  5.0405393 C_bot  0.15 k_c 0.0\n",
      "2341 Train Loss 16.47277\n",
      "Loss  5.0405393 C_bot  0.15 k_c 0.0\n",
      "Loss  9.081256 C_bot  0.15 k_c 0.0\n",
      "2342 Train Loss 20.586308\n",
      "Loss  9.081256 C_bot  0.15 k_c 0.0\n",
      "Loss  3.790053 C_bot  0.15 k_c 0.0\n",
      "2343 Train Loss 15.180885\n",
      "Loss  3.790053 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9383625 C_bot  0.15 k_c 0.0\n",
      "2344 Train Loss 12.322731\n",
      "Loss  0.9383625 C_bot  0.15 k_c 0.0\n",
      "Loss  5.112748 C_bot  0.15 k_c 0.0\n",
      "2345 Train Loss 16.520983\n",
      "Loss  5.112748 C_bot  0.15 k_c 0.0\n",
      "Loss  5.696278 C_bot  0.15 k_c 0.0\n",
      "2346 Train Loss 17.013853\n",
      "Loss  5.696278 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4947104 C_bot  0.15 k_c 0.0\n",
      "2347 Train Loss 12.835034\n",
      "Loss  1.4947104 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3925366 C_bot  0.15 k_c 0.0\n",
      "2348 Train Loss 12.713372\n",
      "Loss  1.3925366 C_bot  0.15 k_c 0.0\n",
      "Loss  4.3192716 C_bot  0.15 k_c 0.0\n",
      "2349 Train Loss 15.578189\n",
      "Loss  4.3192716 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2918077 C_bot  0.15 k_c 0.0\n",
      "2350 Train Loss 14.599903\n",
      "Loss  3.2918077 C_bot  0.15 k_c 0.0\n",
      "Loss  0.75403965 C_bot  0.15 k_c 0.0\n",
      "2351 Train Loss 12.005561\n",
      "Loss  0.75403965 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7162967 C_bot  0.15 k_c 0.0\n",
      "2352 Train Loss 12.941998\n",
      "Loss  1.7162967 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2399123 C_bot  0.15 k_c 0.0\n",
      "2353 Train Loss 14.512485\n",
      "Loss  3.2399123 C_bot  0.15 k_c 0.0\n",
      "Loss  1.916398 C_bot  0.15 k_c 0.0\n",
      "2354 Train Loss 13.114795\n",
      "Loss  1.916398 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6078063 C_bot  0.15 k_c 0.0\n",
      "2355 Train Loss 11.816524\n",
      "Loss  0.6078063 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6801289 C_bot  0.15 k_c 0.0\n",
      "2356 Train Loss 12.902815\n",
      "Loss  1.6801289 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3674667 C_bot  0.15 k_c 0.0\n",
      "2357 Train Loss 13.524856\n",
      "Loss  2.3674667 C_bot  0.15 k_c 0.0\n",
      "Loss  1.142262 C_bot  0.15 k_c 0.0\n",
      "2358 Train Loss 12.332336\n",
      "Loss  1.142262 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63800466 C_bot  0.15 k_c 0.0\n",
      "2359 Train Loss 11.803092\n",
      "Loss  0.63800466 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5396351 C_bot  0.15 k_c 0.0\n",
      "2360 Train Loss 12.668238\n",
      "Loss  1.5396351 C_bot  0.15 k_c 0.0\n",
      "Loss  1.64775 C_bot  0.15 k_c 0.0\n",
      "2361 Train Loss 12.8079815\n",
      "Loss  1.64775 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8089962 C_bot  0.15 k_c 0.0\n",
      "2362 Train Loss 11.924911\n",
      "Loss  0.8089962 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6806374 C_bot  0.15 k_c 0.0\n",
      "2363 Train Loss 11.789034\n",
      "Loss  0.6806374 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2685732 C_bot  0.15 k_c 0.0\n",
      "2364 Train Loss 12.390129\n",
      "Loss  1.2685732 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2237897 C_bot  0.15 k_c 0.0\n",
      "2365 Train Loss 12.305775\n",
      "Loss  1.2237897 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6297283 C_bot  0.15 k_c 0.0\n",
      "2366 Train Loss 11.720957\n",
      "Loss  0.6297283 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6651614 C_bot  0.15 k_c 0.0\n",
      "2367 Train Loss 11.748434\n",
      "Loss  0.6651614 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0716057 C_bot  0.15 k_c 0.0\n",
      "2368 Train Loss 12.130036\n",
      "Loss  1.0716057 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9216624 C_bot  0.15 k_c 0.0\n",
      "2369 Train Loss 11.992202\n",
      "Loss  0.9216624 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5664849 C_bot  0.15 k_c 0.0\n",
      "2370 Train Loss 11.616169\n",
      "Loss  0.5664849 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6497032 C_bot  0.15 k_c 0.0\n",
      "2371 Train Loss 11.688853\n",
      "Loss  0.6497032 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8796746 C_bot  0.15 k_c 0.0\n",
      "2372 Train Loss 11.924337\n",
      "Loss  0.8796746 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7686092 C_bot  0.15 k_c 0.0\n",
      "2373 Train Loss 11.788974\n",
      "Loss  0.7686092 C_bot  0.15 k_c 0.0\n",
      "Loss  0.53085303 C_bot  0.15 k_c 0.0\n",
      "2374 Train Loss 11.551234\n",
      "Loss  0.53085303 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6048869 C_bot  0.15 k_c 0.0\n",
      "2375 Train Loss 11.620428\n",
      "Loss  0.6048869 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7662392 C_bot  0.15 k_c 0.0\n",
      "2376 Train Loss 11.76231\n",
      "Loss  0.7662392 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65614015 C_bot  0.15 k_c 0.0\n",
      "2377 Train Loss 11.657925\n",
      "Loss  0.65614015 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5164953 C_bot  0.15 k_c 0.0\n",
      "2378 Train Loss 11.50358\n",
      "Loss  0.5164953 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5760508 C_bot  0.15 k_c 0.0\n",
      "2379 Train Loss 11.553169\n",
      "Loss  0.5760508 C_bot  0.15 k_c 0.0\n",
      "Loss  0.66164804 C_bot  0.15 k_c 0.0\n",
      "2380 Train Loss 11.642519\n",
      "Loss  0.66164804 C_bot  0.15 k_c 0.0\n",
      "Loss  0.60576546 C_bot  0.15 k_c 0.0\n",
      "2381 Train Loss 11.568157\n",
      "Loss  0.60576546 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5033897 C_bot  0.15 k_c 0.0\n",
      "2382 Train Loss 11.464874\n",
      "Loss  0.5033897 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5370696 C_bot  0.15 k_c 0.0\n",
      "2383 Train Loss 11.494317\n",
      "Loss  0.5370696 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6090629 C_bot  0.15 k_c 0.0\n",
      "2384 Train Loss 11.551249\n",
      "Loss  0.6090629 C_bot  0.15 k_c 0.0\n",
      "Loss  0.55851936 C_bot  0.15 k_c 0.0\n",
      "2385 Train Loss 11.503836\n",
      "Loss  0.55851936 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49691683 C_bot  0.15 k_c 0.0\n",
      "2386 Train Loss 11.430683\n",
      "Loss  0.49691683 C_bot  0.15 k_c 0.0\n",
      "Loss  0.51633936 C_bot  0.15 k_c 0.0\n",
      "2387 Train Loss 11.442509\n",
      "Loss  0.51633936 C_bot  0.15 k_c 0.0\n",
      "Loss  0.55365205 C_bot  0.15 k_c 0.0\n",
      "2388 Train Loss 11.480545\n",
      "Loss  0.55365205 C_bot  0.15 k_c 0.0\n",
      "Loss  0.53842145 C_bot  0.15 k_c 0.0\n",
      "2389 Train Loss 11.451792\n",
      "Loss  0.53842145 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4869993 C_bot  0.15 k_c 0.0\n",
      "2390 Train Loss 11.39915\n",
      "Loss  0.4869993 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49130675 C_bot  0.15 k_c 0.0\n",
      "2391 Train Loss 11.398554\n",
      "Loss  0.49130675 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5256177 C_bot  0.15 k_c 0.0\n",
      "2392 Train Loss 11.422643\n",
      "Loss  0.5256177 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5104994 C_bot  0.15 k_c 0.0\n",
      "2393 Train Loss 11.408232\n",
      "Loss  0.5104994 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48131827 C_bot  0.15 k_c 0.0\n",
      "2394 Train Loss 11.369732\n",
      "Loss  0.48131827 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4775628 C_bot  0.15 k_c 0.0\n",
      "2395 Train Loss 11.361004\n",
      "Loss  0.4775628 C_bot  0.15 k_c 0.0\n",
      "Loss  0.49370983 C_bot  0.15 k_c 0.0\n",
      "2396 Train Loss 11.37553\n",
      "Loss  0.49370983 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4972804 C_bot  0.15 k_c 0.0\n",
      "2397 Train Loss 11.369263\n",
      "Loss  0.4972804 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47162887 C_bot  0.15 k_c 0.0\n",
      "2398 Train Loss 11.34231\n",
      "Loss  0.47162887 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4641853 C_bot  0.15 k_c 0.0\n",
      "2399 Train Loss 11.329163\n",
      "Loss  0.4641853 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47743365 C_bot  0.15 k_c 0.0\n",
      "2400 Train Loss 11.335409\n",
      "Loss  0.47743365 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47710538 C_bot  0.15 k_c 0.0\n",
      "2401 Train Loss 11.334143\n",
      "Loss  0.47710538 C_bot  0.15 k_c 0.0\n",
      "Loss  0.46694705 C_bot  0.15 k_c 0.0\n",
      "2402 Train Loss 11.315866\n",
      "Loss  0.46694705 C_bot  0.15 k_c 0.0\n",
      "Loss  0.45586795 C_bot  0.15 k_c 0.0\n",
      "2403 Train Loss 11.301416\n",
      "Loss  0.45586795 C_bot  0.15 k_c 0.0\n",
      "Loss  0.45934224 C_bot  0.15 k_c 0.0\n",
      "2404 Train Loss 11.301483\n",
      "Loss  0.45934224 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4666118 C_bot  0.15 k_c 0.0\n",
      "2405 Train Loss 11.301345\n",
      "Loss  0.4666118 C_bot  0.15 k_c 0.0\n",
      "Loss  0.45693251 C_bot  0.15 k_c 0.0\n",
      "2406 Train Loss 11.2901745\n",
      "Loss  0.45693251 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4493986 C_bot  0.15 k_c 0.0\n",
      "2407 Train Loss 11.276515\n",
      "Loss  0.4493986 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4494733 C_bot  0.15 k_c 0.0\n",
      "2408 Train Loss 11.27187\n",
      "Loss  0.4494733 C_bot  0.15 k_c 0.0\n",
      "Loss  0.45136264 C_bot  0.15 k_c 0.0\n",
      "2409 Train Loss 11.271378\n",
      "Loss  0.45136264 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4513661 C_bot  0.15 k_c 0.0\n",
      "2410 Train Loss 11.26458\n",
      "Loss  0.4513661 C_bot  0.15 k_c 0.0\n",
      "Loss  0.442648 C_bot  0.15 k_c 0.0\n",
      "2411 Train Loss 11.253437\n",
      "Loss  0.442648 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43996507 C_bot  0.15 k_c 0.0\n",
      "2412 Train Loss 11.2461815\n",
      "Loss  0.43996507 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44266927 C_bot  0.15 k_c 0.0\n",
      "2413 Train Loss 11.243631\n",
      "Loss  0.44266927 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4407464 C_bot  0.15 k_c 0.0\n",
      "2414 Train Loss 11.239534\n",
      "Loss  0.4407464 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43820646 C_bot  0.15 k_c 0.0\n",
      "2415 Train Loss 11.231172\n",
      "Loss  0.43820646 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43323305 C_bot  0.15 k_c 0.0\n",
      "2416 Train Loss 11.223068\n",
      "Loss  0.43323305 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43231848 C_bot  0.15 k_c 0.0\n",
      "2417 Train Loss 11.218592\n",
      "Loss  0.43231848 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43398964 C_bot  0.15 k_c 0.0\n",
      "2418 Train Loss 11.215097\n",
      "Loss  0.43398964 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43046838 C_bot  0.15 k_c 0.0\n",
      "2419 Train Loss 11.209305\n",
      "Loss  0.43046838 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42781076 C_bot  0.15 k_c 0.0\n",
      "2420 Train Loss 11.201769\n",
      "Loss  0.42781076 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4254414 C_bot  0.15 k_c 0.0\n",
      "2421 Train Loss 11.195906\n",
      "Loss  0.4254414 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4245278 C_bot  0.15 k_c 0.0\n",
      "2422 Train Loss 11.191987\n",
      "Loss  0.4245278 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4248264 C_bot  0.15 k_c 0.0\n",
      "2423 Train Loss 11.187471\n",
      "Loss  0.4248264 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42121145 C_bot  0.15 k_c 0.0\n",
      "2424 Train Loss 11.181406\n",
      "Loss  0.42121145 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41913 C_bot  0.15 k_c 0.0\n",
      "2425 Train Loss 11.175158\n",
      "Loss  0.41913 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41791558 C_bot  0.15 k_c 0.0\n",
      "2426 Train Loss 11.170326\n",
      "Loss  0.41791558 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41656494 C_bot  0.15 k_c 0.0\n",
      "2427 Train Loss 11.166228\n",
      "Loss  0.41656494 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4160558 C_bot  0.15 k_c 0.0\n",
      "2428 Train Loss 11.161302\n",
      "Loss  0.4160558 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41303763 C_bot  0.15 k_c 0.0\n",
      "2429 Train Loss 11.155676\n",
      "Loss  0.41303763 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41137636 C_bot  0.15 k_c 0.0\n",
      "2430 Train Loss 11.150328\n",
      "Loss  0.41137636 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41054302 C_bot  0.15 k_c 0.0\n",
      "2431 Train Loss 11.145906\n",
      "Loss  0.41054302 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40886793 C_bot  0.15 k_c 0.0\n",
      "2432 Train Loss 11.141586\n",
      "Loss  0.40886793 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4079779 C_bot  0.15 k_c 0.0\n",
      "2433 Train Loss 11.136658\n",
      "Loss  0.4079779 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40555063 C_bot  0.15 k_c 0.0\n",
      "2434 Train Loss 11.131545\n",
      "Loss  0.40555063 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4041166 C_bot  0.15 k_c 0.0\n",
      "2435 Train Loss 11.126747\n",
      "Loss  0.4041166 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40323988 C_bot  0.15 k_c 0.0\n",
      "2436 Train Loss 11.122426\n",
      "Loss  0.40323988 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40154585 C_bot  0.15 k_c 0.0\n",
      "2437 Train Loss 11.118124\n",
      "Loss  0.40154585 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4005759 C_bot  0.15 k_c 0.0\n",
      "2438 Train Loss 11.113444\n",
      "Loss  0.4005759 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39854375 C_bot  0.15 k_c 0.0\n",
      "2439 Train Loss 11.108717\n",
      "Loss  0.39854375 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39722633 C_bot  0.15 k_c 0.0\n",
      "2440 Train Loss 11.104242\n",
      "Loss  0.39722633 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39626285 C_bot  0.15 k_c 0.0\n",
      "2441 Train Loss 11.100011\n",
      "Loss  0.39626285 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39467964 C_bot  0.15 k_c 0.0\n",
      "2442 Train Loss 11.095837\n",
      "Loss  0.39467964 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39366636 C_bot  0.15 k_c 0.0\n",
      "2443 Train Loss 11.091385\n",
      "Loss  0.39366636 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39193243 C_bot  0.15 k_c 0.0\n",
      "2444 Train Loss 11.0869875\n",
      "Loss  0.39193243 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39068887 C_bot  0.15 k_c 0.0\n",
      "2445 Train Loss 11.0827465\n",
      "Loss  0.39068887 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38966164 C_bot  0.15 k_c 0.0\n",
      "2446 Train Loss 11.078627\n",
      "Loss  0.38966164 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38814607 C_bot  0.15 k_c 0.0\n",
      "2447 Train Loss 11.074557\n",
      "Loss  0.38814607 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38720316 C_bot  0.15 k_c 0.0\n",
      "2448 Train Loss 11.070398\n",
      "Loss  0.38720316 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3855951 C_bot  0.15 k_c 0.0\n",
      "2449 Train Loss 11.066198\n",
      "Loss  0.3855951 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38437653 C_bot  0.15 k_c 0.0\n",
      "2450 Train Loss 11.062096\n",
      "Loss  0.38437653 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38330898 C_bot  0.15 k_c 0.0\n",
      "2451 Train Loss 11.058125\n",
      "Loss  0.38330898 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38191807 C_bot  0.15 k_c 0.0\n",
      "2452 Train Loss 11.054205\n",
      "Loss  0.38191807 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38095978 C_bot  0.15 k_c 0.0\n",
      "2453 Train Loss 11.050228\n",
      "Loss  0.38095978 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37947828 C_bot  0.15 k_c 0.0\n",
      "2454 Train Loss 11.046239\n",
      "Loss  0.37947828 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37835965 C_bot  0.15 k_c 0.0\n",
      "2455 Train Loss 11.042324\n",
      "Loss  0.37835965 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37724787 C_bot  0.15 k_c 0.0\n",
      "2456 Train Loss 11.0384865\n",
      "Loss  0.37724787 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37592307 C_bot  0.15 k_c 0.0\n",
      "2457 Train Loss 11.034657\n",
      "Loss  0.37592307 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37498704 C_bot  0.15 k_c 0.0\n",
      "2458 Train Loss 11.030874\n",
      "Loss  0.37498704 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3736454 C_bot  0.15 k_c 0.0\n",
      "2459 Train Loss 11.027098\n",
      "Loss  0.3736454 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3725861 C_bot  0.15 k_c 0.0\n",
      "2460 Train Loss 11.023329\n",
      "Loss  0.3725861 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37143707 C_bot  0.15 k_c 0.0\n",
      "2461 Train Loss 11.019612\n",
      "Loss  0.37143707 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37022713 C_bot  0.15 k_c 0.0\n",
      "2462 Train Loss 11.015926\n",
      "Loss  0.37022713 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36922675 C_bot  0.15 k_c 0.0\n",
      "2463 Train Loss 11.012239\n",
      "Loss  0.36922675 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36797512 C_bot  0.15 k_c 0.0\n",
      "2464 Train Loss 11.008625\n",
      "Loss  0.36797512 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3670037 C_bot  0.15 k_c 0.0\n",
      "2465 Train Loss 11.005033\n",
      "Loss  0.3670037 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3658453 C_bot  0.15 k_c 0.0\n",
      "2466 Train Loss 11.001444\n",
      "Loss  0.3658453 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36470863 C_bot  0.15 k_c 0.0\n",
      "2467 Train Loss 10.997868\n",
      "Loss  0.36470863 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36374226 C_bot  0.15 k_c 0.0\n",
      "2468 Train Loss 10.994366\n",
      "Loss  0.36374226 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36252066 C_bot  0.15 k_c 0.0\n",
      "2469 Train Loss 10.990839\n",
      "Loss  0.36252066 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3616125 C_bot  0.15 k_c 0.0\n",
      "2470 Train Loss 10.987402\n",
      "Loss  0.3616125 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3604085 C_bot  0.15 k_c 0.0\n",
      "2471 Train Loss 10.98389\n",
      "Loss  0.3604085 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35942173 C_bot  0.15 k_c 0.0\n",
      "2472 Train Loss 10.980497\n",
      "Loss  0.35942173 C_bot  0.15 k_c 0.0\n",
      "Loss  0.358391 C_bot  0.15 k_c 0.0\n",
      "2473 Train Loss 10.977081\n",
      "Loss  0.358391 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3572859 C_bot  0.15 k_c 0.0\n",
      "2474 Train Loss 10.973706\n",
      "Loss  0.3572859 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35634965 C_bot  0.15 k_c 0.0\n",
      "2475 Train Loss 10.97035\n",
      "Loss  0.35634965 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35520577 C_bot  0.15 k_c 0.0\n",
      "2476 Train Loss 10.966991\n",
      "Loss  0.35520577 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35426334 C_bot  0.15 k_c 0.0\n",
      "2477 Train Loss 10.963686\n",
      "Loss  0.35426334 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3532412 C_bot  0.15 k_c 0.0\n",
      "2478 Train Loss 10.960418\n",
      "Loss  0.3532412 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3522023 C_bot  0.15 k_c 0.0\n",
      "2479 Train Loss 10.957131\n",
      "Loss  0.3522023 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3512695 C_bot  0.15 k_c 0.0\n",
      "2480 Train Loss 10.953902\n",
      "Loss  0.3512695 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3502077 C_bot  0.15 k_c 0.0\n",
      "2481 Train Loss 10.950681\n",
      "Loss  0.3502077 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34929037 C_bot  0.15 k_c 0.0\n",
      "2482 Train Loss 10.947469\n",
      "Loss  0.34929037 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34824398 C_bot  0.15 k_c 0.0\n",
      "2483 Train Loss 10.944283\n",
      "Loss  0.34824398 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34730268 C_bot  0.15 k_c 0.0\n",
      "2484 Train Loss 10.941122\n",
      "Loss  0.34730268 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3463116 C_bot  0.15 k_c 0.0\n",
      "2485 Train Loss 10.937952\n",
      "Loss  0.3463116 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34535286 C_bot  0.15 k_c 0.0\n",
      "2486 Train Loss 10.93487\n",
      "Loss  0.34535286 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34445652 C_bot  0.15 k_c 0.0\n",
      "2487 Train Loss 10.931769\n",
      "Loss  0.34445652 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34343365 C_bot  0.15 k_c 0.0\n",
      "2488 Train Loss 10.928677\n",
      "Loss  0.34343365 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34256962 C_bot  0.15 k_c 0.0\n",
      "2489 Train Loss 10.92564\n",
      "Loss  0.34256962 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34158272 C_bot  0.15 k_c 0.0\n",
      "2490 Train Loss 10.922578\n",
      "Loss  0.34158272 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3406251 C_bot  0.15 k_c 0.0\n",
      "2491 Train Loss 10.919523\n",
      "Loss  0.3406251 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33969918 C_bot  0.15 k_c 0.0\n",
      "2492 Train Loss 10.916492\n",
      "Loss  0.33969918 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33876124 C_bot  0.15 k_c 0.0\n",
      "2493 Train Loss 10.913528\n",
      "Loss  0.33876124 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33788446 C_bot  0.15 k_c 0.0\n",
      "2494 Train Loss 10.910543\n",
      "Loss  0.33788446 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33693483 C_bot  0.15 k_c 0.0\n",
      "2495 Train Loss 10.9076\n",
      "Loss  0.33693483 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3360695 C_bot  0.15 k_c 0.0\n",
      "2496 Train Loss 10.904663\n",
      "Loss  0.3360695 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33516055 C_bot  0.15 k_c 0.0\n",
      "2497 Train Loss 10.901754\n",
      "Loss  0.33516055 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33428782 C_bot  0.15 k_c 0.0\n",
      "2498 Train Loss 10.898871\n",
      "Loss  0.33428782 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3333997 C_bot  0.15 k_c 0.0\n",
      "2499 Train Loss 10.895971\n",
      "Loss  0.3333997 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33246905 C_bot  0.15 k_c 0.0\n",
      "2500 Train Loss 10.8930855\n",
      "Loss  0.33246905 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33164433 C_bot  0.15 k_c 0.0\n",
      "2501 Train Loss 10.890251\n",
      "Loss  0.33164433 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33076707 C_bot  0.15 k_c 0.0\n",
      "2502 Train Loss 10.887443\n",
      "Loss  0.33076707 C_bot  0.15 k_c 0.0\n",
      "Loss  0.329899 C_bot  0.15 k_c 0.0\n",
      "2503 Train Loss 10.8846\n",
      "Loss  0.329899 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32901165 C_bot  0.15 k_c 0.0\n",
      "2504 Train Loss 10.881781\n",
      "Loss  0.32901165 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32817563 C_bot  0.15 k_c 0.0\n",
      "2505 Train Loss 10.879017\n",
      "Loss  0.32817563 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32728392 C_bot  0.15 k_c 0.0\n",
      "2506 Train Loss 10.876194\n",
      "Loss  0.32728392 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32645562 C_bot  0.15 k_c 0.0\n",
      "2507 Train Loss 10.873475\n",
      "Loss  0.32645562 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3256226 C_bot  0.15 k_c 0.0\n",
      "2508 Train Loss 10.870717\n",
      "Loss  0.3256226 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32474396 C_bot  0.15 k_c 0.0\n",
      "2509 Train Loss 10.867979\n",
      "Loss  0.32474396 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3239825 C_bot  0.15 k_c 0.0\n",
      "2510 Train Loss 10.865309\n",
      "Loss  0.3239825 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32308432 C_bot  0.15 k_c 0.0\n",
      "2511 Train Loss 10.862566\n",
      "Loss  0.32308432 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32228822 C_bot  0.15 k_c 0.0\n",
      "2512 Train Loss 10.859896\n",
      "Loss  0.32228822 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3214571 C_bot  0.15 k_c 0.0\n",
      "2513 Train Loss 10.857219\n",
      "Loss  0.3214571 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32068363 C_bot  0.15 k_c 0.0\n",
      "2514 Train Loss 10.854614\n",
      "Loss  0.32068363 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3198406 C_bot  0.15 k_c 0.0\n",
      "2515 Train Loss 10.85192\n",
      "Loss  0.3198406 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3190214 C_bot  0.15 k_c 0.0\n",
      "2516 Train Loss 10.849304\n",
      "Loss  0.3190214 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31823298 C_bot  0.15 k_c 0.0\n",
      "2517 Train Loss 10.846677\n",
      "Loss  0.31823298 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31743318 C_bot  0.15 k_c 0.0\n",
      "2518 Train Loss 10.844103\n",
      "Loss  0.31743318 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31662533 C_bot  0.15 k_c 0.0\n",
      "2519 Train Loss 10.841476\n",
      "Loss  0.31662533 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31583923 C_bot  0.15 k_c 0.0\n",
      "2520 Train Loss 10.838923\n",
      "Loss  0.31583923 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31503195 C_bot  0.15 k_c 0.0\n",
      "2521 Train Loss 10.836325\n",
      "Loss  0.31503195 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3142353 C_bot  0.15 k_c 0.0\n",
      "2522 Train Loss 10.833772\n",
      "Loss  0.3142353 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31344575 C_bot  0.15 k_c 0.0\n",
      "2523 Train Loss 10.831217\n",
      "Loss  0.31344575 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31270263 C_bot  0.15 k_c 0.0\n",
      "2524 Train Loss 10.828726\n",
      "Loss  0.31270263 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3118687 C_bot  0.15 k_c 0.0\n",
      "2525 Train Loss 10.826151\n",
      "Loss  0.3118687 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31113768 C_bot  0.15 k_c 0.0\n",
      "2526 Train Loss 10.823675\n",
      "Loss  0.31113768 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31038773 C_bot  0.15 k_c 0.0\n",
      "2527 Train Loss 10.821213\n",
      "Loss  0.31038773 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30964628 C_bot  0.15 k_c 0.0\n",
      "2528 Train Loss 10.818737\n",
      "Loss  0.30964628 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30887735 C_bot  0.15 k_c 0.0\n",
      "2529 Train Loss 10.816273\n",
      "Loss  0.30887735 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30811343 C_bot  0.15 k_c 0.0\n",
      "2530 Train Loss 10.813792\n",
      "Loss  0.30811343 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30735722 C_bot  0.15 k_c 0.0\n",
      "2531 Train Loss 10.811355\n",
      "Loss  0.30735722 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30661055 C_bot  0.15 k_c 0.0\n",
      "2532 Train Loss 10.80891\n",
      "Loss  0.30661055 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30586556 C_bot  0.15 k_c 0.0\n",
      "2533 Train Loss 10.806493\n",
      "Loss  0.30586556 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30512473 C_bot  0.15 k_c 0.0\n",
      "2534 Train Loss 10.804077\n",
      "Loss  0.30512473 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30439854 C_bot  0.15 k_c 0.0\n",
      "2535 Train Loss 10.801684\n",
      "Loss  0.30439854 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30365732 C_bot  0.15 k_c 0.0\n",
      "2536 Train Loss 10.79929\n",
      "Loss  0.30365732 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30292866 C_bot  0.15 k_c 0.0\n",
      "2537 Train Loss 10.796902\n",
      "Loss  0.30292866 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30222738 C_bot  0.15 k_c 0.0\n",
      "2538 Train Loss 10.794569\n",
      "Loss  0.30222738 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30149302 C_bot  0.15 k_c 0.0\n",
      "2539 Train Loss 10.792181\n",
      "Loss  0.30149302 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30078915 C_bot  0.15 k_c 0.0\n",
      "2540 Train Loss 10.789867\n",
      "Loss  0.30078915 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3000864 C_bot  0.15 k_c 0.0\n",
      "2541 Train Loss 10.787521\n",
      "Loss  0.3000864 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29932213 C_bot  0.15 k_c 0.0\n",
      "2542 Train Loss 10.785162\n",
      "Loss  0.29932213 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29865557 C_bot  0.15 k_c 0.0\n",
      "2543 Train Loss 10.782866\n",
      "Loss  0.29865557 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29792252 C_bot  0.15 k_c 0.0\n",
      "2544 Train Loss 10.780552\n",
      "Loss  0.29792252 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29723504 C_bot  0.15 k_c 0.0\n",
      "2545 Train Loss 10.778242\n",
      "Loss  0.29723504 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29649568 C_bot  0.15 k_c 0.0\n",
      "2546 Train Loss 10.775942\n",
      "Loss  0.29649568 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29583633 C_bot  0.15 k_c 0.0\n",
      "2547 Train Loss 10.773667\n",
      "Loss  0.29583633 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29513213 C_bot  0.15 k_c 0.0\n",
      "2548 Train Loss 10.771421\n",
      "Loss  0.29513213 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2944351 C_bot  0.15 k_c 0.0\n",
      "2549 Train Loss 10.769115\n",
      "Loss  0.2944351 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2937455 C_bot  0.15 k_c 0.0\n",
      "2550 Train Loss 10.766903\n",
      "Loss  0.2937455 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2931043 C_bot  0.15 k_c 0.0\n",
      "2551 Train Loss 10.764659\n",
      "Loss  0.2931043 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29239008 C_bot  0.15 k_c 0.0\n",
      "2552 Train Loss 10.762436\n",
      "Loss  0.29239008 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29171848 C_bot  0.15 k_c 0.0\n",
      "2553 Train Loss 10.760174\n",
      "Loss  0.29171848 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29103005 C_bot  0.15 k_c 0.0\n",
      "2554 Train Loss 10.75799\n",
      "Loss  0.29103005 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29042047 C_bot  0.15 k_c 0.0\n",
      "2555 Train Loss 10.755801\n",
      "Loss  0.29042047 C_bot  0.15 k_c 0.0\n",
      "Loss  0.289712 C_bot  0.15 k_c 0.0\n",
      "2556 Train Loss 10.753605\n",
      "Loss  0.289712 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28906026 C_bot  0.15 k_c 0.0\n",
      "2557 Train Loss 10.75139\n",
      "Loss  0.28906026 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28836212 C_bot  0.15 k_c 0.0\n",
      "2558 Train Loss 10.749215\n",
      "Loss  0.28836212 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2877379 C_bot  0.15 k_c 0.0\n",
      "2559 Train Loss 10.747037\n",
      "Loss  0.2877379 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28705934 C_bot  0.15 k_c 0.0\n",
      "2560 Train Loss 10.744892\n",
      "Loss  0.28705934 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2864194 C_bot  0.15 k_c 0.0\n",
      "2561 Train Loss 10.74271\n",
      "Loss  0.2864194 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28571743 C_bot  0.15 k_c 0.0\n",
      "2562 Train Loss 10.740556\n",
      "Loss  0.28571743 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28511363 C_bot  0.15 k_c 0.0\n",
      "2563 Train Loss 10.738418\n",
      "Loss  0.28511363 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28444162 C_bot  0.15 k_c 0.0\n",
      "2564 Train Loss 10.736308\n",
      "Loss  0.28444162 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2838157 C_bot  0.15 k_c 0.0\n",
      "2565 Train Loss 10.734148\n",
      "Loss  0.2838157 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28314108 C_bot  0.15 k_c 0.0\n",
      "2566 Train Loss 10.732058\n",
      "Loss  0.28314108 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28252798 C_bot  0.15 k_c 0.0\n",
      "2567 Train Loss 10.729909\n",
      "Loss  0.28252798 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2818271 C_bot  0.15 k_c 0.0\n",
      "2568 Train Loss 10.727819\n",
      "Loss  0.2818271 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28131312 C_bot  0.15 k_c 0.0\n",
      "2569 Train Loss 10.7257595\n",
      "Loss  0.28131312 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28057683 C_bot  0.15 k_c 0.0\n",
      "2570 Train Loss 10.72367\n",
      "Loss  0.28057683 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28011084 C_bot  0.15 k_c 0.0\n",
      "2571 Train Loss 10.721631\n",
      "Loss  0.28011084 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27933365 C_bot  0.15 k_c 0.0\n",
      "2572 Train Loss 10.719561\n",
      "Loss  0.27933365 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27888855 C_bot  0.15 k_c 0.0\n",
      "2573 Train Loss 10.717489\n",
      "Loss  0.27888855 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27812418 C_bot  0.15 k_c 0.0\n",
      "2574 Train Loss 10.715521\n",
      "Loss  0.27812418 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27779987 C_bot  0.15 k_c 0.0\n",
      "2575 Train Loss 10.713478\n",
      "Loss  0.27779987 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27694422 C_bot  0.15 k_c 0.0\n",
      "2576 Train Loss 10.711558\n",
      "Loss  0.27694422 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27692533 C_bot  0.15 k_c 0.0\n",
      "2577 Train Loss 10.709662\n",
      "Loss  0.27692533 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2760665 C_bot  0.15 k_c 0.0\n",
      "2578 Train Loss 10.707964\n",
      "Loss  0.2760665 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27655438 C_bot  0.15 k_c 0.0\n",
      "2579 Train Loss 10.706306\n",
      "Loss  0.27655438 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27582958 C_bot  0.15 k_c 0.0\n",
      "2580 Train Loss 10.705114\n",
      "Loss  0.27582958 C_bot  0.15 k_c 0.0\n",
      "Loss  0.277657 C_bot  0.15 k_c 0.0\n",
      "2581 Train Loss 10.704336\n",
      "Loss  0.277657 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27776432 C_bot  0.15 k_c 0.0\n",
      "2582 Train Loss 10.704606\n",
      "Loss  0.27776432 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28279406 C_bot  0.15 k_c 0.0\n",
      "2583 Train Loss 10.706222\n",
      "Loss  0.28279406 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28633353 C_bot  0.15 k_c 0.0\n",
      "2584 Train Loss 10.711035\n",
      "Loss  0.28633353 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30069184 C_bot  0.15 k_c 0.0\n",
      "2585 Train Loss 10.720535\n",
      "Loss  0.30069184 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31669095 C_bot  0.15 k_c 0.0\n",
      "2586 Train Loss 10.739813\n",
      "Loss  0.31669095 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35937017 C_bot  0.15 k_c 0.0\n",
      "2587 Train Loss 10.775032\n",
      "Loss  0.35937017 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41978535 C_bot  0.15 k_c 0.0\n",
      "2588 Train Loss 10.842412\n",
      "Loss  0.41978535 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5551523 C_bot  0.15 k_c 0.0\n",
      "2589 Train Loss 10.96559\n",
      "Loss  0.5551523 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7760714 C_bot  0.15 k_c 0.0\n",
      "2590 Train Loss 11.200473\n",
      "Loss  0.7760714 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2317407 C_bot  0.15 k_c 0.0\n",
      "2591 Train Loss 11.635284\n",
      "Loss  1.2317407 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0433035 C_bot  0.15 k_c 0.0\n",
      "2592 Train Loss 12.474624\n",
      "Loss  2.0433035 C_bot  0.15 k_c 0.0\n",
      "Loss  3.6501675 C_bot  0.15 k_c 0.0\n",
      "2593 Train Loss 14.044889\n",
      "Loss  3.6501675 C_bot  0.15 k_c 0.0\n",
      "Loss  6.688008 C_bot  0.15 k_c 0.0\n",
      "2594 Train Loss 17.139235\n",
      "Loss  6.688008 C_bot  0.15 k_c 0.0\n",
      "Loss  12.531586 C_bot  0.15 k_c 0.0\n",
      "2595 Train Loss 22.918594\n",
      "Loss  12.531586 C_bot  0.15 k_c 0.0\n",
      "Loss  24.05937 C_bot  0.15 k_c 0.0\n",
      "2596 Train Loss 34.56764\n",
      "Loss  24.05937 C_bot  0.15 k_c 0.0\n",
      "Loss  45.212624 C_bot  0.15 k_c 0.0\n",
      "2597 Train Loss 55.61139\n",
      "Loss  45.212624 C_bot  0.15 k_c 0.0\n",
      "Loss  87.70243 C_bot  0.15 k_c 0.0\n",
      "2598 Train Loss 98.38492\n",
      "Loss  87.70243 C_bot  0.15 k_c 0.0\n",
      "Loss  155.77792 C_bot  0.15 k_c 0.0\n",
      "2599 Train Loss 166.27338\n",
      "Loss  155.77792 C_bot  0.15 k_c 0.0\n",
      "Loss  282.7042 C_bot  0.15 k_c 0.0\n",
      "2600 Train Loss 293.90756\n",
      "Loss  282.7042 C_bot  0.15 k_c 0.0\n",
      "Loss  407.46857 C_bot  0.15 k_c 0.0\n",
      "2601 Train Loss 418.22382\n",
      "Loss  407.46857 C_bot  0.15 k_c 0.0\n",
      "Loss  541.43335 C_bot  0.15 k_c 0.0\n",
      "2602 Train Loss 553.59937\n",
      "Loss  541.43335 C_bot  0.15 k_c 0.0\n",
      "Loss  444.35223 C_bot  0.15 k_c 0.0\n",
      "2603 Train Loss 455.26166\n",
      "Loss  444.35223 C_bot  0.15 k_c 0.0\n",
      "Loss  216.33594 C_bot  0.15 k_c 0.0\n",
      "2604 Train Loss 228.46475\n",
      "Loss  216.33594 C_bot  0.15 k_c 0.0\n",
      "Loss  20.796381 C_bot  0.15 k_c 0.0\n",
      "2605 Train Loss 32.18368\n",
      "Loss  20.796381 C_bot  0.15 k_c 0.0\n",
      "Loss  50.69874 C_bot  0.15 k_c 0.0\n",
      "2606 Train Loss 62.26979\n",
      "Loss  50.69874 C_bot  0.15 k_c 0.0\n",
      "Loss  209.37552 C_bot  0.15 k_c 0.0\n",
      "2607 Train Loss 222.639\n",
      "Loss  209.37552 C_bot  0.15 k_c 0.0\n",
      "Loss  249.51804 C_bot  0.15 k_c 0.0\n",
      "2608 Train Loss 261.37524\n",
      "Loss  249.51804 C_bot  0.15 k_c 0.0\n",
      "Loss  140.38414 C_bot  0.15 k_c 0.0\n",
      "2609 Train Loss 153.64648\n",
      "Loss  140.38414 C_bot  0.15 k_c 0.0\n",
      "Loss  15.062123 C_bot  0.15 k_c 0.0\n",
      "2610 Train Loss 27.313063\n",
      "Loss  15.062123 C_bot  0.15 k_c 0.0\n",
      "Loss  30.937428 C_bot  0.15 k_c 0.0\n",
      "2611 Train Loss 43.110992\n",
      "Loss  30.937428 C_bot  0.15 k_c 0.0\n",
      "Loss  125.71372 C_bot  0.15 k_c 0.0\n",
      "2612 Train Loss 138.651\n",
      "Loss  125.71372 C_bot  0.15 k_c 0.0\n",
      "Loss  133.97874 C_bot  0.15 k_c 0.0\n",
      "2613 Train Loss 146.04218\n",
      "Loss  133.97874 C_bot  0.15 k_c 0.0\n",
      "Loss  54.586823 C_bot  0.15 k_c 0.0\n",
      "2614 Train Loss 67.02836\n",
      "Loss  54.586823 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8650011 C_bot  0.15 k_c 0.0\n",
      "2615 Train Loss 12.923174\n",
      "Loss  0.8650011 C_bot  0.15 k_c 0.0\n",
      "Loss  39.26564 C_bot  0.15 k_c 0.0\n",
      "2616 Train Loss 51.20598\n",
      "Loss  39.26564 C_bot  0.15 k_c 0.0\n",
      "Loss  88.23005 C_bot  0.15 k_c 0.0\n",
      "2617 Train Loss 100.49316\n",
      "Loss  88.23005 C_bot  0.15 k_c 0.0\n",
      "Loss  60.690517 C_bot  0.15 k_c 0.0\n",
      "2618 Train Loss 72.547516\n",
      "Loss  60.690517 C_bot  0.15 k_c 0.0\n",
      "Loss  9.039073 C_bot  0.15 k_c 0.0\n",
      "2619 Train Loss 20.928698\n",
      "Loss  9.039073 C_bot  0.15 k_c 0.0\n",
      "Loss  9.313865 C_bot  0.15 k_c 0.0\n",
      "2620 Train Loss 21.139805\n",
      "Loss  9.313865 C_bot  0.15 k_c 0.0\n",
      "Loss  45.624104 C_bot  0.15 k_c 0.0\n",
      "2621 Train Loss 57.277287\n",
      "Loss  45.624104 C_bot  0.15 k_c 0.0\n",
      "Loss  50.303043 C_bot  0.15 k_c 0.0\n",
      "2622 Train Loss 62.176434\n",
      "Loss  50.303043 C_bot  0.15 k_c 0.0\n",
      "Loss  16.199326 C_bot  0.15 k_c 0.0\n",
      "2623 Train Loss 27.721134\n",
      "Loss  16.199326 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9197738 C_bot  0.15 k_c 0.0\n",
      "2624 Train Loss 13.429944\n",
      "Loss  1.9197738 C_bot  0.15 k_c 0.0\n",
      "Loss  22.370237 C_bot  0.15 k_c 0.0\n",
      "2625 Train Loss 34.00923\n",
      "Loss  22.370237 C_bot  0.15 k_c 0.0\n",
      "Loss  33.892155 C_bot  0.15 k_c 0.0\n",
      "2626 Train Loss 45.23434\n",
      "Loss  33.892155 C_bot  0.15 k_c 0.0\n",
      "Loss  16.492016 C_bot  0.15 k_c 0.0\n",
      "2627 Train Loss 28.04578\n",
      "Loss  16.492016 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0122683 C_bot  0.15 k_c 0.0\n",
      "2628 Train Loss 12.398898\n",
      "Loss  1.0122683 C_bot  0.15 k_c 0.0\n",
      "Loss  10.238729 C_bot  0.15 k_c 0.0\n",
      "2629 Train Loss 21.54744\n",
      "Loss  10.238729 C_bot  0.15 k_c 0.0\n",
      "Loss  21.800056 C_bot  0.15 k_c 0.0\n",
      "2630 Train Loss 33.3318\n",
      "Loss  21.800056 C_bot  0.15 k_c 0.0\n",
      "Loss  13.657674 C_bot  0.15 k_c 0.0\n",
      "2631 Train Loss 24.925245\n",
      "Loss  13.657674 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3249881 C_bot  0.15 k_c 0.0\n",
      "2632 Train Loss 12.679375\n",
      "Loss  1.3249881 C_bot  0.15 k_c 0.0\n",
      "Loss  4.6003733 C_bot  0.15 k_c 0.0\n",
      "2633 Train Loss 15.972714\n",
      "Loss  4.6003733 C_bot  0.15 k_c 0.0\n",
      "Loss  13.454971 C_bot  0.15 k_c 0.0\n",
      "2634 Train Loss 24.677944\n",
      "Loss  13.454971 C_bot  0.15 k_c 0.0\n",
      "Loss  10.542604 C_bot  0.15 k_c 0.0\n",
      "2635 Train Loss 21.913227\n",
      "Loss  10.542604 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8921466 C_bot  0.15 k_c 0.0\n",
      "2636 Train Loss 13.130661\n",
      "Loss  1.8921466 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1627703 C_bot  0.15 k_c 0.0\n",
      "2637 Train Loss 13.38699\n",
      "Loss  2.1627703 C_bot  0.15 k_c 0.0\n",
      "Loss  8.240305 C_bot  0.15 k_c 0.0\n",
      "2638 Train Loss 19.535957\n",
      "Loss  8.240305 C_bot  0.15 k_c 0.0\n",
      "Loss  7.837432 C_bot  0.15 k_c 0.0\n",
      "2639 Train Loss 19.020206\n",
      "Loss  7.837432 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0398376 C_bot  0.15 k_c 0.0\n",
      "2640 Train Loss 13.25801\n",
      "Loss  2.0398376 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9932218 C_bot  0.15 k_c 0.0\n",
      "2641 Train Loss 12.180479\n",
      "Loss  0.9932218 C_bot  0.15 k_c 0.0\n",
      "Loss  4.9384418 C_bot  0.15 k_c 0.0\n",
      "2642 Train Loss 16.070196\n",
      "Loss  4.9384418 C_bot  0.15 k_c 0.0\n",
      "Loss  5.6897316 C_bot  0.15 k_c 0.0\n",
      "2643 Train Loss 16.85968\n",
      "Loss  5.6897316 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1057532 C_bot  0.15 k_c 0.0\n",
      "2644 Train Loss 13.192773\n",
      "Loss  2.1057532 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5324753 C_bot  0.15 k_c 0.0\n",
      "2645 Train Loss 11.605867\n",
      "Loss  0.5324753 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7994537 C_bot  0.15 k_c 0.0\n",
      "2646 Train Loss 13.882229\n",
      "Loss  2.7994537 C_bot  0.15 k_c 0.0\n",
      "Loss  4.064572 C_bot  0.15 k_c 0.0\n",
      "2647 Train Loss 15.070497\n",
      "Loss  4.064572 C_bot  0.15 k_c 0.0\n",
      "Loss  2.033694 C_bot  0.15 k_c 0.0\n",
      "2648 Train Loss 13.072212\n",
      "Loss  2.033694 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44388267 C_bot  0.15 k_c 0.0\n",
      "2649 Train Loss 11.437509\n",
      "Loss  0.44388267 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5479022 C_bot  0.15 k_c 0.0\n",
      "2650 Train Loss 12.5082655\n",
      "Loss  1.5479022 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7758048 C_bot  0.15 k_c 0.0\n",
      "2651 Train Loss 13.77379\n",
      "Loss  2.7758048 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9649757 C_bot  0.15 k_c 0.0\n",
      "2652 Train Loss 12.891821\n",
      "Loss  1.9649757 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5553604 C_bot  0.15 k_c 0.0\n",
      "2653 Train Loss 11.497082\n",
      "Loss  0.5553604 C_bot  0.15 k_c 0.0\n",
      "Loss  0.79625756 C_bot  0.15 k_c 0.0\n",
      "2654 Train Loss 11.728996\n",
      "Loss  0.79625756 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8474642 C_bot  0.15 k_c 0.0\n",
      "2655 Train Loss 12.73333\n",
      "Loss  1.8474642 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6953982 C_bot  0.15 k_c 0.0\n",
      "2656 Train Loss 12.611488\n",
      "Loss  1.6953982 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7425683 C_bot  0.15 k_c 0.0\n",
      "2657 Train Loss 11.612844\n",
      "Loss  0.7425683 C_bot  0.15 k_c 0.0\n",
      "Loss  0.485142 C_bot  0.15 k_c 0.0\n",
      "2658 Train Loss 11.348463\n",
      "Loss  0.485142 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0965639 C_bot  0.15 k_c 0.0\n",
      "2659 Train Loss 11.967157\n",
      "Loss  1.0965639 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3848684 C_bot  0.15 k_c 0.0\n",
      "2660 Train Loss 12.215187\n",
      "Loss  1.3848684 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8325668 C_bot  0.15 k_c 0.0\n",
      "2661 Train Loss 11.677567\n",
      "Loss  0.8325668 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41092783 C_bot  0.15 k_c 0.0\n",
      "2662 Train Loss 11.234306\n",
      "Loss  0.41092783 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65709925 C_bot  0.15 k_c 0.0\n",
      "2663 Train Loss 11.465457\n",
      "Loss  0.65709925 C_bot  0.15 k_c 0.0\n",
      "Loss  0.99415344 C_bot  0.15 k_c 0.0\n",
      "2664 Train Loss 11.812035\n",
      "Loss  0.99415344 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8593613 C_bot  0.15 k_c 0.0\n",
      "2665 Train Loss 11.6489525\n",
      "Loss  0.8593613 C_bot  0.15 k_c 0.0\n",
      "Loss  0.46596295 C_bot  0.15 k_c 0.0\n",
      "2666 Train Loss 11.259618\n",
      "Loss  0.46596295 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42988786 C_bot  0.15 k_c 0.0\n",
      "2667 Train Loss 11.214791\n",
      "Loss  0.42988786 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69586235 C_bot  0.15 k_c 0.0\n",
      "2668 Train Loss 11.463708\n",
      "Loss  0.69586235 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7553778 C_bot  0.15 k_c 0.0\n",
      "2669 Train Loss 11.531017\n",
      "Loss  0.7553778 C_bot  0.15 k_c 0.0\n",
      "Loss  0.54943264 C_bot  0.15 k_c 0.0\n",
      "2670 Train Loss 11.303635\n",
      "Loss  0.54943264 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38222405 C_bot  0.15 k_c 0.0\n",
      "2671 Train Loss 11.134743\n",
      "Loss  0.38222405 C_bot  0.15 k_c 0.0\n",
      "Loss  0.473112 C_bot  0.15 k_c 0.0\n",
      "2672 Train Loss 11.222624\n",
      "Loss  0.473112 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6224617 C_bot  0.15 k_c 0.0\n",
      "2673 Train Loss 11.353594\n",
      "Loss  0.6224617 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5593394 C_bot  0.15 k_c 0.0\n",
      "2674 Train Loss 11.297071\n",
      "Loss  0.5593394 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41635466 C_bot  0.15 k_c 0.0\n",
      "2675 Train Loss 11.137532\n",
      "Loss  0.41635466 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37968764 C_bot  0.15 k_c 0.0\n",
      "2676 Train Loss 11.095839\n",
      "Loss  0.37968764 C_bot  0.15 k_c 0.0\n",
      "Loss  0.46606833 C_bot  0.15 k_c 0.0\n",
      "2677 Train Loss 11.18214\n",
      "Loss  0.46606833 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5254646 C_bot  0.15 k_c 0.0\n",
      "2678 Train Loss 11.224213\n",
      "Loss  0.5254646 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44662365 C_bot  0.15 k_c 0.0\n",
      "2679 Train Loss 11.149351\n",
      "Loss  0.44662365 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37145603 C_bot  0.15 k_c 0.0\n",
      "2680 Train Loss 11.061984\n",
      "Loss  0.37145603 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38293967 C_bot  0.15 k_c 0.0\n",
      "2681 Train Loss 11.066559\n",
      "Loss  0.38293967 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43681544 C_bot  0.15 k_c 0.0\n",
      "2682 Train Loss 11.120864\n",
      "Loss  0.43681544 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4537604 C_bot  0.15 k_c 0.0\n",
      "2683 Train Loss 11.123276\n",
      "Loss  0.4537604 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39400387 C_bot  0.15 k_c 0.0\n",
      "2684 Train Loss 11.065064\n",
      "Loss  0.39400387 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3580541 C_bot  0.15 k_c 0.0\n",
      "2685 Train Loss 11.020298\n",
      "Loss  0.3580541 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37704685 C_bot  0.15 k_c 0.0\n",
      "2686 Train Loss 11.032341\n",
      "Loss  0.37704685 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4054746 C_bot  0.15 k_c 0.0\n",
      "2687 Train Loss 11.060912\n",
      "Loss  0.4054746 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40787685 C_bot  0.15 k_c 0.0\n",
      "2688 Train Loss 11.051673\n",
      "Loss  0.40787685 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3681224 C_bot  0.15 k_c 0.0\n",
      "2689 Train Loss 11.012037\n",
      "Loss  0.3681224 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34972414 C_bot  0.15 k_c 0.0\n",
      "2690 Train Loss 10.986793\n",
      "Loss  0.34972414 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36380175 C_bot  0.15 k_c 0.0\n",
      "2691 Train Loss 10.994531\n",
      "Loss  0.36380175 C_bot  0.15 k_c 0.0\n",
      "Loss  0.37801147 C_bot  0.15 k_c 0.0\n",
      "2692 Train Loss 11.008342\n",
      "Loss  0.37801147 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3779777 C_bot  0.15 k_c 0.0\n",
      "2693 Train Loss 10.998699\n",
      "Loss  0.3779777 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35263118 C_bot  0.15 k_c 0.0\n",
      "2694 Train Loss 10.972717\n",
      "Loss  0.35263118 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34168744 C_bot  0.15 k_c 0.0\n",
      "2695 Train Loss 10.955887\n",
      "Loss  0.34168744 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34980568 C_bot  0.15 k_c 0.0\n",
      "2696 Train Loss 10.958436\n",
      "Loss  0.34980568 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35727292 C_bot  0.15 k_c 0.0\n",
      "2697 Train Loss 10.964911\n",
      "Loss  0.35727292 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3584818 C_bot  0.15 k_c 0.0\n",
      "2698 Train Loss 10.958004\n",
      "Loss  0.3584818 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34242514 C_bot  0.15 k_c 0.0\n",
      "2699 Train Loss 10.94092\n",
      "Loss  0.34242514 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33490878 C_bot  0.15 k_c 0.0\n",
      "2700 Train Loss 10.927968\n",
      "Loss  0.33490878 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33794433 C_bot  0.15 k_c 0.0\n",
      "2701 Train Loss 10.926271\n",
      "Loss  0.33794433 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34193292 C_bot  0.15 k_c 0.0\n",
      "2702 Train Loss 10.928577\n",
      "Loss  0.34193292 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3444135 C_bot  0.15 k_c 0.0\n",
      "2703 Train Loss 10.924153\n",
      "Loss  0.3444135 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33452553 C_bot  0.15 k_c 0.0\n",
      "2704 Train Loss 10.912893\n",
      "Loss  0.33452553 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3290245 C_bot  0.15 k_c 0.0\n",
      "2705 Train Loss 10.902148\n",
      "Loss  0.3290245 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32860038 C_bot  0.15 k_c 0.0\n",
      "2706 Train Loss 10.897736\n",
      "Loss  0.32860038 C_bot  0.15 k_c 0.0\n",
      "Loss  0.330449 C_bot  0.15 k_c 0.0\n",
      "2707 Train Loss 10.897238\n",
      "Loss  0.330449 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3334009 C_bot  0.15 k_c 0.0\n",
      "2708 Train Loss 10.894281\n",
      "Loss  0.3334009 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32773125 C_bot  0.15 k_c 0.0\n",
      "2709 Train Loss 10.88702\n",
      "Loss  0.32773125 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32404667 C_bot  0.15 k_c 0.0\n",
      "2710 Train Loss 10.878267\n",
      "Loss  0.32404667 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32148436 C_bot  0.15 k_c 0.0\n",
      "2711 Train Loss 10.8724575\n",
      "Loss  0.32148436 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32166284 C_bot  0.15 k_c 0.0\n",
      "2712 Train Loss 10.869799\n",
      "Loss  0.32166284 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32411206 C_bot  0.15 k_c 0.0\n",
      "2713 Train Loss 10.867289\n",
      "Loss  0.32411206 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3212395 C_bot  0.15 k_c 0.0\n",
      "2714 Train Loss 10.862675\n",
      "Loss  0.3212395 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3194013 C_bot  0.15 k_c 0.0\n",
      "2715 Train Loss 10.855998\n",
      "Loss  0.3194013 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31587026 C_bot  0.15 k_c 0.0\n",
      "2716 Train Loss 10.849865\n",
      "Loss  0.31587026 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3148968 C_bot  0.15 k_c 0.0\n",
      "2717 Train Loss 10.845625\n",
      "Loss  0.3148968 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31589076 C_bot  0.15 k_c 0.0\n",
      "2718 Train Loss 10.842561\n",
      "Loss  0.31589076 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31454685 C_bot  0.15 k_c 0.0\n",
      "2719 Train Loss 10.839193\n",
      "Loss  0.31454685 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31416792 C_bot  0.15 k_c 0.0\n",
      "2720 Train Loss 10.834339\n",
      "Loss  0.31416792 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3109698 C_bot  0.15 k_c 0.0\n",
      "2721 Train Loss 10.828934\n",
      "Loss  0.3109698 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30957288 C_bot  0.15 k_c 0.0\n",
      "2722 Train Loss 10.823958\n",
      "Loss  0.30957288 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30901316 C_bot  0.15 k_c 0.0\n",
      "2723 Train Loss 10.82013\n",
      "Loss  0.30901316 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30812258 C_bot  0.15 k_c 0.0\n",
      "2724 Train Loss 10.816826\n",
      "Loss  0.30812258 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30839613 C_bot  0.15 k_c 0.0\n",
      "2725 Train Loss 10.81312\n",
      "Loss  0.30839613 C_bot  0.15 k_c 0.0\n",
      "Loss  0.306179 C_bot  0.15 k_c 0.0\n",
      "2726 Train Loss 10.808835\n",
      "Loss  0.306179 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30519876 C_bot  0.15 k_c 0.0\n",
      "2727 Train Loss 10.804157\n",
      "Loss  0.30519876 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3034748 C_bot  0.15 k_c 0.0\n",
      "2728 Train Loss 10.799816\n",
      "Loss  0.3034748 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30252197 C_bot  0.15 k_c 0.0\n",
      "2729 Train Loss 10.796034\n",
      "Loss  0.30252197 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3024269 C_bot  0.15 k_c 0.0\n",
      "2730 Train Loss 10.792591\n",
      "Loss  0.3024269 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30108172 C_bot  0.15 k_c 0.0\n",
      "2731 Train Loss 10.7890415\n",
      "Loss  0.30108172 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30070987 C_bot  0.15 k_c 0.0\n",
      "2732 Train Loss 10.785124\n",
      "Loss  0.30070987 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29889673 C_bot  0.15 k_c 0.0\n",
      "2733 Train Loss 10.781059\n",
      "Loss  0.29889673 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29801774 C_bot  0.15 k_c 0.0\n",
      "2734 Train Loss 10.777061\n",
      "Loss  0.29801774 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29701093 C_bot  0.15 k_c 0.0\n",
      "2735 Train Loss 10.773309\n",
      "Loss  0.29701093 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29608393 C_bot  0.15 k_c 0.0\n",
      "2736 Train Loss 10.769878\n",
      "Loss  0.29608393 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29580575 C_bot  0.15 k_c 0.0\n",
      "2737 Train Loss 10.766443\n",
      "Loss  0.29580575 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2944816 C_bot  0.15 k_c 0.0\n",
      "2738 Train Loss 10.762932\n",
      "Loss  0.2944816 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29389983 C_bot  0.15 k_c 0.0\n",
      "2739 Train Loss 10.759204\n",
      "Loss  0.29389983 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29255658 C_bot  0.15 k_c 0.0\n",
      "2740 Train Loss 10.755545\n",
      "Loss  0.29255658 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29171762 C_bot  0.15 k_c 0.0\n",
      "2741 Train Loss 10.751932\n",
      "Loss  0.29171762 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29094344 C_bot  0.15 k_c 0.0\n",
      "2742 Train Loss 10.748501\n",
      "Loss  0.29094344 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28996944 C_bot  0.15 k_c 0.0\n",
      "2743 Train Loss 10.745167\n",
      "Loss  0.28996944 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28949064 C_bot  0.15 k_c 0.0\n",
      "2744 Train Loss 10.741804\n",
      "Loss  0.28949064 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28832278 C_bot  0.15 k_c 0.0\n",
      "2745 Train Loss 10.738459\n",
      "Loss  0.28832278 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28770953 C_bot  0.15 k_c 0.0\n",
      "2746 Train Loss 10.73501\n",
      "Loss  0.28770953 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28658515 C_bot  0.15 k_c 0.0\n",
      "2747 Train Loss 10.731617\n",
      "Loss  0.28658515 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28582153 C_bot  0.15 k_c 0.0\n",
      "2748 Train Loss 10.728276\n",
      "Loss  0.28582153 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28502375 C_bot  0.15 k_c 0.0\n",
      "2749 Train Loss 10.724991\n",
      "Loss  0.28502375 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28414854 C_bot  0.15 k_c 0.0\n",
      "2750 Train Loss 10.721818\n",
      "Loss  0.28414854 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28356898 C_bot  0.15 k_c 0.0\n",
      "2751 Train Loss 10.718601\n",
      "Loss  0.28356898 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28258568 C_bot  0.15 k_c 0.0\n",
      "2752 Train Loss 10.715466\n",
      "Loss  0.28258568 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28192195 C_bot  0.15 k_c 0.0\n",
      "2753 Train Loss 10.712177\n",
      "Loss  0.28192195 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28094223 C_bot  0.15 k_c 0.0\n",
      "2754 Train Loss 10.709019\n",
      "Loss  0.28094223 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28027046 C_bot  0.15 k_c 0.0\n",
      "2755 Train Loss 10.705879\n",
      "Loss  0.28027046 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27941874 C_bot  0.15 k_c 0.0\n",
      "2756 Train Loss 10.702728\n",
      "Loss  0.27941874 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27861825 C_bot  0.15 k_c 0.0\n",
      "2757 Train Loss 10.699654\n",
      "Loss  0.27861825 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2779955 C_bot  0.15 k_c 0.0\n",
      "2758 Train Loss 10.696619\n",
      "Loss  0.2779955 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27709892 C_bot  0.15 k_c 0.0\n",
      "2759 Train Loss 10.693584\n",
      "Loss  0.27709892 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2765148 C_bot  0.15 k_c 0.0\n",
      "2760 Train Loss 10.690561\n",
      "Loss  0.2765148 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27561563 C_bot  0.15 k_c 0.0\n",
      "2761 Train Loss 10.687568\n",
      "Loss  0.27561563 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27497613 C_bot  0.15 k_c 0.0\n",
      "2762 Train Loss 10.68455\n",
      "Loss  0.27497613 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27415112 C_bot  0.15 k_c 0.0\n",
      "2763 Train Loss 10.681591\n",
      "Loss  0.27415112 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27343774 C_bot  0.15 k_c 0.0\n",
      "2764 Train Loss 10.678618\n",
      "Loss  0.27343774 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27269956 C_bot  0.15 k_c 0.0\n",
      "2765 Train Loss 10.675678\n",
      "Loss  0.27269956 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27197406 C_bot  0.15 k_c 0.0\n",
      "2766 Train Loss 10.672815\n",
      "Loss  0.27197406 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2713373 C_bot  0.15 k_c 0.0\n",
      "2767 Train Loss 10.669922\n",
      "Loss  0.2713373 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27055055 C_bot  0.15 k_c 0.0\n",
      "2768 Train Loss 10.667086\n",
      "Loss  0.27055055 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26994348 C_bot  0.15 k_c 0.0\n",
      "2769 Train Loss 10.664221\n",
      "Loss  0.26994348 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2691019 C_bot  0.15 k_c 0.0\n",
      "2770 Train Loss 10.661362\n",
      "Loss  0.2691019 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2685167 C_bot  0.15 k_c 0.0\n",
      "2771 Train Loss 10.6585655\n",
      "Loss  0.2685167 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2677386 C_bot  0.15 k_c 0.0\n",
      "2772 Train Loss 10.655762\n",
      "Loss  0.2677386 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26707038 C_bot  0.15 k_c 0.0\n",
      "2773 Train Loss 10.652954\n",
      "Loss  0.26707038 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2664152 C_bot  0.15 k_c 0.0\n",
      "2774 Train Loss 10.650246\n",
      "Loss  0.2664152 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26572144 C_bot  0.15 k_c 0.0\n",
      "2775 Train Loss 10.647492\n",
      "Loss  0.26572144 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26505718 C_bot  0.15 k_c 0.0\n",
      "2776 Train Loss 10.644751\n",
      "Loss  0.26505718 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2643574 C_bot  0.15 k_c 0.0\n",
      "2777 Train Loss 10.6420555\n",
      "Loss  0.2643574 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26371834 C_bot  0.15 k_c 0.0\n",
      "2778 Train Loss 10.639336\n",
      "Loss  0.26371834 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2629822 C_bot  0.15 k_c 0.0\n",
      "2779 Train Loss 10.636642\n",
      "Loss  0.2629822 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26238346 C_bot  0.15 k_c 0.0\n",
      "2780 Train Loss 10.633988\n",
      "Loss  0.26238346 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2617157 C_bot  0.15 k_c 0.0\n",
      "2781 Train Loss 10.6313715\n",
      "Loss  0.2617157 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26108414 C_bot  0.15 k_c 0.0\n",
      "2782 Train Loss 10.628728\n",
      "Loss  0.26108414 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2604039 C_bot  0.15 k_c 0.0\n",
      "2783 Train Loss 10.6261\n",
      "Loss  0.2604039 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25976098 C_bot  0.15 k_c 0.0\n",
      "2784 Train Loss 10.623487\n",
      "Loss  0.25976098 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25914276 C_bot  0.15 k_c 0.0\n",
      "2785 Train Loss 10.620924\n",
      "Loss  0.25914276 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25846708 C_bot  0.15 k_c 0.0\n",
      "2786 Train Loss 10.618317\n",
      "Loss  0.25846708 C_bot  0.15 k_c 0.0\n",
      "Loss  0.257878 C_bot  0.15 k_c 0.0\n",
      "2787 Train Loss 10.615786\n",
      "Loss  0.257878 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25720933 C_bot  0.15 k_c 0.0\n",
      "2788 Train Loss 10.613222\n",
      "Loss  0.25720933 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2565752 C_bot  0.15 k_c 0.0\n",
      "2789 Train Loss 10.610659\n",
      "Loss  0.2565752 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25599256 C_bot  0.15 k_c 0.0\n",
      "2790 Train Loss 10.608206\n",
      "Loss  0.25599256 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25537923 C_bot  0.15 k_c 0.0\n",
      "2791 Train Loss 10.60568\n",
      "Loss  0.25537923 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25476658 C_bot  0.15 k_c 0.0\n",
      "2792 Train Loss 10.603216\n",
      "Loss  0.25476658 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25412896 C_bot  0.15 k_c 0.0\n",
      "2793 Train Loss 10.600689\n",
      "Loss  0.25412896 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2535163 C_bot  0.15 k_c 0.0\n",
      "2794 Train Loss 10.598242\n",
      "Loss  0.2535163 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2529468 C_bot  0.15 k_c 0.0\n",
      "2795 Train Loss 10.595803\n",
      "Loss  0.2529468 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25234216 C_bot  0.15 k_c 0.0\n",
      "2796 Train Loss 10.593384\n",
      "Loss  0.25234216 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25176674 C_bot  0.15 k_c 0.0\n",
      "2797 Train Loss 10.590954\n",
      "Loss  0.25176674 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25113034 C_bot  0.15 k_c 0.0\n",
      "2798 Train Loss 10.58853\n",
      "Loss  0.25113034 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25057694 C_bot  0.15 k_c 0.0\n",
      "2799 Train Loss 10.586132\n",
      "Loss  0.25057694 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24994144 C_bot  0.15 k_c 0.0\n",
      "2800 Train Loss 10.583736\n",
      "Loss  0.24994144 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24942802 C_bot  0.15 k_c 0.0\n",
      "2801 Train Loss 10.581386\n",
      "Loss  0.24942802 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24878591 C_bot  0.15 k_c 0.0\n",
      "2802 Train Loss 10.579012\n",
      "Loss  0.24878591 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24828891 C_bot  0.15 k_c 0.0\n",
      "2803 Train Loss 10.576683\n",
      "Loss  0.24828891 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24760962 C_bot  0.15 k_c 0.0\n",
      "2804 Train Loss 10.5743065\n",
      "Loss  0.24760962 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24713199 C_bot  0.15 k_c 0.0\n",
      "2805 Train Loss 10.5720005\n",
      "Loss  0.24713199 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2465085 C_bot  0.15 k_c 0.0\n",
      "2806 Train Loss 10.569707\n",
      "Loss  0.2465085 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24600309 C_bot  0.15 k_c 0.0\n",
      "2807 Train Loss 10.567377\n",
      "Loss  0.24600309 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24536546 C_bot  0.15 k_c 0.0\n",
      "2808 Train Loss 10.565104\n",
      "Loss  0.24536546 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24487852 C_bot  0.15 k_c 0.0\n",
      "2809 Train Loss 10.562788\n",
      "Loss  0.24487852 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24424063 C_bot  0.15 k_c 0.0\n",
      "2810 Train Loss 10.560558\n",
      "Loss  0.24424063 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24383774 C_bot  0.15 k_c 0.0\n",
      "2811 Train Loss 10.558307\n",
      "Loss  0.24383774 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24314578 C_bot  0.15 k_c 0.0\n",
      "2812 Train Loss 10.556085\n",
      "Loss  0.24314578 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24279112 C_bot  0.15 k_c 0.0\n",
      "2813 Train Loss 10.553843\n",
      "Loss  0.24279112 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24205309 C_bot  0.15 k_c 0.0\n",
      "2814 Train Loss 10.551655\n",
      "Loss  0.24205309 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24183635 C_bot  0.15 k_c 0.0\n",
      "2815 Train Loss 10.549482\n",
      "Loss  0.24183635 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24108623 C_bot  0.15 k_c 0.0\n",
      "2816 Train Loss 10.547408\n",
      "Loss  0.24108623 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24106492 C_bot  0.15 k_c 0.0\n",
      "2817 Train Loss 10.545307\n",
      "Loss  0.24106492 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2402751 C_bot  0.15 k_c 0.0\n",
      "2818 Train Loss 10.543386\n",
      "Loss  0.2402751 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24068944 C_bot  0.15 k_c 0.0\n",
      "2819 Train Loss 10.541505\n",
      "Loss  0.24068944 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23998886 C_bot  0.15 k_c 0.0\n",
      "2820 Train Loss 10.539989\n",
      "Loss  0.23998886 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24138731 C_bot  0.15 k_c 0.0\n",
      "2821 Train Loss 10.538719\n",
      "Loss  0.24138731 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24128824 C_bot  0.15 k_c 0.0\n",
      "2822 Train Loss 10.538326\n",
      "Loss  0.24128824 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24505208 C_bot  0.15 k_c 0.0\n",
      "2823 Train Loss 10.538777\n",
      "Loss  0.24505208 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24712391 C_bot  0.15 k_c 0.0\n",
      "2824 Train Loss 10.541444\n",
      "Loss  0.24712391 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25719562 C_bot  0.15 k_c 0.0\n",
      "2825 Train Loss 10.547081\n",
      "Loss  0.25719562 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2671151 C_bot  0.15 k_c 0.0\n",
      "2826 Train Loss 10.559142\n",
      "Loss  0.2671151 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29539767 C_bot  0.15 k_c 0.0\n",
      "2827 Train Loss 10.581013\n",
      "Loss  0.29539767 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33222798 C_bot  0.15 k_c 0.0\n",
      "2828 Train Loss 10.622752\n",
      "Loss  0.33222798 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4169569 C_bot  0.15 k_c 0.0\n",
      "2829 Train Loss 10.697545\n",
      "Loss  0.4169569 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5469786 C_bot  0.15 k_c 0.0\n",
      "2830 Train Loss 10.837577\n",
      "Loss  0.5469786 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8165016 C_bot  0.15 k_c 0.0\n",
      "2831 Train Loss 11.090815\n",
      "Loss  0.8165016 C_bot  0.15 k_c 0.0\n",
      "Loss  1.274845 C_bot  0.15 k_c 0.0\n",
      "2832 Train Loss 11.568899\n",
      "Loss  1.274845 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1788232 C_bot  0.15 k_c 0.0\n",
      "2833 Train Loss 12.445177\n",
      "Loss  2.1788232 C_bot  0.15 k_c 0.0\n",
      "Loss  3.826266 C_bot  0.15 k_c 0.0\n",
      "2834 Train Loss 14.1318\n",
      "Loss  3.826266 C_bot  0.15 k_c 0.0\n",
      "Loss  6.983236 C_bot  0.15 k_c 0.0\n",
      "2835 Train Loss 17.240948\n",
      "Loss  6.983236 C_bot  0.15 k_c 0.0\n",
      "Loss  13.028863 C_bot  0.15 k_c 0.0\n",
      "2836 Train Loss 23.367334\n",
      "Loss  13.028863 C_bot  0.15 k_c 0.0\n",
      "Loss  24.236532 C_bot  0.15 k_c 0.0\n",
      "2837 Train Loss 34.49344\n",
      "Loss  24.236532 C_bot  0.15 k_c 0.0\n",
      "Loss  46.391953 C_bot  0.15 k_c 0.0\n",
      "2838 Train Loss 56.827633\n",
      "Loss  46.391953 C_bot  0.15 k_c 0.0\n",
      "Loss  84.21665 C_bot  0.15 k_c 0.0\n",
      "2839 Train Loss 94.51636\n",
      "Loss  84.21665 C_bot  0.15 k_c 0.0\n",
      "Loss  157.60521 C_bot  0.15 k_c 0.0\n",
      "2840 Train Loss 168.33661\n",
      "Loss  157.60521 C_bot  0.15 k_c 0.0\n",
      "Loss  253.72008 C_bot  0.15 k_c 0.0\n",
      "2841 Train Loss 264.18802\n",
      "Loss  253.72008 C_bot  0.15 k_c 0.0\n",
      "Loss  401.72104 C_bot  0.15 k_c 0.0\n",
      "2842 Train Loss 413.1887\n",
      "Loss  401.72104 C_bot  0.15 k_c 0.0\n",
      "Loss  453.22122 C_bot  0.15 k_c 0.0\n",
      "2843 Train Loss 463.91635\n",
      "Loss  453.22122 C_bot  0.15 k_c 0.0\n",
      "Loss  406.23627 C_bot  0.15 k_c 0.0\n",
      "2844 Train Loss 418.30307\n",
      "Loss  406.23627 C_bot  0.15 k_c 0.0\n",
      "Loss  187.9115 C_bot  0.15 k_c 0.0\n",
      "2845 Train Loss 198.73676\n",
      "Loss  187.9115 C_bot  0.15 k_c 0.0\n",
      "Loss  18.533367 C_bot  0.15 k_c 0.0\n",
      "2846 Train Loss 30.064083\n",
      "Loss  18.533367 C_bot  0.15 k_c 0.0\n",
      "Loss  34.995026 C_bot  0.15 k_c 0.0\n",
      "2847 Train Loss 46.934975\n",
      "Loss  34.995026 C_bot  0.15 k_c 0.0\n",
      "Loss  165.75041 C_bot  0.15 k_c 0.0\n",
      "2848 Train Loss 177.19258\n",
      "Loss  165.75041 C_bot  0.15 k_c 0.0\n",
      "Loss  242.55118 C_bot  0.15 k_c 0.0\n",
      "2849 Train Loss 255.6791\n",
      "Loss  242.55118 C_bot  0.15 k_c 0.0\n",
      "Loss  157.31459 C_bot  0.15 k_c 0.0\n",
      "2850 Train Loss 168.97183\n",
      "Loss  157.31459 C_bot  0.15 k_c 0.0\n",
      "Loss  36.644722 C_bot  0.15 k_c 0.0\n",
      "2851 Train Loss 48.88396\n",
      "Loss  36.644722 C_bot  0.15 k_c 0.0\n",
      "Loss  5.9604826 C_bot  0.15 k_c 0.0\n",
      "2852 Train Loss 17.923927\n",
      "Loss  5.9604826 C_bot  0.15 k_c 0.0\n",
      "Loss  74.17106 C_bot  0.15 k_c 0.0\n",
      "2853 Train Loss 85.86205\n",
      "Loss  74.17106 C_bot  0.15 k_c 0.0\n",
      "Loss  130.01495 C_bot  0.15 k_c 0.0\n",
      "2854 Train Loss 142.27165\n",
      "Loss  130.01495 C_bot  0.15 k_c 0.0\n",
      "Loss  86.636475 C_bot  0.15 k_c 0.0\n",
      "2855 Train Loss 98.28636\n",
      "Loss  86.636475 C_bot  0.15 k_c 0.0\n",
      "Loss  16.348072 C_bot  0.15 k_c 0.0\n",
      "2856 Train Loss 28.08728\n",
      "Loss  16.348072 C_bot  0.15 k_c 0.0\n",
      "Loss  6.48915 C_bot  0.15 k_c 0.0\n",
      "2857 Train Loss 18.127848\n",
      "Loss  6.48915 C_bot  0.15 k_c 0.0\n",
      "Loss  52.148003 C_bot  0.15 k_c 0.0\n",
      "2858 Train Loss 63.67249\n",
      "Loss  52.148003 C_bot  0.15 k_c 0.0\n",
      "Loss  75.288605 C_bot  0.15 k_c 0.0\n",
      "2859 Train Loss 87.041016\n",
      "Loss  75.288605 C_bot  0.15 k_c 0.0\n",
      "Loss  39.196533 C_bot  0.15 k_c 0.0\n",
      "2860 Train Loss 50.597984\n",
      "Loss  39.196533 C_bot  0.15 k_c 0.0\n",
      "Loss  3.1449099 C_bot  0.15 k_c 0.0\n",
      "2861 Train Loss 14.558257\n",
      "Loss  3.1449099 C_bot  0.15 k_c 0.0\n",
      "Loss  12.922072 C_bot  0.15 k_c 0.0\n",
      "2862 Train Loss 24.344795\n",
      "Loss  12.922072 C_bot  0.15 k_c 0.0\n",
      "Loss  41.062393 C_bot  0.15 k_c 0.0\n",
      "2863 Train Loss 52.27048\n",
      "Loss  41.062393 C_bot  0.15 k_c 0.0\n",
      "Loss  39.79348 C_bot  0.15 k_c 0.0\n",
      "2864 Train Loss 51.24474\n",
      "Loss  39.79348 C_bot  0.15 k_c 0.0\n",
      "Loss  12.078834 C_bot  0.15 k_c 0.0\n",
      "2865 Train Loss 23.202192\n",
      "Loss  12.078834 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5095065 C_bot  0.15 k_c 0.0\n",
      "2866 Train Loss 12.64976\n",
      "Loss  1.5095065 C_bot  0.15 k_c 0.0\n",
      "Loss  17.404484 C_bot  0.15 k_c 0.0\n",
      "2867 Train Loss 28.683872\n",
      "Loss  17.404484 C_bot  0.15 k_c 0.0\n",
      "Loss  27.56798 C_bot  0.15 k_c 0.0\n",
      "2868 Train Loss 38.598843\n",
      "Loss  27.56798 C_bot  0.15 k_c 0.0\n",
      "Loss  15.205888 C_bot  0.15 k_c 0.0\n",
      "2869 Train Loss 26.444998\n",
      "Loss  15.205888 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2450727 C_bot  0.15 k_c 0.0\n",
      "2870 Train Loss 12.32362\n",
      "Loss  1.2450727 C_bot  0.15 k_c 0.0\n",
      "Loss  5.807021 C_bot  0.15 k_c 0.0\n",
      "2871 Train Loss 16.840862\n",
      "Loss  5.807021 C_bot  0.15 k_c 0.0\n",
      "Loss  16.475689 C_bot  0.15 k_c 0.0\n",
      "2872 Train Loss 27.672455\n",
      "Loss  16.475689 C_bot  0.15 k_c 0.0\n",
      "Loss  13.682946 C_bot  0.15 k_c 0.0\n",
      "2873 Train Loss 24.672382\n",
      "Loss  13.682946 C_bot  0.15 k_c 0.0\n",
      "Loss  2.966682 C_bot  0.15 k_c 0.0\n",
      "2874 Train Loss 14.049946\n",
      "Loss  2.966682 C_bot  0.15 k_c 0.0\n",
      "Loss  1.393502 C_bot  0.15 k_c 0.0\n",
      "2875 Train Loss 12.447808\n",
      "Loss  1.393502 C_bot  0.15 k_c 0.0\n",
      "Loss  8.604882 C_bot  0.15 k_c 0.0\n",
      "2876 Train Loss 19.583422\n",
      "Loss  8.604882 C_bot  0.15 k_c 0.0\n",
      "Loss  10.600063 C_bot  0.15 k_c 0.0\n",
      "2877 Train Loss 21.681438\n",
      "Loss  10.600063 C_bot  0.15 k_c 0.0\n",
      "Loss  4.336444 C_bot  0.15 k_c 0.0\n",
      "2878 Train Loss 15.301797\n",
      "Loss  4.336444 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44100448 C_bot  0.15 k_c 0.0\n",
      "2879 Train Loss 11.41194\n",
      "Loss  0.44100448 C_bot  0.15 k_c 0.0\n",
      "Loss  3.8553655 C_bot  0.15 k_c 0.0\n",
      "2880 Train Loss 14.837921\n",
      "Loss  3.8553655 C_bot  0.15 k_c 0.0\n",
      "Loss  7.146087 C_bot  0.15 k_c 0.0\n",
      "2881 Train Loss 18.05017\n",
      "Loss  7.146087 C_bot  0.15 k_c 0.0\n",
      "Loss  4.5341554 C_bot  0.15 k_c 0.0\n",
      "2882 Train Loss 15.472097\n",
      "Loss  4.5341554 C_bot  0.15 k_c 0.0\n",
      "Loss  0.72713184 C_bot  0.15 k_c 0.0\n",
      "2883 Train Loss 11.595261\n",
      "Loss  0.72713184 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4107286 C_bot  0.15 k_c 0.0\n",
      "2884 Train Loss 12.247686\n",
      "Loss  1.4107286 C_bot  0.15 k_c 0.0\n",
      "Loss  4.221083 C_bot  0.15 k_c 0.0\n",
      "2885 Train Loss 15.087626\n",
      "Loss  4.221083 C_bot  0.15 k_c 0.0\n",
      "Loss  4.068767 C_bot  0.15 k_c 0.0\n",
      "2886 Train Loss 14.849396\n",
      "Loss  4.068767 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3297244 C_bot  0.15 k_c 0.0\n",
      "2887 Train Loss 12.13843\n",
      "Loss  1.3297244 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43416363 C_bot  0.15 k_c 0.0\n",
      "2888 Train Loss 11.211908\n",
      "Loss  0.43416363 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1167338 C_bot  0.15 k_c 0.0\n",
      "2889 Train Loss 12.852191\n",
      "Loss  2.1167338 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0624533 C_bot  0.15 k_c 0.0\n",
      "2890 Train Loss 13.841137\n",
      "Loss  3.0624533 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8460411 C_bot  0.15 k_c 0.0\n",
      "2891 Train Loss 12.554846\n",
      "Loss  1.8460411 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42983496 C_bot  0.15 k_c 0.0\n",
      "2892 Train Loss 11.150019\n",
      "Loss  0.42983496 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8198774 C_bot  0.15 k_c 0.0\n",
      "2893 Train Loss 11.534166\n",
      "Loss  0.8198774 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9480377 C_bot  0.15 k_c 0.0\n",
      "2894 Train Loss 12.61799\n",
      "Loss  1.9480377 C_bot  0.15 k_c 0.0\n",
      "Loss  1.826828 C_bot  0.15 k_c 0.0\n",
      "2895 Train Loss 12.525745\n",
      "Loss  1.826828 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7949754 C_bot  0.15 k_c 0.0\n",
      "2896 Train Loss 11.450386\n",
      "Loss  0.7949754 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35966328 C_bot  0.15 k_c 0.0\n",
      "2897 Train Loss 11.011799\n",
      "Loss  0.35966328 C_bot  0.15 k_c 0.0\n",
      "Loss  0.938033 C_bot  0.15 k_c 0.0\n",
      "2898 Train Loss 11.593952\n",
      "Loss  0.938033 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4222528 C_bot  0.15 k_c 0.0\n",
      "2899 Train Loss 12.044378\n",
      "Loss  1.4222528 C_bot  0.15 k_c 0.0\n",
      "Loss  1.008588 C_bot  0.15 k_c 0.0\n",
      "2900 Train Loss 11.646705\n",
      "Loss  1.008588 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40874818 C_bot  0.15 k_c 0.0\n",
      "2901 Train Loss 11.022766\n",
      "Loss  0.40874818 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40998438 C_bot  0.15 k_c 0.0\n",
      "2902 Train Loss 11.016372\n",
      "Loss  0.40998438 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8270137 C_bot  0.15 k_c 0.0\n",
      "2903 Train Loss 11.440202\n",
      "Loss  0.8270137 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9565964 C_bot  0.15 k_c 0.0\n",
      "2904 Train Loss 11.544209\n",
      "Loss  0.9565964 C_bot  0.15 k_c 0.0\n",
      "Loss  0.58745193 C_bot  0.15 k_c 0.0\n",
      "2905 Train Loss 11.185037\n",
      "Loss  0.58745193 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30285773 C_bot  0.15 k_c 0.0\n",
      "2906 Train Loss 10.885336\n",
      "Loss  0.30285773 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42366374 C_bot  0.15 k_c 0.0\n",
      "2907 Train Loss 10.996191\n",
      "Loss  0.42366374 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6595966 C_bot  0.15 k_c 0.0\n",
      "2908 Train Loss 11.239309\n",
      "Loss  0.6595966 C_bot  0.15 k_c 0.0\n",
      "Loss  0.65534854 C_bot  0.15 k_c 0.0\n",
      "2909 Train Loss 11.211716\n",
      "Loss  0.65534854 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40038282 C_bot  0.15 k_c 0.0\n",
      "2910 Train Loss 10.963551\n",
      "Loss  0.40038282 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2776354 C_bot  0.15 k_c 0.0\n",
      "2911 Train Loss 10.829218\n",
      "Loss  0.2776354 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3912031 C_bot  0.15 k_c 0.0\n",
      "2912 Train Loss 10.931492\n",
      "Loss  0.3912031 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5110503 C_bot  0.15 k_c 0.0\n",
      "2913 Train Loss 11.057678\n",
      "Loss  0.5110503 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47907236 C_bot  0.15 k_c 0.0\n",
      "2914 Train Loss 11.005327\n",
      "Loss  0.47907236 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31949785 C_bot  0.15 k_c 0.0\n",
      "2915 Train Loss 10.849569\n",
      "Loss  0.31949785 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26253542 C_bot  0.15 k_c 0.0\n",
      "2916 Train Loss 10.783413\n",
      "Loss  0.26253542 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33990815 C_bot  0.15 k_c 0.0\n",
      "2917 Train Loss 10.850434\n",
      "Loss  0.33990815 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40436196 C_bot  0.15 k_c 0.0\n",
      "2918 Train Loss 10.918674\n",
      "Loss  0.40436196 C_bot  0.15 k_c 0.0\n",
      "Loss  0.38179538 C_bot  0.15 k_c 0.0\n",
      "2919 Train Loss 10.879961\n",
      "Loss  0.38179538 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28482738 C_bot  0.15 k_c 0.0\n",
      "2920 Train Loss 10.784702\n",
      "Loss  0.28482738 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24988931 C_bot  0.15 k_c 0.0\n",
      "2921 Train Loss 10.742054\n",
      "Loss  0.24988931 C_bot  0.15 k_c 0.0\n",
      "Loss  0.293321 C_bot  0.15 k_c 0.0\n",
      "2922 Train Loss 10.777237\n",
      "Loss  0.293321 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3319408 C_bot  0.15 k_c 0.0\n",
      "2923 Train Loss 10.817678\n",
      "Loss  0.3319408 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32484818 C_bot  0.15 k_c 0.0\n",
      "2924 Train Loss 10.797948\n",
      "Loss  0.32484818 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26571873 C_bot  0.15 k_c 0.0\n",
      "2925 Train Loss 10.739855\n",
      "Loss  0.26571873 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23743944 C_bot  0.15 k_c 0.0\n",
      "2926 Train Loss 10.704609\n",
      "Loss  0.23743944 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25531304 C_bot  0.15 k_c 0.0\n",
      "2927 Train Loss 10.716347\n",
      "Loss  0.25531304 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27929175 C_bot  0.15 k_c 0.0\n",
      "2928 Train Loss 10.740806\n",
      "Loss  0.27929175 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28420684 C_bot  0.15 k_c 0.0\n",
      "2929 Train Loss 10.735497\n",
      "Loss  0.28420684 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24994121 C_bot  0.15 k_c 0.0\n",
      "2930 Train Loss 10.702167\n",
      "Loss  0.24994121 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2268309 C_bot  0.15 k_c 0.0\n",
      "2931 Train Loss 10.672276\n",
      "Loss  0.2268309 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22771962 C_bot  0.15 k_c 0.0\n",
      "2932 Train Loss 10.668872\n",
      "Loss  0.22771962 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24124631 C_bot  0.15 k_c 0.0\n",
      "2933 Train Loss 10.681494\n",
      "Loss  0.24124631 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25235817 C_bot  0.15 k_c 0.0\n",
      "2934 Train Loss 10.684312\n",
      "Loss  0.25235817 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23603779 C_bot  0.15 k_c 0.0\n",
      "2935 Train Loss 10.668568\n",
      "Loss  0.23603779 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22020853 C_bot  0.15 k_c 0.0\n",
      "2936 Train Loss 10.645964\n",
      "Loss  0.22020853 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21135613 C_bot  0.15 k_c 0.0\n",
      "2937 Train Loss 10.634306\n",
      "Loss  0.21135613 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21572739 C_bot  0.15 k_c 0.0\n",
      "2938 Train Loss 10.636288\n",
      "Loss  0.21572739 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22615734 C_bot  0.15 k_c 0.0\n",
      "2939 Train Loss 10.640282\n",
      "Loss  0.22615734 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22177121 C_bot  0.15 k_c 0.0\n",
      "2940 Train Loss 10.635693\n",
      "Loss  0.22177121 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21469922 C_bot  0.15 k_c 0.0\n",
      "2941 Train Loss 10.62208\n",
      "Loss  0.21469922 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20345268 C_bot  0.15 k_c 0.0\n",
      "2942 Train Loss 10.608984\n",
      "Loss  0.20345268 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20133775 C_bot  0.15 k_c 0.0\n",
      "2943 Train Loss 10.603154\n",
      "Loss  0.20133775 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20632127 C_bot  0.15 k_c 0.0\n",
      "2944 Train Loss 10.60335\n",
      "Loss  0.20632127 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2073593 C_bot  0.15 k_c 0.0\n",
      "2945 Train Loss 10.603201\n",
      "Loss  0.2073593 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20765033 C_bot  0.15 k_c 0.0\n",
      "2946 Train Loss 10.597543\n",
      "Loss  0.20765033 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19966939 C_bot  0.15 k_c 0.0\n",
      "2947 Train Loss 10.588299\n",
      "Loss  0.19966939 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19548184 C_bot  0.15 k_c 0.0\n",
      "2948 Train Loss 10.579576\n",
      "Loss  0.19548184 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19405489 C_bot  0.15 k_c 0.0\n",
      "2949 Train Loss 10.574938\n",
      "Loss  0.19405489 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1948139 C_bot  0.15 k_c 0.0\n",
      "2950 Train Loss 10.573439\n",
      "Loss  0.1948139 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19781938 C_bot  0.15 k_c 0.0\n",
      "2951 Train Loss 10.571576\n",
      "Loss  0.19781938 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19486412 C_bot  0.15 k_c 0.0\n",
      "2952 Train Loss 10.567355\n",
      "Loss  0.19486412 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19304755 C_bot  0.15 k_c 0.0\n",
      "2953 Train Loss 10.560776\n",
      "Loss  0.19304755 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18868682 C_bot  0.15 k_c 0.0\n",
      "2954 Train Loss 10.554374\n",
      "Loss  0.18868682 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18738188 C_bot  0.15 k_c 0.0\n",
      "2955 Train Loss 10.549801\n",
      "Loss  0.18738188 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18812443 C_bot  0.15 k_c 0.0\n",
      "2956 Train Loss 10.547021\n",
      "Loss  0.18812443 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18775973 C_bot  0.15 k_c 0.0\n",
      "2957 Train Loss 10.544805\n",
      "Loss  0.18775973 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1887103 C_bot  0.15 k_c 0.0\n",
      "2958 Train Loss 10.541466\n",
      "Loss  0.1887103 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18580939 C_bot  0.15 k_c 0.0\n",
      "2959 Train Loss 10.537016\n",
      "Loss  0.18580939 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1845425 C_bot  0.15 k_c 0.0\n",
      "2960 Train Loss 10.531908\n",
      "Loss  0.1845425 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18242127 C_bot  0.15 k_c 0.0\n",
      "2961 Train Loss 10.527481\n",
      "Loss  0.18242127 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18171948 C_bot  0.15 k_c 0.0\n",
      "2962 Train Loss 10.52407\n",
      "Loss  0.18171948 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18225205 C_bot  0.15 k_c 0.0\n",
      "2963 Train Loss 10.521339\n",
      "Loss  0.18225205 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1813979 C_bot  0.15 k_c 0.0\n",
      "2964 Train Loss 10.518659\n",
      "Loss  0.1813979 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18171774 C_bot  0.15 k_c 0.0\n",
      "2965 Train Loss 10.515302\n",
      "Loss  0.18171774 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17971586 C_bot  0.15 k_c 0.0\n",
      "2966 Train Loss 10.5115795\n",
      "Loss  0.17971586 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17903301 C_bot  0.15 k_c 0.0\n",
      "2967 Train Loss 10.5075865\n",
      "Loss  0.17903301 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17766741 C_bot  0.15 k_c 0.0\n",
      "2968 Train Loss 10.50398\n",
      "Loss  0.17766741 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17707676 C_bot  0.15 k_c 0.0\n",
      "2969 Train Loss 10.500841\n",
      "Loss  0.17707676 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1771281 C_bot  0.15 k_c 0.0\n",
      "2970 Train Loss 10.498004\n",
      "Loss  0.1771281 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17636448 C_bot  0.15 k_c 0.0\n",
      "2971 Train Loss 10.495315\n",
      "Loss  0.17636448 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17660154 C_bot  0.15 k_c 0.0\n",
      "2972 Train Loss 10.492359\n",
      "Loss  0.17660154 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17521681 C_bot  0.15 k_c 0.0\n",
      "2973 Train Loss 10.4892\n",
      "Loss  0.17521681 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17498636 C_bot  0.15 k_c 0.0\n",
      "2974 Train Loss 10.4859495\n",
      "Loss  0.17498636 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17382891 C_bot  0.15 k_c 0.0\n",
      "2975 Train Loss 10.48274\n",
      "Loss  0.17382891 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1733687 C_bot  0.15 k_c 0.0\n",
      "2976 Train Loss 10.479745\n",
      "Loss  0.1733687 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17304882 C_bot  0.15 k_c 0.0\n",
      "2977 Train Loss 10.476959\n",
      "Loss  0.17304882 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17245969 C_bot  0.15 k_c 0.0\n",
      "2978 Train Loss 10.474307\n",
      "Loss  0.17245969 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17253512 C_bot  0.15 k_c 0.0\n",
      "2979 Train Loss 10.471629\n",
      "Loss  0.17253512 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17165464 C_bot  0.15 k_c 0.0\n",
      "2980 Train Loss 10.468931\n",
      "Loss  0.17165464 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1716057 C_bot  0.15 k_c 0.0\n",
      "2981 Train Loss 10.466122\n",
      "Loss  0.1716057 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17066082 C_bot  0.15 k_c 0.0\n",
      "2982 Train Loss 10.463312\n",
      "Loss  0.17066082 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17031586 C_bot  0.15 k_c 0.0\n",
      "2983 Train Loss 10.4604435\n",
      "Loss  0.17031586 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16974789 C_bot  0.15 k_c 0.0\n",
      "2984 Train Loss 10.457782\n",
      "Loss  0.16974789 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16929655 C_bot  0.15 k_c 0.0\n",
      "2985 Train Loss 10.45514\n",
      "Loss  0.16929655 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16909584 C_bot  0.15 k_c 0.0\n",
      "2986 Train Loss 10.45261\n",
      "Loss  0.16909584 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16851781 C_bot  0.15 k_c 0.0\n",
      "2987 Train Loss 10.450107\n",
      "Loss  0.16851781 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16847724 C_bot  0.15 k_c 0.0\n",
      "2988 Train Loss 10.447607\n",
      "Loss  0.16847724 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16776483 C_bot  0.15 k_c 0.0\n",
      "2989 Train Loss 10.445097\n",
      "Loss  0.16776483 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16767886 C_bot  0.15 k_c 0.0\n",
      "2990 Train Loss 10.442572\n",
      "Loss  0.16767886 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16696826 C_bot  0.15 k_c 0.0\n",
      "2991 Train Loss 10.440045\n",
      "Loss  0.16696826 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1667572 C_bot  0.15 k_c 0.0\n",
      "2992 Train Loss 10.437535\n",
      "Loss  0.1667572 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16618334 C_bot  0.15 k_c 0.0\n",
      "2993 Train Loss 10.435039\n",
      "Loss  0.16618334 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16586071 C_bot  0.15 k_c 0.0\n",
      "2994 Train Loss 10.432611\n",
      "Loss  0.16586071 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16553587 C_bot  0.15 k_c 0.0\n",
      "2995 Train Loss 10.430229\n",
      "Loss  0.16553587 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16513696 C_bot  0.15 k_c 0.0\n",
      "2996 Train Loss 10.427908\n",
      "Loss  0.16513696 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16493353 C_bot  0.15 k_c 0.0\n",
      "2997 Train Loss 10.425548\n",
      "Loss  0.16493353 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16441017 C_bot  0.15 k_c 0.0\n",
      "2998 Train Loss 10.423224\n",
      "Loss  0.16441017 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1643157 C_bot  0.15 k_c 0.0\n",
      "2999 Train Loss 10.420938\n",
      "Loss  0.1643157 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16376294 C_bot  0.15 k_c 0.0\n",
      "3000 Train Loss 10.418646\n",
      "Loss  0.16376294 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16362385 C_bot  0.15 k_c 0.0\n",
      "3001 Train Loss 10.416344\n",
      "Loss  0.16362385 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1630932 C_bot  0.15 k_c 0.0\n",
      "3002 Train Loss 10.414076\n",
      "Loss  0.1630932 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1628998 C_bot  0.15 k_c 0.0\n",
      "3003 Train Loss 10.411797\n",
      "Loss  0.1628998 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16245715 C_bot  0.15 k_c 0.0\n",
      "3004 Train Loss 10.409579\n",
      "Loss  0.16245715 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16220656 C_bot  0.15 k_c 0.0\n",
      "3005 Train Loss 10.407342\n",
      "Loss  0.16220656 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16182604 C_bot  0.15 k_c 0.0\n",
      "3006 Train Loss 10.405136\n",
      "Loss  0.16182604 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16152717 C_bot  0.15 k_c 0.0\n",
      "3007 Train Loss 10.402948\n",
      "Loss  0.16152717 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16122252 C_bot  0.15 k_c 0.0\n",
      "3008 Train Loss 10.400778\n",
      "Loss  0.16122252 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16089731 C_bot  0.15 k_c 0.0\n",
      "3009 Train Loss 10.398649\n",
      "Loss  0.16089731 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16063814 C_bot  0.15 k_c 0.0\n",
      "3010 Train Loss 10.396495\n",
      "Loss  0.16063814 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1602651 C_bot  0.15 k_c 0.0\n",
      "3011 Train Loss 10.394388\n",
      "Loss  0.1602651 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16007487 C_bot  0.15 k_c 0.0\n",
      "3012 Train Loss 10.392289\n",
      "Loss  0.16007487 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15965448 C_bot  0.15 k_c 0.0\n",
      "3013 Train Loss 10.390186\n",
      "Loss  0.15965448 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15947327 C_bot  0.15 k_c 0.0\n",
      "3014 Train Loss 10.388097\n",
      "Loss  0.15947327 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15906858 C_bot  0.15 k_c 0.0\n",
      "3015 Train Loss 10.386047\n",
      "Loss  0.15906858 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15889598 C_bot  0.15 k_c 0.0\n",
      "3016 Train Loss 10.38398\n",
      "Loss  0.15889598 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15849607 C_bot  0.15 k_c 0.0\n",
      "3017 Train Loss 10.381964\n",
      "Loss  0.15849607 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15835038 C_bot  0.15 k_c 0.0\n",
      "3018 Train Loss 10.37994\n",
      "Loss  0.15835038 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15789394 C_bot  0.15 k_c 0.0\n",
      "3019 Train Loss 10.377887\n",
      "Loss  0.15789394 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15774895 C_bot  0.15 k_c 0.0\n",
      "3020 Train Loss 10.375884\n",
      "Loss  0.15774895 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15734164 C_bot  0.15 k_c 0.0\n",
      "3021 Train Loss 10.373903\n",
      "Loss  0.15734164 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15720204 C_bot  0.15 k_c 0.0\n",
      "3022 Train Loss 10.3719225\n",
      "Loss  0.15720204 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15675904 C_bot  0.15 k_c 0.0\n",
      "3023 Train Loss 10.369926\n",
      "Loss  0.15675904 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1566102 C_bot  0.15 k_c 0.0\n",
      "3024 Train Loss 10.367956\n",
      "Loss  0.1566102 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15620627 C_bot  0.15 k_c 0.0\n",
      "3025 Train Loss 10.366021\n",
      "Loss  0.15620627 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15607269 C_bot  0.15 k_c 0.0\n",
      "3026 Train Loss 10.364077\n",
      "Loss  0.15607269 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15565059 C_bot  0.15 k_c 0.0\n",
      "3027 Train Loss 10.362154\n",
      "Loss  0.15565059 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15556131 C_bot  0.15 k_c 0.0\n",
      "3028 Train Loss 10.36025\n",
      "Loss  0.15556131 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15514077 C_bot  0.15 k_c 0.0\n",
      "3029 Train Loss 10.358381\n",
      "Loss  0.15514077 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15507892 C_bot  0.15 k_c 0.0\n",
      "3030 Train Loss 10.356476\n",
      "Loss  0.15507892 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15461022 C_bot  0.15 k_c 0.0\n",
      "3031 Train Loss 10.354639\n",
      "Loss  0.15461022 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15464996 C_bot  0.15 k_c 0.0\n",
      "3032 Train Loss 10.352776\n",
      "Loss  0.15464996 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15411907 C_bot  0.15 k_c 0.0\n",
      "3033 Train Loss 10.3509865\n",
      "Loss  0.15411907 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15431193 C_bot  0.15 k_c 0.0\n",
      "3034 Train Loss 10.349176\n",
      "Loss  0.15431193 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15374447 C_bot  0.15 k_c 0.0\n",
      "3035 Train Loss 10.347509\n",
      "Loss  0.15374447 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15428686 C_bot  0.15 k_c 0.0\n",
      "3036 Train Loss 10.345888\n",
      "Loss  0.15428686 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1537268 C_bot  0.15 k_c 0.0\n",
      "3037 Train Loss 10.344476\n",
      "Loss  0.1537268 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15485986 C_bot  0.15 k_c 0.0\n",
      "3038 Train Loss 10.343164\n",
      "Loss  0.15485986 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15453777 C_bot  0.15 k_c 0.0\n",
      "3039 Train Loss 10.342383\n",
      "Loss  0.15453777 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1570652 C_bot  0.15 k_c 0.0\n",
      "3040 Train Loss 10.342001\n",
      "Loss  0.1570652 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1576673 C_bot  0.15 k_c 0.0\n",
      "3041 Train Loss 10.342783\n",
      "Loss  0.1576673 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16346018 C_bot  0.15 k_c 0.0\n",
      "3042 Train Loss 10.344885\n",
      "Loss  0.16346018 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16742523 C_bot  0.15 k_c 0.0\n",
      "3043 Train Loss 10.35009\n",
      "Loss  0.16742523 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18182458 C_bot  0.15 k_c 0.0\n",
      "3044 Train Loss 10.359471\n",
      "Loss  0.18182458 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19684541 C_bot  0.15 k_c 0.0\n",
      "3045 Train Loss 10.377552\n",
      "Loss  0.19684541 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23546492 C_bot  0.15 k_c 0.0\n",
      "3046 Train Loss 10.408841\n",
      "Loss  0.23546492 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28660303 C_bot  0.15 k_c 0.0\n",
      "3047 Train Loss 10.466263\n",
      "Loss  0.28660303 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39809245 C_bot  0.15 k_c 0.0\n",
      "3048 Train Loss 10.566367\n",
      "Loss  0.39809245 C_bot  0.15 k_c 0.0\n",
      "Loss  0.56917626 C_bot  0.15 k_c 0.0\n",
      "3049 Train Loss 10.749586\n",
      "Loss  0.56917626 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9125064 C_bot  0.15 k_c 0.0\n",
      "3050 Train Loss 11.074354\n",
      "Loss  0.9125064 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4917365 C_bot  0.15 k_c 0.0\n",
      "3051 Train Loss 11.676743\n",
      "Loss  1.4917365 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6047537 C_bot  0.15 k_c 0.0\n",
      "3052 Train Loss 12.758495\n",
      "Loss  2.6047537 C_bot  0.15 k_c 0.0\n",
      "Loss  4.6070266 C_bot  0.15 k_c 0.0\n",
      "3053 Train Loss 14.805687\n",
      "Loss  4.6070266 C_bot  0.15 k_c 0.0\n",
      "Loss  8.351068 C_bot  0.15 k_c 0.0\n",
      "3054 Train Loss 18.49637\n",
      "Loss  8.351068 C_bot  0.15 k_c 0.0\n",
      "Loss  15.407033 C_bot  0.15 k_c 0.0\n",
      "3055 Train Loss 25.643301\n",
      "Loss  15.407033 C_bot  0.15 k_c 0.0\n",
      "Loss  28.120632 C_bot  0.15 k_c 0.0\n",
      "3056 Train Loss 38.26637\n",
      "Loss  28.120632 C_bot  0.15 k_c 0.0\n",
      "Loss  52.70789 C_bot  0.15 k_c 0.0\n",
      "3057 Train Loss 63.05197\n",
      "Loss  52.70789 C_bot  0.15 k_c 0.0\n",
      "Loss  92.96855 C_bot  0.15 k_c 0.0\n",
      "3058 Train Loss 103.157814\n",
      "Loss  92.96855 C_bot  0.15 k_c 0.0\n",
      "Loss  168.04782 C_bot  0.15 k_c 0.0\n",
      "3059 Train Loss 178.7057\n",
      "Loss  168.04782 C_bot  0.15 k_c 0.0\n",
      "Loss  258.34915 C_bot  0.15 k_c 0.0\n",
      "3060 Train Loss 268.68597\n",
      "Loss  258.34915 C_bot  0.15 k_c 0.0\n",
      "Loss  383.06525 C_bot  0.15 k_c 0.0\n",
      "3061 Train Loss 394.42908\n",
      "Loss  383.06525 C_bot  0.15 k_c 0.0\n",
      "Loss  400.3231 C_bot  0.15 k_c 0.0\n",
      "3062 Train Loss 410.82864\n",
      "Loss  400.3231 C_bot  0.15 k_c 0.0\n",
      "Loss  317.28308 C_bot  0.15 k_c 0.0\n",
      "3063 Train Loss 329.0705\n",
      "Loss  317.28308 C_bot  0.15 k_c 0.0\n",
      "Loss  121.2096 C_bot  0.15 k_c 0.0\n",
      "3064 Train Loss 131.9395\n",
      "Loss  121.2096 C_bot  0.15 k_c 0.0\n",
      "Loss  5.005354 C_bot  0.15 k_c 0.0\n",
      "3065 Train Loss 16.294739\n",
      "Loss  5.005354 C_bot  0.15 k_c 0.0\n",
      "Loss  51.158955 C_bot  0.15 k_c 0.0\n",
      "3066 Train Loss 62.991386\n",
      "Loss  51.158955 C_bot  0.15 k_c 0.0\n",
      "Loss  163.79224 C_bot  0.15 k_c 0.0\n",
      "3067 Train Loss 175.08337\n",
      "Loss  163.79224 C_bot  0.15 k_c 0.0\n",
      "Loss  208.91606 C_bot  0.15 k_c 0.0\n",
      "3068 Train Loss 221.54207\n",
      "Loss  208.91606 C_bot  0.15 k_c 0.0\n",
      "Loss  122.22589 C_bot  0.15 k_c 0.0\n",
      "3069 Train Loss 133.64302\n",
      "Loss  122.22589 C_bot  0.15 k_c 0.0\n",
      "Loss  23.114878 C_bot  0.15 k_c 0.0\n",
      "3070 Train Loss 34.89591\n",
      "Loss  23.114878 C_bot  0.15 k_c 0.0\n",
      "Loss  7.670069 C_bot  0.15 k_c 0.0\n",
      "3071 Train Loss 19.270588\n",
      "Loss  7.670069 C_bot  0.15 k_c 0.0\n",
      "Loss  68.163376 C_bot  0.15 k_c 0.0\n",
      "3072 Train Loss 79.53939\n",
      "Loss  68.163376 C_bot  0.15 k_c 0.0\n",
      "Loss  112.2729 C_bot  0.15 k_c 0.0\n",
      "3073 Train Loss 124.0715\n",
      "Loss  112.2729 C_bot  0.15 k_c 0.0\n",
      "Loss  74.63416 C_bot  0.15 k_c 0.0\n",
      "3074 Train Loss 85.97264\n",
      "Loss  74.63416 C_bot  0.15 k_c 0.0\n",
      "Loss  15.073161 C_bot  0.15 k_c 0.0\n",
      "3075 Train Loss 26.455769\n",
      "Loss  15.073161 C_bot  0.15 k_c 0.0\n",
      "Loss  4.597894 C_bot  0.15 k_c 0.0\n",
      "3076 Train Loss 15.8893175\n",
      "Loss  4.597894 C_bot  0.15 k_c 0.0\n",
      "Loss  42.043976 C_bot  0.15 k_c 0.0\n",
      "3077 Train Loss 53.246414\n",
      "Loss  42.043976 C_bot  0.15 k_c 0.0\n",
      "Loss  64.78019 C_bot  0.15 k_c 0.0\n",
      "3078 Train Loss 76.17164\n",
      "Loss  64.78019 C_bot  0.15 k_c 0.0\n",
      "Loss  38.23024 C_bot  0.15 k_c 0.0\n",
      "3079 Train Loss 49.307903\n",
      "Loss  38.23024 C_bot  0.15 k_c 0.0\n",
      "Loss  5.058376 C_bot  0.15 k_c 0.0\n",
      "3080 Train Loss 16.16733\n",
      "Loss  5.058376 C_bot  0.15 k_c 0.0\n",
      "Loss  7.241371 C_bot  0.15 k_c 0.0\n",
      "3081 Train Loss 18.326574\n",
      "Loss  7.241371 C_bot  0.15 k_c 0.0\n",
      "Loss  31.34777 C_bot  0.15 k_c 0.0\n",
      "3082 Train Loss 42.25618\n",
      "Loss  31.34777 C_bot  0.15 k_c 0.0\n",
      "Loss  36.503456 C_bot  0.15 k_c 0.0\n",
      "3083 Train Loss 47.669823\n",
      "Loss  36.503456 C_bot  0.15 k_c 0.0\n",
      "Loss  15.317882 C_bot  0.15 k_c 0.0\n",
      "3084 Train Loss 26.17254\n",
      "Loss  15.317882 C_bot  0.15 k_c 0.0\n",
      "Loss  0.82299083 C_bot  0.15 k_c 0.0\n",
      "3085 Train Loss 11.747317\n",
      "Loss  0.82299083 C_bot  0.15 k_c 0.0\n",
      "Loss  9.993636 C_bot  0.15 k_c 0.0\n",
      "3086 Train Loss 21.00579\n",
      "Loss  9.993636 C_bot  0.15 k_c 0.0\n",
      "Loss  22.486303 C_bot  0.15 k_c 0.0\n",
      "3087 Train Loss 33.29592\n",
      "Loss  22.486303 C_bot  0.15 k_c 0.0\n",
      "Loss  17.290089 C_bot  0.15 k_c 0.0\n",
      "3088 Train Loss 28.324162\n",
      "Loss  17.290089 C_bot  0.15 k_c 0.0\n",
      "Loss  3.5538375 C_bot  0.15 k_c 0.0\n",
      "3089 Train Loss 14.400412\n",
      "Loss  3.5538375 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8575546 C_bot  0.15 k_c 0.0\n",
      "3090 Train Loss 12.708794\n",
      "Loss  1.8575546 C_bot  0.15 k_c 0.0\n",
      "Loss  10.987649 C_bot  0.15 k_c 0.0\n",
      "3091 Train Loss 21.946491\n",
      "Loss  10.987649 C_bot  0.15 k_c 0.0\n",
      "Loss  13.8149605 C_bot  0.15 k_c 0.0\n",
      "3092 Train Loss 24.61326\n",
      "Loss  13.8149605 C_bot  0.15 k_c 0.0\n",
      "Loss  6.116699 C_bot  0.15 k_c 0.0\n",
      "3093 Train Loss 17.007973\n",
      "Loss  6.116699 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48189315 C_bot  0.15 k_c 0.0\n",
      "3094 Train Loss 11.298096\n",
      "Loss  0.48189315 C_bot  0.15 k_c 0.0\n",
      "Loss  4.1309786 C_bot  0.15 k_c 0.0\n",
      "3095 Train Loss 14.906776\n",
      "Loss  4.1309786 C_bot  0.15 k_c 0.0\n",
      "Loss  8.971995 C_bot  0.15 k_c 0.0\n",
      "3096 Train Loss 19.802322\n",
      "Loss  8.971995 C_bot  0.15 k_c 0.0\n",
      "Loss  6.7223463 C_bot  0.15 k_c 0.0\n",
      "3097 Train Loss 17.449585\n",
      "Loss  6.7223463 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4224093 C_bot  0.15 k_c 0.0\n",
      "3098 Train Loss 12.159613\n",
      "Loss  1.4224093 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0186422 C_bot  0.15 k_c 0.0\n",
      "3099 Train Loss 11.726482\n",
      "Loss  1.0186422 C_bot  0.15 k_c 0.0\n",
      "Loss  4.6441693 C_bot  0.15 k_c 0.0\n",
      "3100 Train Loss 15.295633\n",
      "Loss  4.6441693 C_bot  0.15 k_c 0.0\n",
      "Loss  5.5959034 C_bot  0.15 k_c 0.0\n",
      "3101 Train Loss 16.286434\n",
      "Loss  5.5959034 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5698256 C_bot  0.15 k_c 0.0\n",
      "3102 Train Loss 13.179756\n",
      "Loss  2.5698256 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36096266 C_bot  0.15 k_c 0.0\n",
      "3103 Train Loss 10.97526\n",
      "Loss  0.36096266 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7315742 C_bot  0.15 k_c 0.0\n",
      "3104 Train Loss 12.353185\n",
      "Loss  1.7315742 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7155898 C_bot  0.15 k_c 0.0\n",
      "3105 Train Loss 14.274369\n",
      "Loss  3.7155898 C_bot  0.15 k_c 0.0\n",
      "Loss  2.9731603 C_bot  0.15 k_c 0.0\n",
      "3106 Train Loss 13.582325\n",
      "Loss  2.9731603 C_bot  0.15 k_c 0.0\n",
      "Loss  0.92607486 C_bot  0.15 k_c 0.0\n",
      "3107 Train Loss 11.47638\n",
      "Loss  0.92607486 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48315537 C_bot  0.15 k_c 0.0\n",
      "3108 Train Loss 11.028737\n",
      "Loss  0.48315537 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7800456 C_bot  0.15 k_c 0.0\n",
      "3109 Train Loss 12.343786\n",
      "Loss  1.7800456 C_bot  0.15 k_c 0.0\n",
      "Loss  2.5116704 C_bot  0.15 k_c 0.0\n",
      "3110 Train Loss 13.019213\n",
      "Loss  2.5116704 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5292923 C_bot  0.15 k_c 0.0\n",
      "3111 Train Loss 12.065559\n",
      "Loss  1.5292923 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44086504 C_bot  0.15 k_c 0.0\n",
      "3112 Train Loss 10.942034\n",
      "Loss  0.44086504 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6100058 C_bot  0.15 k_c 0.0\n",
      "3113 Train Loss 11.09839\n",
      "Loss  0.6100058 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4374756 C_bot  0.15 k_c 0.0\n",
      "3114 Train Loss 11.93889\n",
      "Loss  1.4374756 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5845397 C_bot  0.15 k_c 0.0\n",
      "3115 Train Loss 12.049118\n",
      "Loss  1.5845397 C_bot  0.15 k_c 0.0\n",
      "Loss  0.83610773 C_bot  0.15 k_c 0.0\n",
      "3116 Train Loss 11.314077\n",
      "Loss  0.83610773 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31800202 C_bot  0.15 k_c 0.0\n",
      "3117 Train Loss 10.7777405\n",
      "Loss  0.31800202 C_bot  0.15 k_c 0.0\n",
      "Loss  0.58655787 C_bot  0.15 k_c 0.0\n",
      "3118 Train Loss 11.034645\n",
      "Loss  0.58655787 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0528251 C_bot  0.15 k_c 0.0\n",
      "3119 Train Loss 11.510814\n",
      "Loss  1.0528251 C_bot  0.15 k_c 0.0\n",
      "Loss  1.02049 C_bot  0.15 k_c 0.0\n",
      "3120 Train Loss 11.452103\n",
      "Loss  1.02049 C_bot  0.15 k_c 0.0\n",
      "Loss  0.537029 C_bot  0.15 k_c 0.0\n",
      "3121 Train Loss 10.976667\n",
      "Loss  0.537029 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29384163 C_bot  0.15 k_c 0.0\n",
      "3122 Train Loss 10.720625\n",
      "Loss  0.29384163 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5068205 C_bot  0.15 k_c 0.0\n",
      "3123 Train Loss 10.921419\n",
      "Loss  0.5068205 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7613271 C_bot  0.15 k_c 0.0\n",
      "3124 Train Loss 11.183825\n",
      "Loss  0.7613271 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71073467 C_bot  0.15 k_c 0.0\n",
      "3125 Train Loss 11.109203\n",
      "Loss  0.71073467 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41346708 C_bot  0.15 k_c 0.0\n",
      "3126 Train Loss 10.817814\n",
      "Loss  0.41346708 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28278607 C_bot  0.15 k_c 0.0\n",
      "3127 Train Loss 10.675562\n",
      "Loss  0.28278607 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41540068 C_bot  0.15 k_c 0.0\n",
      "3128 Train Loss 10.796534\n",
      "Loss  0.41540068 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5612245 C_bot  0.15 k_c 0.0\n",
      "3129 Train Loss 10.948272\n",
      "Loss  0.5612245 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5398804 C_bot  0.15 k_c 0.0\n",
      "3130 Train Loss 10.906324\n",
      "Loss  0.5398804 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36234856 C_bot  0.15 k_c 0.0\n",
      "3131 Train Loss 10.733104\n",
      "Loss  0.36234856 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27368546 C_bot  0.15 k_c 0.0\n",
      "3132 Train Loss 10.633949\n",
      "Loss  0.27368546 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3385465 C_bot  0.15 k_c 0.0\n",
      "3133 Train Loss 10.689907\n",
      "Loss  0.3385465 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4308597 C_bot  0.15 k_c 0.0\n",
      "3134 Train Loss 10.784987\n",
      "Loss  0.4308597 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4422076 C_bot  0.15 k_c 0.0\n",
      "3135 Train Loss 10.780424\n",
      "Loss  0.4422076 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34308147 C_bot  0.15 k_c 0.0\n",
      "3136 Train Loss 10.684152\n",
      "Loss  0.34308147 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27362847 C_bot  0.15 k_c 0.0\n",
      "3137 Train Loss 10.604879\n",
      "Loss  0.27362847 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28837678 C_bot  0.15 k_c 0.0\n",
      "3138 Train Loss 10.613522\n",
      "Loss  0.28837678 C_bot  0.15 k_c 0.0\n",
      "Loss  0.34403807 C_bot  0.15 k_c 0.0\n",
      "3139 Train Loss 10.669401\n",
      "Loss  0.34403807 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3746474 C_bot  0.15 k_c 0.0\n",
      "3140 Train Loss 10.687567\n",
      "Loss  0.3746474 C_bot  0.15 k_c 0.0\n",
      "Loss  0.32863513 C_bot  0.15 k_c 0.0\n",
      "3141 Train Loss 10.643923\n",
      "Loss  0.32863513 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27807635 C_bot  0.15 k_c 0.0\n",
      "3142 Train Loss 10.583832\n",
      "Loss  0.27807635 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2612804 C_bot  0.15 k_c 0.0\n",
      "3143 Train Loss 10.563604\n",
      "Loss  0.2612804 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2854552 C_bot  0.15 k_c 0.0\n",
      "3144 Train Loss 10.586102\n",
      "Loss  0.2854552 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3181554 C_bot  0.15 k_c 0.0\n",
      "3145 Train Loss 10.609369\n",
      "Loss  0.3181554 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30779123 C_bot  0.15 k_c 0.0\n",
      "3146 Train Loss 10.6009245\n",
      "Loss  0.30779123 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28157786 C_bot  0.15 k_c 0.0\n",
      "3147 Train Loss 10.565519\n",
      "Loss  0.28157786 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25367156 C_bot  0.15 k_c 0.0\n",
      "3148 Train Loss 10.536241\n",
      "Loss  0.25367156 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2538114 C_bot  0.15 k_c 0.0\n",
      "3149 Train Loss 10.532545\n",
      "Loss  0.2538114 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27368167 C_bot  0.15 k_c 0.0\n",
      "3150 Train Loss 10.545713\n",
      "Loss  0.27368167 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28077927 C_bot  0.15 k_c 0.0\n",
      "3151 Train Loss 10.553137\n",
      "Loss  0.28077927 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27744058 C_bot  0.15 k_c 0.0\n",
      "3152 Train Loss 10.54138\n",
      "Loss  0.27744058 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25604615 C_bot  0.15 k_c 0.0\n",
      "3153 Train Loss 10.519545\n",
      "Loss  0.25604615 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24504642 C_bot  0.15 k_c 0.0\n",
      "3154 Train Loss 10.502997\n",
      "Loss  0.24504642 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2465304 C_bot  0.15 k_c 0.0\n",
      "3155 Train Loss 10.500365\n",
      "Loss  0.2465304 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25355574 C_bot  0.15 k_c 0.0\n",
      "3156 Train Loss 10.505744\n",
      "Loss  0.25355574 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2617041 C_bot  0.15 k_c 0.0\n",
      "3157 Train Loss 10.507169\n",
      "Loss  0.2617041 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25455144 C_bot  0.15 k_c 0.0\n",
      "3158 Train Loss 10.499631\n",
      "Loss  0.25455144 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24689254 C_bot  0.15 k_c 0.0\n",
      "3159 Train Loss 10.485822\n",
      "Loss  0.24689254 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23769985 C_bot  0.15 k_c 0.0\n",
      "3160 Train Loss 10.474526\n",
      "Loss  0.23769985 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23663425 C_bot  0.15 k_c 0.0\n",
      "3161 Train Loss 10.470013\n",
      "Loss  0.23663425 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2415891 C_bot  0.15 k_c 0.0\n",
      "3162 Train Loss 10.4703245\n",
      "Loss  0.2415891 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24294679 C_bot  0.15 k_c 0.0\n",
      "3163 Train Loss 10.470453\n",
      "Loss  0.24294679 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24419114 C_bot  0.15 k_c 0.0\n",
      "3164 Train Loss 10.465985\n",
      "Loss  0.24419114 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2373029 C_bot  0.15 k_c 0.0\n",
      "3165 Train Loss 10.457999\n",
      "Loss  0.2373029 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23316835 C_bot  0.15 k_c 0.0\n",
      "3166 Train Loss 10.449181\n",
      "Loss  0.23316835 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22978783 C_bot  0.15 k_c 0.0\n",
      "3167 Train Loss 10.443168\n",
      "Loss  0.22978783 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22971207 C_bot  0.15 k_c 0.0\n",
      "3168 Train Loss 10.440403\n",
      "Loss  0.22971207 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23255306 C_bot  0.15 k_c 0.0\n",
      "3169 Train Loss 10.438983\n",
      "Loss  0.23255306 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23157015 C_bot  0.15 k_c 0.0\n",
      "3170 Train Loss 10.436631\n",
      "Loss  0.23157015 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23162861 C_bot  0.15 k_c 0.0\n",
      "3171 Train Loss 10.431965\n",
      "Loss  0.23162861 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22711223 C_bot  0.15 k_c 0.0\n",
      "3172 Train Loss 10.425994\n",
      "Loss  0.22711223 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22490503 C_bot  0.15 k_c 0.0\n",
      "3173 Train Loss 10.419902\n",
      "Loss  0.22490503 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22274329 C_bot  0.15 k_c 0.0\n",
      "3174 Train Loss 10.415224\n",
      "Loss  0.22274329 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22211346 C_bot  0.15 k_c 0.0\n",
      "3175 Train Loss 10.412041\n",
      "Loss  0.22211346 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22316694 C_bot  0.15 k_c 0.0\n",
      "3176 Train Loss 10.409512\n",
      "Loss  0.22316694 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22208399 C_bot  0.15 k_c 0.0\n",
      "3177 Train Loss 10.406775\n",
      "Loss  0.22208399 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22225338 C_bot  0.15 k_c 0.0\n",
      "3178 Train Loss 10.402986\n",
      "Loss  0.22225338 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21947339 C_bot  0.15 k_c 0.0\n",
      "3179 Train Loss 10.398618\n",
      "Loss  0.21947339 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21828794 C_bot  0.15 k_c 0.0\n",
      "3180 Train Loss 10.393889\n",
      "Loss  0.21828794 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21617346 C_bot  0.15 k_c 0.0\n",
      "3181 Train Loss 10.389618\n",
      "Loss  0.21617346 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2152615 C_bot  0.15 k_c 0.0\n",
      "3182 Train Loss 10.385992\n",
      "Loss  0.2152615 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2149888 C_bot  0.15 k_c 0.0\n",
      "3183 Train Loss 10.382843\n",
      "Loss  0.2149888 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21409701 C_bot  0.15 k_c 0.0\n",
      "3184 Train Loss 10.379977\n",
      "Loss  0.21409701 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21434912 C_bot  0.15 k_c 0.0\n",
      "3185 Train Loss 10.376915\n",
      "Loss  0.21434912 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2127342 C_bot  0.15 k_c 0.0\n",
      "3186 Train Loss 10.373651\n",
      "Loss  0.2127342 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21230742 C_bot  0.15 k_c 0.0\n",
      "3187 Train Loss 10.369932\n",
      "Loss  0.21230742 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21033658 C_bot  0.15 k_c 0.0\n",
      "3188 Train Loss 10.3661785\n",
      "Loss  0.21033658 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20950304 C_bot  0.15 k_c 0.0\n",
      "3189 Train Loss 10.362463\n",
      "Loss  0.20950304 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20826918 C_bot  0.15 k_c 0.0\n",
      "3190 Train Loss 10.359041\n",
      "Loss  0.20826918 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20740503 C_bot  0.15 k_c 0.0\n",
      "3191 Train Loss 10.355837\n",
      "Loss  0.20740503 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20699498 C_bot  0.15 k_c 0.0\n",
      "3192 Train Loss 10.352831\n",
      "Loss  0.20699498 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20602033 C_bot  0.15 k_c 0.0\n",
      "3193 Train Loss 10.349951\n",
      "Loss  0.20602033 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20581639 C_bot  0.15 k_c 0.0\n",
      "3194 Train Loss 10.346922\n",
      "Loss  0.20581639 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20450686 C_bot  0.15 k_c 0.0\n",
      "3195 Train Loss 10.343906\n",
      "Loss  0.20450686 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20412526 C_bot  0.15 k_c 0.0\n",
      "3196 Train Loss 10.3407135\n",
      "Loss  0.20412526 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2027079 C_bot  0.15 k_c 0.0\n",
      "3197 Train Loss 10.337559\n",
      "Loss  0.2027079 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20208184 C_bot  0.15 k_c 0.0\n",
      "3198 Train Loss 10.334327\n",
      "Loss  0.20208184 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20090061 C_bot  0.15 k_c 0.0\n",
      "3199 Train Loss 10.33123\n",
      "Loss  0.20090061 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20017172 C_bot  0.15 k_c 0.0\n",
      "3200 Train Loss 10.328183\n",
      "Loss  0.20017172 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19934945 C_bot  0.15 k_c 0.0\n",
      "3201 Train Loss 10.325229\n",
      "Loss  0.19934945 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19853586 C_bot  0.15 k_c 0.0\n",
      "3202 Train Loss 10.322376\n",
      "Loss  0.19853586 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19800363 C_bot  0.15 k_c 0.0\n",
      "3203 Train Loss 10.319538\n",
      "Loss  0.19800363 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19705339 C_bot  0.15 k_c 0.0\n",
      "3204 Train Loss 10.316756\n",
      "Loss  0.19705339 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19661662 C_bot  0.15 k_c 0.0\n",
      "3205 Train Loss 10.313923\n",
      "Loss  0.19661662 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1955731 C_bot  0.15 k_c 0.0\n",
      "3206 Train Loss 10.311161\n",
      "Loss  0.1955731 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19515419 C_bot  0.15 k_c 0.0\n",
      "3207 Train Loss 10.308344\n",
      "Loss  0.19515419 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19408557 C_bot  0.15 k_c 0.0\n",
      "3208 Train Loss 10.305588\n",
      "Loss  0.19408557 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19359316 C_bot  0.15 k_c 0.0\n",
      "3209 Train Loss 10.302765\n",
      "Loss  0.19359316 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19254948 C_bot  0.15 k_c 0.0\n",
      "3210 Train Loss 10.300008\n",
      "Loss  0.19254948 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19202653 C_bot  0.15 k_c 0.0\n",
      "3211 Train Loss 10.29726\n",
      "Loss  0.19202653 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19106306 C_bot  0.15 k_c 0.0\n",
      "3212 Train Loss 10.294535\n",
      "Loss  0.19106306 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19047216 C_bot  0.15 k_c 0.0\n",
      "3213 Train Loss 10.291837\n",
      "Loss  0.19047216 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18965377 C_bot  0.15 k_c 0.0\n",
      "3214 Train Loss 10.2892\n",
      "Loss  0.18965377 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18897556 C_bot  0.15 k_c 0.0\n",
      "3215 Train Loss 10.286531\n",
      "Loss  0.18897556 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18824762 C_bot  0.15 k_c 0.0\n",
      "3216 Train Loss 10.283938\n",
      "Loss  0.18824762 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18753439 C_bot  0.15 k_c 0.0\n",
      "3217 Train Loss 10.281334\n",
      "Loss  0.18753439 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1869143 C_bot  0.15 k_c 0.0\n",
      "3218 Train Loss 10.278818\n",
      "Loss  0.1869143 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18614973 C_bot  0.15 k_c 0.0\n",
      "3219 Train Loss 10.276247\n",
      "Loss  0.18614973 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18551597 C_bot  0.15 k_c 0.0\n",
      "3220 Train Loss 10.273697\n",
      "Loss  0.18551597 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1847739 C_bot  0.15 k_c 0.0\n",
      "3221 Train Loss 10.271219\n",
      "Loss  0.1847739 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1841861 C_bot  0.15 k_c 0.0\n",
      "3222 Train Loss 10.268706\n",
      "Loss  0.1841861 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18341231 C_bot  0.15 k_c 0.0\n",
      "3223 Train Loss 10.266256\n",
      "Loss  0.18341231 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18289642 C_bot  0.15 k_c 0.0\n",
      "3224 Train Loss 10.263811\n",
      "Loss  0.18289642 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18210584 C_bot  0.15 k_c 0.0\n",
      "3225 Train Loss 10.261405\n",
      "Loss  0.18210584 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18161729 C_bot  0.15 k_c 0.0\n",
      "3226 Train Loss 10.258974\n",
      "Loss  0.18161729 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1807827 C_bot  0.15 k_c 0.0\n",
      "3227 Train Loss 10.256595\n",
      "Loss  0.1807827 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18034197 C_bot  0.15 k_c 0.0\n",
      "3228 Train Loss 10.254186\n",
      "Loss  0.18034197 C_bot  0.15 k_c 0.0\n",
      "Loss  0.179508 C_bot  0.15 k_c 0.0\n",
      "3229 Train Loss 10.251891\n",
      "Loss  0.179508 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17917372 C_bot  0.15 k_c 0.0\n",
      "3230 Train Loss 10.249537\n",
      "Loss  0.17917372 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17832723 C_bot  0.15 k_c 0.0\n",
      "3231 Train Loss 10.247345\n",
      "Loss  0.17832723 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17818221 C_bot  0.15 k_c 0.0\n",
      "3232 Train Loss 10.245094\n",
      "Loss  0.17818221 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17725457 C_bot  0.15 k_c 0.0\n",
      "3233 Train Loss 10.242981\n",
      "Loss  0.17725457 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17747103 C_bot  0.15 k_c 0.0\n",
      "3234 Train Loss 10.24094\n",
      "Loss  0.17747103 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17658019 C_bot  0.15 k_c 0.0\n",
      "3235 Train Loss 10.239102\n",
      "Loss  0.17658019 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17740256 C_bot  0.15 k_c 0.0\n",
      "3236 Train Loss 10.237417\n",
      "Loss  0.17740256 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17683586 C_bot  0.15 k_c 0.0\n",
      "3237 Train Loss 10.236274\n",
      "Loss  0.17683586 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1790326 C_bot  0.15 k_c 0.0\n",
      "3238 Train Loss 10.235542\n",
      "Loss  0.1790326 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17955478 C_bot  0.15 k_c 0.0\n",
      "3239 Train Loss 10.236084\n",
      "Loss  0.17955478 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18511972 C_bot  0.15 k_c 0.0\n",
      "3240 Train Loss 10.238006\n",
      "Loss  0.18511972 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18927681 C_bot  0.15 k_c 0.0\n",
      "3241 Train Loss 10.243172\n",
      "Loss  0.18927681 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20365968 C_bot  0.15 k_c 0.0\n",
      "3242 Train Loss 10.252689\n",
      "Loss  0.20365968 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21969664 C_bot  0.15 k_c 0.0\n",
      "3243 Train Loss 10.271437\n",
      "Loss  0.21969664 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25926545 C_bot  0.15 k_c 0.0\n",
      "3244 Train Loss 10.30401\n",
      "Loss  0.25926545 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31380317 C_bot  0.15 k_c 0.0\n",
      "3245 Train Loss 10.364273\n",
      "Loss  0.31380317 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42983583 C_bot  0.15 k_c 0.0\n",
      "3246 Train Loss 10.469567\n",
      "Loss  0.42983583 C_bot  0.15 k_c 0.0\n",
      "Loss  0.61235315 C_bot  0.15 k_c 0.0\n",
      "3247 Train Loss 10.663319\n",
      "Loss  0.61235315 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9739471 C_bot  0.15 k_c 0.0\n",
      "3248 Train Loss 11.007557\n",
      "Loss  0.9739471 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5947258 C_bot  0.15 k_c 0.0\n",
      "3249 Train Loss 11.650064\n",
      "Loss  1.5947258 C_bot  0.15 k_c 0.0\n",
      "Loss  2.781075 C_bot  0.15 k_c 0.0\n",
      "3250 Train Loss 12.807406\n",
      "Loss  2.781075 C_bot  0.15 k_c 0.0\n",
      "Loss  4.945811 C_bot  0.15 k_c 0.0\n",
      "3251 Train Loss 15.014989\n",
      "Loss  4.945811 C_bot  0.15 k_c 0.0\n",
      "Loss  8.978461 C_bot  0.15 k_c 0.0\n",
      "3252 Train Loss 18.99862\n",
      "Loss  8.978461 C_bot  0.15 k_c 0.0\n",
      "Loss  16.660517 C_bot  0.15 k_c 0.0\n",
      "3253 Train Loss 26.769608\n",
      "Loss  16.660517 C_bot  0.15 k_c 0.0\n",
      "Loss  30.346615 C_bot  0.15 k_c 0.0\n",
      "3254 Train Loss 40.373657\n",
      "Loss  30.346615 C_bot  0.15 k_c 0.0\n",
      "Loss  56.807602 C_bot  0.15 k_c 0.0\n",
      "3255 Train Loss 67.03508\n",
      "Loss  56.807602 C_bot  0.15 k_c 0.0\n",
      "Loss  98.21838 C_bot  0.15 k_c 0.0\n",
      "3256 Train Loss 108.30427\n",
      "Loss  98.21838 C_bot  0.15 k_c 0.0\n",
      "Loss  172.01239 C_bot  0.15 k_c 0.0\n",
      "3257 Train Loss 182.57927\n",
      "Loss  172.01239 C_bot  0.15 k_c 0.0\n",
      "Loss  245.60706 C_bot  0.15 k_c 0.0\n",
      "3258 Train Loss 255.84496\n",
      "Loss  245.60706 C_bot  0.15 k_c 0.0\n",
      "Loss  321.94702 C_bot  0.15 k_c 0.0\n",
      "3259 Train Loss 333.14764\n",
      "Loss  321.94702 C_bot  0.15 k_c 0.0\n",
      "Loss  279.71796 C_bot  0.15 k_c 0.0\n",
      "3260 Train Loss 290.06717\n",
      "Loss  279.71796 C_bot  0.15 k_c 0.0\n",
      "Loss  157.79074 C_bot  0.15 k_c 0.0\n",
      "3261 Train Loss 169.1022\n",
      "Loss  157.79074 C_bot  0.15 k_c 0.0\n",
      "Loss  30.121256 C_bot  0.15 k_c 0.0\n",
      "3262 Train Loss 40.810246\n",
      "Loss  30.121256 C_bot  0.15 k_c 0.0\n",
      "Loss  10.949918 C_bot  0.15 k_c 0.0\n",
      "3263 Train Loss 21.886894\n",
      "Loss  10.949918 C_bot  0.15 k_c 0.0\n",
      "Loss  88.86245 C_bot  0.15 k_c 0.0\n",
      "3264 Train Loss 100.64892\n",
      "Loss  88.86245 C_bot  0.15 k_c 0.0\n",
      "Loss  154.36879 C_bot  0.15 k_c 0.0\n",
      "3265 Train Loss 165.41542\n",
      "Loss  154.36879 C_bot  0.15 k_c 0.0\n",
      "Loss  143.76643 C_bot  0.15 k_c 0.0\n",
      "3266 Train Loss 155.82336\n",
      "Loss  143.76643 C_bot  0.15 k_c 0.0\n",
      "Loss  60.95554 C_bot  0.15 k_c 0.0\n",
      "3267 Train Loss 72.13645\n",
      "Loss  60.95554 C_bot  0.15 k_c 0.0\n",
      "Loss  4.0375185 C_bot  0.15 k_c 0.0\n",
      "3268 Train Loss 15.38658\n",
      "Loss  4.0375185 C_bot  0.15 k_c 0.0\n",
      "Loss  17.995398 C_bot  0.15 k_c 0.0\n",
      "3269 Train Loss 29.374237\n",
      "Loss  17.995398 C_bot  0.15 k_c 0.0\n",
      "Loss  66.27262 C_bot  0.15 k_c 0.0\n",
      "3270 Train Loss 77.51324\n",
      "Loss  66.27262 C_bot  0.15 k_c 0.0\n",
      "Loss  85.27931 C_bot  0.15 k_c 0.0\n",
      "3271 Train Loss 96.725105\n",
      "Loss  85.27931 C_bot  0.15 k_c 0.0\n",
      "Loss  48.63024 C_bot  0.15 k_c 0.0\n",
      "3272 Train Loss 59.809216\n",
      "Loss  48.63024 C_bot  0.15 k_c 0.0\n",
      "Loss  7.753138 C_bot  0.15 k_c 0.0\n",
      "3273 Train Loss 18.891644\n",
      "Loss  7.753138 C_bot  0.15 k_c 0.0\n",
      "Loss  5.443751 C_bot  0.15 k_c 0.0\n",
      "3274 Train Loss 16.514347\n",
      "Loss  5.443751 C_bot  0.15 k_c 0.0\n",
      "Loss  33.299503 C_bot  0.15 k_c 0.0\n",
      "3275 Train Loss 44.26492\n",
      "Loss  33.299503 C_bot  0.15 k_c 0.0\n",
      "Loss  49.44612 C_bot  0.15 k_c 0.0\n",
      "3276 Train Loss 60.55328\n",
      "Loss  49.44612 C_bot  0.15 k_c 0.0\n",
      "Loss  31.535595 C_bot  0.15 k_c 0.0\n",
      "3277 Train Loss 42.357338\n",
      "Loss  31.535595 C_bot  0.15 k_c 0.0\n",
      "Loss  6.2066245 C_bot  0.15 k_c 0.0\n",
      "3278 Train Loss 17.084984\n",
      "Loss  6.2066245 C_bot  0.15 k_c 0.0\n",
      "Loss  2.866193 C_bot  0.15 k_c 0.0\n",
      "3279 Train Loss 13.695036\n",
      "Loss  2.866193 C_bot  0.15 k_c 0.0\n",
      "Loss  19.010124 C_bot  0.15 k_c 0.0\n",
      "3280 Train Loss 29.71156\n",
      "Loss  19.010124 C_bot  0.15 k_c 0.0\n",
      "Loss  28.26346 C_bot  0.15 k_c 0.0\n",
      "3281 Train Loss 39.20135\n",
      "Loss  28.26346 C_bot  0.15 k_c 0.0\n",
      "Loss  17.558928 C_bot  0.15 k_c 0.0\n",
      "3282 Train Loss 28.226955\n",
      "Loss  17.558928 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7778726 C_bot  0.15 k_c 0.0\n",
      "3283 Train Loss 13.554451\n",
      "Loss  2.7778726 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1398678 C_bot  0.15 k_c 0.0\n",
      "3284 Train Loss 12.896345\n",
      "Loss  2.1398678 C_bot  0.15 k_c 0.0\n",
      "Loss  12.234839 C_bot  0.15 k_c 0.0\n",
      "3285 Train Loss 22.882484\n",
      "Loss  12.234839 C_bot  0.15 k_c 0.0\n",
      "Loss  16.25484 C_bot  0.15 k_c 0.0\n",
      "3286 Train Loss 27.066925\n",
      "Loss  16.25484 C_bot  0.15 k_c 0.0\n",
      "Loss  8.7573395 C_bot  0.15 k_c 0.0\n",
      "3287 Train Loss 19.402243\n",
      "Loss  8.7573395 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9520818 C_bot  0.15 k_c 0.0\n",
      "3288 Train Loss 11.642308\n",
      "Loss  0.9520818 C_bot  0.15 k_c 0.0\n",
      "Loss  2.453768 C_bot  0.15 k_c 0.0\n",
      "3289 Train Loss 13.142763\n",
      "Loss  2.453768 C_bot  0.15 k_c 0.0\n",
      "Loss  8.608365 C_bot  0.15 k_c 0.0\n",
      "3290 Train Loss 19.23722\n",
      "Loss  8.608365 C_bot  0.15 k_c 0.0\n",
      "Loss  9.51983 C_bot  0.15 k_c 0.0\n",
      "3291 Train Loss 20.203089\n",
      "Loss  9.51983 C_bot  0.15 k_c 0.0\n",
      "Loss  4.228902 C_bot  0.15 k_c 0.0\n",
      "3292 Train Loss 14.830675\n",
      "Loss  4.228902 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40210965 C_bot  0.15 k_c 0.0\n",
      "3293 Train Loss 10.995058\n",
      "Loss  0.40210965 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2942564 C_bot  0.15 k_c 0.0\n",
      "3294 Train Loss 12.874825\n",
      "Loss  2.2942564 C_bot  0.15 k_c 0.0\n",
      "Loss  5.767928 C_bot  0.15 k_c 0.0\n",
      "3295 Train Loss 16.28714\n",
      "Loss  5.767928 C_bot  0.15 k_c 0.0\n",
      "Loss  5.4088645 C_bot  0.15 k_c 0.0\n",
      "3296 Train Loss 15.952479\n",
      "Loss  5.4088645 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0371964 C_bot  0.15 k_c 0.0\n",
      "3297 Train Loss 12.504211\n",
      "Loss  2.0371964 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2612998 C_bot  0.15 k_c 0.0\n",
      "3298 Train Loss 10.720815\n",
      "Loss  0.2612998 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7877991 C_bot  0.15 k_c 0.0\n",
      "3299 Train Loss 12.251448\n",
      "Loss  1.7877991 C_bot  0.15 k_c 0.0\n",
      "Loss  3.7535791 C_bot  0.15 k_c 0.0\n",
      "3300 Train Loss 14.153823\n",
      "Loss  3.7535791 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2209342 C_bot  0.15 k_c 0.0\n",
      "3301 Train Loss 13.666569\n",
      "Loss  3.2209342 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2041332 C_bot  0.15 k_c 0.0\n",
      "3302 Train Loss 11.588639\n",
      "Loss  1.2041332 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2844589 C_bot  0.15 k_c 0.0\n",
      "3303 Train Loss 10.671012\n",
      "Loss  0.2844589 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2505137 C_bot  0.15 k_c 0.0\n",
      "3304 Train Loss 11.645553\n",
      "Loss  1.2505137 C_bot  0.15 k_c 0.0\n",
      "Loss  2.3974354 C_bot  0.15 k_c 0.0\n",
      "3305 Train Loss 12.746183\n",
      "Loss  2.3974354 C_bot  0.15 k_c 0.0\n",
      "Loss  2.0596542 C_bot  0.15 k_c 0.0\n",
      "3306 Train Loss 12.439732\n",
      "Loss  2.0596542 C_bot  0.15 k_c 0.0\n",
      "Loss  0.85515034 C_bot  0.15 k_c 0.0\n",
      "3307 Train Loss 11.194057\n",
      "Loss  0.85515034 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23936059 C_bot  0.15 k_c 0.0\n",
      "3308 Train Loss 10.578781\n",
      "Loss  0.23936059 C_bot  0.15 k_c 0.0\n",
      "Loss  0.74246347 C_bot  0.15 k_c 0.0\n",
      "3309 Train Loss 11.083281\n",
      "Loss  0.74246347 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4538603 C_bot  0.15 k_c 0.0\n",
      "3310 Train Loss 11.767515\n",
      "Loss  1.4538603 C_bot  0.15 k_c 0.0\n",
      "Loss  1.3553098 C_bot  0.15 k_c 0.0\n",
      "3311 Train Loss 11.684994\n",
      "Loss  1.3553098 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6689517 C_bot  0.15 k_c 0.0\n",
      "3312 Train Loss 10.97193\n",
      "Loss  0.6689517 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20719033 C_bot  0.15 k_c 0.0\n",
      "3313 Train Loss 10.510258\n",
      "Loss  0.20719033 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41153702 C_bot  0.15 k_c 0.0\n",
      "3314 Train Loss 10.711983\n",
      "Loss  0.41153702 C_bot  0.15 k_c 0.0\n",
      "Loss  0.86626804 C_bot  0.15 k_c 0.0\n",
      "3315 Train Loss 11.146704\n",
      "Loss  0.86626804 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9213488 C_bot  0.15 k_c 0.0\n",
      "3316 Train Loss 11.213875\n",
      "Loss  0.9213488 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5761884 C_bot  0.15 k_c 0.0\n",
      "3317 Train Loss 10.844135\n",
      "Loss  0.5761884 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22356234 C_bot  0.15 k_c 0.0\n",
      "3318 Train Loss 10.494123\n",
      "Loss  0.22356234 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23853274 C_bot  0.15 k_c 0.0\n",
      "3319 Train Loss 10.503077\n",
      "Loss  0.23853274 C_bot  0.15 k_c 0.0\n",
      "Loss  0.50193375 C_bot  0.15 k_c 0.0\n",
      "3320 Train Loss 10.749783\n",
      "Loss  0.50193375 C_bot  0.15 k_c 0.0\n",
      "Loss  0.62312514 C_bot  0.15 k_c 0.0\n",
      "3321 Train Loss 10.880802\n",
      "Loss  0.62312514 C_bot  0.15 k_c 0.0\n",
      "Loss  0.50233775 C_bot  0.15 k_c 0.0\n",
      "3322 Train Loss 10.736485\n",
      "Loss  0.50233775 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25639063 C_bot  0.15 k_c 0.0\n",
      "3323 Train Loss 10.494824\n",
      "Loss  0.25639063 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17017566 C_bot  0.15 k_c 0.0\n",
      "3324 Train Loss 10.398268\n",
      "Loss  0.17017566 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27632758 C_bot  0.15 k_c 0.0\n",
      "3325 Train Loss 10.493511\n",
      "Loss  0.27632758 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40062407 C_bot  0.15 k_c 0.0\n",
      "3326 Train Loss 10.621859\n",
      "Loss  0.40062407 C_bot  0.15 k_c 0.0\n",
      "Loss  0.41842622 C_bot  0.15 k_c 0.0\n",
      "3327 Train Loss 10.621674\n",
      "Loss  0.41842622 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29240906 C_bot  0.15 k_c 0.0\n",
      "3328 Train Loss 10.500038\n",
      "Loss  0.29240906 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18407874 C_bot  0.15 k_c 0.0\n",
      "3329 Train Loss 10.380229\n",
      "Loss  0.18407874 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1717288 C_bot  0.15 k_c 0.0\n",
      "3330 Train Loss 10.363286\n",
      "Loss  0.1717288 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23904337 C_bot  0.15 k_c 0.0\n",
      "3331 Train Loss 10.430181\n",
      "Loss  0.23904337 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30698973 C_bot  0.15 k_c 0.0\n",
      "3332 Train Loss 10.48616\n",
      "Loss  0.30698973 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2863759 C_bot  0.15 k_c 0.0\n",
      "3333 Train Loss 10.469419\n",
      "Loss  0.2863759 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22315426 C_bot  0.15 k_c 0.0\n",
      "3334 Train Loss 10.39491\n",
      "Loss  0.22315426 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15967917 C_bot  0.15 k_c 0.0\n",
      "3335 Train Loss 10.33122\n",
      "Loss  0.15967917 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15415443 C_bot  0.15 k_c 0.0\n",
      "3336 Train Loss 10.321511\n",
      "Loss  0.15415443 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19360012 C_bot  0.15 k_c 0.0\n",
      "3337 Train Loss 10.353894\n",
      "Loss  0.19360012 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22135684 C_bot  0.15 k_c 0.0\n",
      "3338 Train Loss 10.383692\n",
      "Loss  0.22135684 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22410856 C_bot  0.15 k_c 0.0\n",
      "3339 Train Loss 10.376159\n",
      "Loss  0.22410856 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18392901 C_bot  0.15 k_c 0.0\n",
      "3340 Train Loss 10.338219\n",
      "Loss  0.18392901 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15171674 C_bot  0.15 k_c 0.0\n",
      "3341 Train Loss 10.298646\n",
      "Loss  0.15171674 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1394859 C_bot  0.15 k_c 0.0\n",
      "3342 Train Loss 10.283867\n",
      "Loss  0.1394859 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15180801 C_bot  0.15 k_c 0.0\n",
      "3343 Train Loss 10.294453\n",
      "Loss  0.15180801 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17553294 C_bot  0.15 k_c 0.0\n",
      "3344 Train Loss 10.310867\n",
      "Loss  0.17553294 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17773022 C_bot  0.15 k_c 0.0\n",
      "3345 Train Loss 10.31439\n",
      "Loss  0.17773022 C_bot  0.15 k_c 0.0\n",
      "Loss  0.17020299 C_bot  0.15 k_c 0.0\n",
      "3346 Train Loss 10.2986355\n",
      "Loss  0.17020299 C_bot  0.15 k_c 0.0\n",
      "Loss  0.14657724 C_bot  0.15 k_c 0.0\n",
      "3347 Train Loss 10.275103\n",
      "Loss  0.14657724 C_bot  0.15 k_c 0.0\n",
      "Loss  0.13405524 C_bot  0.15 k_c 0.0\n",
      "3348 Train Loss 10.257215\n",
      "Loss  0.13405524 C_bot  0.15 k_c 0.0\n",
      "Loss  0.13295552 C_bot  0.15 k_c 0.0\n",
      "3349 Train Loss 10.252736\n",
      "Loss  0.13295552 C_bot  0.15 k_c 0.0\n",
      "Loss  0.14005212 C_bot  0.15 k_c 0.0\n",
      "3350 Train Loss 10.258157\n",
      "Loss  0.14005212 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15165026 C_bot  0.15 k_c 0.0\n",
      "3351 Train Loss 10.263614\n",
      "Loss  0.15165026 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15022354 C_bot  0.15 k_c 0.0\n",
      "3352 Train Loss 10.262329\n",
      "Loss  0.15022354 C_bot  0.15 k_c 0.0\n",
      "Loss  0.14674838 C_bot  0.15 k_c 0.0\n",
      "3353 Train Loss 10.252401\n",
      "Loss  0.14674838 C_bot  0.15 k_c 0.0\n",
      "Loss  0.13435926 C_bot  0.15 k_c 0.0\n",
      "3354 Train Loss 10.23944\n",
      "Loss  0.13435926 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1281828 C_bot  0.15 k_c 0.0\n",
      "3355 Train Loss 10.228735\n",
      "Loss  0.1281828 C_bot  0.15 k_c 0.0\n",
      "Loss  0.12607808 C_bot  0.15 k_c 0.0\n",
      "3356 Train Loss 10.223921\n",
      "Loss  0.12607808 C_bot  0.15 k_c 0.0\n",
      "Loss  0.12818111 C_bot  0.15 k_c 0.0\n",
      "3357 Train Loss 10.224066\n",
      "Loss  0.12818111 C_bot  0.15 k_c 0.0\n",
      "Loss  0.13411084 C_bot  0.15 k_c 0.0\n",
      "3358 Train Loss 10.225375\n",
      "Loss  0.13411084 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1340147 C_bot  0.15 k_c 0.0\n",
      "3359 Train Loss 10.224882\n",
      "Loss  0.1340147 C_bot  0.15 k_c 0.0\n",
      "Loss  0.13475122 C_bot  0.15 k_c 0.0\n",
      "3360 Train Loss 10.220455\n",
      "Loss  0.13475122 C_bot  0.15 k_c 0.0\n",
      "Loss  0.12840675 C_bot  0.15 k_c 0.0\n",
      "3361 Train Loss 10.213662\n",
      "Loss  0.12840675 C_bot  0.15 k_c 0.0\n",
      "Loss  0.12509006 C_bot  0.15 k_c 0.0\n",
      "3362 Train Loss 10.206102\n",
      "Loss  0.12509006 C_bot  0.15 k_c 0.0\n",
      "Loss  0.12086056 C_bot  0.15 k_c 0.0\n",
      "3363 Train Loss 10.200224\n",
      "Loss  0.12086056 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11989563 C_bot  0.15 k_c 0.0\n",
      "3364 Train Loss 10.196645\n",
      "Loss  0.11989563 C_bot  0.15 k_c 0.0\n",
      "Loss  0.12130833 C_bot  0.15 k_c 0.0\n",
      "3365 Train Loss 10.195002\n",
      "Loss  0.12130833 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1216849 C_bot  0.15 k_c 0.0\n",
      "3366 Train Loss 10.1941185\n",
      "Loss  0.1216849 C_bot  0.15 k_c 0.0\n",
      "Loss  0.12395256 C_bot  0.15 k_c 0.0\n",
      "3367 Train Loss 10.192476\n",
      "Loss  0.12395256 C_bot  0.15 k_c 0.0\n",
      "Loss  0.122028925 C_bot  0.15 k_c 0.0\n",
      "3368 Train Loss 10.189844\n",
      "Loss  0.122028925 C_bot  0.15 k_c 0.0\n",
      "Loss  0.12191161 C_bot  0.15 k_c 0.0\n",
      "3369 Train Loss 10.185796\n",
      "Loss  0.12191161 C_bot  0.15 k_c 0.0\n",
      "Loss  0.118451186 C_bot  0.15 k_c 0.0\n",
      "3370 Train Loss 10.1813755\n",
      "Loss  0.118451186 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11724227 C_bot  0.15 k_c 0.0\n",
      "3371 Train Loss 10.176883\n",
      "Loss  0.11724227 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11518706 C_bot  0.15 k_c 0.0\n",
      "3372 Train Loss 10.173139\n",
      "Loss  0.11518706 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11457931 C_bot  0.15 k_c 0.0\n",
      "3373 Train Loss 10.170161\n",
      "Loss  0.11457931 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11474808 C_bot  0.15 k_c 0.0\n",
      "3374 Train Loss 10.167836\n",
      "Loss  0.11474808 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11441237 C_bot  0.15 k_c 0.0\n",
      "3375 Train Loss 10.165934\n",
      "Loss  0.11441237 C_bot  0.15 k_c 0.0\n",
      "Loss  0.115476735 C_bot  0.15 k_c 0.0\n",
      "3376 Train Loss 10.163951\n",
      "Loss  0.115476735 C_bot  0.15 k_c 0.0\n",
      "Loss  0.114484094 C_bot  0.15 k_c 0.0\n",
      "3377 Train Loss 10.161854\n",
      "Loss  0.114484094 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11507567 C_bot  0.15 k_c 0.0\n",
      "3378 Train Loss 10.159239\n",
      "Loss  0.11507567 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11335269 C_bot  0.15 k_c 0.0\n",
      "3379 Train Loss 10.15649\n",
      "Loss  0.11335269 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11325201 C_bot  0.15 k_c 0.0\n",
      "3380 Train Loss 10.153385\n",
      "Loss  0.11325201 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1115421 C_bot  0.15 k_c 0.0\n",
      "3381 Train Loss 10.150429\n",
      "Loss  0.1115421 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11114037 C_bot  0.15 k_c 0.0\n",
      "3382 Train Loss 10.147446\n",
      "Loss  0.11114037 C_bot  0.15 k_c 0.0\n",
      "Loss  0.110095724 C_bot  0.15 k_c 0.0\n",
      "3383 Train Loss 10.144787\n",
      "Loss  0.110095724 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10969964 C_bot  0.15 k_c 0.0\n",
      "3384 Train Loss 10.142298\n",
      "Loss  0.10969964 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10936364 C_bot  0.15 k_c 0.0\n",
      "3385 Train Loss 10.139983\n",
      "Loss  0.10936364 C_bot  0.15 k_c 0.0\n",
      "Loss  0.108896315 C_bot  0.15 k_c 0.0\n",
      "3386 Train Loss 10.137851\n",
      "Loss  0.108896315 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10903631 C_bot  0.15 k_c 0.0\n",
      "3387 Train Loss 10.13574\n",
      "Loss  0.10903631 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10834308 C_bot  0.15 k_c 0.0\n",
      "3388 Train Loss 10.133691\n",
      "Loss  0.10834308 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10865802 C_bot  0.15 k_c 0.0\n",
      "3389 Train Loss 10.131596\n",
      "Loss  0.10865802 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10776757 C_bot  0.15 k_c 0.0\n",
      "3390 Train Loss 10.129531\n",
      "Loss  0.10776757 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10808259 C_bot  0.15 k_c 0.0\n",
      "3391 Train Loss 10.127379\n",
      "Loss  0.10808259 C_bot  0.15 k_c 0.0\n",
      "Loss  0.107065946 C_bot  0.15 k_c 0.0\n",
      "3392 Train Loss 10.125273\n",
      "Loss  0.107065946 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10729676 C_bot  0.15 k_c 0.0\n",
      "3393 Train Loss 10.123061\n",
      "Loss  0.10729676 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10626156 C_bot  0.15 k_c 0.0\n",
      "3394 Train Loss 10.120951\n",
      "Loss  0.10626156 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10639402 C_bot  0.15 k_c 0.0\n",
      "3395 Train Loss 10.118713\n",
      "Loss  0.10639402 C_bot  0.15 k_c 0.0\n",
      "Loss  0.105381936 C_bot  0.15 k_c 0.0\n",
      "3396 Train Loss 10.116605\n",
      "Loss  0.105381936 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1055287 C_bot  0.15 k_c 0.0\n",
      "3397 Train Loss 10.114467\n",
      "Loss  0.1055287 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10460669 C_bot  0.15 k_c 0.0\n",
      "3398 Train Loss 10.112415\n",
      "Loss  0.10460669 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10470422 C_bot  0.15 k_c 0.0\n",
      "3399 Train Loss 10.110307\n",
      "Loss  0.10470422 C_bot  0.15 k_c 0.0\n",
      "Loss  0.103847615 C_bot  0.15 k_c 0.0\n",
      "3400 Train Loss 10.108303\n",
      "Loss  0.103847615 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1039889 C_bot  0.15 k_c 0.0\n",
      "3401 Train Loss 10.106299\n",
      "Loss  0.1039889 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10319255 C_bot  0.15 k_c 0.0\n",
      "3402 Train Loss 10.104366\n",
      "Loss  0.10319255 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10335413 C_bot  0.15 k_c 0.0\n",
      "3403 Train Loss 10.102413\n",
      "Loss  0.10335413 C_bot  0.15 k_c 0.0\n",
      "Loss  0.102612525 C_bot  0.15 k_c 0.0\n",
      "3404 Train Loss 10.100575\n",
      "Loss  0.102612525 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10284025 C_bot  0.15 k_c 0.0\n",
      "3405 Train Loss 10.098681\n",
      "Loss  0.10284025 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10210675 C_bot  0.15 k_c 0.0\n",
      "3406 Train Loss 10.096935\n",
      "Loss  0.10210675 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10252818 C_bot  0.15 k_c 0.0\n",
      "3407 Train Loss 10.095178\n",
      "Loss  0.10252818 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10181216 C_bot  0.15 k_c 0.0\n",
      "3408 Train Loss 10.093591\n",
      "Loss  0.10181216 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10252476 C_bot  0.15 k_c 0.0\n",
      "3409 Train Loss 10.092001\n",
      "Loss  0.10252476 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10186679 C_bot  0.15 k_c 0.0\n",
      "3410 Train Loss 10.090694\n",
      "Loss  0.10186679 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10315065 C_bot  0.15 k_c 0.0\n",
      "3411 Train Loss 10.089455\n",
      "Loss  0.10315065 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10274371 C_bot  0.15 k_c 0.0\n",
      "3412 Train Loss 10.088738\n",
      "Loss  0.10274371 C_bot  0.15 k_c 0.0\n",
      "Loss  0.105198875 C_bot  0.15 k_c 0.0\n",
      "3413 Train Loss 10.088295\n",
      "Loss  0.105198875 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10563179 C_bot  0.15 k_c 0.0\n",
      "3414 Train Loss 10.088953\n",
      "Loss  0.10563179 C_bot  0.15 k_c 0.0\n",
      "Loss  0.110741235 C_bot  0.15 k_c 0.0\n",
      "3415 Train Loss 10.090539\n",
      "Loss  0.110741235 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11361223 C_bot  0.15 k_c 0.0\n",
      "3416 Train Loss 10.094495\n",
      "Loss  0.11361223 C_bot  0.15 k_c 0.0\n",
      "Loss  0.124889344 C_bot  0.15 k_c 0.0\n",
      "3417 Train Loss 10.10122\n",
      "Loss  0.124889344 C_bot  0.15 k_c 0.0\n",
      "Loss  0.13503762 C_bot  0.15 k_c 0.0\n",
      "3418 Train Loss 10.113849\n",
      "Loss  0.13503762 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16189565 C_bot  0.15 k_c 0.0\n",
      "3419 Train Loss 10.134449\n",
      "Loss  0.16189565 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19357933 C_bot  0.15 k_c 0.0\n",
      "3420 Train Loss 10.170951\n",
      "Loss  0.19357933 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26296604 C_bot  0.15 k_c 0.0\n",
      "3421 Train Loss 10.231203\n",
      "Loss  0.26296604 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35973758 C_bot  0.15 k_c 0.0\n",
      "3422 Train Loss 10.336834\n",
      "Loss  0.35973758 C_bot  0.15 k_c 0.0\n",
      "Loss  0.55158794 C_bot  0.15 k_c 0.0\n",
      "3423 Train Loss 10.514659\n",
      "Loss  0.55158794 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8510479 C_bot  0.15 k_c 0.0\n",
      "3424 Train Loss 10.830194\n",
      "Loss  0.8510479 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4153785 C_bot  0.15 k_c 0.0\n",
      "3425 Train Loss 11.37211\n",
      "Loss  1.4153785 C_bot  0.15 k_c 0.0\n",
      "Loss  2.36611 C_bot  0.15 k_c 0.0\n",
      "3426 Train Loss 12.352376\n",
      "Loss  2.36611 C_bot  0.15 k_c 0.0\n",
      "Loss  4.10697 C_bot  0.15 k_c 0.0\n",
      "3427 Train Loss 14.056479\n",
      "Loss  4.10697 C_bot  0.15 k_c 0.0\n",
      "Loss  7.2045736 C_bot  0.15 k_c 0.0\n",
      "3428 Train Loss 17.21021\n",
      "Loss  7.2045736 C_bot  0.15 k_c 0.0\n",
      "Loss  12.730502 C_bot  0.15 k_c 0.0\n",
      "3429 Train Loss 22.675266\n",
      "Loss  12.730502 C_bot  0.15 k_c 0.0\n",
      "Loss  22.926376 C_bot  0.15 k_c 0.0\n",
      "3430 Train Loss 32.98428\n",
      "Loss  22.926376 C_bot  0.15 k_c 0.0\n",
      "Loss  40.152847 C_bot  0.15 k_c 0.0\n",
      "3431 Train Loss 50.109447\n",
      "Loss  40.152847 C_bot  0.15 k_c 0.0\n",
      "Loss  71.92579 C_bot  0.15 k_c 0.0\n",
      "3432 Train Loss 82.129585\n",
      "Loss  71.92579 C_bot  0.15 k_c 0.0\n",
      "Loss  117.70664 C_bot  0.15 k_c 0.0\n",
      "3433 Train Loss 127.72785\n",
      "Loss  117.70664 C_bot  0.15 k_c 0.0\n",
      "Loss  192.33112 C_bot  0.15 k_c 0.0\n",
      "3434 Train Loss 202.91225\n",
      "Loss  192.33112 C_bot  0.15 k_c 0.0\n",
      "Loss  253.87523 C_bot  0.15 k_c 0.0\n",
      "3435 Train Loss 264.02655\n",
      "Loss  253.87523 C_bot  0.15 k_c 0.0\n",
      "Loss  299.10886 C_bot  0.15 k_c 0.0\n",
      "3436 Train Loss 310.26288\n",
      "Loss  299.10886 C_bot  0.15 k_c 0.0\n",
      "Loss  234.18417 C_bot  0.15 k_c 0.0\n",
      "3437 Train Loss 244.435\n",
      "Loss  234.18417 C_bot  0.15 k_c 0.0\n",
      "Loss  114.34116 C_bot  0.15 k_c 0.0\n",
      "3438 Train Loss 125.47346\n",
      "Loss  114.34116 C_bot  0.15 k_c 0.0\n",
      "Loss  15.526953 C_bot  0.15 k_c 0.0\n",
      "3439 Train Loss 26.1644\n",
      "Loss  15.526953 C_bot  0.15 k_c 0.0\n",
      "Loss  15.581783 C_bot  0.15 k_c 0.0\n",
      "3440 Train Loss 26.354753\n",
      "Loss  15.581783 C_bot  0.15 k_c 0.0\n",
      "Loss  87.51179 C_bot  0.15 k_c 0.0\n",
      "3441 Train Loss 99.03111\n",
      "Loss  87.51179 C_bot  0.15 k_c 0.0\n",
      "Loss  138.78574 C_bot  0.15 k_c 0.0\n",
      "3442 Train Loss 149.63045\n",
      "Loss  138.78574 C_bot  0.15 k_c 0.0\n",
      "Loss  125.9869 C_bot  0.15 k_c 0.0\n",
      "3443 Train Loss 137.61652\n",
      "Loss  125.9869 C_bot  0.15 k_c 0.0\n",
      "Loss  54.50881 C_bot  0.15 k_c 0.0\n",
      "3444 Train Loss 65.408676\n",
      "Loss  54.50881 C_bot  0.15 k_c 0.0\n",
      "Loss  4.2322793 C_bot  0.15 k_c 0.0\n",
      "3445 Train Loss 15.247437\n",
      "Loss  4.2322793 C_bot  0.15 k_c 0.0\n",
      "Loss  12.875248 C_bot  0.15 k_c 0.0\n",
      "3446 Train Loss 23.891285\n",
      "Loss  12.875248 C_bot  0.15 k_c 0.0\n",
      "Loss  54.052708 C_bot  0.15 k_c 0.0\n",
      "3447 Train Loss 64.97716\n",
      "Loss  54.052708 C_bot  0.15 k_c 0.0\n",
      "Loss  75.259476 C_bot  0.15 k_c 0.0\n",
      "3448 Train Loss 86.35591\n",
      "Loss  75.259476 C_bot  0.15 k_c 0.0\n",
      "Loss  49.18299 C_bot  0.15 k_c 0.0\n",
      "3449 Train Loss 60.057983\n",
      "Loss  49.18299 C_bot  0.15 k_c 0.0\n",
      "Loss  11.9983425 C_bot  0.15 k_c 0.0\n",
      "3450 Train Loss 22.848824\n",
      "Loss  11.9983425 C_bot  0.15 k_c 0.0\n",
      "Loss  1.8608232 C_bot  0.15 k_c 0.0\n",
      "3451 Train Loss 12.624599\n",
      "Loss  1.8608232 C_bot  0.15 k_c 0.0\n",
      "Loss  22.032478 C_bot  0.15 k_c 0.0\n",
      "3452 Train Loss 32.714897\n",
      "Loss  22.032478 C_bot  0.15 k_c 0.0\n",
      "Loss  41.326954 C_bot  0.15 k_c 0.0\n",
      "3453 Train Loss 52.17006\n",
      "Loss  41.326954 C_bot  0.15 k_c 0.0\n",
      "Loss  33.870365 C_bot  0.15 k_c 0.0\n",
      "3454 Train Loss 44.452297\n",
      "Loss  33.870365 C_bot  0.15 k_c 0.0\n",
      "Loss  11.688588 C_bot  0.15 k_c 0.0\n",
      "3455 Train Loss 22.400599\n",
      "Loss  11.688588 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6473193 C_bot  0.15 k_c 0.0\n",
      "3456 Train Loss 11.251162\n",
      "Loss  0.6473193 C_bot  0.15 k_c 0.0\n",
      "Loss  9.7225685 C_bot  0.15 k_c 0.0\n",
      "3457 Train Loss 20.254002\n",
      "Loss  9.7225685 C_bot  0.15 k_c 0.0\n",
      "Loss  22.266623 C_bot  0.15 k_c 0.0\n",
      "3458 Train Loss 33.01976\n",
      "Loss  22.266623 C_bot  0.15 k_c 0.0\n",
      "Loss  20.55147 C_bot  0.15 k_c 0.0\n",
      "3459 Train Loss 31.054634\n",
      "Loss  20.55147 C_bot  0.15 k_c 0.0\n",
      "Loss  7.859595 C_bot  0.15 k_c 0.0\n",
      "3460 Train Loss 18.51838\n",
      "Loss  7.859595 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4147993 C_bot  0.15 k_c 0.0\n",
      "3461 Train Loss 10.981094\n",
      "Loss  0.4147993 C_bot  0.15 k_c 0.0\n",
      "Loss  5.2151527 C_bot  0.15 k_c 0.0\n",
      "3462 Train Loss 15.7404375\n",
      "Loss  5.2151527 C_bot  0.15 k_c 0.0\n",
      "Loss  12.849461 C_bot  0.15 k_c 0.0\n",
      "3463 Train Loss 23.483368\n",
      "Loss  12.849461 C_bot  0.15 k_c 0.0\n",
      "Loss  12.199951 C_bot  0.15 k_c 0.0\n",
      "3464 Train Loss 22.70451\n",
      "Loss  12.199951 C_bot  0.15 k_c 0.0\n",
      "Loss  4.8098154 C_bot  0.15 k_c 0.0\n",
      "3465 Train Loss 15.369234\n",
      "Loss  4.8098154 C_bot  0.15 k_c 0.0\n",
      "Loss  0.43050277 C_bot  0.15 k_c 0.0\n",
      "3466 Train Loss 10.9354725\n",
      "Loss  0.43050277 C_bot  0.15 k_c 0.0\n",
      "Loss  3.2884867 C_bot  0.15 k_c 0.0\n",
      "3467 Train Loss 13.761539\n",
      "Loss  3.2884867 C_bot  0.15 k_c 0.0\n",
      "Loss  7.790846 C_bot  0.15 k_c 0.0\n",
      "3468 Train Loss 18.296703\n",
      "Loss  7.790846 C_bot  0.15 k_c 0.0\n",
      "Loss  7.4144483 C_bot  0.15 k_c 0.0\n",
      "3469 Train Loss 17.83675\n",
      "Loss  7.4144483 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0238082 C_bot  0.15 k_c 0.0\n",
      "3470 Train Loss 13.458264\n",
      "Loss  3.0238082 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3637412 C_bot  0.15 k_c 0.0\n",
      "3471 Train Loss 10.749735\n",
      "Loss  0.3637412 C_bot  0.15 k_c 0.0\n",
      "Loss  1.967837 C_bot  0.15 k_c 0.0\n",
      "3472 Train Loss 12.320728\n",
      "Loss  1.967837 C_bot  0.15 k_c 0.0\n",
      "Loss  4.6701293 C_bot  0.15 k_c 0.0\n",
      "3473 Train Loss 15.053729\n",
      "Loss  4.6701293 C_bot  0.15 k_c 0.0\n",
      "Loss  4.6941934 C_bot  0.15 k_c 0.0\n",
      "3474 Train Loss 15.00326\n",
      "Loss  4.6941934 C_bot  0.15 k_c 0.0\n",
      "Loss  2.1634305 C_bot  0.15 k_c 0.0\n",
      "3475 Train Loss 12.507964\n",
      "Loss  2.1634305 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39745572 C_bot  0.15 k_c 0.0\n",
      "3476 Train Loss 10.702831\n",
      "Loss  0.39745572 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0884228 C_bot  0.15 k_c 0.0\n",
      "3477 Train Loss 11.375183\n",
      "Loss  1.0884228 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7280998 C_bot  0.15 k_c 0.0\n",
      "3478 Train Loss 13.050314\n",
      "Loss  2.7280998 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0998213 C_bot  0.15 k_c 0.0\n",
      "3479 Train Loss 13.359798\n",
      "Loss  3.0998213 C_bot  0.15 k_c 0.0\n",
      "Loss  1.7592459 C_bot  0.15 k_c 0.0\n",
      "3480 Train Loss 12.055332\n",
      "Loss  1.7592459 C_bot  0.15 k_c 0.0\n",
      "Loss  0.48681876 C_bot  0.15 k_c 0.0\n",
      "3481 Train Loss 10.746501\n",
      "Loss  0.48681876 C_bot  0.15 k_c 0.0\n",
      "Loss  0.53156817 C_bot  0.15 k_c 0.0\n",
      "3482 Train Loss 10.782531\n",
      "Loss  0.53156817 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4640641 C_bot  0.15 k_c 0.0\n",
      "3483 Train Loss 11.729149\n",
      "Loss  1.4640641 C_bot  0.15 k_c 0.0\n",
      "Loss  1.990023 C_bot  0.15 k_c 0.0\n",
      "3484 Train Loss 12.219515\n",
      "Loss  1.990023 C_bot  0.15 k_c 0.0\n",
      "Loss  1.4522566 C_bot  0.15 k_c 0.0\n",
      "3485 Train Loss 11.701307\n",
      "Loss  1.4522566 C_bot  0.15 k_c 0.0\n",
      "Loss  0.59512806 C_bot  0.15 k_c 0.0\n",
      "3486 Train Loss 10.818196\n",
      "Loss  0.59512806 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3009391 C_bot  0.15 k_c 0.0\n",
      "3487 Train Loss 10.521564\n",
      "Loss  0.3009391 C_bot  0.15 k_c 0.0\n",
      "Loss  0.71379405 C_bot  0.15 k_c 0.0\n",
      "3488 Train Loss 10.936659\n",
      "Loss  0.71379405 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2048717 C_bot  0.15 k_c 0.0\n",
      "3489 Train Loss 11.404904\n",
      "Loss  1.2048717 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1446582 C_bot  0.15 k_c 0.0\n",
      "3490 Train Loss 11.359376\n",
      "Loss  1.1446582 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68775326 C_bot  0.15 k_c 0.0\n",
      "3491 Train Loss 10.877502\n",
      "Loss  0.68775326 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30700302 C_bot  0.15 k_c 0.0\n",
      "3492 Train Loss 10.499611\n",
      "Loss  0.30700302 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35738122 C_bot  0.15 k_c 0.0\n",
      "3493 Train Loss 10.545554\n",
      "Loss  0.35738122 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6711132 C_bot  0.15 k_c 0.0\n",
      "3494 Train Loss 10.842317\n",
      "Loss  0.6711132 C_bot  0.15 k_c 0.0\n",
      "Loss  0.82049483 C_bot  0.15 k_c 0.0\n",
      "3495 Train Loss 11.003589\n",
      "Loss  0.82049483 C_bot  0.15 k_c 0.0\n",
      "Loss  0.69296414 C_bot  0.15 k_c 0.0\n",
      "3496 Train Loss 10.852002\n",
      "Loss  0.69296414 C_bot  0.15 k_c 0.0\n",
      "Loss  0.40300387 C_bot  0.15 k_c 0.0\n",
      "3497 Train Loss 10.568596\n",
      "Loss  0.40300387 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2680277 C_bot  0.15 k_c 0.0\n",
      "3498 Train Loss 10.422205\n",
      "Loss  0.2680277 C_bot  0.15 k_c 0.0\n",
      "Loss  0.35645255 C_bot  0.15 k_c 0.0\n",
      "3499 Train Loss 10.501432\n",
      "Loss  0.35645255 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5142246 C_bot  0.15 k_c 0.0\n",
      "3500 Train Loss 10.66346\n",
      "Loss  0.5142246 C_bot  0.15 k_c 0.0\n",
      "Loss  0.585149 C_bot  0.15 k_c 0.0\n",
      "3501 Train Loss 10.71609\n",
      "Loss  0.585149 C_bot  0.15 k_c 0.0\n",
      "Loss  0.47697437 C_bot  0.15 k_c 0.0\n",
      "3502 Train Loss 10.6145\n",
      "Loss  0.47697437 C_bot  0.15 k_c 0.0\n",
      "Loss  0.335377 C_bot  0.15 k_c 0.0\n",
      "3503 Train Loss 10.45922\n",
      "Loss  0.335377 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2622566 C_bot  0.15 k_c 0.0\n",
      "3504 Train Loss 10.384279\n",
      "Loss  0.2622566 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3041871 C_bot  0.15 k_c 0.0\n",
      "3505 Train Loss 10.423806\n",
      "Loss  0.3041871 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39733198 C_bot  0.15 k_c 0.0\n",
      "3506 Train Loss 10.5063715\n",
      "Loss  0.39733198 C_bot  0.15 k_c 0.0\n",
      "Loss  0.42833972 C_bot  0.15 k_c 0.0\n",
      "3507 Train Loss 10.541651\n",
      "Loss  0.42833972 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39396855 C_bot  0.15 k_c 0.0\n",
      "3508 Train Loss 10.494534\n",
      "Loss  0.39396855 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30749893 C_bot  0.15 k_c 0.0\n",
      "3509 Train Loss 10.410588\n",
      "Loss  0.30749893 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25701398 C_bot  0.15 k_c 0.0\n",
      "3510 Train Loss 10.35276\n",
      "Loss  0.25701398 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26160598 C_bot  0.15 k_c 0.0\n",
      "3511 Train Loss 10.353179\n",
      "Loss  0.26160598 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29955515 C_bot  0.15 k_c 0.0\n",
      "3512 Train Loss 10.391416\n",
      "Loss  0.29955515 C_bot  0.15 k_c 0.0\n",
      "Loss  0.3395889 C_bot  0.15 k_c 0.0\n",
      "3513 Train Loss 10.421572\n",
      "Loss  0.3395889 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33059484 C_bot  0.15 k_c 0.0\n",
      "3514 Train Loss 10.416128\n",
      "Loss  0.33059484 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30192715 C_bot  0.15 k_c 0.0\n",
      "3515 Train Loss 10.377361\n",
      "Loss  0.30192715 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25868493 C_bot  0.15 k_c 0.0\n",
      "3516 Train Loss 10.334894\n",
      "Loss  0.25868493 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2419364 C_bot  0.15 k_c 0.0\n",
      "3517 Train Loss 10.312786\n",
      "Loss  0.2419364 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25085938 C_bot  0.15 k_c 0.0\n",
      "3518 Train Loss 10.317139\n",
      "Loss  0.25085938 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2686693 C_bot  0.15 k_c 0.0\n",
      "3519 Train Loss 10.334694\n",
      "Loss  0.2686693 C_bot  0.15 k_c 0.0\n",
      "Loss  0.28729355 C_bot  0.15 k_c 0.0\n",
      "3520 Train Loss 10.345207\n",
      "Loss  0.28729355 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27995 C_bot  0.15 k_c 0.0\n",
      "3521 Train Loss 10.339384\n",
      "Loss  0.27995 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2669938 C_bot  0.15 k_c 0.0\n",
      "3522 Train Loss 10.318543\n",
      "Loss  0.2669938 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24427925 C_bot  0.15 k_c 0.0\n",
      "3523 Train Loss 10.295605\n",
      "Loss  0.24427925 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23398525 C_bot  0.15 k_c 0.0\n",
      "3524 Train Loss 10.28044\n",
      "Loss  0.23398525 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23427486 C_bot  0.15 k_c 0.0\n",
      "3525 Train Loss 10.277288\n",
      "Loss  0.23427486 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24064732 C_bot  0.15 k_c 0.0\n",
      "3526 Train Loss 10.282175\n",
      "Loss  0.24064732 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25142995 C_bot  0.15 k_c 0.0\n",
      "3527 Train Loss 10.287052\n",
      "Loss  0.25142995 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25085935 C_bot  0.15 k_c 0.0\n",
      "3528 Train Loss 10.286775\n",
      "Loss  0.25085935 C_bot  0.15 k_c 0.0\n",
      "Loss  0.24926955 C_bot  0.15 k_c 0.0\n",
      "3529 Train Loss 10.278813\n",
      "Loss  0.24926955 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23749593 C_bot  0.15 k_c 0.0\n",
      "3530 Train Loss 10.266985\n",
      "Loss  0.23749593 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23024657 C_bot  0.15 k_c 0.0\n",
      "3531 Train Loss 10.25479\n",
      "Loss  0.23024657 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22372212 C_bot  0.15 k_c 0.0\n",
      "3532 Train Loss 10.246469\n",
      "Loss  0.22372212 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22262694 C_bot  0.15 k_c 0.0\n",
      "3533 Train Loss 10.242661\n",
      "Loss  0.22262694 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22576205 C_bot  0.15 k_c 0.0\n",
      "3534 Train Loss 10.242076\n",
      "Loss  0.22576205 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2270595 C_bot  0.15 k_c 0.0\n",
      "3535 Train Loss 10.2424555\n",
      "Loss  0.2270595 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23054259 C_bot  0.15 k_c 0.0\n",
      "3536 Train Loss 10.2411\n",
      "Loss  0.23054259 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2272606 C_bot  0.15 k_c 0.0\n",
      "3537 Train Loss 10.237562\n",
      "Loss  0.2272606 C_bot  0.15 k_c 0.0\n",
      "Loss  0.22585873 C_bot  0.15 k_c 0.0\n",
      "3538 Train Loss 10.231344\n",
      "Loss  0.22585873 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21958952 C_bot  0.15 k_c 0.0\n",
      "3539 Train Loss 10.224385\n",
      "Loss  0.21958952 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21650733 C_bot  0.15 k_c 0.0\n",
      "3540 Train Loss 10.217395\n",
      "Loss  0.21650733 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21257181 C_bot  0.15 k_c 0.0\n",
      "3541 Train Loss 10.211728\n",
      "Loss  0.21257181 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21111645 C_bot  0.15 k_c 0.0\n",
      "3542 Train Loss 10.207601\n",
      "Loss  0.21111645 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21107337 C_bot  0.15 k_c 0.0\n",
      "3543 Train Loss 10.204721\n",
      "Loss  0.21107337 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21061885 C_bot  0.15 k_c 0.0\n",
      "3544 Train Loss 10.20266\n",
      "Loss  0.21061885 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21200481 C_bot  0.15 k_c 0.0\n",
      "3545 Train Loss 10.200437\n",
      "Loss  0.21200481 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21054305 C_bot  0.15 k_c 0.0\n",
      "3546 Train Loss 10.197987\n",
      "Loss  0.21054305 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21104793 C_bot  0.15 k_c 0.0\n",
      "3547 Train Loss 10.194593\n",
      "Loss  0.21104793 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20811807 C_bot  0.15 k_c 0.0\n",
      "3548 Train Loss 10.190817\n",
      "Loss  0.20811807 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20741421 C_bot  0.15 k_c 0.0\n",
      "3549 Train Loss 10.186377\n",
      "Loss  0.20741421 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20407331 C_bot  0.15 k_c 0.0\n",
      "3550 Train Loss 10.181956\n",
      "Loss  0.20407331 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20283046 C_bot  0.15 k_c 0.0\n",
      "3551 Train Loss 10.177434\n",
      "Loss  0.20283046 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20018962 C_bot  0.15 k_c 0.0\n",
      "3552 Train Loss 10.173281\n",
      "Loss  0.20018962 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19898091 C_bot  0.15 k_c 0.0\n",
      "3553 Train Loss 10.169364\n",
      "Loss  0.19898091 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19740845 C_bot  0.15 k_c 0.0\n",
      "3554 Train Loss 10.165804\n",
      "Loss  0.19740845 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19626121 C_bot  0.15 k_c 0.0\n",
      "3555 Train Loss 10.162496\n",
      "Loss  0.19626121 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19551255 C_bot  0.15 k_c 0.0\n",
      "3556 Train Loss 10.159358\n",
      "Loss  0.19551255 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19431774 C_bot  0.15 k_c 0.0\n",
      "3557 Train Loss 10.1564455\n",
      "Loss  0.19431774 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19405521 C_bot  0.15 k_c 0.0\n",
      "3558 Train Loss 10.153504\n",
      "Loss  0.19405521 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1925892 C_bot  0.15 k_c 0.0\n",
      "3559 Train Loss 10.150644\n",
      "Loss  0.1925892 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1925156 C_bot  0.15 k_c 0.0\n",
      "3560 Train Loss 10.147706\n",
      "Loss  0.1925156 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19085494 C_bot  0.15 k_c 0.0\n",
      "3561 Train Loss 10.144874\n",
      "Loss  0.19085494 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19082549 C_bot  0.15 k_c 0.0\n",
      "3562 Train Loss 10.14187\n",
      "Loss  0.19082549 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1890055 C_bot  0.15 k_c 0.0\n",
      "3563 Train Loss 10.139024\n",
      "Loss  0.1890055 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18901885 C_bot  0.15 k_c 0.0\n",
      "3564 Train Loss 10.135998\n",
      "Loss  0.18901885 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18716355 C_bot  0.15 k_c 0.0\n",
      "3565 Train Loss 10.13324\n",
      "Loss  0.18716355 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18731713 C_bot  0.15 k_c 0.0\n",
      "3566 Train Loss 10.130287\n",
      "Loss  0.18731713 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18546355 C_bot  0.15 k_c 0.0\n",
      "3567 Train Loss 10.127666\n",
      "Loss  0.18546355 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1859937 C_bot  0.15 k_c 0.0\n",
      "3568 Train Loss 10.124985\n",
      "Loss  0.1859937 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18430962 C_bot  0.15 k_c 0.0\n",
      "3569 Train Loss 10.122728\n",
      "Loss  0.18430962 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18543942 C_bot  0.15 k_c 0.0\n",
      "3570 Train Loss 10.12046\n",
      "Loss  0.18543942 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18410416 C_bot  0.15 k_c 0.0\n",
      "3571 Train Loss 10.118849\n",
      "Loss  0.18410416 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18637988 C_bot  0.15 k_c 0.0\n",
      "3572 Train Loss 10.117416\n",
      "Loss  0.18637988 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18591316 C_bot  0.15 k_c 0.0\n",
      "3573 Train Loss 10.11713\n",
      "Loss  0.18591316 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1905467 C_bot  0.15 k_c 0.0\n",
      "3574 Train Loss 10.11755\n",
      "Loss  0.1905467 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19230194 C_bot  0.15 k_c 0.0\n",
      "3575 Train Loss 10.120197\n",
      "Loss  0.19230194 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20202266 C_bot  0.15 k_c 0.0\n",
      "3576 Train Loss 10.124881\n",
      "Loss  0.20202266 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20953447 C_bot  0.15 k_c 0.0\n",
      "3577 Train Loss 10.134419\n",
      "Loss  0.20953447 C_bot  0.15 k_c 0.0\n",
      "Loss  0.23094693 C_bot  0.15 k_c 0.0\n",
      "3578 Train Loss 10.149457\n",
      "Loss  0.23094693 C_bot  0.15 k_c 0.0\n",
      "Loss  0.25352713 C_bot  0.15 k_c 0.0\n",
      "3579 Train Loss 10.17589\n",
      "Loss  0.25352713 C_bot  0.15 k_c 0.0\n",
      "Loss  0.30367061 C_bot  0.15 k_c 0.0\n",
      "3580 Train Loss 10.217484\n",
      "Loss  0.30367061 C_bot  0.15 k_c 0.0\n",
      "Loss  0.36739025 C_bot  0.15 k_c 0.0\n",
      "3581 Train Loss 10.288078\n",
      "Loss  0.36739025 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4923347 C_bot  0.15 k_c 0.0\n",
      "3582 Train Loss 10.400897\n",
      "Loss  0.4923347 C_bot  0.15 k_c 0.0\n",
      "Loss  0.6722582 C_bot  0.15 k_c 0.0\n",
      "3583 Train Loss 10.5928335\n",
      "Loss  0.6722582 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0035555 C_bot  0.15 k_c 0.0\n",
      "3584 Train Loss 10.906076\n",
      "Loss  1.0035555 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5243266 C_bot  0.15 k_c 0.0\n",
      "3585 Train Loss 11.447943\n",
      "Loss  1.5243266 C_bot  0.15 k_c 0.0\n",
      "Loss  2.4528766 C_bot  0.15 k_c 0.0\n",
      "3586 Train Loss 12.348581\n",
      "Loss  2.4528766 C_bot  0.15 k_c 0.0\n",
      "Loss  4.0101686 C_bot  0.15 k_c 0.0\n",
      "3587 Train Loss 13.943814\n",
      "Loss  4.0101686 C_bot  0.15 k_c 0.0\n",
      "Loss  6.7252636 C_bot  0.15 k_c 0.0\n",
      "3588 Train Loss 16.614723\n",
      "Loss  6.7252636 C_bot  0.15 k_c 0.0\n",
      "Loss  11.490694 C_bot  0.15 k_c 0.0\n",
      "3589 Train Loss 21.451485\n",
      "Loss  11.490694 C_bot  0.15 k_c 0.0\n",
      "Loss  19.513025 C_bot  0.15 k_c 0.0\n",
      "3590 Train Loss 29.403046\n",
      "Loss  19.513025 C_bot  0.15 k_c 0.0\n",
      "Loss  33.885273 C_bot  0.15 k_c 0.0\n",
      "3591 Train Loss 43.918446\n",
      "Loss  33.885273 C_bot  0.15 k_c 0.0\n",
      "Loss  55.974487 C_bot  0.15 k_c 0.0\n",
      "3592 Train Loss 65.89079\n",
      "Loss  55.974487 C_bot  0.15 k_c 0.0\n",
      "Loss  93.77664 C_bot  0.15 k_c 0.0\n",
      "3593 Train Loss 103.99872\n",
      "Loss  93.77664 C_bot  0.15 k_c 0.0\n",
      "Loss  137.90544 C_bot  0.15 k_c 0.0\n",
      "3594 Train Loss 147.9013\n",
      "Loss  137.90544 C_bot  0.15 k_c 0.0\n",
      "Loss  194.87914 C_bot  0.15 k_c 0.0\n",
      "3595 Train Loss 205.48984\n",
      "Loss  194.87914 C_bot  0.15 k_c 0.0\n",
      "Loss  210.95378 C_bot  0.15 k_c 0.0\n",
      "3596 Train Loss 221.04152\n",
      "Loss  210.95378 C_bot  0.15 k_c 0.0\n",
      "Loss  186.16537 C_bot  0.15 k_c 0.0\n",
      "3597 Train Loss 197.08041\n",
      "Loss  186.16537 C_bot  0.15 k_c 0.0\n",
      "Loss  101.036736 C_bot  0.15 k_c 0.0\n",
      "3598 Train Loss 111.23002\n",
      "Loss  101.036736 C_bot  0.15 k_c 0.0\n",
      "Loss  22.82264 C_bot  0.15 k_c 0.0\n",
      "3599 Train Loss 33.51912\n",
      "Loss  22.82264 C_bot  0.15 k_c 0.0\n",
      "Loss  2.7651973 C_bot  0.15 k_c 0.0\n",
      "3600 Train Loss 13.432314\n",
      "Loss  2.7651973 C_bot  0.15 k_c 0.0\n",
      "Loss  40.47279 C_bot  0.15 k_c 0.0\n",
      "3601 Train Loss 51.013817\n",
      "Loss  40.47279 C_bot  0.15 k_c 0.0\n",
      "Loss  90.23752 C_bot  0.15 k_c 0.0\n",
      "3602 Train Loss 101.46412\n",
      "Loss  90.23752 C_bot  0.15 k_c 0.0\n",
      "Loss  100.91694 C_bot  0.15 k_c 0.0\n",
      "3603 Train Loss 111.56639\n",
      "Loss  100.91694 C_bot  0.15 k_c 0.0\n",
      "Loss  72.2792 C_bot  0.15 k_c 0.0\n",
      "3604 Train Loss 83.36786\n",
      "Loss  72.2792 C_bot  0.15 k_c 0.0\n",
      "Loss  24.708464 C_bot  0.15 k_c 0.0\n",
      "3605 Train Loss 35.414135\n",
      "Loss  24.708464 C_bot  0.15 k_c 0.0\n",
      "Loss  0.83581215 C_bot  0.15 k_c 0.0\n",
      "3606 Train Loss 11.58392\n",
      "Loss  0.83581215 C_bot  0.15 k_c 0.0\n",
      "Loss  12.456572 C_bot  0.15 k_c 0.0\n",
      "3607 Train Loss 23.23437\n",
      "Loss  12.456572 C_bot  0.15 k_c 0.0\n",
      "Loss  39.156242 C_bot  0.15 k_c 0.0\n",
      "3608 Train Loss 49.86006\n",
      "Loss  39.156242 C_bot  0.15 k_c 0.0\n",
      "Loss  52.90801 C_bot  0.15 k_c 0.0\n",
      "3609 Train Loss 63.72483\n",
      "Loss  52.90801 C_bot  0.15 k_c 0.0\n",
      "Loss  38.90802 C_bot  0.15 k_c 0.0\n",
      "3610 Train Loss 49.5264\n",
      "Loss  38.90802 C_bot  0.15 k_c 0.0\n",
      "Loss  14.54859 C_bot  0.15 k_c 0.0\n",
      "3611 Train Loss 25.192461\n",
      "Loss  14.54859 C_bot  0.15 k_c 0.0\n",
      "Loss  0.93045574 C_bot  0.15 k_c 0.0\n",
      "3612 Train Loss 11.457366\n",
      "Loss  0.93045574 C_bot  0.15 k_c 0.0\n",
      "Loss  6.9740615 C_bot  0.15 k_c 0.0\n",
      "3613 Train Loss 17.445244\n",
      "Loss  6.9740615 C_bot  0.15 k_c 0.0\n",
      "Loss  21.50908 C_bot  0.15 k_c 0.0\n",
      "3614 Train Loss 32.118023\n",
      "Loss  21.50908 C_bot  0.15 k_c 0.0\n",
      "Loss  27.323706 C_bot  0.15 k_c 0.0\n",
      "3615 Train Loss 37.717934\n",
      "Loss  27.323706 C_bot  0.15 k_c 0.0\n",
      "Loss  19.39641 C_bot  0.15 k_c 0.0\n",
      "3616 Train Loss 29.981752\n",
      "Loss  19.39641 C_bot  0.15 k_c 0.0\n",
      "Loss  6.182951 C_bot  0.15 k_c 0.0\n",
      "3617 Train Loss 16.572422\n",
      "Loss  6.182951 C_bot  0.15 k_c 0.0\n",
      "Loss  0.33492178 C_bot  0.15 k_c 0.0\n",
      "3618 Train Loss 10.761589\n",
      "Loss  0.33492178 C_bot  0.15 k_c 0.0\n",
      "Loss  5.0752134 C_bot  0.15 k_c 0.0\n",
      "3619 Train Loss 15.550846\n",
      "Loss  5.0752134 C_bot  0.15 k_c 0.0\n",
      "Loss  12.691062 C_bot  0.15 k_c 0.0\n",
      "3620 Train Loss 23.044083\n",
      "Loss  12.691062 C_bot  0.15 k_c 0.0\n",
      "Loss  14.048511 C_bot  0.15 k_c 0.0\n",
      "3621 Train Loss 24.539202\n",
      "Loss  14.048511 C_bot  0.15 k_c 0.0\n",
      "Loss  8.116398 C_bot  0.15 k_c 0.0\n",
      "3622 Train Loss 18.468807\n",
      "Loss  8.116398 C_bot  0.15 k_c 0.0\n",
      "Loss  1.6115491 C_bot  0.15 k_c 0.0\n",
      "3623 Train Loss 12.008034\n",
      "Loss  1.6115491 C_bot  0.15 k_c 0.0\n",
      "Loss  0.68733174 C_bot  0.15 k_c 0.0\n",
      "3624 Train Loss 11.064486\n",
      "Loss  0.68733174 C_bot  0.15 k_c 0.0\n",
      "Loss  4.649399 C_bot  0.15 k_c 0.0\n",
      "3625 Train Loss 14.991696\n",
      "Loss  4.649399 C_bot  0.15 k_c 0.0\n",
      "Loss  8.013161 C_bot  0.15 k_c 0.0\n",
      "3626 Train Loss 18.399082\n",
      "Loss  8.013161 C_bot  0.15 k_c 0.0\n",
      "Loss  7.0015135 C_bot  0.15 k_c 0.0\n",
      "3627 Train Loss 17.315304\n",
      "Loss  7.0015135 C_bot  0.15 k_c 0.0\n",
      "Loss  3.0775645 C_bot  0.15 k_c 0.0\n",
      "3628 Train Loss 13.405132\n",
      "Loss  3.0775645 C_bot  0.15 k_c 0.0\n",
      "Loss  0.39917603 C_bot  0.15 k_c 0.0\n",
      "3629 Train Loss 10.679884\n",
      "Loss  0.39917603 C_bot  0.15 k_c 0.0\n",
      "Loss  1.0852228 C_bot  0.15 k_c 0.0\n",
      "3630 Train Loss 11.338999\n",
      "Loss  1.0852228 C_bot  0.15 k_c 0.0\n",
      "Loss  3.4983575 C_bot  0.15 k_c 0.0\n",
      "3631 Train Loss 13.768968\n",
      "Loss  3.4983575 C_bot  0.15 k_c 0.0\n",
      "Loss  4.695114 C_bot  0.15 k_c 0.0\n",
      "3632 Train Loss 14.899246\n",
      "Loss  4.695114 C_bot  0.15 k_c 0.0\n",
      "Loss  3.428773 C_bot  0.15 k_c 0.0\n",
      "3633 Train Loss 13.670281\n",
      "Loss  3.428773 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2631922 C_bot  0.15 k_c 0.0\n",
      "3634 Train Loss 11.447203\n",
      "Loss  1.2631922 C_bot  0.15 k_c 0.0\n",
      "Loss  0.21534137 C_bot  0.15 k_c 0.0\n",
      "3635 Train Loss 10.402809\n",
      "Loss  0.21534137 C_bot  0.15 k_c 0.0\n",
      "Loss  0.9332561 C_bot  0.15 k_c 0.0\n",
      "3636 Train Loss 11.1250305\n",
      "Loss  0.9332561 C_bot  0.15 k_c 0.0\n",
      "Loss  2.2761562 C_bot  0.15 k_c 0.0\n",
      "3637 Train Loss 12.427363\n",
      "Loss  2.2761562 C_bot  0.15 k_c 0.0\n",
      "Loss  2.6763809 C_bot  0.15 k_c 0.0\n",
      "3638 Train Loss 12.864268\n",
      "Loss  2.6763809 C_bot  0.15 k_c 0.0\n",
      "Loss  1.9029806 C_bot  0.15 k_c 0.0\n",
      "3639 Train Loss 12.040707\n",
      "Loss  1.9029806 C_bot  0.15 k_c 0.0\n",
      "Loss  0.7059388 C_bot  0.15 k_c 0.0\n",
      "3640 Train Loss 10.861155\n",
      "Loss  0.7059388 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19091602 C_bot  0.15 k_c 0.0\n",
      "3641 Train Loss 10.328116\n",
      "Loss  0.19091602 C_bot  0.15 k_c 0.0\n",
      "Loss  0.5735627 C_bot  0.15 k_c 0.0\n",
      "3642 Train Loss 10.697526\n",
      "Loss  0.5735627 C_bot  0.15 k_c 0.0\n",
      "Loss  1.2538699 C_bot  0.15 k_c 0.0\n",
      "3643 Train Loss 11.390129\n",
      "Loss  1.2538699 C_bot  0.15 k_c 0.0\n",
      "Loss  1.5465596 C_bot  0.15 k_c 0.0\n",
      "3644 Train Loss 11.6544\n",
      "Loss  1.5465596 C_bot  0.15 k_c 0.0\n",
      "Loss  1.1678833 C_bot  0.15 k_c 0.0\n",
      "3645 Train Loss 11.289967\n",
      "Loss  1.1678833 C_bot  0.15 k_c 0.0\n",
      "Loss  0.546545 C_bot  0.15 k_c 0.0\n",
      "3646 Train Loss 10.645839\n",
      "Loss  0.546545 C_bot  0.15 k_c 0.0\n",
      "Loss  0.16743784 C_bot  0.15 k_c 0.0\n",
      "3647 Train Loss 10.2673235\n",
      "Loss  0.16743784 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26451555 C_bot  0.15 k_c 0.0\n",
      "3648 Train Loss 10.361082\n",
      "Loss  0.26451555 C_bot  0.15 k_c 0.0\n",
      "Loss  0.63106513 C_bot  0.15 k_c 0.0\n",
      "3649 Train Loss 10.71184\n",
      "Loss  0.63106513 C_bot  0.15 k_c 0.0\n",
      "Loss  0.8574837 C_bot  0.15 k_c 0.0\n",
      "3650 Train Loss 10.950325\n",
      "Loss  0.8574837 C_bot  0.15 k_c 0.0\n",
      "Loss  0.79497623 C_bot  0.15 k_c 0.0\n",
      "3651 Train Loss 10.863527\n",
      "Loss  0.79497623 C_bot  0.15 k_c 0.0\n",
      "Loss  0.4771628 C_bot  0.15 k_c 0.0\n",
      "3652 Train Loss 10.556552\n",
      "Loss  0.4771628 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20877506 C_bot  0.15 k_c 0.0\n",
      "3653 Train Loss 10.271963\n",
      "Loss  0.20877506 C_bot  0.15 k_c 0.0\n",
      "Loss  0.13768095 C_bot  0.15 k_c 0.0\n",
      "3654 Train Loss 10.197718\n",
      "Loss  0.13768095 C_bot  0.15 k_c 0.0\n",
      "Loss  0.26295528 C_bot  0.15 k_c 0.0\n",
      "3655 Train Loss 10.323252\n",
      "Loss  0.26295528 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44998443 C_bot  0.15 k_c 0.0\n",
      "3656 Train Loss 10.493498\n",
      "Loss  0.44998443 C_bot  0.15 k_c 0.0\n",
      "Loss  0.50782734 C_bot  0.15 k_c 0.0\n",
      "3657 Train Loss 10.560264\n",
      "Loss  0.50782734 C_bot  0.15 k_c 0.0\n",
      "Loss  0.44119522 C_bot  0.15 k_c 0.0\n",
      "3658 Train Loss 10.474142\n",
      "Loss  0.44119522 C_bot  0.15 k_c 0.0\n",
      "Loss  0.2740645 C_bot  0.15 k_c 0.0\n",
      "3659 Train Loss 10.312441\n",
      "Loss  0.2740645 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15400228 C_bot  0.15 k_c 0.0\n",
      "3660 Train Loss 10.18076\n",
      "Loss  0.15400228 C_bot  0.15 k_c 0.0\n",
      "Loss  0.12514536 C_bot  0.15 k_c 0.0\n",
      "3661 Train Loss 10.148304\n",
      "Loss  0.12514536 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1823661 C_bot  0.15 k_c 0.0\n",
      "3662 Train Loss 10.20429\n",
      "Loss  0.1823661 C_bot  0.15 k_c 0.0\n",
      "Loss  0.27360156 C_bot  0.15 k_c 0.0\n",
      "3663 Train Loss 10.284388\n",
      "Loss  0.27360156 C_bot  0.15 k_c 0.0\n",
      "Loss  0.31144312 C_bot  0.15 k_c 0.0\n",
      "3664 Train Loss 10.326834\n",
      "Loss  0.31144312 C_bot  0.15 k_c 0.0\n",
      "Loss  0.29981282 C_bot  0.15 k_c 0.0\n",
      "3665 Train Loss 10.301893\n",
      "Loss  0.29981282 C_bot  0.15 k_c 0.0\n",
      "Loss  0.226144 C_bot  0.15 k_c 0.0\n",
      "3666 Train Loss 10.232244\n",
      "Loss  0.226144 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15984501 C_bot  0.15 k_c 0.0\n",
      "3667 Train Loss 10.156134\n",
      "Loss  0.15984501 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1163462 C_bot  0.15 k_c 0.0\n",
      "3668 Train Loss 10.111725\n",
      "Loss  0.1163462 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11779029 C_bot  0.15 k_c 0.0\n",
      "3669 Train Loss 10.109713\n",
      "Loss  0.11779029 C_bot  0.15 k_c 0.0\n",
      "Loss  0.15189387 C_bot  0.15 k_c 0.0\n",
      "3670 Train Loss 10.13713\n",
      "Loss  0.15189387 C_bot  0.15 k_c 0.0\n",
      "Loss  0.18264973 C_bot  0.15 k_c 0.0\n",
      "3671 Train Loss 10.169822\n",
      "Loss  0.18264973 C_bot  0.15 k_c 0.0\n",
      "Loss  0.20727424 C_bot  0.15 k_c 0.0\n",
      "3672 Train Loss 10.184305\n",
      "Loss  0.20727424 C_bot  0.15 k_c 0.0\n",
      "Loss  0.19425897 C_bot  0.15 k_c 0.0\n",
      "3673 Train Loss 10.174916\n",
      "Loss  0.19425897 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1741386 C_bot  0.15 k_c 0.0\n",
      "3674 Train Loss 10.144986\n",
      "Loss  0.1741386 C_bot  0.15 k_c 0.0\n",
      "Loss  0.13786055 C_bot  0.15 k_c 0.0\n",
      "3675 Train Loss 10.110285\n",
      "Loss  0.13786055 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11652262 C_bot  0.15 k_c 0.0\n",
      "3676 Train Loss 10.082388\n",
      "Loss  0.11652262 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10600877 C_bot  0.15 k_c 0.0\n",
      "3677 Train Loss 10.069685\n",
      "Loss  0.10600877 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11015543 C_bot  0.15 k_c 0.0\n",
      "3678 Train Loss 10.071285\n",
      "Loss  0.11015543 C_bot  0.15 k_c 0.0\n",
      "Loss  0.12538257 C_bot  0.15 k_c 0.0\n",
      "3679 Train Loss 10.080951\n",
      "Loss  0.12538257 C_bot  0.15 k_c 0.0\n",
      "Loss  0.13588496 C_bot  0.15 k_c 0.0\n",
      "3680 Train Loss 10.091787\n",
      "Loss  0.13588496 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1480695 C_bot  0.15 k_c 0.0\n",
      "3681 Train Loss 10.096593\n",
      "Loss  0.1480695 C_bot  0.15 k_c 0.0\n",
      "Loss  0.14430615 C_bot  0.15 k_c 0.0\n",
      "3682 Train Loss 10.09418\n",
      "Loss  0.14430615 C_bot  0.15 k_c 0.0\n",
      "Loss  0.14138396 C_bot  0.15 k_c 0.0\n",
      "3683 Train Loss 10.083847\n",
      "Loss  0.14138396 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1269779 C_bot  0.15 k_c 0.0\n",
      "3684 Train Loss 10.070217\n",
      "Loss  0.1269779 C_bot  0.15 k_c 0.0\n",
      "Loss  0.1183709 C_bot  0.15 k_c 0.0\n",
      "3685 Train Loss 10.055589\n",
      "Loss  0.1183709 C_bot  0.15 k_c 0.0\n",
      "Loss  0.107436195 C_bot  0.15 k_c 0.0\n",
      "3686 Train Loss 10.043903\n",
      "Loss  0.107436195 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10347768 C_bot  0.15 k_c 0.0\n",
      "3687 Train Loss 10.03601\n",
      "Loss  0.10347768 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10233753 C_bot  0.15 k_c 0.0\n",
      "3688 Train Loss 10.032306\n",
      "Loss  0.10233753 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10379577 C_bot  0.15 k_c 0.0\n",
      "3689 Train Loss 10.03184\n",
      "Loss  0.10379577 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10899331 C_bot  0.15 k_c 0.0\n",
      "3690 Train Loss 10.032916\n",
      "Loss  0.10899331 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11114356 C_bot  0.15 k_c 0.0\n",
      "3691 Train Loss 10.034598\n",
      "Loss  0.11114356 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11676127 C_bot  0.15 k_c 0.0\n",
      "3692 Train Loss 10.035138\n",
      "Loss  0.11676127 C_bot  0.15 k_c 0.0\n",
      "Loss  0.116105594 C_bot  0.15 k_c 0.0\n",
      "3693 Train Loss 10.034801\n",
      "Loss  0.116105594 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11911423 C_bot  0.15 k_c 0.0\n",
      "3694 Train Loss 10.032433\n",
      "Loss  0.11911423 C_bot  0.15 k_c 0.0\n",
      "Loss  0.115455955 C_bot  0.15 k_c 0.0\n",
      "3695 Train Loss 10.029271\n",
      "Loss  0.115455955 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11603224 C_bot  0.15 k_c 0.0\n",
      "3696 Train Loss 10.024658\n",
      "Loss  0.11603224 C_bot  0.15 k_c 0.0\n",
      "Loss  0.11113559 C_bot  0.15 k_c 0.0\n",
      "3697 Train Loss 10.020015\n",
      "Loss  0.11113559 C_bot  0.15 k_c 0.0\n",
      "Loss  0.110569715 C_bot  0.15 k_c 0.0\n",
      "3698 Train Loss 10.014714\n",
      "Loss  0.110569715 C_bot  0.15 k_c 0.0\n",
      "Loss  0.105952166 C_bot  0.15 k_c 0.0\n",
      "3699 Train Loss 10.009925\n",
      "Loss  0.105952166 C_bot  0.15 k_c 0.0\n",
      "Loss  0.10523904 C_bot  0.15 k_c 0.0\n",
      "3700 Train Loss 10.005048\n",
      "Loss  0.10523904 C_bot  0.15 k_c 0.0\n",
      "Loss  0.101660825 C_bot  0.15 k_c 0.0\n",
      "3701 Train Loss 10.000845\n",
      "Loss  0.101660825 C_bot  0.15 k_c 0.0\n",
      "Loss  0.101193026 C_bot  0.15 k_c 0.0\n",
      "3702 Train Loss 9.9967785\n",
      "Loss Less than 7.5...\n",
      "Training time: 898.27\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ./Models_Trained does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 69\u001b[0m\n\u001b[1;32m     65\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     66\u001b[0m train_model(max_iter,reps,n_batches)\n\u001b[0;32m---> 69\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_PINN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Models_Trained/AFSD_Exp_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOmega\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrpm_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmms.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# train_loss_full.append(train_loss)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# test_mse_full.append(test_mse_loss)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# test_re_full.append(test_re_loss)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining time: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (elapsed_time[reps]))\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ./Models_Trained does not exist."
     ]
    }
   ],
   "source": [
    "# from Seq_model import Sequentialmodel\n",
    "from Seq_Model_Parallel_600_calibration import coupled_PINN\n",
    "from training_samples_calibration import trainingdata_uvw,trainingdata_T\n",
    "\n",
    "\n",
    "folder_main = '/home/smartlab/Documents/jupyterNB/raghav/Projects_git_summer2024/PINN_AFSD/Code_Final_Sept2024/AFSD_PINN/Experimental_Comparison_Only/ExperimentalData_and_Plots/'\n",
    "# filename = 'Models_Trained_AFSD_Exp_2mms_z1mm_300rpm_2mms_8.pt'\n",
    "filename = 'AFSD_Exp_600rpm_2mms.pt'\n",
    "\n",
    "sheet_name = '600rpm_2mms'\n",
    "\n",
    "label = 'meltpool'\n",
    "max_reps = 1\n",
    "max_iter = 10000\n",
    "p_iters = 10\n",
    "\n",
    "N_B = 1000\n",
    "N_f = 10000\n",
    "n_batches = 5\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "\n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*3)\n",
    "     #Total number of collocation points\n",
    "\n",
    "\n",
    "    layers1 = np.array([3,50,50,50,4]) #9 hidden layers\n",
    "    layers2 = np.array([3,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([3,50,50,50,5])\n",
    "    # layers = np.array([3,64,64,64,1])\n",
    "    model_PINN = coupled_PINN(layers1,layers2,device1,device2,lb_xyz,ub_xyz,sheet_name)\n",
    "    # PINN = nn.DataParallel(PINN)\n",
    "    #PINN.to(device)\n",
    "\n",
    "    model_PINN.load_state_dict(torch.load(folder_main + filename),strict = False)\n",
    "    'Neural Network Summary'\n",
    "    #print(PINN)\n",
    "\n",
    "    #params = list(PINN.parameters())\n",
    "\n",
    "    # optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25,\n",
    "    #                           max_iter = 30,\n",
    "    #                           max_eval = 50,\n",
    "    #                           tolerance_grad = 1e-5,\n",
    "    #                           tolerance_change = 1e-5,\n",
    "    #                           history_size = 100,\n",
    "    #                           line_search_fn = 'strong_wolfe')\n",
    "\n",
    "    optimizer = torch.optim.Adam(model_PINN.PINN_T.parameters(),lr=0.008, betas=(0.9, 0.999))\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_model(max_iter,reps,n_batches)\n",
    "\n",
    "\n",
    "    torch.save(model_PINN.state_dict(),'./Models_Trained/AFSD_Exp_'+str(Omega)+'rpm_'+str(V)+ 'mms.pt')\n",
    "    # train_loss_full.append(train_loss)\n",
    "    # test_mse_full.append(test_mse_loss)\n",
    "    # test_re_full.append(test_re_loss)\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c8eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_PINN.state_dict(),'AFSD_Exp_calib_'+str(Omega)+'rpm_'+str(V)+ 'mms_1data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fccb21-7030-4050-ae16-7f138f7ba249",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_min,y_min,z_min] = lb_xyz\n",
    "[x_max,y_max,z_max] = ub_xyz\n",
    "\n",
    "x_min = -20.0\n",
    "x_max = 20.0\n",
    "\n",
    "x = np.linspace(x_min,x_max,200).reshape(-1,1)\n",
    "# y = np.linspace(y_min,y_max,200).reshape(-1,1)\n",
    "y = 0.0\n",
    "z = np.linspace(z_min,z_max,50).reshape(-1,1)\n",
    "# z = 0.0\n",
    "X,Y,Z = np.meshgrid(x,y,z)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "Z = Z.flatten('F').reshape(-1,1)\n",
    "\n",
    "xyz = np.hstack((X,Y,Z))\n",
    "xyz_test_tensor = torch.from_numpy(xyz).float().to(device1)\n",
    "\n",
    "uvwp = model_PINN.PINN_uvw.forward(xyz_test_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac24ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fd7203c89a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(uvwp[:,1].reshape(50,200)/1000)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d000d1-c6fb-4074-8861-823db543fa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$y$ (mm)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_vel = np.sqrt(np.square(uvwp[:,0])+np.square(uvwp[:,1])+np.square(uvwp[:,2]))\n",
    "# r_vel = np.sqrt(np.square(uvwp[:,2]))\n",
    "# r_vel = uvwp[:,2]\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow((r_vel/1000).reshape(50,200),cmap = 'jet',extent = [-20,20,-20,20],vmax = 0.15,vmin = 0)\n",
    "fig.colorbar(im)\n",
    "ax.set_title('Resultant Velocity (m/s)',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "ax.set_ylabel('$y$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "# plt.savefig('Res_vel_xy_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1f440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$z$ (mm)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cross Section\n",
    "r_vel = np.sqrt(np.square(uvwp[:,0])+np.square(uvwp[:,1])+np.square(uvwp[:,2]))\n",
    "# r_vel = np.sqrt(np.square(uvwp[:,2]))\n",
    "# r_vel = uvwp[:,2]\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow((np.flip(r_vel)/1000).reshape(50,200),cmap = 'jet',extent = [-20,20,-3,0],vmax = 0.15,vmin = 0)\n",
    "# fig.colorbar(im)\n",
    "# ax.set_title('Resultant Velocity (m/s)',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "ax.set_ylabel('$z$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "# plt.savefig('Res_vel_xz_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef87f55-d125-4c5b-a16d-544611395158",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = xyz_test_tensor.clone()\n",
    "g.requires_grad = True\n",
    "\n",
    "out_full = model_PINN.PINN_uvw.forward(g.to(device1)).cpu() \n",
    "u = out_full[:,0:1]\n",
    "v = out_full[:,1:2]\n",
    "w = out_full[:,2:3]\n",
    "p = out_full[:,3:4]\n",
    "\n",
    "\n",
    "# print(T.shape)\n",
    "T = model_PINN.PINN_T.forward(g.to(device2)).cpu()\n",
    "\n",
    "# p_xyz = autograd.grad(p,g,torch.ones([xyz_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "u_xyz = autograd.grad(u,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "v_xyz = autograd.grad(v,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "w_xyz = autograd.grad(w,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "\n",
    "eps2_11 = torch.square(1/2*(2*u_xyz[:,0]))\n",
    "eps2_12 = torch.square(1/2*(u_xyz[:,1] + v_xyz[:,0]))\n",
    "eps2_13 = torch.square(1/2*(u_xyz[:,2] + w_xyz[:,0]))\n",
    "\n",
    "eps2_21 = eps2_12\n",
    "eps2_22 = torch.square(1/2*(2*v_xyz[:,1])) \n",
    "eps2_23 = torch.square(1/2*(v_xyz[:,2] + w_xyz[:,1]))\n",
    "\n",
    "eps2_31 = eps2_13\n",
    "eps2_32 = eps2_23 \n",
    "eps2_33 = torch.square(1/2*(2*w_xyz[:,2]))\n",
    "\n",
    "eps_e = torch.sqrt((2/3)*(eps2_11 + eps2_12 + eps2_13 + eps2_21 + eps2_22 + eps2_23 + eps2_31 + eps2_32 + eps2_33)).reshape(-1,1)\n",
    "\n",
    "\n",
    "# Z = eps_e*torch.exp(E_a/(R*T))\n",
    "# log_Z = torch.log(eps_e) + E_a/(R*T)\n",
    "log_Z = torch.log(eps_e) + E_a/(R*T) #Simplification\n",
    "\n",
    "\n",
    "W = (log_Z - log_A)/n\n",
    "\n",
    "\n",
    "\n",
    "# sigma_e =  (1/alpha_sig)*torch.asinh(W) \n",
    "sigma_e = (1/alpha_sig)*(np.log(2)/n + W) #Approximation\n",
    "\n",
    "#____________________________#\n",
    "mu_vis = sigma_e/(3*eps_e)\n",
    "\n",
    "\n",
    "eps_e = eps_e.cpu().detach().numpy()\n",
    "sigma_e = sigma_e.cpu().detach().numpy()\n",
    "mu_vis = mu_vis.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0592b72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(609.2927, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfcef78-9322-40dc-9938-90498e7cc584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$y$ (mm)')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(T.cpu().detach().numpy().reshape(50,200),cmap = 'jet',extent = [-20,20,-3,0],vmax = 800,vmin = 300)\n",
    "fig.colorbar(im)\n",
    "ax.set_title('Temperature (K)',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "ax.set_ylabel('$y$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "# plt.savefig('Temp_xy_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ff22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$z$ (mm)')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(np.flip(T.cpu().detach().numpy().reshape(50,200)),cmap = 'jet',extent = [-20,20,-3,0],vmax = 800,vmin = 300)\n",
    "# fig.colorbar(im)\n",
    "# ax.set_title('Temperature (K)',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "ax.set_ylabel('$z$ (mm)',math_fontfamily = 'cm',fontsize = 14)\n",
    "# plt.savefig('Temp_xz_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb960cb-2ad1-4850-8cde-8fee710dc085",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 10000 into shape (200,200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fig,ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[0;32m----> 2\u001b[0m im \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mimshow(\u001b[43meps_e\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m,cmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjet\u001b[39m\u001b[38;5;124m'\u001b[39m,extent \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m],vmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m175\u001b[39m,vmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m fig\u001b[38;5;241m.\u001b[39mcolorbar(im)\n\u001b[1;32m      4\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEffective Strain Rate ($s^\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m-1}$)\u001b[39m\u001b[38;5;124m'\u001b[39m,math_fontfamily \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcm\u001b[39m\u001b[38;5;124m'\u001b[39m,fontsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m18\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10000 into shape (200,200)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(eps_e.reshape(200,200),cmap = 'jet',extent = [-20,20,-20,20],vmax = 175,vmin = 0)\n",
    "fig.colorbar(im)\n",
    "ax.set_title('Effective Strain Rate ($s^{-1}$)',math_fontfamily = 'cm',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 16)\n",
    "ax.set_ylabel('$y$ (mm)',math_fontfamily = 'cm',fontsize = 16)\n",
    "# plt.savefig('Viscosity_Feb7.svg',format = 'svg',bbox_inches = 'tight')\n",
    "# plt.savefig('Strain_Rate_xy_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846a92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(np.flip(eps_e.reshape(50,200)),cmap = 'jet',extent = [-20,20,-3,0],vmax = 175,vmin = 0)\n",
    "# fig.colorbar(im)\n",
    "# ax.set_title('$\\dot\\epsilon_e$ ($s^{-1}$)',math_fontfamily = 'cm',fontsize = 18)\n",
    "ax.set_xlabel('$x$ (mm)',math_fontfamily = 'cm',fontsize = 16)\n",
    "ax.set_ylabel('$z$ (mm)',math_fontfamily = 'cm',fontsize = 16)\n",
    "# plt.savefig('Viscosity_Feb7.svg',format = 'svg',bbox_inches = 'tight')\n",
    "# plt.savefig('Strain_Rate_xz_Proposal.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499dc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74129033"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(eps_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba456a6-0f56-4100-a4b2-57d4afa0978c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartlab/anaconda3/envs/raghav/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:227: MatReadWarning: Duplicate variable name \"None\" in stream - replacing previous with new\n",
      "Consider mio5.varmats_from_mat to split file into single variable files\n",
      "  matfile_dict = MR.get_variables(variable_names)\n"
     ]
    }
   ],
   "source": [
    "#Testing with FVM data\n",
    "fvm_data = loadmat('/home/smartlab/Documents/jupyterNB/raghav/Projects_git_summer2024/Data/AFSD_Nikhil/Exponential_300_2mms.mat')\n",
    "\n",
    "u_fvm = fvm_data['u_star']\n",
    "v_fvm = fvm_data['v_star']\n",
    "w_fvm = fvm_data['w_star']\n",
    "\n",
    "u_fvm = (u_fvm[0:-1,:,:] + u_fvm[1:,:,:])/2\n",
    "v_fvm = (v_fvm[:,0:-1,:] + v_fvm[:,1:,:])/2\n",
    "w_fvm = (w_fvm[:,:,0:-1] + w_fvm[:,:,1:])/2\n",
    "\n",
    "\n",
    "Res_v_fvm = np.sqrt(np.square(u_fvm) + np.square(v_fvm) + np.square(w_fvm))\n",
    "T_fvm = fvm_data['T']\n",
    "sigma_e_fvm = fvm_data['effectivestress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7129b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'ABC', 'ALPHA', 'Db', 'De', 'Dn', 'Ds', 'Dt', 'Dw', 'Dx', 'Dy', 'Dz', 'FL', 'Fb', 'Fe', 'Fn', 'Fs', 'Ft', 'Fw', 'None', 'Lx', 'Ly', 'Lz', 'N', 'Nx', 'Ny', 'Nz', 'RPS', 'SZ', 'T', 'Tb', 'Te', 'Theat', 'Tn', 'Told', 'Ts', 'Tt', 'Tw', 'X', 'Xcenter', 'Y', 'Ycenter', 'Z', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'aB', 'aE', 'aN', 'aP', 'aS', 'aT', 'aW', 'alpha', 'alpha4', 'alpha5', 'alpha6', 'alphaP', 'alphaU', 'ans', 'b1', 'b2', 'ba', 'c', 'c1', 'c2', 'c3', 'd_u', 'd_v', 'd_w', 'delta', 'delta1', 'dx', 'dy', 'dz', 'eexx', 'eeyy', 'eezz', 'effectivestress', 'effstrrate', 'ep', 'ep1', 'errorheat', 'errormax', 'exp1', 'hbo', 'heat', 'hup', 'i', 'imax', 'ite', 'itera', 'iteration', 'j', 'jmax', 'k', 'k1', 'k2', 'k3', 'kmax', 'ku', 'l', 'maxRes', 'maxRes_u', 'maxRes_v', 'maxRes_w', 'mu', 'mumax', 'p', 'pB', 'pE', 'pN', 'pP', 'pRes', 'pS', 'pT', 'pW', 'p_prime', 'p_star', 'plasticheat', 'pold', 'pressure_term', 'q', 'q1', 'q2', 'q3', 'qu', 'ro', 'rrt', 'rrxy', 'rrxz', 'rryz', 'slip', 'sxx', 'syy', 'szz', 'thet', 'theta', 'theta1', 'tilte', 'tol', 'trt', 'txx', 'txy', 'txz', 'tyy', 'tyz', 'tzz', 'u', 'uRes', 'u_star', 'uavg', 'ub', 'uold', 'ur', 'ut', 'uth', 'v', 'v1', 'vRes', 'v_star', 'vavg', 'vb', 'vold', 'vt', 'w', 'wRes', 'w_star', 'wavg', 'wold', 'wt', 'x', 'x3', 'y', 'y3', 'z', 'z3', '__function_workspace__'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fvm_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79467057",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_min,y_min,z_min] = lb_xyz\n",
    "[x_max,y_max,z_max] = ub_xyz\n",
    "\n",
    "# x_min = -20.0\n",
    "# x_max = 20.0\n",
    "\n",
    "# x = np.linspace(x_min,x_max,250)\n",
    "x = np.linspace(x_min,x_max,251)\n",
    "x = (x[0:-1] + x[1:]).reshape(-1,1)/2\n",
    "y = np.linspace(y_min,y_max,101)\n",
    "y = (y[0:-1] + y[1:]).reshape(-1,1)/2\n",
    "z = np.linspace(z_min,z_max,13)\n",
    "z = (z[0:-1] + z[1:]).reshape(-1,1)/2\n",
    "\n",
    "X,Y,Z = np.meshgrid(x,y,z)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "Z = Z.flatten('F').reshape(-1,1)\n",
    "\n",
    "xyz = np.hstack((X,Y,Z))\n",
    "xyz_test_tensor = torch.from_numpy(xyz).float().to(device1)\n",
    "\n",
    "uvwp = model_PINN.PINN_uvw.forward(xyz_test_tensor).cpu().detach().numpy()\n",
    "\n",
    "Res_v_PINN = np.sqrt(np.square(uvwp[:,0])+np.square(uvwp[:,1])+np.square(uvwp[:,2])).reshape(12,250,100,order = 'C')\n",
    "\n",
    "Res_v_PINN = np.swapaxes(np.swapaxes(Res_v_PINN,0,1),1,2)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad2673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f6424ee80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Res_v_fvm[:,:,11],cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7d6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f642c3910>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Res_v_PINN[:,:,11],cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a17f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27328509046394744\n"
     ]
    }
   ],
   "source": [
    "RE = np.linalg.norm((Res_v_PINN-Res_v_fvm).reshape(-1,),2)/np.linalg.norm(Res_v_fvm.reshape(-1,),2)\n",
    "print(RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f5ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034875685104070664\n"
     ]
    }
   ],
   "source": [
    "RMSE = np.sqrt(np.mean(np.square(Res_v_fvm[:]-Res_v_PINN[:])))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb688df",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = xyz_test_tensor.clone()\n",
    "g.requires_grad = True\n",
    "\n",
    "out_full = model_PINN.PINN_uvw.forward(g.to(device1)).cpu() \n",
    "u = out_full[:,0:1]\n",
    "v = out_full[:,1:2]\n",
    "w = out_full[:,2:3]\n",
    "p = out_full[:,3:4]\n",
    "\n",
    "\n",
    "# print(T.shape)\n",
    "T = model_PINN.PINN_T.forward(g.to(device2)).cpu()\n",
    "\n",
    "# p_xyz = autograd.grad(p,g,torch.ones([xyz_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "u_xyz = autograd.grad(u,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "v_xyz = autograd.grad(v,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "w_xyz = autograd.grad(w,g,torch.ones([xyz_test_tensor.shape[0], 1]).to('cpu'),retain_graph=True,allow_unused = True)[0].cpu()\n",
    "\n",
    "eps2_11 = torch.square(1/2*(2*u_xyz[:,0]))\n",
    "eps2_12 = torch.square(1/2*(u_xyz[:,1] + v_xyz[:,0]))\n",
    "eps2_13 = torch.square(1/2*(u_xyz[:,2] + w_xyz[:,0]))\n",
    "\n",
    "eps2_21 = eps2_12\n",
    "eps2_22 = torch.square(1/2*(2*v_xyz[:,1])) \n",
    "eps2_23 = torch.square(1/2*(v_xyz[:,2] + w_xyz[:,1]))\n",
    "\n",
    "eps2_31 = eps2_13\n",
    "eps2_32 = eps2_23 \n",
    "eps2_33 = torch.square(1/2*(2*w_xyz[:,2]))\n",
    "\n",
    "eps_e = torch.sqrt((2/3)*(eps2_11 + eps2_12 + eps2_13 + eps2_21 + eps2_22 + eps2_23 + eps2_31 + eps2_32 + eps2_33)).reshape(-1,1)\n",
    "\n",
    "\n",
    "# Z = eps_e*torch.exp(E_a/(R*T))\n",
    "# log_Z = torch.log(eps_e) + E_a/(R*T)\n",
    "log_Z = torch.log(eps_e) + E_a/(R*T) #Simplification\n",
    "\n",
    "\n",
    "W = (log_Z - log_A)/n\n",
    "\n",
    "\n",
    "\n",
    "# sigma_e =  (1/alpha_sig)*torch.asinh(W) \n",
    "sigma_e = (1/alpha_sig)*(np.log(2)/n + W) #Approximation\n",
    "\n",
    "#____________________________#\n",
    "mu_vis = sigma_e/(3*eps_e)\n",
    "\n",
    "\n",
    "eps_e = eps_e.cpu().detach().numpy()\n",
    "sigma_e = sigma_e.cpu().detach().numpy()\n",
    "mu_vis = mu_vis.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd34586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE:  0.08500561240854837\n",
      "RMSE:  45.964735108661316\n"
     ]
    }
   ],
   "source": [
    "T_PINN = T.cpu().detach().numpy().reshape(12,250,100,order = 'C')\n",
    "T_PINN = np.swapaxes(np.swapaxes(T_PINN,0,1),1,2)\n",
    "\n",
    "print(\"RE: \",np.linalg.norm((T_PINN-T_fvm).reshape(-1,),2)/np.linalg.norm(T_fvm.reshape(-1,),2))\n",
    "print(\"RMSE: \",np.sqrt(np.mean(np.square(T_fvm[:]-T_PINN[:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956c1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.92027801],\n",
       "       [0.92027801, 1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation between Predicted and Actual \n",
    "np.corrcoef(T_PINN.reshape(-1,),T_fvm.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1607be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.95771673],\n",
       "       [0.95771673, 1.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(Res_v_PINN.reshape(-1,),Res_v_fvm.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57bf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000000e+00, -7.1171441e-04],\n",
       "       [-7.1171441e-04,  1.0000000e+00]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_e = eps_e.reshape(12,250,100,order = 'C')\n",
    "eps_e = np.swapaxes(np.swapaxes(eps_e,0,1),1,2)\n",
    "\n",
    "eps_e_fvm = fvm_data['effstrrate']\n",
    "np.corrcoef(eps_e.reshape(-1,),eps_e_fvm.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3efdf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE:  4.834573293348854\n",
      "RMSE:  28.021321318860586\n"
     ]
    }
   ],
   "source": [
    "print(\"RE: \",np.linalg.norm((eps_e-eps_e_fvm).reshape(-1,),2)/np.linalg.norm(eps_e_fvm.reshape(-1,),2))\n",
    "print(\"RMSE: \",np.sqrt(np.mean(np.square(eps_e_fvm[:]-eps_e[:]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raghav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
