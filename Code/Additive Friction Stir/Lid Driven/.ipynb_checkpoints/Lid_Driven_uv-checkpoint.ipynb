{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "# def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "#     x = xt[:,0].reshape(-1,1)\n",
    "#     t = xt[:,1].reshape(-1,1)\n",
    "#     y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "#     return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "Re = 100\n",
    "level = \"high\"\n",
    "label = \"NS_stan_\" + level\n",
    "\n",
    "x = np.linspace(0,1,101).reshape(-1,1)\n",
    "y = np.linspace(0,1,101).reshape(-1,1)\n",
    "t = np.linspace(0,1,101).reshape(-1,1)\n",
    "\n",
    "X,Y,T = np.meshgrid(x,y,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xyt = np.hstack((X,Y,T))\n",
    "\n",
    "# y_true = true_2D_1(xt)\n",
    "# y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xyt_test_tensor = torch.from_numpy(xyt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xyt = xyt[0]\n",
    "ub_xyt = xyt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_I = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    y_I = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_I = np.zeros((N_I,1))\n",
    "    xyt_I = np.hstack((x_I,y_I,t_I))\n",
    "    u_I = np.zeros((N_I,1))\n",
    "    v_I = np.zeros((N_I,1))\n",
    "    p_I = np.zeros((N_I,1))\n",
    "    \n",
    "    #Top\n",
    "    x_BC1 = np.random.uniform(size = N_B).reshape(-1,1)\n",
    "    y_BC1 = np.ones((N_B,1))\n",
    "    t_BC1 = np.random.uniform(size = N_B).reshape(-1,1)\n",
    "    xyt_BC1 = np.hstack((x_BC1,y_BC1,t_BC1))\n",
    "    u_BC1 = np.ones((N_B,1))\n",
    "    v_BC1 = np.zeros((N_B,1))\n",
    "    \n",
    "    #Right\n",
    "    x_BC2 = np.ones((N_B,1))\n",
    "    y_BC2 = np.random.uniform(size = N_B).reshape(-1,1)\n",
    "    t_BC2 = np.random.uniform(size = N_B).reshape(-1,1)\n",
    "    xyt_BC2 = np.hstack((x_BC2,y_BC2,t_BC2))\n",
    "    u_BC2 = np.zeros((N_B,1))\n",
    "    v_BC2 = np.zeros((N_B,1))\n",
    "\n",
    "    #Bottom\n",
    "    x_BC3 = np.random.uniform(size = N_B).reshape(-1,1)\n",
    "    y_BC3 = np.zeros((N_B,1))\n",
    "    t_BC3 = np.random.uniform(size = N_B).reshape(-1,1)\n",
    "    xyt_BC3 = np.hstack((x_BC3,y_BC3,t_BC3))\n",
    "    u_BC3 = np.zeros((N_B,1))\n",
    "    v_BC3 = np.zeros((N_B,1))\n",
    "    \n",
    "    #Left\n",
    "    x_BC4 = np.zeros((N_B,1))\n",
    "    y_BC4 = np.random.uniform(size = N_B).reshape(-1,1)\n",
    "    t_BC4 = np.random.uniform(size = N_B).reshape(-1,1)\n",
    "    xyt_BC4 = np.hstack((x_BC4,y_BC4,t_BC4))\n",
    "    u_BC4 = np.zeros((N_B,1))\n",
    "    v_BC4 = np.zeros((N_B,1))\n",
    "    \n",
    "    \n",
    "    xyt_BC = np.vstack((xyt_BC1,xyt_BC2,xyt_BC3,xyt_BC4))\n",
    "    u_BC = np.vstack((u_BC1,u_BC2,u_BC3,u_BC4))\n",
    "    v_BC = np.vstack((v_BC1,v_BC2,v_BC3,v_BC4))\n",
    "\n",
    "    x_p = np.zeros((N_B,1))\n",
    "    y_p = np.zeros((N_B,1))\n",
    "    t_p = np.random.uniform(size = N_B).reshape(-1,1)\n",
    "    xyt_p = np.hstack((x_p,y_p,t_p))\n",
    "    u_p = np.zeros((N_B,1))\n",
    "    v_p = np.zeros((N_B,1))\n",
    "    p_p = np.zeros((N_B,1))\n",
    "    \n",
    "    xyt_Ip = np.vstack((xyt_I,xyt_p))\n",
    "    u_Ip = np.vstack((u_I,u_p))\n",
    "    v_Ip = np.vstack((v_I,v_p))\n",
    "    p_Ip = np.vstack((p_I,p_p))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xyt_coll = lb_xyt + (ub_xyt - lb_xyt)*samples\n",
    "    \n",
    "    xyt_coll = np.vstack((xyt_coll, xyt_BC,xyt_I,xyt_p)) # append training points to collocation points \n",
    "\n",
    "    return xyt_coll, xyt_BC,u_BC,v_BC, xyt_Ip, u_Ip,v_Ip, p_Ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        beta_mean = 1.0*torch.ones((50,len(layers)-2))\n",
    "        beta_std = 0.01*torch.ones((50,len(layers)-2))\n",
    "        \n",
    "        self.beta = Parameter(torch.normal(beta_mean,beta_std))\n",
    "        self.beta.requiresGrad = True\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xyt):\n",
    "        if torch.is_tensor(xyt) != True:         \n",
    "            xt = torch.from_numpy(xyt)                \n",
    "        \n",
    "        ubxyt = torch.from_numpy(ub_xyt).float().to(device)\n",
    "        lbxyt = torch.from_numpy(lb_xyt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xyt = 2.0*(xyt - lbxyt)/(ubxyt - lbxyt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xyt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            z1 = self.activation(z)\n",
    "            a = z1 + self.beta[:,i]*z*z1            \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xyt_BC,u_BC,v_BC):\n",
    "                \n",
    "        uvp = self.forward(xyt_BC)\n",
    "        \n",
    "        loss_bc_u = self.loss_function(uvp[:,0:1],u_BC)\n",
    "        loss_bc_v = self.loss_function(uvp[:,1:2],v_BC)\n",
    "        \n",
    "        # psi_p_pred = self.forward(torch.cat((x1,y1,t1),dim =1))\n",
    "        # psi = psi_p_pred[:,0:1]\n",
    "        # p_pred = psi_p_pred[:,1:2]\n",
    "                \n",
    "        return loss_bc_u + loss_bc_v\n",
    "    \n",
    "    def loss_Ip(self,xyt_Ip,u_Ip,v_Ip,p_Ip):\n",
    "                \n",
    "        uvp = self.forward(xyt_Ip)\n",
    "        \n",
    "        loss_ip_u = self.loss_function(uvp[:,0:1],u_Ip)\n",
    "        loss_ip_v = self.loss_function(uvp[:,1:2],v_Ip)\n",
    "        loss_ip_p = self.loss_function(uvp[:,2:3],p_Ip)\n",
    "        \n",
    "        # psi_p_pred = self.forward(torch.cat((x1,y1,t1),dim =1))\n",
    "        # psi = psi_p_pred[:,0:1]\n",
    "        # p_pred = psi_p_pred[:,1:2]\n",
    "                \n",
    "        return loss_ip_u + loss_ip_v+loss_ip_p\n",
    "    \n",
    "    def loss_PDE(self, xyt_coll, f_hat):\n",
    "        \n",
    "        g = xyt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        uvp = self.forward(g) \n",
    "        \n",
    "        u = uvp[:,0:1]\n",
    "        v = uvp[:,1:2]\n",
    "        p = uvp[:,2:3]\n",
    "        \n",
    "        \n",
    "        #u\n",
    "        u_xyt = autograd.grad(u,g,torch.ones([xyt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "    \n",
    "        u_xx_yy_tt = autograd.grad(u_xyt,g,torch.ones(xyt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        du_dx = u_xyt[:,[0]]\n",
    "        du_dy = u_xyt[:,[1]]\n",
    "        du_dt = u_xyt[:,[2]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy_tt[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy_tt[:,[1]]\n",
    "        \n",
    "        #v\n",
    "        v_xyt = autograd.grad(v,g,torch.ones([xyt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        v_xx_yy_tt = autograd.grad(v_xyt,g,torch.ones(xyt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dv_dx = v_xyt[:,[0]]\n",
    "        dv_dy = v_xyt[:,[1]]\n",
    "        dv_dt = v_xyt[:,[2]]\n",
    "        \n",
    "        d2v_dx2 = v_xx_yy_tt[:,[0]]\n",
    "        d2v_dy2 = v_xx_yy_tt[:,[1]]\n",
    "        \n",
    "        #p\n",
    "        p_xyt = autograd.grad(p,g,torch.ones([xyt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dp_dx = p_xyt[:,[0]]\n",
    "        dp_dy = p_xyt[:,[1]]\n",
    "    \n",
    "        \n",
    "        \n",
    "        f_u = du_dt + u*du_dx + v*du_dy + dp_dx - (d2u_dx2 + d2u_dy2)/Re\n",
    "        f_v = dv_dt + u*dv_dx + v*dv_dy + dp_dy - (d2v_dx2 + d2v_dy2)/Re\n",
    "        \n",
    "        \n",
    "        loss_f_u = self.loss_function(f_u,f_hat)\n",
    "        loss_f_v = self.loss_function(f_v,f_hat)\n",
    "                \n",
    "        return loss_f_u + loss_f_v\n",
    "    \n",
    "    \n",
    "    def loss_NBC(self,xyt_coll,N_hat):\n",
    "        g = xyt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        uvp = self.forward(g)\n",
    "        \n",
    "        u = uvp[:,0:1]\n",
    "        v = uvp[:,1:2]\n",
    "        \n",
    "        u_xyt = autograd.grad(u,g,torch.ones([xyt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        v_xyt = autograd.grad(v,g,torch.ones([xyt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        du_dx = u_xyt[:,[0]]\n",
    "        dv_dy = v_xyt[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(du_dx + dv_dy, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    \n",
    "    def loss(self,xyt_coll, xyt_BC,u_BC,v_BC, xyt_Ip, u_Ip,v_Ip, p_Ip,f_hat,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xyt_BC,u_BC,v_BC)\n",
    "        loss_Ip = self.loss_Ip(xyt_Ip,u_Ip,v_Ip,p_Ip)\n",
    "        loss_NBC = self.loss_NBC(xyt_coll,N_hat)\n",
    "        loss_f = self.loss_PDE(xyt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC +loss_Ip\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        # y_pred = self.test()\n",
    "        \n",
    "        # test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        # test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        test_mse = 0\n",
    "        test_re = 0\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xyt_coll, xyt_BC,u_BC,v_BC, xyt_Ip, u_Ip,v_Ip, p_Ip,f_hat,N_hat,seed):\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xyt_coll, xyt_BC,u_BC,v_BC, xyt_Ip, u_Ip,v_Ip, p_Ip,f_hat,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xyt_coll, xyt_BC,u_BC,v_BC, xyt_Ip, u_Ip,v_Ip, p_Ip = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xyt_coll = torch.from_numpy(xyt_coll).float().to(device)\n",
    "    xyt_BC = torch.from_numpy(xyt_BC).float().to(device)\n",
    "    u_BC = torch.from_numpy(u_BC).float().to(device)\n",
    "    v_BC = torch.from_numpy(v_BC).float().to(device)\n",
    "    \n",
    "    xyt_Ip = torch.from_numpy(xyt_Ip).float().to(device)\n",
    "    u_Ip = torch.from_numpy(u_Ip).float().to(device)\n",
    "    v_Ip = torch.from_numpy(v_Ip).float().to(device)\n",
    "    p_Ip = torch.from_numpy(p_Ip).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xyt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xyt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xyt_coll, xyt_BC,u_BC,v_BC, xyt_Ip, u_Ip,v_Ip, p_Ip,f_hat,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xyt_coll, xyt_BC,u_BC,v_BC, xyt_Ip, u_Ip,v_Ip, p_Ip,f_hat,N_hat,i)\n",
    "            loss_np = PINN.loss(xyt_coll, xyt_BC,u_BC,v_BC, xyt_Ip, u_Ip,v_Ip, p_Ip,f_hat,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "\n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NS_stan_high\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 0.08603969 Test MSE 0 Test RE 0\n",
      "1 Train Loss 0.04983189 Test MSE 0 Test RE 0\n",
      "2 Train Loss 0.029015135 Test MSE 0 Test RE 0\n",
      "3 Train Loss 0.024466563 Test MSE 0 Test RE 0\n",
      "4 Train Loss 0.022890786 Test MSE 0 Test RE 0\n",
      "5 Train Loss 0.021737412 Test MSE 0 Test RE 0\n",
      "6 Train Loss 0.02078842 Test MSE 0 Test RE 0\n",
      "7 Train Loss 0.020129146 Test MSE 0 Test RE 0\n",
      "8 Train Loss 0.01941903 Test MSE 0 Test RE 0\n",
      "9 Train Loss 0.018742539 Test MSE 0 Test RE 0\n",
      "10 Train Loss 0.018283535 Test MSE 0 Test RE 0\n",
      "11 Train Loss 0.017862186 Test MSE 0 Test RE 0\n",
      "12 Train Loss 0.017467726 Test MSE 0 Test RE 0\n",
      "13 Train Loss 0.017112112 Test MSE 0 Test RE 0\n",
      "14 Train Loss 0.01687136 Test MSE 0 Test RE 0\n",
      "15 Train Loss 0.0166578 Test MSE 0 Test RE 0\n",
      "16 Train Loss 0.01648138 Test MSE 0 Test RE 0\n",
      "17 Train Loss 0.016290585 Test MSE 0 Test RE 0\n",
      "18 Train Loss 0.016110143 Test MSE 0 Test RE 0\n",
      "19 Train Loss 0.015970271 Test MSE 0 Test RE 0\n",
      "20 Train Loss 0.015816309 Test MSE 0 Test RE 0\n",
      "21 Train Loss 0.01563783 Test MSE 0 Test RE 0\n",
      "22 Train Loss 0.015467797 Test MSE 0 Test RE 0\n",
      "23 Train Loss 0.015324539 Test MSE 0 Test RE 0\n",
      "24 Train Loss 0.015203666 Test MSE 0 Test RE 0\n",
      "25 Train Loss 0.015089415 Test MSE 0 Test RE 0\n",
      "26 Train Loss 0.014965964 Test MSE 0 Test RE 0\n",
      "27 Train Loss 0.014858688 Test MSE 0 Test RE 0\n",
      "28 Train Loss 0.014760799 Test MSE 0 Test RE 0\n",
      "29 Train Loss 0.0146732405 Test MSE 0 Test RE 0\n",
      "30 Train Loss 0.014579727 Test MSE 0 Test RE 0\n",
      "31 Train Loss 0.014486308 Test MSE 0 Test RE 0\n",
      "32 Train Loss 0.014378046 Test MSE 0 Test RE 0\n",
      "33 Train Loss 0.014294908 Test MSE 0 Test RE 0\n",
      "34 Train Loss 0.014208558 Test MSE 0 Test RE 0\n",
      "35 Train Loss 0.014138883 Test MSE 0 Test RE 0\n",
      "36 Train Loss 0.014043633 Test MSE 0 Test RE 0\n",
      "37 Train Loss 0.013958888 Test MSE 0 Test RE 0\n",
      "38 Train Loss 0.013867231 Test MSE 0 Test RE 0\n",
      "39 Train Loss 0.013796649 Test MSE 0 Test RE 0\n",
      "40 Train Loss 0.013733875 Test MSE 0 Test RE 0\n",
      "41 Train Loss 0.013665729 Test MSE 0 Test RE 0\n",
      "42 Train Loss 0.0136036975 Test MSE 0 Test RE 0\n",
      "43 Train Loss 0.013523061 Test MSE 0 Test RE 0\n",
      "44 Train Loss 0.013448291 Test MSE 0 Test RE 0\n",
      "45 Train Loss 0.01335641 Test MSE 0 Test RE 0\n",
      "46 Train Loss 0.013260934 Test MSE 0 Test RE 0\n",
      "47 Train Loss 0.013168173 Test MSE 0 Test RE 0\n",
      "48 Train Loss 0.013079963 Test MSE 0 Test RE 0\n",
      "49 Train Loss 0.012986562 Test MSE 0 Test RE 0\n",
      "50 Train Loss 0.012890212 Test MSE 0 Test RE 0\n",
      "51 Train Loss 0.012794144 Test MSE 0 Test RE 0\n",
      "52 Train Loss 0.012696918 Test MSE 0 Test RE 0\n",
      "53 Train Loss 0.01257404 Test MSE 0 Test RE 0\n",
      "54 Train Loss 0.012486162 Test MSE 0 Test RE 0\n",
      "55 Train Loss 0.012365418 Test MSE 0 Test RE 0\n",
      "56 Train Loss 0.0122286305 Test MSE 0 Test RE 0\n",
      "57 Train Loss 0.012103728 Test MSE 0 Test RE 0\n",
      "58 Train Loss 0.011975692 Test MSE 0 Test RE 0\n",
      "59 Train Loss 0.011848547 Test MSE 0 Test RE 0\n",
      "60 Train Loss 0.011726342 Test MSE 0 Test RE 0\n",
      "61 Train Loss 0.011589679 Test MSE 0 Test RE 0\n",
      "62 Train Loss 0.011457243 Test MSE 0 Test RE 0\n",
      "63 Train Loss 0.011318189 Test MSE 0 Test RE 0\n",
      "64 Train Loss 0.011187754 Test MSE 0 Test RE 0\n",
      "65 Train Loss 0.011081506 Test MSE 0 Test RE 0\n",
      "66 Train Loss 0.0109737795 Test MSE 0 Test RE 0\n",
      "67 Train Loss 0.010862042 Test MSE 0 Test RE 0\n",
      "68 Train Loss 0.0107535375 Test MSE 0 Test RE 0\n",
      "69 Train Loss 0.010647312 Test MSE 0 Test RE 0\n",
      "70 Train Loss 0.010567156 Test MSE 0 Test RE 0\n",
      "71 Train Loss 0.010473202 Test MSE 0 Test RE 0\n",
      "72 Train Loss 0.0103942845 Test MSE 0 Test RE 0\n",
      "73 Train Loss 0.010324575 Test MSE 0 Test RE 0\n",
      "74 Train Loss 0.010244897 Test MSE 0 Test RE 0\n",
      "75 Train Loss 0.010167768 Test MSE 0 Test RE 0\n",
      "76 Train Loss 0.010103823 Test MSE 0 Test RE 0\n",
      "77 Train Loss 0.010031969 Test MSE 0 Test RE 0\n",
      "78 Train Loss 0.009963801 Test MSE 0 Test RE 0\n",
      "79 Train Loss 0.009905274 Test MSE 0 Test RE 0\n"
     ]
    }
   ],
   "source": [
    "max_reps = 1 #10\n",
    "max_iter = 500 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 2000  #Total number of data points for 'y'\n",
    "N_B = 2000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([3,50,50,50,50,3]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_flag = train_model(max_iter,reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvp_pred = PINN.forward(xyt_test_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [],
   "source": [
    "u_pred = uvp_pred[:,0].reshape(101,101,101)\n",
    "v_pred = uvp_pred[:,1].reshape(101,101,101)\n",
    "\n",
    "a = 10\n",
    "b = 10\n",
    "fig,axs = plt.subplots(3,2)\n",
    "\n",
    "frame_idx = 19\n",
    "\n",
    "ax = axs[0,0]\n",
    "ax.figure.set_size_inches(a,b)\n",
    "img = ax.imshow(np.flip(np.transpose(u_pred[frame_idx,:,:]),axis =0),cmap = 'jet',extent= [0,1,0,1],vmin = np.min(u_pred),vmax = np.max(u_pred))\n",
    "# fig.colorbar(img)\n",
    "cbar = fig.colorbar(img, ax=ax,aspect = 10)\n",
    "\n",
    "ax.set_xlabel('x',fontsize = 14)\n",
    "ax.set_ylabel('y',fontsize = 14)\n",
    "\n",
    "ax.set_title(\"$u (t=0.2s)$\",fontsize = 12)\n",
    "ax.tick_params(axis = 'x',labelsize = 12)\n",
    "ax.tick_params(axis = 'y',labelsize = 12)\n",
    "\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "ax = axs[0,1]\n",
    "ax.figure.set_size_inches(a,b)\n",
    "img = ax.imshow(np.flip(np.transpose(v_pred[frame_idx,:,:]),axis =0),cmap = 'jet',extent= [0,1,0,1])\n",
    "# fig.colorbar(img)\n",
    "cbar = fig.colorbar(img, ax=ax,aspect = 10)\n",
    "\n",
    "ax.set_xlabel('x',fontsize = 14)\n",
    "ax.set_ylabel('y',fontsize = 14)\n",
    "\n",
    "ax.set_title(\"$v (t=0.2s)$\",fontsize = 12)\n",
    "ax.tick_params(axis = 'x',labelsize = 12)\n",
    "ax.tick_params(axis = 'y',labelsize = 12)\n",
    "\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "frame_idx = 59\n",
    "\n",
    "ax = axs[1,0]\n",
    "ax.figure.set_size_inches(a,b)\n",
    "img = ax.imshow(np.flip(np.transpose(u_pred[frame_idx,:,:]),axis =0),cmap = 'jet',extent= [0,1,0,1],vmin = np.min(u_pred),vmax = np.max(u_pred))\n",
    "# fig.colorbar(img)\n",
    "cbar = fig.colorbar(img, ax=ax,aspect = 10)\n",
    "\n",
    "ax.set_xlabel('x',fontsize = 14)\n",
    "ax.set_ylabel('y',fontsize = 14)\n",
    "\n",
    "ax.set_title(\"$u (t=0.6s)$\",fontsize = 12)\n",
    "ax.tick_params(axis = 'x',labelsize = 12)\n",
    "ax.tick_params(axis = 'y',labelsize = 12)\n",
    "\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "ax = axs[1,1]\n",
    "ax.figure.set_size_inches(a,b)\n",
    "img = ax.imshow(np.flip(np.transpose(v_pred[frame_idx,:,:]),axis =0),cmap = 'jet',extent= [0,1,0,1])\n",
    "# fig.colorbar(img)\n",
    "cbar = fig.colorbar(img, ax=ax,aspect = 10)\n",
    "\n",
    "ax.set_xlabel('x',fontsize = 14)\n",
    "ax.set_ylabel('y',fontsize = 14)\n",
    "\n",
    "ax.set_title(\"$v (t=0.6s)$\",fontsize = 12)\n",
    "ax.tick_params(axis = 'x',labelsize = 12)\n",
    "ax.tick_params(axis = 'y',labelsize = 12)\n",
    "\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "fig.subplots_adjust(wspace = 0.7)\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "frame_idx = 99\n",
    "\n",
    "ax = axs[2,0]\n",
    "ax.figure.set_size_inches(a,b)\n",
    "img = ax.imshow(np.flip(np.transpose(u_pred[frame_idx,:,:]),axis =0),cmap = 'jet',extent= [0,1,0,1],vmin = np.min(u_pred),vmax = np.max(u_pred))\n",
    "# fig.colorbar(img)\n",
    "cbar = fig.colorbar(img, ax=ax,aspect = 10)\n",
    "\n",
    "ax.set_xlabel('x',fontsize = 14)\n",
    "ax.set_ylabel('y',fontsize = 14)\n",
    "\n",
    "ax.set_title(\"$u (t=1.0s)$\",fontsize = 12)\n",
    "ax.tick_params(axis = 'x',labelsize = 12)\n",
    "ax.tick_params(axis = 'y',labelsize = 12)\n",
    "\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "ax = axs[2,1]\n",
    "ax.figure.set_size_inches(a,b)\n",
    "img = ax.imshow(np.flip(np.transpose(v_pred[frame_idx,:,:]),axis =0),cmap = 'jet',extent= [0,1,0,1])\n",
    "# fig.colorbar(img)\n",
    "cbar = fig.colorbar(img, ax=ax,aspect = 10)\n",
    "\n",
    "ax.set_xlabel('x',fontsize = 14)\n",
    "ax.set_ylabel('y',fontsize = 14)\n",
    "\n",
    "ax.set_title(\"$v (t=1.0s)$\",fontsize = 12)\n",
    "ax.tick_params(axis = 'x',labelsize = 12)\n",
    "ax.tick_params(axis = 'y',labelsize = 12)\n",
    "\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "fig.subplots_adjust(wspace = 0.1,hspace = 0.4)\n",
    "# plt.savefig('NS_lid.svg', format='svg',pad_inches=0, bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "frame_idx = 99\n",
    "ax.figure.set_size_inches(a,b)\n",
    "psi = np.sqrt(np.square(v_pred[frame_idx,:,:]) + np.square(u_pred[frame_idx,:,:])) \n",
    "img = ax.imshow(np.flip(np.transpose(psi),axis =0),cmap = 'jet',extent= [0,1,0,1],vmax = 5,vmin = 0)\n",
    "# fig.colorbar(img)\n",
    "cbar = fig.colorbar(img, ax=ax,aspect = 10)\n",
    "\n",
    "ax.set_xlabel('x',fontsize = 14)\n",
    "ax.set_ylabel('y',fontsize = 14)\n",
    "\n",
    "ax.set_title(\"$v (t=1.0s)$\",fontsize = 12)\n",
    "ax.tick_params(axis = 'x',labelsize = 12)\n",
    "ax.tick_params(axis = 'y',labelsize = 12)\n",
    "\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "plt.savefig('NS_lid.svg', format='svg',pad_inches=0, bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_matlab = loadmat(\"uv_matlab.mat\")['u']\n",
    "v_matlab = loadmat(\"uv_matlab.mat\")['v']\n",
    "\n",
    "frame_idx = 100\n",
    "fig,axs = plt.subplots(1,2)\n",
    "a = 10\n",
    "b = 3\n",
    "\n",
    "fig.set_size_inches(a,b)\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(y,u_matlab[50,:],'b-.',label = 'SOR')\n",
    "ax.plot(y,u_pred[frame_idx,50,:],'r',label = 'PINN')\n",
    "ax.set_xlim([0,1])\n",
    "ax.legend()\n",
    "ax.set_xlabel('$y$')\n",
    "ax.set_ylabel('$u(x=0.5)$')\n",
    "ax.set_title('Velocity in $x$-direction') \n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(x,v_matlab[:,50],'b-.',label = 'SOR')\n",
    "ax.plot(x,v_pred[frame_idx,:,50],'r',label = 'PINN')\n",
    "ax.set_xlim([0,1])\n",
    "ax.legend(loc = 1)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$v(y=0.5)$')\n",
    "ax.set_title('Velocity in $y$-direction') \n",
    "\n",
    "fig.subplots_adjust(wspace = 0.4)\n",
    "# plt.savefig('SOR_PINN.svg', format='svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = u_matlab\n",
    "v_pred = v_matlab\n",
    "\n",
    "a = 10\n",
    "b = 10\n",
    "fig,axs = plt.subplots(1,2)\n",
    "\n",
    "frame_idx = 99\n",
    "\n",
    "ax = axs[0]\n",
    "ax.figure.set_size_inches(a,b)\n",
    "img = ax.imshow(np.flip(np.transpose(u_pred[:,:]),axis =0),cmap = 'jet',extent= [0,1,0,1],vmin = np.min(u_pred),vmax = np.max(u_pred))\n",
    "# fig.colorbar(img)\n",
    "cbar = fig.colorbar(img, ax=ax,aspect = 10,fraction=0.08)\n",
    "\n",
    "ax.set_xlabel('x',fontsize = 14)\n",
    "ax.set_ylabel('y',fontsize = 14)\n",
    "\n",
    "ax.set_title(\"$u (t=1.0s)$\",fontsize = 12)\n",
    "ax.tick_params(axis = 'x',labelsize = 12)\n",
    "ax.tick_params(axis = 'y',labelsize = 12)\n",
    "\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "ax = axs[1]\n",
    "ax.figure.set_size_inches(a,b)\n",
    "img = ax.imshow(np.flip(np.transpose(v_pred[:,:]),axis =0),cmap = 'jet',extent= [0,1,0,1])\n",
    "# fig.colorbar(img)\n",
    "cbar = fig.colorbar(img, ax=ax,aspect = 10,fraction=0.08)\n",
    "\n",
    "ax.set_xlabel('x',fontsize = 14)\n",
    "ax.set_ylabel('y',fontsize = 14)\n",
    "\n",
    "ax.set_title(\"$v (t=1.0s)$\",fontsize = 12)\n",
    "ax.tick_params(axis = 'x',labelsize = 12)\n",
    "ax.tick_params(axis = 'y',labelsize = 12)\n",
    "\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "fig.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "plt.savefig('NS_lid_SOR.svg', format='svg',pad_inches=0, bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(np.linspace(0, 1, 101), np.linspace(0, 1, 101))\n",
    "u = u_pred[frame_idx,:,:]  # Replace with your u values\n",
    "v = v_pred[frame_idx,:,:]  # Replace with your v values\n",
    "xstart =np.random.uniform()\n",
    "ystart = np.random.uniform()  # Replace with your starting points\n",
    "L = 1  # Replace with the desired value for L\n",
    "\n",
    "# Create the streamline plot\n",
    "# fig = plt.figure(3)\n",
    "h = plt.streamplot(X, Y, u.T, v.T, start_points=np.column_stack([xstart, ystart]), color='k',linewidth=1.5, density=0.1, arrowstyle='->', arrowsize=1.5)\n",
    "plt.title('Stream Function')\n",
    "plt.xlabel('x-location')\n",
    "plt.ylabel('y-location')\n",
    "# plt.axis('equal', [0,1, 0, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pred = uvp_pred[:,2].reshape(100,100,100)\n",
    "fig,ax = plt.subplots()\n",
    "img = ax.imshow(np.flip(np.transpose(p_pred[99,:,:]),axis =0),cmap = 'jet')\n",
    "fig.colorbar(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
