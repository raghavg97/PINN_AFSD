{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7e8113-fc6b-42be-9a3c-685830458daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "# from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import loadmat,savemat\n",
    "from training_samples import trainingdata_uvw,trainingdata_T\n",
    "\n",
    "\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e12c536f-3169-48e3-82a1-915d437b21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "R0 = 5 #mm\n",
    "Rs = 19 #mm\n",
    "# mu_vis = 0.3 \n",
    "mu = 0.3 #Friction Coefficient (not viscosity)\n",
    "# delta = 0.5\n",
    "A = 6.41 #For slip factor\n",
    "pi = np.pi\n",
    "Omega = 300 #rpm\n",
    "V = 2 #mm/s\n",
    "F = 0.67 #mm\n",
    "rho = 2700 * 1e-6 #g/mm3\n",
    "k_B = 1.380649*1e-23 #J/K\n",
    "R = 8.314 #J/(K.mol)\n",
    "E_a = 205000 #J/mol #Q\n",
    "alpha_sig = 52 #mm^2/N\n",
    "# A = np.exp(27.78)\n",
    "log_A = 27.78\n",
    "n = 3.49\n",
    "k = 0.167 #Thermal Conductivity #W/(mmK)\n",
    "c_p = 0.897 #J/gK \n",
    "alpha_m = k/(rho*c_p)\n",
    "T_a = 298.0\n",
    "\n",
    "\n",
    "k_t = 0.0176 #W/(mmK)\n",
    "c_p_t = 0.46 #J/gk\n",
    "rho_t = 2700 * 1e-6 #g/mm3\n",
    "alpha_t = k_t/(rho_t*c_p_t)\n",
    "\n",
    "h_sides = 5*1e-6 #W/mm^2K\n",
    "C_bot = 0.15*1e-6 #W/mm^2K^3\n",
    "\n",
    "eeta = alpha_m/(alpha_m+alpha_t)\n",
    "\n",
    "lb_xyz = np.array([-50.0,-20.0,-3.0])\n",
    "ub_xyz = np.array([50.0,20.0,0.0])\n",
    "\n",
    "lb_xyz_uvw = np.array([-20.0,-20.0,-3.0])\n",
    "ub_xyz_uvw = np.array([20.0,20.0,0.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb877af0-8a4e-4628-b94d-de92a0d130bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat)\n",
    "        loss.backward()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5478b554-59b5-4825-95bb-acf6c27211d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep,p_iters):\n",
    "    print(rep)\n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot = trainingdata_uvw(N_B,N_f,lb_xyz,ub_xyz,rep*123)\n",
    "    xyz_coll = torch.from_numpy(xyz_coll).float().to(device)\n",
    "    xyz_1 = torch.from_numpy(xyz_1).float().to(device)\n",
    "    xyz_2 = torch.from_numpy(xyz_2).float().to(device)\n",
    "    xyz_3 = torch.from_numpy(xyz_3).float().to(device)\n",
    "    xyz_4 = torch.from_numpy(xyz_4).float().to(device)\n",
    "    \n",
    "    xyz_top = torch.from_numpy(xyz_top).float().to(device)\n",
    "    xyz_bot = torch.from_numpy(xyz_bot).float().to(device)\n",
    "   \n",
    "    f_hat = torch.zeros(xyz_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xyz_top.shape[0],1).to(device)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "#         if(i>0 and i%50==0):\n",
    "#             _,_,_,_,_,xyz_top,xyz_bot = trainingdata(N_B,N_f,i*123)\n",
    "#             # xyz_coll = torch.from_numpy(xyz_coll).float().to(device)\n",
    "#             # xyz_1 = torch.from_numpy(xyz_1).float().to(device)\n",
    "#             # xyz_2 = torch.from_numpy(xyz_2).float().to(device)\n",
    "#             # xyz_3 = torch.from_numpy(xyz_3).float().to(device)\n",
    "#             # xyz_4 = torch.from_numpy(xyz_4).float().to(device)\n",
    "\n",
    "#             xyz_top = torch.from_numpy(xyz_top).float().to(device)\n",
    "#             xyz_bot = torch.from_numpy(xyz_bot).float().to(device)\n",
    "\n",
    "        train_step(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat)\n",
    "\n",
    "        loss_np = PINN.loss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat).cpu().detach().numpy()\n",
    "\n",
    "        # print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "        print(i,\"Train Loss\",loss_np)\n",
    "\n",
    "        # if(i>0 and i%25 ==0):\n",
    "        #   pretrain(xyt_DBC,p_iters)\n",
    "\n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b5a6e4a-7ebc-437a-a707-0b7256025237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (1-2): 2 x Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 3532.1504\n",
      "1 Train Loss 760.0564\n",
      "2 Train Loss 466.381\n",
      "3 Train Loss 287.98132\n",
      "4 Train Loss 194.53987\n",
      "5 Train Loss 155.4568\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 52\u001b[0m\n\u001b[1;32m     42\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mLBFGS(PINN\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m,\n\u001b[1;32m     43\u001b[0m                           max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m     44\u001b[0m                           max_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m                           history_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     48\u001b[0m                           line_search_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrong_wolfe\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 52\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp_iters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAFSD_vPINN\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(PINN\u001b[38;5;241m.\u001b[39mstate_dict(),label\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(reps)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(max_iter, rep, p_iters)\u001b[0m\n\u001b[1;32m     18\u001b[0m     N_hat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(xyz_top\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#         if(i>0 and i%50==0):\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#             _,_,_,_,_,xyz_top,xyz_bot = trainingdata(N_B,N_f,i*123)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#             xyz_top = torch.from_numpy(xyz_top).float().to(device)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#             xyz_bot = torch.from_numpy(xyz_bot).float().to(device)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m         \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz_coll\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxyz_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxyz_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxyz_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxyz_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxyz_top\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxyz_bot\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m         loss_np \u001b[38;5;241m=\u001b[39m PINN\u001b[38;5;241m.\u001b[39mloss(xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m# print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(xyz_coll, xyz_1, xyz_2, xyz_3, xyz_4, xyz_top, xyz_bot, f_hat, N_hat)\u001b[0m\n\u001b[1;32m      5\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m----> 9\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/optim/lbfgs.py:426\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[0;32m--> 426\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m    429\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/optim/lbfgs.py:50\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m     48\u001b[0m g \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# evaluate objective and gradient using initial step\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     52\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/optim/lbfgs.py:424\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/optim/lbfgs.py:278\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m--> 278\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    279\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_param(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mtrain_step.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m():\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mPINN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz_coll\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxyz_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxyz_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxyz_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxyz_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxyz_top\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxyz_bot\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Documents/jupyterNB/raghav/Projects_git_summer2024/PINN_AFSD/Code/QSR Paper Competition/Seq_model_vPINN.py:479\u001b[0m, in \u001b[0;36mSequentialmodel.loss\u001b[0;34m(self, xyz_coll, xyz_1, xyz_2, xyz_3, xyz_4, xyz_top, xyz_bot, f_hat, N_hat)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m,xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot,f_hat,N_hat):\n\u001b[0;32m--> 479\u001b[0m     loss_PDE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_PDE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz_coll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     loss_B_top \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_B_top(xyz_top,N_hat)\n\u001b[1;32m    481\u001b[0m     loss_B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_B_uvw(xyz_1, xyz_2, xyz_3, xyz_4, xyz_bot)\n",
      "File \u001b[0;32m~/Documents/jupyterNB/raghav/Projects_git_summer2024/PINN_AFSD/Code/QSR Paper Competition/Seq_model_vPINN.py:457\u001b[0m, in \u001b[0;36mSequentialmodel.loss_PDE\u001b[0;34m(self, xyz_coll, f_hat)\u001b[0m\n\u001b[1;32m    454\u001b[0m kT_yy \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m*\u001b[39mT_y_xyz[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    455\u001b[0m kT_zz \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m*\u001b[39mT_z_xyz[:,\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 457\u001b[0m uT_x \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mgrad(u\u001b[38;5;241m*\u001b[39mT,g,\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxyz_coll_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,allow_unused \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    458\u001b[0m vT_y \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mgrad(v\u001b[38;5;241m*\u001b[39mT,g,torch\u001b[38;5;241m.\u001b[39mones([xyz_coll_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,allow_unused \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    459\u001b[0m wT_z \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mgrad(w\u001b[38;5;241m*\u001b[39mT,g,torch\u001b[38;5;241m.\u001b[39mones([xyz_coll_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,allow_unused \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][:,\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Seq_model_vPINN import Sequentialmodel\n",
    "label = 'meltpool'\n",
    "max_reps = 1\n",
    "max_iter = 100\n",
    "p_iters = 10\n",
    "\n",
    "N_B = 6000\n",
    "N_f = 5000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "\n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*3)\n",
    "     #Total number of collocation points\n",
    "\n",
    "\n",
    "    # layers1 = np.array([3,50,50,50,4]) #9 hidden layers\n",
    "    # layers2 = np.array([3,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([3,60,60,60,60,60,5])\n",
    "    layers = np.array([3,64,64,64,5])\n",
    "    PINN = Sequentialmodel(layers,lb_xyz,ub_xyz)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25,\n",
    "                              max_iter = 30,\n",
    "                              max_eval = 50,\n",
    "                              tolerance_grad = 1e-5,\n",
    "                              tolerance_change = 1e-5,\n",
    "                              history_size = 100,\n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_model(max_iter,reps,p_iters)\n",
    "\n",
    "    label = \"AFSD_vPINN\"\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.normal(mean=0, std=torch.arange(1, 0, -0.08)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a286f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66fce42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fccb21-7030-4050-ae16-7f138f7ba249",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_min,y_min,z_min] = lb_xyz\n",
    "[x_max,y_max,z_max] = ub_xyz\n",
    "\n",
    "x_min = -20.0\n",
    "x_max = 20.0\n",
    "\n",
    "x = np.linspace(x_min,x_max,100).reshape(-1,1)\n",
    "y = np.linspace(y_min,y_max,100).reshape(-1,1)\n",
    "#z = np.linspace(z_min,z_max,20).reshape(-1,1)\n",
    "z = -0.125\n",
    "\n",
    "X,Y,Z = np.meshgrid(x,y,z)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "Z = Z.flatten('F').reshape(-1,1)\n",
    "\n",
    "xyz = np.hstack((X,Y,Z))\n",
    "xyz_test_tensor = torch.from_numpy(xyz).float().to(device)\n",
    "\n",
    "uvwp = PINN.forward1(xyz_test_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d000d1-c6fb-4074-8861-823db543fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_vel = np.sqrt(np.square(uvwp[:,0])+np.square(uvwp[:,1])+np.square(uvwp[:,2]))\n",
    "# r_vel = np.sqrt(np.square(uvwp[:,2]))\n",
    "# r_vel = uvwp[:,2]\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow((r_vel/1000).reshape(100,100),cmap = 'jet',extent = [-20,20,-20,20])\n",
    "fig.colorbar(im)\n",
    "ax.set_title('Resultant Velocity (Top) (m/s)')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "# plt.savefig('Res_u_top_Feb7.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef87f55-d125-4c5b-a16d-544611395158",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = xyz_test_tensor.clone()\n",
    "g.requires_grad = True\n",
    "\n",
    "out_full = PINN.forward1(g) \n",
    "u = out_full[:,0:1]\n",
    "v = out_full[:,1:2]\n",
    "w = out_full[:,2:3]\n",
    "p = out_full[:,3:4]\n",
    "\n",
    "\n",
    "# print(T.shape)\n",
    "T = PINN.forward2(g)\n",
    "\n",
    "# p_xyz = autograd.grad(p,g,torch.ones([xyz_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "u_xyz = autograd.grad(u,g,torch.ones([xyz_test_tensor.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "v_xyz = autograd.grad(v,g,torch.ones([xyz_test_tensor.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "w_xyz = autograd.grad(w,g,torch.ones([xyz_test_tensor.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "eps2_11 = torch.square(1/2*(2*u_xyz[:,0]))\n",
    "eps2_12 = torch.square(1/2*(u_xyz[:,1] + v_xyz[:,0]))\n",
    "eps2_13 = torch.square(1/2*(u_xyz[:,2] + w_xyz[:,0]))\n",
    "\n",
    "eps2_21 = eps2_12\n",
    "eps2_22 = torch.square(1/2*(2*v_xyz[:,1])) \n",
    "eps2_23 = torch.square(1/2*(v_xyz[:,2] + w_xyz[:,1]))\n",
    "\n",
    "eps2_31 = eps2_13\n",
    "eps2_32 = eps2_23 \n",
    "eps2_33 = torch.square(1/2*(2*w_xyz[:,2]))\n",
    "\n",
    "eps_e = torch.sqrt((2/3)*(eps2_11 + eps2_12 + eps2_13 + eps2_21 + eps2_22 + eps2_23 + eps2_31 + eps2_32 + eps2_33)).reshape(-1,1)\n",
    "\n",
    "\n",
    "# Z = eps_e*torch.exp(E_a/(R*T))\n",
    "# log_Z = torch.log(eps_e) + E_a/(R*T)\n",
    "log_Z = torch.log(eps_e) + E_a/(R*T) #Simplification\n",
    "\n",
    "\n",
    "W = (log_Z - log_A)/n\n",
    "\n",
    "\n",
    "\n",
    "# sigma_e =  (1/alpha_sig)*torch.asinh(W) \n",
    "sigma_e = (1/alpha_sig)*(np.log(2)/n + W) #Approximation\n",
    "\n",
    "#____________________________#\n",
    "mu_vis = sigma_e/(3*eps_e)\n",
    "\n",
    "\n",
    "eps_e = eps_e.cpu().detach().numpy()\n",
    "sigma_e = sigma_e.cpu().detach().numpy()\n",
    "mu_vis = mu_vis.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfcef78-9322-40dc-9938-90498e7cc584",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb960cb-2ad1-4850-8cde-8fee710dc085",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(eps_e.reshape(100,100),cmap = 'jet',extent = [-20,20,-20,20])\n",
    "fig.colorbar(im)\n",
    "ax.set_title('Effective Stress (Pa)')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "# plt.savefig('Viscosity_Feb7.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba456a6-0f56-4100-a4b2-57d4afa0978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(x_min,x_max,100).reshape(-1,1)\n",
    "y =0\n",
    "z = np.linspace(z_min,z_max,20).reshape(-1,1)\n",
    "# z = z_max\n",
    "\n",
    "X,Y,Z = np.meshgrid(x,y,z)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "Z = Z.flatten('F').reshape(-1,1)\n",
    "\n",
    "xyz = np.hstack((X,Y,Z))\n",
    "xyz_test_tensor = torch.from_numpy(xyz).float().to(device)\n",
    "\n",
    "uvwp = PINN.forward1(xyz_test_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e3580-5a58-45f2-aaf5-41f933feba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_vel = np.sqrt(np.square(uvwp[:,0])+np.square(uvwp[:,1])+np.square(uvwp[:,2]))\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(np.flip((r_vel/1000).reshape(20,100)),cmap = 'jet',extent = [-20,20,-3,0])\n",
    "fig.colorbar(im,orientation = 'horizontal',shrink = 0.5)\n",
    "ax.set_title('Resultant Velocity (CS) (m/s)')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$z$')\n",
    "# plt.savefig('Res_u_Front_Feb7.svg',format = 'svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f2ceb-1d08-48c0-b0d9-6caf37f75946",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(x_min,x_max,100).reshape(-1,1)\n",
    "y = np.linspace(y_min,y_max,100).reshape(-1,1)\n",
    "#z = np.linspace(z_min,z_max,20).reshape(-1,1)\n",
    "z = -0.125\n",
    "\n",
    "X,Y,Z = np.meshgrid(x,y,z)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "Z = Z.flatten('F').reshape(-1,1)\n",
    "\n",
    "xyz = np.hstack((X,Y,Z))\n",
    "xyz_test_tensor = torch.from_numpy(xyz).float().to(device)\n",
    "\n",
    "T = PINN.forward2(xyz_test_tensor).cpu().detach().numpy()\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(T.reshape(100,100),cmap = 'jet',extent = [-20,20,-20,20],vmax = 1000,vmin =300)\n",
    "fig.colorbar(im)\n",
    "ax.set_title('Temperature (top) (K)')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "# plt.savefig('Temp_top_Feb7.svg',format = 'svg',bbox_inches = 'tight')\n",
    "# plt.scatter(X,Y,c=T,cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1043c3d-416c-42f2-afa0-a54441d9df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6553c77-ea35-42f2-84cb-bacc0491bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(x_min,x_max,100).reshape(-1,1)\n",
    "y =0\n",
    "z = np.linspace(z_min,z_max,20).reshape(-1,1)\n",
    "# z = z_max\n",
    "\n",
    "X,Y,Z = np.meshgrid(x,y,z)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "Z = Z.flatten('F').reshape(-1,1)\n",
    "\n",
    "xyz = np.hstack((X,Y,Z))\n",
    "xyz_test_tensor = torch.from_numpy(xyz).float().to(device)\n",
    "\n",
    "uvwp = PINN.forward1(xyz_test_tensor).cpu().detach().numpy()\n",
    "\n",
    "T = PINN.forward2(xyz_test_tensor).cpu().detach().numpy()\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(np.flip(T.reshape(20,100)),cmap = 'jet',extent = [-20,20,-3,0])\n",
    "fig.colorbar(im,orientation = 'horizontal',shrink = 0.5)\n",
    "ax.set_title('Temperature (CS) (K)')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$z$')\n",
    "# plt.savefig('Temp_CS_Feb7.svg',format = 'svg',bbox_inches = 'tight')\n",
    "# plt.scatter(X,Y,c=T,cmap = 'jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5fd82-28d2-488f-9369-6673bebdfe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e728242-b7a1-4dc7-9165-2f0d32de5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_coll,xyz_1, xyz_2, xyz_3, xyz_4,xyz_top,xyz_bot = trainingdata(N_B,N_f,123)\n",
    "    \n",
    "r = np.sqrt(np.square(xyz_top[:,0]) + np.square(xyz_top[:,1]))\n",
    "        \n",
    "r_fr = (r<R0).reshape(-1,1)\n",
    "r_ph = np.logical_and(r>=R0,r<=Rs).reshape(-1,1)\n",
    "r_out = np.logical_not(r<=Rs).reshape(-1,1)\n",
    "\n",
    "cos_theta = xyz_top[:,1]/r #\n",
    "sin_theta = xyz_top[:,0]/r #\n",
    "\n",
    "r = r.reshape(-1,1)\n",
    "cos_theta = cos_theta.reshape(-1,1)\n",
    "sin_theta = sin_theta.reshape(-1,1)\n",
    "\n",
    "# out_top = self.forward1(g)\n",
    "\n",
    "#BC1\n",
    "u_true_ph = (1-delta)*(2*pi/60)*Omega*r*cos_theta\n",
    "v_true_ph = (1-delta)*(2*pi/60)*Omega*r*sin_theta - V\n",
    "w_true_ph = 0.0\n",
    "\n",
    "#BC2\n",
    "u_true_fr = (2*pi/60)*Omega*r*cos_theta\n",
    "v_true_fr = (2*pi/60)*Omega*r*sin_theta - V\n",
    "w_true_fr = -F\n",
    "\n",
    "#OTHER\n",
    "u_true_out = 0.0\n",
    "v_true_out = -V\n",
    "w_true_out = 0.0\n",
    "\n",
    "u_true = u_true_fr*r_fr + u_true_ph*r_ph + u_true_out*r_out\n",
    "v_true = v_true_fr*r_fr + v_true_ph*r_ph + v_true_out*r_out\n",
    "w_true = w_true_fr*r_fr + w_true_ph*r_ph + w_true_out*r_out\n",
    "\n",
    "# u = out_top[:,0:1]\n",
    "# v = out_top[:,1:2]\n",
    "# w = out_top[:,2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab744504-7410-41df-b62e-93d6fde7dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_vel = np.sqrt(np.square(u_true)+np.square(v_true))\n",
    "# plt.imshow(r_vel.reshape(100,100),cmap = 'jet')\n",
    "plt.scatter(xyz_top[:,0],xyz_top[:,1],c=r_vel,cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1181640-7589-4478-bb0c-efba789075ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(r_vel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
