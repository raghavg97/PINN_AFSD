{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat,loadmat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "#     y = np.exp(-4.0*x) + np.exp(3.0*x)\n",
    "#     return y\n",
    "\n",
    "import websocket\n",
    "import threading\n",
    "# import numpy as np\n",
    "import base64\n",
    "import uuid\n",
    "import json\n",
    "# import time\n",
    "\n",
    "run_uuid = \"1e8254d2-dda0-402c-87d2-c4bcad726a97\" #Random fixed https://www.uuidgenerator.net/version4\n",
    "client_uuid = uuid_v4 = uuid.uuid4()\n",
    "\n",
    "def get_random_loss():\n",
    "    return np.float32(np.random.rand(6,1))\n",
    "\n",
    "def initialize_message(client_uuid, run_uuid):\n",
    "    return '{\"messageType\":\"initialize\",\"clientUUID\":\"' + str(client_uuid) + '\",\"runUUID\":\"' + str(run_uuid) + '\"}'\n",
    "\n",
    "\n",
    "def update_message(client_uuid, run_uuid, data):\n",
    "    base64_data = base64.b64encode(data.tobytes())\n",
    "    return '{\"messageType\":\"update\",\"clientUUID\":\"' + str(client_uuid) + '\",\"runUUID\":\"' + str(run_uuid) + '\", \"data\":\"' + str(base64_data, \"ascii\") + '\"}'\n",
    "\n",
    "class WebSocketClient:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.response = None\n",
    "        self.ws = websocket.WebSocketApp(\n",
    "            url,\n",
    "            on_message=self.on_message,\n",
    "            on_open=self.on_open,\n",
    "            on_error=self.on_error,\n",
    "            on_close=self.on_close\n",
    "        )\n",
    "        self.ws_thread = threading.Thread(target=self.ws.run_forever)\n",
    "        self.connected = threading.Event()\n",
    "\n",
    "    def on_message(self, ws, message):\n",
    "        #print(\"|\", message, \"|\")\n",
    "        json_data = json.loads(message)\n",
    "        self.response = np.frombuffer(base64.b64decode(json_data[\"data\"]), dtype=np.float32)\n",
    "        \n",
    "    def on_open(self, ws):\n",
    "        self.connected.set()\n",
    "\n",
    "    def on_error(self, ws, error):\n",
    "        print(f\"WebSocket error: {error}\")\n",
    "\n",
    "    def on_close(self, ws, close_status_code, close_msg):\n",
    "        self.connected.clear()\n",
    "        print(\"WebSocket closed\")\n",
    "\n",
    "    def send_message(self, message):\n",
    "        self.response = None\n",
    "        self.ws.send(message)\n",
    "\n",
    "    def start(self):\n",
    "        self.ws_thread.start()\n",
    "        self.connected.wait()  # Wait until the connection is open\n",
    "\n",
    "    def stop(self):\n",
    "        self.ws.close()\n",
    "        self.ws_thread.join()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"high\"\n",
    "label = \"1D_SODE_Stan\" + level\n",
    "\n",
    "#MATLAB Van Der Pol Example https://www.mathworks.com/help/matlab/ref/ode89.html\n",
    "mu = 1\n",
    "fo_val = 0.0\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(0,10,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y1 = np.array([2]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y1_bc1_train = torch.from_numpy(bc1_y1).float().to(device)\n",
    "    \n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y2 = np.array([fo_val]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y2_bc1_train = torch.from_numpy(bc1_y2).float().to(device)    \n",
    "\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "# y_true = true_1D_1(x_test)\n",
    "# y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears1 = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears1[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears1[i].bias.data) \n",
    "        \n",
    "        self.beta1 = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta1.requiresGrad = True\n",
    "        \n",
    "        self.linears2 = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears2[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears2[i].bias.data) \n",
    "        \n",
    "        self.beta2 = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta2.requiresGrad = True\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward1(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears1[i](a)\n",
    "            a = self.activation(z) + self.beta1[:,i]*z*self.activation(z)\n",
    "            \n",
    "        a = self.linears1[-1](a) \n",
    "         \n",
    "        return a\n",
    "    \n",
    "    def forward2(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears2[i](a)\n",
    "            a = self.activation(z) + self.beta2[:,i]*z*self.activation(z)\n",
    "            \n",
    "        a = self.linears2[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward1(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x,y):\n",
    "                \n",
    "        loss_bc2 = self.loss_function(self.forward2(x), y)\n",
    "                \n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE1(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y1 = self.forward1(g)\n",
    "        y2 = self.forward2(g)\n",
    "\n",
    "        y1_x = autograd.grad(y1,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "       \n",
    "        dy1_dx = y1_x[:,[0]]\n",
    "        \n",
    "        f = dy1_dx - y2 \n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss_PDE2(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y1 = self.forward1(g)\n",
    "        y2 = self.forward2(g)\n",
    "\n",
    "        y2_x = autograd.grad(y2,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "       \n",
    "        dy2_dx = y2_x[:,[0]]\n",
    "        \n",
    "        f = dy2_dx - mu*(1-torch.square(y1))*y2 + y1\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss_y1(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE1(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def loss_y2(self,x_bc2,y_bc2,x_coll,f_hat):\n",
    "\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,y_bc2)\n",
    "        loss_f = self.loss_PDE2(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward1(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        # test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        # test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        test_mse = 0\n",
    "        test_re = 0\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    \n",
    "    def closure1():\n",
    "        optimizer.zero_grad()\n",
    "        # loss = PINN.loss_y1(x_bc1_train,y1_bc1_train,x_coll,f_hat) \n",
    "        # print(loss)\n",
    "        loss = PINN.loss_y2(x_bc1_train,y2_bc1_train,x_coll,f_hat)\n",
    "        \n",
    "        cpu_loss = loss.clone().cpu().detach().numpy()\n",
    "\n",
    "        ws_client.send_message(update_message(client_uuid, run_uuid, cpu_loss))\n",
    "        while ws_client.response is None:\n",
    "            pass\n",
    "        \n",
    "        loss.copy_(torch.from_numpy(ws_client.response.copy().reshape(loss.shape)))\n",
    "        # print(\"recieved\", aggregated_loss)\n",
    "        ws_client.response = None\n",
    "        loss.backward()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "#     def closure2():\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = PINN.loss_y2(x_bc1_train,y2_bc1_train,x_coll,f_hat)\n",
    "#         loss.backward()\n",
    "        \n",
    "#         return loss\n",
    "\n",
    "    # optimizer.step(closure2)\n",
    "    \n",
    "    optimizer.step(closure1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np1 = PINN.loss_y1(x_bc1_train,y1_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    loss_np2 = PINN.loss_y2(x_bc1_train,y2_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    \n",
    "    # data_update(loss_np1)\n",
    "    for i in range(max_iter):\n",
    "        # x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        # f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np1 = PINN.loss_y1(x_bc1_train,y1_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        loss_np2 = PINN.loss_y2(x_bc1_train,y2_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "            \n",
    "        # data_update(loss_np1)\n",
    "        # print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "        print(i,\"Loss1\",loss_np1,\"Loss2\",loss_np2)\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears1): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1-8): 8 x Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (linears2): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1-8): 8 x Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Loss1 3.5670803 Loss2 0.25592807\n",
      "WebSocket error: Connection to remote host was lost.\n",
      "WebSocket closed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 62\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# IMPORTANT: this give you time to start the other script and have \u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# it reach the same starting point. If they don't start together,\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# one training will complete before the other and the other will never\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# finish.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(PINN\u001b[38;5;241m.\u001b[39mstate_dict(),label\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(reps)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     66\u001b[0m train_loss_full\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(max_iter, rep)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# data_update(loss_np1)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# f_hat = torch.zeros(x_coll.shape[0],1).to(device)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_coll\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     loss_np1 \u001b[38;5;241m=\u001b[39m PINN\u001b[38;5;241m.\u001b[39mloss_y1(x_bc1_train,y1_bc1_train,x_coll,f_hat)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     20\u001b[0m     loss_np2 \u001b[38;5;241m=\u001b[39m PINN\u001b[38;5;241m.\u001b[39mloss_y2(x_bc1_train,y2_bc1_train,x_coll,f_hat)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(x_coll, f_hat)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     def closure2():\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#         optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#         loss = PINN.loss_y2(x_bc1_train,y2_bc1_train,x_coll,f_hat)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# optimizer.step(closure2)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/optim/lbfgs.py:312\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    309\u001b[0m state\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# evaluate initial f(x) and df/dx\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m orig_loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(orig_loss)\n\u001b[1;32m    314\u001b[0m current_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/raghav/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mtrain_step.<locals>.closure1\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m cpu_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     11\u001b[0m ws_client\u001b[38;5;241m.\u001b[39msend_message(update_message(client_uuid, run_uuid, cpu_loss))\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mws_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mcopy_(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(ws_client\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mreshape(loss\u001b[38;5;241m.\u001b[39mshape)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_reps = 1\n",
    "max_iter = 200\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    beta_val = []\n",
    "    \n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "    \n",
    "    \n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([1,50,50,50,50,1])\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "   \n",
    "\n",
    "     # Usage\n",
    "    ws_client = WebSocketClient(\"ws://128.173.95.177:8087\")\n",
    "\n",
    "    # Start WebSocket communication in a separate thread\n",
    "    ws_client.start()\n",
    "\n",
    "    # Send a message and wait for the response\n",
    "    ws_client.send_message(initialize_message(client_uuid, run_uuid))\n",
    "\n",
    "    # IMPORTANT: this give you time to start the other script and have \n",
    "    # it reach the same starting point. If they don't start together,\n",
    "    # one training will complete before the other and the other will never\n",
    "    # finish.\n",
    "    time.sleep(10)\n",
    "\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    beta_full.append(beta_val)    \n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"beta\": beta_full, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7981f8b8e0>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.plot(x,u_pred,'r')\n",
    "# plt.plot(y_true,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket error: Connection to remote host was lost.\n",
      "WebSocket closed\n"
     ]
    }
   ],
   "source": [
    "# data_mat = loadmat('Vanderpol_ODEsolver.mat')\n",
    "# y = data_mat['y'][:,0]\n",
    "# t = data_mat['t']\n",
    "\n",
    "# fig,ax = plt.subplots()\n",
    "# ax.plot(t,y,'b',linewidth = 2,label = 'Numerical Solver')\n",
    "# ax.plot(x,u_pred,'r-.',linewidth = 2,label = 'Coupled PINN')\n",
    "# ax.set_xlabel('Time(s)')\n",
    "# ax.set_ylabel('Value')\n",
    "# ax.set_title('van der Pol Oscillator')\n",
    "# ax.legend(loc = 3)\n",
    "# plt.savefig('Coupled_PINN_VanderPol.svg',format = 'svg')\n",
    "# plt.savefig('Coupled_PINN_VanderPol.png',format = 'png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
