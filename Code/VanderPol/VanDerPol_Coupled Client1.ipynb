{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device1  cuda:1\n",
      "device2  cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat,loadmat\n",
    "\n",
    "\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device1 = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device2 = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Device1 \",device1)\n",
    "print(\"device2 \",device2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "#     y = np.exp(-4.0*x) + np.exp(3.0*x)\n",
    "#     return y\n",
    "import websocket\n",
    "import threading\n",
    "# import numpy as np\n",
    "import base64\n",
    "import uuid\n",
    "import json\n",
    "# import time\n",
    "\n",
    "run_uuid = \"0e8254d2-dda0-402c-87d2-c4bcad726a97\" #Random fixed https://www.uuidgenerator.net/version4\n",
    "client_uuid = uuid_v4 = uuid.uuid4()\n",
    "\n",
    "def get_random_loss():\n",
    "    return np.float32(np.random.rand(6,1))\n",
    "\n",
    "def initialize_message(client_uuid, run_uuid):\n",
    "    return '{\"messageType\":\"initialize\",\"clientUUID\":\"' + str(client_uuid) + '\",\"runUUID\":\"' + str(run_uuid) + '\"}'\n",
    "\n",
    "\n",
    "def update_message(client_uuid, run_uuid, data):\n",
    "    base64_data = base64.b64encode(data.tobytes())\n",
    "    return '{\"messageType\":\"update\",\"clientUUID\":\"' + str(client_uuid) + '\",\"runUUID\":\"' + str(run_uuid) + '\", \"data\":\"' + str(base64_data, \"ascii\") + '\"}'\n",
    "\n",
    "class WebSocketClient:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.response = None\n",
    "        self.ws = websocket.WebSocketApp(\n",
    "            url,\n",
    "            on_message=self.on_message,\n",
    "            on_open=self.on_open,\n",
    "            on_error=self.on_error,\n",
    "            on_close=self.on_close\n",
    "        )\n",
    "        self.ws_thread = threading.Thread(target=self.ws.run_forever)\n",
    "        self.connected = threading.Event()\n",
    "\n",
    "    def on_message(self, ws, message):\n",
    "        print(\"|\", message, \"|\")\n",
    "        json_data = json.loads(message)\n",
    "        self.response = np.frombuffer(base64.b64decode(json_data[\"data\"]), dtype=np.float32)\n",
    "        \n",
    "    def on_open(self, ws):\n",
    "        self.connected.set()\n",
    "\n",
    "    def on_error(self, ws, error):\n",
    "        print(f\"WebSocket error: {error}\")\n",
    "\n",
    "    def on_close(self, ws, close_status_code, close_msg):\n",
    "        self.connected.clear()\n",
    "        print(\"WebSocket closed\")\n",
    "\n",
    "    def send_message(self, message):\n",
    "        self.response = None\n",
    "        self.ws.send(message)\n",
    "\n",
    "    def start(self):\n",
    "        self.ws_thread.start()\n",
    "        self.connected.wait()  # Wait until the connection is open\n",
    "\n",
    "    def stop(self):\n",
    "        self.ws.close()\n",
    "        self.ws_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"high\"\n",
    "label = \"1D_SODE_Stan\" + level\n",
    "\n",
    "#MATLAB Van Der Pol Example https://www.mathworks.com/help/matlab/ref/ode89.html\n",
    "mu = 1\n",
    "fo_val = 0.0\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(0,10,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y1 = np.array([2]).reshape(-1,1)\n",
    "x1_bc1_train = torch.from_numpy(bc1_x).float()#.to(device1)\n",
    "y1_bc1_train = torch.from_numpy(bc1_y1).float()#.to(device1)\n",
    "    \n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y2 = np.array([fo_val]).reshape(-1,1)\n",
    "x2_bc1_train = torch.from_numpy(bc1_x).float()#.to(device2)\n",
    "y2_bc1_train = torch.from_numpy(bc1_y2).float()#.to(device2)    \n",
    "\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float()#.to(device)\n",
    "# y_true = true_1D_1(x_test)\n",
    "# y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model_PINN,optimizer,x1_bc1,y1_bc1,x2_bc1,y2_bc1,x_coll1,x_coll2,f_hat1,f_hat2):\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss1 = model_PINN.loss_y1(x1_bc1,y1_bc1,x_coll1,f_hat1)\n",
    "    \n",
    "    ws_client.send_message(update_message(client_uuid, run_uuid, loss1))\n",
    "    while ws_client.response is None:\n",
    "        pass\n",
    "    \n",
    "    aggregated_loss = ws_client.response.copy().reshape(6,1)\n",
    "    # print(\"recieved\", aggregated_loss)\n",
    "    ws_client.response = None\n",
    "\n",
    "\n",
    "    # loss2 = model_PINN.loss_y2(x2_bc1,y2_bc1,x_coll2,f_hat2)\n",
    "    # loss1.backward()\n",
    "    aggregated_loss.backward()\n",
    "    # loss2.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # optimizer1.step(closure1)\n",
    "    # optimizer2.step(closure2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_update(loss_np):\n",
    "#     train_loss.append(loss_np)\n",
    "#     beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "#     test_mse, test_re = PINN.test_loss()\n",
    "#     test_mse_loss.append(test_mse)\n",
    "#     test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_PINN,optimizer,max_iter,rep,N_f):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    x_coll1 = torch.from_numpy(colloc_pts(N_f,0)).float()#.to(device1)\n",
    "    x_coll2 = torch.from_numpy(colloc_pts(N_f,1)).float()#.to(device2)\n",
    "    \n",
    "    f_hat1 = torch.zeros(x_coll1.shape[0],1).to(device1)\n",
    "    f_hat2= torch.zeros(x_coll2.shape[0],1).to(device2)\n",
    "\n",
    "    loss_np1 = model_PINN.loss_y1(x1_bc1_train,y1_bc1_train,x_coll1,f_hat1).cpu().detach().numpy()\n",
    "    loss_np2 = model_PINN.loss_y2(x2_bc1_train,y2_bc1_train,x_coll2,f_hat2).cpu().detach().numpy()\n",
    "    \n",
    "    # data_update(loss_np1)\n",
    "    for i in range(max_iter):\n",
    "        # x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        # f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(model_PINN,optimizer,x1_bc1_train,y1_bc1_train,x2_bc1_train,y2_bc1_train,x_coll1,x_coll2,f_hat1,f_hat2)\n",
    "        \n",
    "        if(i%100==0):\n",
    "            loss_np1 = model_PINN.loss_y1(x1_bc1_train,y1_bc1_train,x_coll1,f_hat1).cpu().detach().numpy()\n",
    "            loss_np2 = model_PINN.loss_y2(x2_bc1_train,y2_bc1_train,x_coll2,f_hat2).cpu().detach().numpy()\n",
    "                \n",
    "            # data_update(loss_np1)\n",
    "            # print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "            print(i,\"Loss1\",loss_np1,\"Loss2\",loss_np2)\n",
    "        \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1-3): 3 x Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "WebSocket error: [Errno 111] Connection refused\n",
      "WebSocket closed\n"
     ]
    }
   ],
   "source": [
    "from models import coupled_PINN\n",
    "max_reps = 1\n",
    "max_iter = 2000 #5000 for Adam\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    beta_val = []\n",
    "    \n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "    \n",
    "    \n",
    "    layers1 = np.array([1,50,50,50,1])\n",
    "    layers2 = np.array([1,50,50,50,50,1])\n",
    "    # layers = np.array([1,50,50,50,50,1])\n",
    "    model_PINN = coupled_PINN(layers1,layers2,device1,device2)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "\n",
    "    optimizer = torch.optim.Adam(model_PINN.parameters(),lr=0.01, betas=(0.9, 0.999))\n",
    "\n",
    "    # Usage\n",
    "    ws_client = WebSocketClient(\"ws://128.173.95.177:8087\")\n",
    "\n",
    "    # Start WebSocket communication in a separate thread\n",
    "    ws_client.start()\n",
    "\n",
    "    # Send a message and wait for the response\n",
    "    ws_client.send_message(initialize_message(client_uuid, run_uuid))\n",
    "\n",
    "\n",
    "    train_model(model_PINN,optimizer,max_iter,reps,N_f)\n",
    "\n",
    "    \n",
    "    # torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    # train_loss_full.append(train_loss)\n",
    "    # test_mse_full.append(test_mse_loss)\n",
    "    # test_re_full.append(test_re_loss)\n",
    "    # beta_full.append(beta_val)    \n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"beta\": beta_full, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_PINN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x,u_pred,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# plt.plot(y_true,'b')\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/jupyterNB/raghav/Projects_git_summer2024/PINN_AFSD/Code/VanderPol/models.py:161\u001b[0m, in \u001b[0;36mcoupled_PINN.test\u001b[0;34m(self, x_test_tensor)\u001b[0m\n\u001b[1;32m    158\u001b[0m PINN_test\u001b[38;5;241m.\u001b[39mub \u001b[38;5;241m=\u001b[39m PINN_test\u001b[38;5;241m.\u001b[39mub\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    159\u001b[0m PINN_test\u001b[38;5;241m.\u001b[39mlb \u001b[38;5;241m=\u001b[39m PINN_test\u001b[38;5;241m.\u001b[39mlb\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mPINN_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/Documents/jupyterNB/raghav/Projects_git_summer2024/PINN_AFSD/Code/VanderPol/models.py:51\u001b[0m, in \u001b[0;36mSequentialmodel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#preprocessing input \u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlb\u001b[49m)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mub \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlb) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;66;03m#feature scaling\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#convert to float\u001b[39;00m\n\u001b[1;32m     54\u001b[0m a \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu!"
     ]
    }
   ],
   "source": [
    "u_pred = model_PINN.test(x_test_tensor)\n",
    "plt.plot(x,u_pred,'r')\n",
    "# plt.plot(y_true,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_mat = loadmat('Vanderpol_ODEsolver.mat')\n",
    "# y = data_mat['y'][:,0]\n",
    "# t = data_mat['t']\n",
    "\n",
    "# fig,ax = plt.subplots()\n",
    "# ax.plot(t,y,'b',linewidth = 2,label = 'Numerical Solver')\n",
    "# ax.plot(x,u_pred,'r-.',linewidth = 2,label = 'Coupled PINN')\n",
    "# ax.set_xlabel('Time(s)')\n",
    "# ax.set_ylabel('Value')\n",
    "# ax.set_title('van der Pol Oscillator')\n",
    "# ax.legend(loc = 3)\n",
    "# plt.savefig('Coupled_PINN_VanderPol.svg',format = 'svg')\n",
    "# plt.savefig('Coupled_PINN_VanderPol.png',format = 'png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
